{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030ccd3",
   "metadata": {},
   "source": [
    "# Melanoma Detection with the ResNet-50 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce87f3",
   "metadata": {},
   "source": [
    "This code was used in the Hoffman2 Linux Compute Cluster, making use of UCLA's high performance cloud computing resources like the Tesla P4 - GPU (6.1 Compute Capability, 2560 CUDA Cores, 8GB) with additional 32GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460317",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad9aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1e190",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a1310",
   "metadata": {},
   "source": [
    "General histograms and bar charts for frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262eb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positives: 0.017589052123163616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mel_df = pd.read_csv(os.path.join('train_data', 'train.csv'))\n",
    "gt = mel_df['target']\n",
    "isic_id = mel_df['image_name']\n",
    "\n",
    "# proportion of postives\n",
    "print(\"Proportion of positives:\", np.mean(gt))\n",
    "\n",
    "plt.hist(mel_df['age_approx'])\n",
    "plt.title('Histogram of Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = mel_df['benign_malignant'],\n",
    "            y = mel_df['age_approx'])\n",
    "plt.title('Ages Grouped By Benign / Malignant Status')\n",
    "plt.xlabel('Benign / Malignant Status')\n",
    "plt.ylabel('Approximate Age')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(mel_df.sex.value_counts().index,  mel_df.sex.value_counts().values)\n",
    "plt.title('Sex / Gender in Dataset')\n",
    "plt.show()\n",
    "\n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, mel_df.anatom_site_general_challenge.value_counts().values)\n",
    "plt.title('Lesion Locations in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb11e5",
   "metadata": {},
   "source": [
    "Tests to find potential correlation between target variables and other categorical variables such as sex/gender or lesion location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101b246a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\n",
      "benign_malignant  benign  malignant\n",
      "sex                                \n",
      "female             11824        170\n",
      "male               12535        267\n",
      "Chi-Squared test of independence (P-value): 7.87631386486258e-05 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\n",
      "anatom_site_general_challenge  head/neck  lower extremity  oral/genital  \\\n",
      "sex                                                                       \n",
      "female                               629             3363            33   \n",
      "male                                 767             2966            57   \n",
      "\n",
      "anatom_site_general_challenge  palms/soles  torso  upper extremity  \n",
      "sex                                                                 \n",
      "female                                 111   5683             2001  \n",
      "male                                   169   6926             1698  \n",
      "Chi-Squared test of independence (P-value): 3.917186815096256e-37 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['benign_malignant'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df1 = mel_df.groupby(['sex']).mean()\n",
    "plt.bar(mel_df.sex.value_counts().index,  g_df1['target'].values)\n",
    "plt.title(\"Proportion of positives by Sex / Gender\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\\n******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['anatom_site_general_challenge'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df2 = mel_df.groupby(['anatom_site_general_challenge']).mean() \n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, g_df2['target'].values)\n",
    "plt.title(\"Proportion of positives by Lesion Location\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713af71",
   "metadata": {},
   "source": [
    "## ResNet-50 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efcaad",
   "metadata": {},
   "source": [
    "Set device as CPU, or GPU if available. Code will have to change if using multiple GPUs (cuda:0, cuda:1, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eba207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    n_workers = os.cpu_count()\n",
    "else:\n",
    "    n_workers = torch.cuda.device_count()\n",
    "\n",
    "# If on a CUDA machine, this should print a CUDA device:\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of devices:\", n_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cea86",
   "metadata": {},
   "source": [
    "We create a custom dataset loader class to use the ID and target information from the CSV to properly load our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset to load in with the benign \n",
    "# and malignant images in the same directory\n",
    "class ISICDatasetImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, patientfile, num_samples=100, start_ind=0, up_sample=False, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        mel_df = pd.read_csv(patientfile) \n",
    "        \n",
    "        if up_sample:\n",
    "            \n",
    "            # Separate majority and minority classes\n",
    "            df_benign = mel_df[mel_df['target']==0]\n",
    "            df_malignant = mel_df[mel_df['target']==1]\n",
    "            \n",
    "\n",
    "            # sample minority class\n",
    "            df_benign_sampled = resample(df_benign, \n",
    "                                         replace=True,     # sample with replacement\n",
    "                                         n_samples=num_samples//2)\n",
    "            \n",
    "\n",
    "            # Upsample minority class\n",
    "            df_malignant_upsampled = resample(df_malignant, \n",
    "                                              replace=True,     # sample with replacement\n",
    "                                              n_samples=num_samples//2)\n",
    "            \n",
    "            # Combine majority class with upsampled minority class\n",
    "            mel_df = pd.concat([df_benign_sampled, df_malignant_upsampled])\n",
    "            \n",
    "            # randomly mix them up (not necessary due to shuffling in dataloader)\n",
    "            mel_df = shuffle(mel_df)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.start_ind = start_ind\n",
    "            self.end_ind = start_ind+num_samples\n",
    "\n",
    "            if self.end_ind > len(mel_df):\n",
    "                self.end_ind = len(mel_df)\n",
    "        \n",
    "            mel_df = mel_df[self.start_ind:self.end_ind]\n",
    "            \n",
    "        self.gt = mel_df['target'].reset_index(drop=True)\n",
    "        self.isic_id = mel_df['image_name'].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{self.isic_id[idx]}.jpg\")\n",
    "        img = read_image(img_path).float()\n",
    "        class_id = torch.tensor([self.gt[idx]])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        \n",
    "        return img, class_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c73fa",
   "metadata": {},
   "source": [
    "We create a custom collate function to pad lower resolution images with zeros to maintain a constant high resolution of 3x4000x6000 for the CNN to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364d0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that a CNN needs the inputs to be the same dimension so we \n",
    "# custom collate function to pad small res images with 0s if they are not 3x4000x6000\n",
    "def pad_collate2d(batch):\n",
    "    \n",
    "    # init lists\n",
    "    image_list, label_list = [], []\n",
    "   \n",
    "    for _image, _label in batch:\n",
    "        \n",
    "        image_list.append(torch.unsqueeze(_image, dim=0))\n",
    "        label_list.append(_label)\n",
    "        \n",
    "\n",
    "    image_out = torch.cat(image_list, dim=0) \n",
    "    label_out = torch.tensor(label_list, dtype=torch.int64)\n",
    "   \n",
    "    return image_out, label_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "# set our batch size\n",
    "batch_size = 4\n",
    "\n",
    "tr_transf = transforms.Compose(\n",
    "    [transforms.Resize(416),\n",
    "     transforms.RandomHorizontalFlip(p=0.3),\n",
    "     transforms.RandomVerticalFlip(p=0.3),\n",
    "     transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=(5, 7), sigma=(0.1, 2))]), p=0.2),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "     transforms.RandomErasing(scale=(0.02, 0.05), p=0.2)\n",
    "    ])\n",
    "\n",
    "val_transf = transforms.Compose(\n",
    "    [transforms.Resize(416),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "train_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data768x768\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data768x768\", \"train.csv\"), \n",
    "                            num_samples=5*2*24408, up_sample=True, start_ind=0, transform=tr_transf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=pad_collate2d, \n",
    "                          num_workers=n_workers)\n",
    "\n",
    "\n",
    "val_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data768x768\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data768x768\", \"val.csv\"), \n",
    "                            num_samples=2*100, up_sample=True, start_ind=0, transform=val_transf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=pad_collate2d, \n",
    "                        num_workers=n_workers)\n",
    "\n",
    "\n",
    "\n",
    "# test DataLoader with custom settings\n",
    "if testing:\n",
    "    for imgs, labels in train_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ef7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show the image\n",
    "def imshow(img):\n",
    "    mean=[0.485, 0.456, 0.406]\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    \n",
    "    img = img * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg.astype('int'), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "label_id = [\"Benign\", \"Malignant\"]\n",
    "\n",
    "if testing:\n",
    "    # get some random training images\n",
    "    trainiter = iter(train_loader)\n",
    "    images, labels = next(trainiter)\n",
    "    print(\"Size:\", images.shape)\n",
    "\n",
    "\n",
    "    # show images\n",
    "    imshow(images[0,])\n",
    "\n",
    "    # print labels\n",
    "    print(\"Label:\", label_id[labels[0,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e4f1",
   "metadata": {},
   "source": [
    "Sample and image from the data loader object to confirm it worked. Continue to run the cell for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d401950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/zhanghang1989/ResNeSt/zipball/master\" to /u/home/a/andrewma/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new ResNeSt FC Layer weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /u/home/a/andrewma/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    }
   ],
   "source": [
    "load_weights = True\n",
    "create_new_weights = False\n",
    "PATH = './melanoma_ResNeSt.pth'\n",
    "\n",
    "# get list of models\n",
    "torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n",
    "\n",
    "if load_weights:\n",
    "    print('Loading the pre-trained ResNeSt weights.')\n",
    "    \n",
    "    # network weights load\n",
    "    net = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True).to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # optimizer state load\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.fc.parameters(), weight_decay=0.01)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=12204, gamma=0.5)\n",
    "    lr_sched.load_state_dict(checkpoint['lr_sched'])\n",
    "    \n",
    "    # total mini_batch state load\n",
    "    mini_batch = checkpoint['mini_batch']\n",
    "    \n",
    "    print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "    \n",
    "elif create_new_weights:\n",
    "    print('Creating new ResNeSt FC Layer weights.')\n",
    "    \n",
    "    net = torch.hub.load('zhanghang1989/ResNeSt', 'resnest269', pretrained=True).to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "    \n",
    "    \n",
    "    mini_batch = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.fc.parameters(), weight_decay=0.001)\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=12204, gamma=0.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training CUDA Memory Allocation: 448489472\n",
      "CUDA Memory Allocated: 6869538304\n",
      "[Epoch 0, Batch 1] Loss: 0.6282063126564026\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.4244\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 2] Loss: 0.6699393391609192\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 3] Loss: 0.6885474920272827\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 4] Loss: 0.7213612049818039\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 5] Loss: 0.724096953868866\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 6] Loss: 0.7505567967891693\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 7] Loss: 0.7536597166742597\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 8] Loss: 0.7554258927702904\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 9] Loss: 0.7480280730459425\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 10] Loss: 0.746552312374115\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 11] Loss: 0.7576319846239957\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 12] Loss: 0.7389717350403467\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 13] Loss: 0.7450065933741056\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 14] Loss: 0.7486910777432578\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 15] Loss: 0.7384332299232483\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 16] Loss: 0.7275402694940567\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 17] Loss: 0.7178126538501066\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 18] Loss: 0.7080413103103638\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 19] Loss: 0.7040416566949141\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 20] Loss: 0.6886975020170212\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 21] Loss: 0.6847644874027797\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 22] Loss: 0.6876340481367978\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 23] Loss: 0.6845145355100217\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 24] Loss: 0.681738831102848\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 25] Loss: 0.6773280882835389\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 26] Loss: 0.6674049084003155\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 27] Loss: 0.6745615513236435\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 28] Loss: 0.67389358154365\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 29] Loss: 0.6728451108110363\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 30] Loss: 0.6710789342721303\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 31] Loss: 0.6718943965050482\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 32] Loss: 0.6661376999691129\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 33] Loss: 0.6609084217837362\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 34] Loss: 0.6597712486982346\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 35] Loss: 0.666330270256315\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 36] Loss: 0.6719618183043268\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 37] Loss: 0.6737231555822734\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 38] Loss: 0.6749486978116789\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 39] Loss: 0.679011882115633\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 40] Loss: 0.6806227169930935\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 41] Loss: 0.684742865765967\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 42] Loss: 0.6778887857993444\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 43] Loss: 0.6719427101833876\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 44] Loss: 0.6718917400999502\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 45] Loss: 0.6733468472957611\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 46] Loss: 0.6754684882319492\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 47] Loss: 0.6757309151456711\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 48] Loss: 0.677354833111167\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 49] Loss: 0.6729894402075787\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 50] Loss: 0.6677065849304199\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 51] Loss: 0.6681999949847951\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 52] Loss: 0.6634193314955785\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 53] Loss: 0.6654877032873765\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 54] Loss: 0.6628487684108593\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 55] Loss: 0.6624701651659879\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 56] Loss: 0.6599693255765098\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 57] Loss: 0.6612957841471622\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 58] Loss: 0.6583766521051012\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 59] Loss: 0.6573703576952724\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 60] Loss: 0.6609412158528963\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 61] Loss: 0.657785428840606\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 62] Loss: 0.6521577532252958\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 63] Loss: 0.6576536501210833\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 64] Loss: 0.6574991648085415\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 65] Loss: 0.6581806719303132\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 66] Loss: 0.6616377302191474\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 67] Loss: 0.664080996566744\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 68] Loss: 0.6636565323261654\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 69] Loss: 0.6635673300943513\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 70] Loss: 0.6709030010870525\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 71] Loss: 0.6686448862015362\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 72] Loss: 0.6677700177662902\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 73] Loss: 0.6672576645465746\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 74] Loss: 0.6688912410188366\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 75] Loss: 0.6689912370840708\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 76] Loss: 0.6667709268237415\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 77] Loss: 0.6631974984299053\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 78] Loss: 0.6662399092545876\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 79] Loss: 0.668384653480747\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 80] Loss: 0.6680498611181974\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 81] Loss: 0.6717533031363546\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 82] Loss: 0.6695200433818306\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 83] Loss: 0.6684554380824766\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 84] Loss: 0.664900425644148\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 85] Loss: 0.668517773992875\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 86] Loss: 0.6690092176892036\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 87] Loss: 0.6674580252033541\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 88] Loss: 0.6674193827943369\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 89] Loss: 0.6621112096845434\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 90] Loss: 0.6615079399612215\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 91] Loss: 0.6634466657926749\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 92] Loss: 0.6631502240248348\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 93] Loss: 0.6590577722877584\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 94] Loss: 0.661576101754574\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 95] Loss: 0.6594830418887891\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 96] Loss: 0.6617513441791137\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 97] Loss: 0.6600949112901983\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 98] Loss: 0.6585717894593064\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 99] Loss: 0.6607092835686423\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 100] Loss: 0.660706068277359\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 101] Loss: 0.660247534218401\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 102] Loss: 0.6636065133646423\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 103] Loss: 0.6642806182787256\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 104] Loss: 0.6623823356169921\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 105] Loss: 0.6639427582422892\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 106] Loss: 0.6625765786980683\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 107] Loss: 0.6649883523165623\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 108] Loss: 0.66805341232706\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 109] Loss: 0.667696346383576\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 110] Loss: 0.6662838377735831\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 111] Loss: 0.667534483982636\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 112] Loss: 0.665083288614239\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 113] Loss: 0.6631706652388109\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 114] Loss: 0.6640642186005911\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 115] Loss: 0.6619588813056116\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 116] Loss: 0.6635658240009998\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 117] Loss: 0.662857321337757\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 118] Loss: 0.6649246273909585\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 119] Loss: 0.6640193960746797\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 120] Loss: 0.6606131886442502\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 121] Loss: 0.662047977782478\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 122] Loss: 0.6606859540353056\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 123] Loss: 0.6581143102025598\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 124] Loss: 0.6588955223560333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 125] Loss: 0.6580925068855286\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 126] Loss: 0.6588035476586175\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 127] Loss: 0.6565090990441991\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 128] Loss: 0.6568814162164927\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 129] Loss: 0.659698066785354\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 130] Loss: 0.6614258729494535\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 131] Loss: 0.6604211662561839\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 132] Loss: 0.6614485649448453\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 133] Loss: 0.6622436597831267\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 134] Loss: 0.6606569145597628\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 135] Loss: 0.6622857241718857\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 136] Loss: 0.6606808252194348\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 137] Loss: 0.6599960305394917\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 138] Loss: 0.6596219595791637\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 139] Loss: 0.6586839852573203\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 140] Loss: 0.6582926856619972\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 141] Loss: 0.6567685604095459\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 142] Loss: 0.6556386225660082\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 143] Loss: 0.6541350375522267\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 144] Loss: 0.6522162655989329\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 145] Loss: 0.651666404049972\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 146] Loss: 0.6499254564716391\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 147] Loss: 0.6531049467268444\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 148] Loss: 0.6543195738985732\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 149] Loss: 0.6560448176108751\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 150] Loss: 0.6568974582354228\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 151] Loss: 0.6554791668787697\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 152] Loss: 0.6570610562829595\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 153] Loss: 0.6571080900874793\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 154] Loss: 0.656913903433007\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 155] Loss: 0.6577205348399378\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 156] Loss: 0.6563695556460283\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 157] Loss: 0.6552767791565816\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 158] Loss: 0.6546119002601768\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 159] Loss: 0.6550799102153418\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 160] Loss: 0.655242421105504\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 161] Loss: 0.6550682890489234\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 162] Loss: 0.6535885083822557\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 163] Loss: 0.6542864701499237\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 164] Loss: 0.6531336605548859\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 165] Loss: 0.6519081101273045\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 166] Loss: 0.6503027120986616\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 167] Loss: 0.6491837128550707\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 168] Loss: 0.6482103623095012\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 169] Loss: 0.6463635011890231\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 170] Loss: 0.6457352541825351\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 171] Loss: 0.6445777557398144\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 172] Loss: 0.64447565775278\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 173] Loss: 0.6434407261754737\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 174] Loss: 0.6455936651120241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 175] Loss: 0.6477166707175118\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 176] Loss: 0.6468446383422072\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 177] Loss: 0.6456269655524001\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 178] Loss: 0.6443767681550444\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 179] Loss: 0.6449196598383301\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 180] Loss: 0.6469819962978363\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 181] Loss: 0.6466120468318791\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 182] Loss: 0.6465961906936143\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 183] Loss: 0.6445620800953745\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 184] Loss: 0.6448412088920241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 185] Loss: 0.6464813585216934\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 186] Loss: 0.6471790624882585\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 187] Loss: 0.646736342161097\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 188] Loss: 0.6474074409046071\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 189] Loss: 0.6469643574858469\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 190] Loss: 0.6470059600315596\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 191] Loss: 0.6455868652665803\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 192] Loss: 0.6471327973219255\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 193] Loss: 0.6478826025298222\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 194] Loss: 0.6465583277731827\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 195] Loss: 0.6456710951450544\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 196] Loss: 0.6461527136211492\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 197] Loss: 0.6457638869128252\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 198] Loss: 0.6470053384099343\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 199] Loss: 0.6462492721164645\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 200] Loss: 0.6464801448583603\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 201] Loss: 0.6460289889900246\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 202] Loss: 0.6471551013464975\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 203] Loss: 0.6477201322616615\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 204] Loss: 0.6478605474911484\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 205] Loss: 0.6472479456808509\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 206] Loss: 0.6462381513952051\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 207] Loss: 0.6445492727744982\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 208] Loss: 0.6430145573730652\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 209] Loss: 0.6431569405719995\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 210] Loss: 0.643451703446252\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 211] Loss: 0.6468039799075556\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 212] Loss: 0.6449181978010906\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 213] Loss: 0.6432542784812865\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 214] Loss: 0.6430167194421046\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 215] Loss: 0.6419536937807881\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 216] Loss: 0.6412157255604312\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 217] Loss: 0.6401267292724776\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 218] Loss: 0.6402595630342808\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 219] Loss: 0.6411817367082318\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 220] Loss: 0.6408314005217769\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 221] Loss: 0.6397869065741069\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 222] Loss: 0.6389891840181909\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 223] Loss: 0.6395072602236752\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 224] Loss: 0.6382140867811229\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 225] Loss: 0.6386177586846882\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 226] Loss: 0.6384196626269711\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 227] Loss: 0.6384420391615266\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 228] Loss: 0.6379253079363129\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 229] Loss: 0.6386309270645333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 230] Loss: 0.6383107607131419\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 231] Loss: 0.6383879571120976\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 232] Loss: 0.637958661685216\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 233] Loss: 0.6381622258046155\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 234] Loss: 0.6396524416457894\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 235] Loss: 0.6381616946864636\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 236] Loss: 0.6374954011101844\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 237] Loss: 0.6375741119248958\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 238] Loss: 0.636244847681843\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 239] Loss: 0.637047926439401\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 240] Loss: 0.6361664469664295\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 241] Loss: 0.6351755208865241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 242] Loss: 0.6357181263733501\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 243] Loss: 0.6344525527684286\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 244] Loss: 0.6338957806468987\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 245] Loss: 0.6336966260963557\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 246] Loss: 0.6321638315552618\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 247] Loss: 0.631848964553613\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 248] Loss: 0.6347320357998533\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 249] Loss: 0.6353798570283445\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 250] Loss: 0.6358423730731011\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 251] Loss: 0.6360454708337784\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 252] Loss: 0.6349319069986306\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 253] Loss: 0.6351272472633204\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 254] Loss: 0.6343745972345195\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 255] Loss: 0.6343515801079133\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 256] Loss: 0.6335528145427816\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 257] Loss: 0.6342483380309338\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 258] Loss: 0.6337168324709863\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 259] Loss: 0.6341417079151367\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 260] Loss: 0.6328102043614938\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 261] Loss: 0.6359066164470724\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 262] Loss: 0.6367578898336141\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 263] Loss: 0.6383539796895401\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 264] Loss: 0.6396128745806037\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 265] Loss: 0.6392254193436425\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 266] Loss: 0.6393330124647993\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 267] Loss: 0.6406767232699341\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 268] Loss: 0.6412351930430576\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 269] Loss: 0.6413834314917987\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 270] Loss: 0.6418763419544256\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 271] Loss: 0.6432104509365075\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 272] Loss: 0.6432821987854207\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 273] Loss: 0.6428172270129452\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 274] Loss: 0.6422953010149246\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 275] Loss: 0.6424165069515055\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 276] Loss: 0.641950696112885\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 277] Loss: 0.6419949848406582\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 278] Loss: 0.6423909829782067\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 279] Loss: 0.6416581230885666\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 280] Loss: 0.6424388702958822\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 281] Loss: 0.6414251084111339\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 282] Loss: 0.6410469922719272\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 283] Loss: 0.641418289011443\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 284] Loss: 0.6407093546864852\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 285] Loss: 0.6398689714962976\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 286] Loss: 0.6389356221665036\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 287] Loss: 0.6384321598121929\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 288] Loss: 0.6388972163096898\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 289] Loss: 0.6391262180561837\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 290] Loss: 0.6382304070838567\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 291] Loss: 0.6380136015591343\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 292] Loss: 0.6387805300318214\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 293] Loss: 0.6378222423710513\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 294] Loss: 0.6365485997731183\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 295] Loss: 0.6365444332361221\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 296] Loss: 0.6355900111532694\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 297] Loss: 0.6348373933572962\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 298] Loss: 0.6354809696942367\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 299] Loss: 0.6347506091646526\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 300] Loss: 0.6353617606063684\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 301] Loss: 0.6357489550529525\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 302] Loss: 0.6354638771801595\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 303] Loss: 0.6359655646109345\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 304] Loss: 0.6350519464498288\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 305] Loss: 0.6349353121440918\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 306] Loss: 0.6344087591845226\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 307] Loss: 0.6340518695232534\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 308] Loss: 0.634692440220675\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 309] Loss: 0.6337547841870669\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 310] Loss: 0.6346078674158743\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 311] Loss: 0.6350831638099297\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 312] Loss: 0.6352727017245996\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 313] Loss: 0.6348677642714863\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 314] Loss: 0.6351279655744315\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 315] Loss: 0.6358252621359295\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 316] Loss: 0.6349224284574201\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 317] Loss: 0.6347914665749397\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 318] Loss: 0.6346558758391524\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 319] Loss: 0.6352454665405997\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 320] Loss: 0.6358536517713219\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 321] Loss: 0.6361860592510099\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 322] Loss: 0.6357708584910594\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 323] Loss: 0.6352428397619319\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 324] Loss: 0.6350695886821659\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 325] Loss: 0.6342561707588342\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 326] Loss: 0.6338821394037615\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 327] Loss: 0.633940809226911\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 328] Loss: 0.634200756733374\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 329] Loss: 0.6335274984318434\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 330] Loss: 0.6324673912290371\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 331] Loss: 0.6329563605371199\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 332] Loss: 0.6324318106544305\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 333] Loss: 0.6314947179577373\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 334] Loss: 0.6310089071264524\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 335] Loss: 0.6302194833310683\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 336] Loss: 0.6305422436534649\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 337] Loss: 0.6310064199681805\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 338] Loss: 0.6310512742259093\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 339] Loss: 0.6316633166025521\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 340] Loss: 0.6319553909494596\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 341] Loss: 0.6319630519648102\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 342] Loss: 0.6323658178685702\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 343] Loss: 0.6325543902966441\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 344] Loss: 0.6331594461185295\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 345] Loss: 0.6330101163059041\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 346] Loss: 0.6321621245645375\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 347] Loss: 0.6319266045385548\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 348] Loss: 0.6314901361434624\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 349] Loss: 0.6309770467373567\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 350] Loss: 0.6301834364022527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 351] Loss: 0.630337259920574\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 352] Loss: 0.6301346186294474\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 353] Loss: 0.6299639699226061\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 354] Loss: 0.6305707829904421\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 355] Loss: 0.6308966296239638\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 356] Loss: 0.6306384197865309\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 357] Loss: 0.6303783680627993\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 358] Loss: 0.6304600091037138\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 359] Loss: 0.6311169125990616\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 360] Loss: 0.6316374375174443\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 361] Loss: 0.6307009463907939\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 362] Loss: 0.6312991020511527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 363] Loss: 0.63153189326285\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 364] Loss: 0.6305818052982891\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 365] Loss: 0.6310381777890741\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 366] Loss: 0.6319297861124649\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 367] Loss: 0.6322789074858138\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 368] Loss: 0.6323404894817782\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 369] Loss: 0.6320123718925285\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 370] Loss: 0.6316035355667811\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 371] Loss: 0.6315648511975923\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 372] Loss: 0.6312103098038063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 373] Loss: 0.6324053679570436\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 374] Loss: 0.63210774292761\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 375] Loss: 0.6326336961984634\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 376] Loss: 0.6321982733826054\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 377] Loss: 0.6325403615160393\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 378] Loss: 0.6321201529846621\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 379] Loss: 0.6319107393240236\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 380] Loss: 0.6317099468096307\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 381] Loss: 0.6312530827256325\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 382] Loss: 0.6305892339161553\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 383] Loss: 0.6317092556477215\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 384] Loss: 0.6315082187065855\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 385] Loss: 0.6308783262968063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 386] Loss: 0.6301984487033878\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 387] Loss: 0.629968369307444\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 388] Loss: 0.6301856238740621\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 389] Loss: 0.6310637902401407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 390] Loss: 0.630468850907607\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 391] Loss: 0.6299506328676058\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 392] Loss: 0.6306039808432058\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 393] Loss: 0.6301941228959397\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 394] Loss: 0.6300190114203443\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 395] Loss: 0.62955006583582\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 396] Loss: 0.6293515493397159\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 397] Loss: 0.629126681451233\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 398] Loss: 0.6288050549039289\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 399] Loss: 0.6282770206829659\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 400] Loss: 0.6282880422845483\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 401] Loss: 0.6279644006282611\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 402] Loss: 0.6274589554068462\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 403] Loss: 0.6270672207508726\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 404] Loss: 0.6276467493043678\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 405] Loss: 0.6273160797210388\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 406] Loss: 0.6268893143006147\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 407] Loss: 0.6271608022638855\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 408] Loss: 0.6275986658372715\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 409] Loss: 0.6272361713181498\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 410] Loss: 0.6268777732078622\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 411] Loss: 0.627347867092947\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 412] Loss: 0.6265545083408796\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 413] Loss: 0.6259655034210145\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 414] Loss: 0.625592751023562\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 415] Loss: 0.6250956362629512\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 416] Loss: 0.6248344277175\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 417] Loss: 0.624661201160017\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 418] Loss: 0.6249427482770961\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 419] Loss: 0.6244960078405025\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 420] Loss: 0.6244257946454344\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 421] Loss: 0.6239307848050872\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 422] Loss: 0.6249504138437493\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 423] Loss: 0.6242403453898486\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 424] Loss: 0.6248002549598239\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 425] Loss: 0.6255908291129505\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 426] Loss: 0.6255439372619552\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 427] Loss: 0.6255201126080207\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 428] Loss: 0.6250931579863357\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 429] Loss: 0.6243797882106199\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 430] Loss: 0.623640963954981\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 431] Loss: 0.6231831932081701\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 432] Loss: 0.6227026493805978\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 433] Loss: 0.6226976046179514\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 434] Loss: 0.6228371610358563\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 435] Loss: 0.6232858651328361\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 436] Loss: 0.6232633675798911\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 437] Loss: 0.6224614320753368\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 438] Loss: 0.6221381112524907\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 439] Loss: 0.6225417873786088\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 440] Loss: 0.6225430496375669\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 441] Loss: 0.6228070007362604\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 442] Loss: 0.6225748593114081\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 443] Loss: 0.6219550037828041\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 444] Loss: 0.6227651644196059\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 445] Loss: 0.6225001233682204\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 446] Loss: 0.6225353227134778\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 447] Loss: 0.6232425354804502\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 448] Loss: 0.6229930219706148\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 449] Loss: 0.6226463255810578\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 450] Loss: 0.6229323684175809\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 451] Loss: 0.6234494888134912\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 452] Loss: 0.6234957113268629\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 453] Loss: 0.6227445483010337\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 454] Loss: 0.6226754513146594\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 455] Loss: 0.6226587792346766\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 456] Loss: 0.622606251748246\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 457] Loss: 0.6224299347439793\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 458] Loss: 0.6220580280542894\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 459] Loss: 0.6223533676535475\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 460] Loss: 0.6221500949691171\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 461] Loss: 0.621660565702879\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 462] Loss: 0.6212752006335176\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 463] Loss: 0.6217655082822618\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 464] Loss: 0.6218681295948296\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 465] Loss: 0.6232167284014405\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 466] Loss: 0.622919408964241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 467] Loss: 0.623356148090046\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 468] Loss: 0.6225545734612861\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 469] Loss: 0.6221607804997389\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 470] Loss: 0.6217846191626915\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 471] Loss: 0.6212956817096965\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 472] Loss: 0.6210421897407811\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 473] Loss: 0.620827292318576\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 474] Loss: 0.6206004670212037\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 475] Loss: 0.619675519497771\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 476] Loss: 0.6195387072986415\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 477] Loss: 0.619320933330234\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 478] Loss: 0.6189940123191439\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 479] Loss: 0.6185502667827746\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 480] Loss: 0.6181186798028648\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 481] Loss: 0.6182601172128487\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 482] Loss: 0.6178100663411172\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 483] Loss: 0.6180648377037937\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 484] Loss: 0.6182335142569602\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 485] Loss: 0.6176058512680309\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 486] Loss: 0.6172246263044361\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 487] Loss: 0.6177741834698761\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 488] Loss: 0.6179510845695851\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 489] Loss: 0.6173373673164527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 490] Loss: 0.6173699395084867\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 491] Loss: 0.6183461853115233\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 492] Loss: 0.6180231013009704\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 493] Loss: 0.6177822964730659\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 494] Loss: 0.6177751599596097\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 495] Loss: 0.6177459494333074\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 496] Loss: 0.6182107030444087\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 497] Loss: 0.6180783195095043\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 498] Loss: 0.6184951956552195\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 499] Loss: 0.6194842954974376\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 500] Loss: 0.6200259883701801\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 501] Loss: 0.6194119271106586\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.7207\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 502] Loss: 0.6193704883831431\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 503] Loss: 0.6204990376949784\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 504] Loss: 0.620095052623323\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 505] Loss: 0.6198742464922442\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 506] Loss: 0.6199461302679518\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 507] Loss: 0.6207734359027837\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 508] Loss: 0.6203731257087133\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 509] Loss: 0.620562013304538\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 510] Loss: 0.6200040680228495\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 511] Loss: 0.6203507185857123\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 512] Loss: 0.6204141134803649\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 513] Loss: 0.6204405819405356\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 514] Loss: 0.6203409191873287\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 515] Loss: 0.6203058543425162\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 516] Loss: 0.6206257377657317\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 517] Loss: 0.6215705267177098\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 518] Loss: 0.6218940023922552\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 519] Loss: 0.6218760966508146\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 520] Loss: 0.6223223447513122\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 521] Loss: 0.622169956107286\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 522] Loss: 0.6227480424032814\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 523] Loss: 0.6229527404328833\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 524] Loss: 0.6227975687623479\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 525] Loss: 0.62249949157238\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 526] Loss: 0.6227959570945896\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 527] Loss: 0.6223430224964696\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 528] Loss: 0.6222570490825808\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 529] Loss: 0.623143039460669\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 530] Loss: 0.6234736048669185\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 531] Loss: 0.6237936524740945\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 532] Loss: 0.6234708998940492\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 533] Loss: 0.6234950671779729\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 534] Loss: 0.6234710992554601\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 535] Loss: 0.6231050491054482\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 536] Loss: 0.6229352373629808\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 537] Loss: 0.6223870765286007\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 538] Loss: 0.6220910127333549\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 539] Loss: 0.6223330758995824\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 540] Loss: 0.6216501990126239\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 541] Loss: 0.6217273973107559\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 542] Loss: 0.6214709289894332\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 543] Loss: 0.6220526843714231\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 544] Loss: 0.6223054561380517\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 545] Loss: 0.6219853338571864\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 546] Loss: 0.6218930018635896\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 547] Loss: 0.6213978728112617\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 548] Loss: 0.6217730781403337\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 549] Loss: 0.6213085792809453\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 550] Loss: 0.621665454371409\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 551] Loss: 0.6221115297338707\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 552] Loss: 0.6216200586084438\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 553] Loss: 0.6217701275838003\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 554] Loss: 0.6216184128116184\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 555] Loss: 0.6210069715708225\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 556] Loss: 0.6208959208171574\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 557] Loss: 0.6209677705270383\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 558] Loss: 0.6203155464970083\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 559] Loss: 0.6198716942814041\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 560] Loss: 0.619381438275533\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 561] Loss: 0.6194511335110707\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 562] Loss: 0.619558768844053\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 563] Loss: 0.6193946852724251\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 564] Loss: 0.6197266666126167\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 565] Loss: 0.6195828698113957\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 566] Loss: 0.6191075813591269\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 567] Loss: 0.6192009725215364\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 568] Loss: 0.6197915306760812\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 569] Loss: 0.6193511923660503\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 570] Loss: 0.6189032089030534\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 571] Loss: 0.6197464832230333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 572] Loss: 0.6194863537964704\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 573] Loss: 0.6192107542595106\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 574] Loss: 0.6188942342217791\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 575] Loss: 0.6187335570739663\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 576] Loss: 0.6189470960396446\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 577] Loss: 0.6191459522038647\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 578] Loss: 0.61882974426536\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 579] Loss: 0.6191934077181759\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 580] Loss: 0.6191228973197526\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 581] Loss: 0.6197088954524617\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 582] Loss: 0.6194627924831873\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 583] Loss: 0.6191855951964753\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 584] Loss: 0.6193394605580667\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 585] Loss: 0.6188680901231929\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 586] Loss: 0.6185296970982194\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 587] Loss: 0.6185170690032449\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 588] Loss: 0.6193588237930723\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 589] Loss: 0.6191729938386858\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 590] Loss: 0.6191766572958332\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 591] Loss: 0.6196073087691857\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 592] Loss: 0.619487986748887\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 593] Loss: 0.6190929119090407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 594] Loss: 0.6202683560926505\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 595] Loss: 0.6199594349169931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 596] Loss: 0.6198648512113414\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 597] Loss: 0.6194607715061562\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 598] Loss: 0.6192022002112108\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 599] Loss: 0.6195742329940175\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 600] Loss: 0.6192592746267717\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 601] Loss: 0.6188616710226865\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 602] Loss: 0.6187648837798062\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 603] Loss: 0.6197689031536504\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 604] Loss: 0.6195271573960781\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 605] Loss: 0.6196694043303325\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 606] Loss: 0.6211732734400447\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 607] Loss: 0.621348891879817\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 608] Loss: 0.6213125232852211\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 609] Loss: 0.6206644722834009\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 610] Loss: 0.6210991914399334\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 611] Loss: 0.6207597459835624\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 612] Loss: 0.6208364843007397\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 613] Loss: 0.6204913004527862\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 614] Loss: 0.6211150030117082\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 615] Loss: 0.6211001205008204\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 616] Loss: 0.6213318388909101\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 617] Loss: 0.6209287982271016\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 618] Loss: 0.6206657168693527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 619] Loss: 0.6204191045489565\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 620] Loss: 0.6207173516433085\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 621] Loss: 0.6205411011806049\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 622] Loss: 0.6203924755526892\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 623] Loss: 0.6202541626810454\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 624] Loss: 0.6200833931708565\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 625] Loss: 0.6198126785993576\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 626] Loss: 0.6195094648022621\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 627] Loss: 0.6199731005198267\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 628] Loss: 0.6204474914557995\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 629] Loss: 0.6205968936173829\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 630] Loss: 0.6206235704677445\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 631] Loss: 0.6205340377077248\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 632] Loss: 0.6200543888903494\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 633] Loss: 0.6203253959168755\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 634] Loss: 0.6204218242775754\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 635] Loss: 0.6201466023687302\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 636] Loss: 0.6197789801788405\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 637] Loss: 0.6194201060563467\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 638] Loss: 0.6194113027946703\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 639] Loss: 0.6198957816395961\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 640] Loss: 0.619575348845683\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 641] Loss: 0.6197409876934638\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 642] Loss: 0.6201945108555931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 643] Loss: 0.620476084377495\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 644] Loss: 0.6201945241795194\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 645] Loss: 0.619789268365202\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 646] Loss: 0.6194942658392268\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 647] Loss: 0.6192508636753563\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 648] Loss: 0.6194469225305466\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 649] Loss: 0.6197751148134608\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 650] Loss: 0.619880038522757\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 651] Loss: 0.6201615113129814\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 652] Loss: 0.6205060759250738\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 653] Loss: 0.6207325782792309\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 654] Loss: 0.6207431127582121\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 655] Loss: 0.6207706008476156\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 656] Loss: 0.6204504802505054\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 657] Loss: 0.6200624953167261\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 658] Loss: 0.6198120749694236\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 659] Loss: 0.6194557715122544\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 660] Loss: 0.6196148722686551\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 661] Loss: 0.6196187830413163\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 662] Loss: 0.6197237992079596\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 663] Loss: 0.6197598791634875\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 664] Loss: 0.6193092023527407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 665] Loss: 0.6190591852243682\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 666] Loss: 0.6193036541521728\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 667] Loss: 0.6197336192565344\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 668] Loss: 0.6195014782785299\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 669] Loss: 0.6192473196528953\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 670] Loss: 0.6191193910009826\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 671] Loss: 0.6191213667703634\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 672] Loss: 0.618946495000273\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 673] Loss: 0.6184596353131631\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 674] Loss: 0.6180990463680966\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 675] Loss: 0.6184206010456439\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 676] Loss: 0.6182770863748513\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 677] Loss: 0.6187566088036561\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 678] Loss: 0.6184028597839814\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 679] Loss: 0.6186958444092164\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 680] Loss: 0.6184825040619163\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 681] Loss: 0.6184110806683262\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 682] Loss: 0.6187017826347058\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 683] Loss: 0.6188755167830915\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 684] Loss: 0.618590537110093\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 685] Loss: 0.6190327280411755\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 686] Loss: 0.6186104530452292\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 687] Loss: 0.6185289894432654\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 688] Loss: 0.6185856988047098\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 689] Loss: 0.6184531396419805\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 690] Loss: 0.6179351462186247\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 691] Loss: 0.6178074908886219\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 692] Loss: 0.6174121596608203\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 693] Loss: 0.6175283562784415\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 694] Loss: 0.6179113021544489\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 695] Loss: 0.6175201828745629\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 696] Loss: 0.6173480105768333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 697] Loss: 0.6170657889615514\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 698] Loss: 0.6167032981029896\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 699] Loss: 0.6168664603657988\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 700] Loss: 0.6171994255483151\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 701] Loss: 0.6171270064084914\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 702] Loss: 0.616844877282269\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 703] Loss: 0.6168337183478547\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 704] Loss: 0.6175808442375538\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 705] Loss: 0.6176203665792519\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 706] Loss: 0.617279402911663\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 707] Loss: 0.617094339015123\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 708] Loss: 0.6166750979583479\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 709] Loss: 0.6164317180012446\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 710] Loss: 0.6161486874373866\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 711] Loss: 0.6162287878965024\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 712] Loss: 0.6158827437569251\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 713] Loss: 0.6157801224631982\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 714] Loss: 0.6157696382129559\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 715] Loss: 0.6158703917181575\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 716] Loss: 0.6154437975635408\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 717] Loss: 0.6155075552032915\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 718] Loss: 0.6155559995670836\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 719] Loss: 0.6155390657163297\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 720] Loss: 0.6153411449036664\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 721] Loss: 0.6147560888950437\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 722] Loss: 0.6150422651846983\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 723] Loss: 0.6152927854908617\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 724] Loss: 0.61527397372446\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 725] Loss: 0.6152329826354981\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 726] Loss: 0.6150331934785711\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 727] Loss: 0.6152715782187828\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 728] Loss: 0.6158083933559093\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 729] Loss: 0.6160978115635154\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 730] Loss: 0.6166835610997187\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 731] Loss: 0.6165991601637385\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 732] Loss: 0.6162137938001768\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 733] Loss: 0.6162444058739635\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 734] Loss: 0.6158545957599089\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 735] Loss: 0.6156588827266174\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 736] Loss: 0.6157643748447299\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 737] Loss: 0.6153017309174609\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 738] Loss: 0.6154639001299695\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 739] Loss: 0.6160563663636235\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 740] Loss: 0.616076652665396\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 741] Loss: 0.616972527925463\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 742] Loss: 0.6169368252760637\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 743] Loss: 0.6176178752974899\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 744] Loss: 0.61745537601171\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 745] Loss: 0.6171362080830055\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 746] Loss: 0.6169805866304096\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 747] Loss: 0.6170894711052717\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 748] Loss: 0.617152210464452\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 749] Loss: 0.6170613594621778\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 750] Loss: 0.6168363080024719\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 751] Loss: 0.6171741391148929\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 752] Loss: 0.6169934972248813\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 753] Loss: 0.6167073009577722\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 754] Loss: 0.617709581708086\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 755] Loss: 0.6178292020661942\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 756] Loss: 0.6176789867736044\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 757] Loss: 0.618205577056348\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 758] Loss: 0.617857422394614\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 759] Loss: 0.6177903471099844\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 760] Loss: 0.6174626028067187\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 761] Loss: 0.6175633102616249\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 762] Loss: 0.6173540353775024\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 763] Loss: 0.6169271506222641\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 764] Loss: 0.6170412477944534\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 765] Loss: 0.6177197653873294\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 766] Loss: 0.6179958643007527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 767] Loss: 0.6180328051067859\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 768] Loss: 0.6178178952153152\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 769] Loss: 0.6180609184449298\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 770] Loss: 0.6178122597855407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 771] Loss: 0.6179286928801531\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 772] Loss: 0.6180929885163826\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 773] Loss: 0.6181903992710879\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 774] Loss: 0.6179962553257166\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 775] Loss: 0.6180869786200985\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 776] Loss: 0.6178579957598878\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 777] Loss: 0.6174685343275352\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 778] Loss: 0.6177849976829514\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 779] Loss: 0.6174567564843708\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 780] Loss: 0.6172257592662787\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 781] Loss: 0.617533079068273\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 782] Loss: 0.6171053464684035\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 783] Loss: 0.6168538524958366\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 784] Loss: 0.6171169511745779\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 785] Loss: 0.6173426023334455\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 786] Loss: 0.6171021769368314\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 787] Loss: 0.6166720122969893\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 788] Loss: 0.6168498922574338\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 789] Loss: 0.6168961918550451\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 790] Loss: 0.6168345627150958\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 791] Loss: 0.6169724026612476\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 792] Loss: 0.6171216794637718\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 793] Loss: 0.6172186004709627\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 794] Loss: 0.6172566909333621\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 795] Loss: 0.6174863824304545\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 796] Loss: 0.6173994891607582\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 797] Loss: 0.6169325995026449\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 798] Loss: 0.6173713649424694\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 799] Loss: 0.6178111589894874\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 800] Loss: 0.6179445487260818\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 801] Loss: 0.6177399865399288\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 802] Loss: 0.6180134286309715\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 803] Loss: 0.6178387973183861\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 804] Loss: 0.6176689217117295\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 805] Loss: 0.617468678988285\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 806] Loss: 0.6172307770394214\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 807] Loss: 0.6169476735473713\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 808] Loss: 0.6170293756271943\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 809] Loss: 0.616721088681439\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 810] Loss: 0.6165724554915487\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 811] Loss: 0.6161949468085269\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 812] Loss: 0.616438967730905\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 813] Loss: 0.6164784560857517\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 814] Loss: 0.6162274863195654\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 815] Loss: 0.6159727800111829\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 816] Loss: 0.6156814493165881\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 817] Loss: 0.6156320203838909\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 818] Loss: 0.6154346804528481\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 819] Loss: 0.6151576850367698\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 820] Loss: 0.6149423006467702\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 821] Loss: 0.6150740031130276\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 822] Loss: 0.6149649513101346\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 823] Loss: 0.614854816569158\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 824] Loss: 0.6146351195220808\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 825] Loss: 0.6144623304135872\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 826] Loss: 0.6150659269339813\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 827] Loss: 0.6150602632018646\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 828] Loss: 0.615289613460573\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 829] Loss: 0.6150086869376704\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 830] Loss: 0.6147428217063468\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 831] Loss: 0.6144960073285728\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 832] Loss: 0.6143185629222828\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 833] Loss: 0.6139272184861378\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 834] Loss: 0.6138463861865106\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 835] Loss: 0.6139455748532346\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 836] Loss: 0.6142149687740222\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 837] Loss: 0.6138478298554711\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 838] Loss: 0.6135733781253523\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 839] Loss: 0.6134877368292735\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 840] Loss: 0.6136601395550229\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 841] Loss: 0.6134116207731182\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 842] Loss: 0.6131287233421752\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 843] Loss: 0.6133846022621734\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 844] Loss: 0.6134752276666922\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 845] Loss: 0.6133081041144196\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 846] Loss: 0.6135451156055955\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 847] Loss: 0.613608037355799\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 848] Loss: 0.613439239174971\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 849] Loss: 0.6133461304281008\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 850] Loss: 0.613437668260406\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 851] Loss: 0.6138603920872147\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 852] Loss: 0.6136310863452898\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 853] Loss: 0.6133167058194509\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 854] Loss: 0.6134098750785586\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 855] Loss: 0.6136486478019179\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 856] Loss: 0.6132730800554017\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 857] Loss: 0.6133386122721357\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 858] Loss: 0.613297590147921\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 859] Loss: 0.6129457080461371\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 860] Loss: 0.6130811978218167\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 861] Loss: 0.6129583485865843\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 862] Loss: 0.6127324191088466\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 863] Loss: 0.6128429384040943\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 864] Loss: 0.6127596801422812\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 865] Loss: 0.6126736677795477\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 866] Loss: 0.612595907156517\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 867] Loss: 0.6124634879201891\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 868] Loss: 0.6125502843529947\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 869] Loss: 0.6122714497140417\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 870] Loss: 0.6119067965225241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 871] Loss: 0.6116468309329653\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 872] Loss: 0.6114462723425769\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 873] Loss: 0.6115935470776596\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 874] Loss: 0.6113240823865755\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 875] Loss: 0.6111658648763384\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 876] Loss: 0.6117181077803651\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 877] Loss: 0.6117258137145092\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 878] Loss: 0.611480286629162\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 879] Loss: 0.6112447816696319\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 880] Loss: 0.6112641418183392\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 881] Loss: 0.6110361605442883\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 882] Loss: 0.6116185940447307\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 883] Loss: 0.6116766357205867\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 884] Loss: 0.6114632375369784\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 885] Loss: 0.6113523463071403\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 886] Loss: 0.6110832346077697\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 887] Loss: 0.6112452148047214\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 888] Loss: 0.6114850728898436\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 889] Loss: 0.6119729473566714\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 890] Loss: 0.6117691549022546\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 891] Loss: 0.6118757956223322\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 892] Loss: 0.6119446594084325\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 893] Loss: 0.6116000206312968\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 894] Loss: 0.6114916159402604\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 895] Loss: 0.6110697624736658\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 896] Loss: 0.6109812617235418\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 897] Loss: 0.6107984372604651\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 898] Loss: 0.6109432356394744\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 899] Loss: 0.6105607312765217\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 900] Loss: 0.610430749422974\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 901] Loss: 0.6104307739967512\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 902] Loss: 0.6102014777070931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 903] Loss: 0.6099305468078203\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 904] Loss: 0.6094907555828052\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 905] Loss: 0.6094438317072326\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 906] Loss: 0.6096235355136147\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 907] Loss: 0.6096258149651734\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 908] Loss: 0.6094043470164228\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 909] Loss: 0.6095682541267051\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 910] Loss: 0.6094763142066998\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 911] Loss: 0.6092575219931116\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 912] Loss: 0.6090031534171941\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 913] Loss: 0.6091840074592456\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 914] Loss: 0.6092749914924739\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 915] Loss: 0.6091973260452187\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 916] Loss: 0.6089605339945143\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 917] Loss: 0.6086414171994188\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 918] Loss: 0.609047557111659\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 919] Loss: 0.6088199885612733\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 920] Loss: 0.608463205785855\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 921] Loss: 0.6081434903781655\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 922] Loss: 0.6085071888249246\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 923] Loss: 0.6082835546164962\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 924] Loss: 0.6083363212032236\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 925] Loss: 0.6080245308940475\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 926] Loss: 0.6081795786099095\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 927] Loss: 0.6078953806957895\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 928] Loss: 0.6078170560749954\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 929] Loss: 0.6080262573401818\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 930] Loss: 0.6078706953794726\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 931] Loss: 0.6075498164980547\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 932] Loss: 0.6070797343302694\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 933] Loss: 0.6070871181618362\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 934] Loss: 0.6068322120565418\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 935] Loss: 0.606571684068537\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 936] Loss: 0.6064289229420515\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 937] Loss: 0.6064445478175722\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 938] Loss: 0.6063329623833394\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 939] Loss: 0.606197938497582\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 940] Loss: 0.6063262386524931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 941] Loss: 0.6062018345253627\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 942] Loss: 0.6059373918042821\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 943] Loss: 0.6055750546943345\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 944] Loss: 0.6059652852620614\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 945] Loss: 0.6057844617694774\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 946] Loss: 0.6055362956090407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 947] Loss: 0.6053571227107909\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 948] Loss: 0.6052287729291976\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 949] Loss: 0.6053540250963607\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 950] Loss: 0.6057509405675687\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 951] Loss: 0.6059066318249727\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 952] Loss: 0.6059146799272349\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 953] Loss: 0.6055606262443699\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 954] Loss: 0.6054742806425134\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 955] Loss: 0.6054832669764914\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 956] Loss: 0.6055781092167399\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 957] Loss: 0.6056052415535368\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 958] Loss: 0.6055563390566063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 959] Loss: 0.6058573583306063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 960] Loss: 0.6057619973706703\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 961] Loss: 0.6055258747876373\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 962] Loss: 0.6051341102704437\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 963] Loss: 0.6051108017795925\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 964] Loss: 0.6052796153266647\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 965] Loss: 0.6050509953900323\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 966] Loss: 0.6048437593423802\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 967] Loss: 0.6047618965605792\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 968] Loss: 0.6046236870610271\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 969] Loss: 0.6050803185401195\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 970] Loss: 0.604784756176865\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 971] Loss: 0.6047778105177177\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 972] Loss: 0.6046458060389438\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 973] Loss: 0.6042887929440279\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 974] Loss: 0.6040630188351784\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 975] Loss: 0.6037433982659609\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 976] Loss: 0.6034341991466822\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 977] Loss: 0.603106442941858\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 978] Loss: 0.6029790331036279\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 979] Loss: 0.6028144067501511\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 980] Loss: 0.6026298251839317\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 981] Loss: 0.6032102232102103\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 982] Loss: 0.6030967486092855\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 983] Loss: 0.6032252159966336\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 984] Loss: 0.6030346446375294\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 985] Loss: 0.6027455809606513\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 986] Loss: 0.6029073331678857\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 987] Loss: 0.6026945762872212\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 988] Loss: 0.60310965850346\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 989] Loss: 0.6033772392418797\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 990] Loss: 0.6033282464351317\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 991] Loss: 0.6032183675394289\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 992] Loss: 0.6033282181878965\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 993] Loss: 0.6033041663130244\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 994] Loss: 0.6035392154120583\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 995] Loss: 0.6032656649998085\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 996] Loss: 0.6032841469060226\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 997] Loss: 0.6033065466279371\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 998] Loss: 0.6030098124144072\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 999] Loss: 0.6028633259825997\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1000] Loss: 0.6027922345548868\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1001] Loss: 0.6025162397415845\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.7511\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1002] Loss: 0.6026084534154681\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1003] Loss: 0.6024986615001502\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1004] Loss: 0.6022130546134069\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1005] Loss: 0.6019384992211613\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1006] Loss: 0.6021577698839587\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1007] Loss: 0.6028689514945493\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1008] Loss: 0.6030308981056488\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1009] Loss: 0.6028530543487302\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1010] Loss: 0.6027915774153011\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1011] Loss: 0.6029164768261679\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1012] Loss: 0.6029693305404055\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1013] Loss: 0.602770183967226\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1014] Loss: 0.6024856805007839\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1015] Loss: 0.6027312716973826\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1016] Loss: 0.6024624798740223\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1017] Loss: 0.60209862744269\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1018] Loss: 0.6018289602078014\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1019] Loss: 0.6025666540545266\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1020] Loss: 0.6034606034118756\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1021] Loss: 0.6036897436966508\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1022] Loss: 0.6038757637143135\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1023] Loss: 0.6041891904491367\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1024] Loss: 0.6040083776897518\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1025] Loss: 0.6041303425736544\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1026] Loss: 0.6043303028969039\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1027] Loss: 0.6043630321714175\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1028] Loss: 0.6046073666197549\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1029] Loss: 0.604635899671081\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1030] Loss: 0.6043113027527495\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1031] Loss: 0.6042518862726386\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1032] Loss: 0.604431206706998\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1033] Loss: 0.6043788655827838\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1034] Loss: 0.6043413827480384\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1035] Loss: 0.6040859728475699\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1036] Loss: 0.6041078458047512\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1037] Loss: 0.604012472118568\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1038] Loss: 0.6041078969319432\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1039] Loss: 0.604179669605412\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1040] Loss: 0.6046476104941506\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1041] Loss: 0.6047162213054101\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1042] Loss: 0.6045144757903012\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1043] Loss: 0.6045152704273409\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1044] Loss: 0.6043650247442083\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1045] Loss: 0.6040519058561782\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1046] Loss: 0.6038697387446181\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1047] Loss: 0.6045557948642383\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1048] Loss: 0.6043922191215608\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1049] Loss: 0.6041443200055705\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1050] Loss: 0.6042801750699679\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1051] Loss: 0.6044350384276442\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1052] Loss: 0.6042137556911195\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1053] Loss: 0.6042885267072253\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1054] Loss: 0.6043271765791488\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1055] Loss: 0.6041610791361163\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1056] Loss: 0.6038967078749203\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1057] Loss: 0.6039209861093348\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1058] Loss: 0.6036931818706778\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1059] Loss: 0.6034060396795795\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1060] Loss: 0.6033713043720093\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1061] Loss: 0.6036443818048078\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1062] Loss: 0.6037248904955365\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1063] Loss: 0.6033623864907537\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1064] Loss: 0.6038529385945627\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1065] Loss: 0.6041081595728655\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1066] Loss: 0.6043578346467823\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1067] Loss: 0.6044681350287703\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1068] Loss: 0.6044046955134315\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1069] Loss: 0.6046869867839358\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1070] Loss: 0.6046222039333013\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1071] Loss: 0.6044384648346879\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1072] Loss: 0.6040948470220414\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1073] Loss: 0.6038578561917711\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1074] Loss: 0.6036587117076808\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1075] Loss: 0.6032812406573185\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1076] Loss: 0.6035378541811248\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1077] Loss: 0.6033024915468947\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1078] Loss: 0.6030638905480532\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1079] Loss: 0.6028641006590814\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1080] Loss: 0.6025967495860877\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1081] Loss: 0.6024888509076354\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1082] Loss: 0.6026481986045837\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1083] Loss: 0.6029059682196197\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1084] Loss: 0.6027592888507456\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1085] Loss: 0.6025734436402123\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1086] Loss: 0.6025012805371873\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1087] Loss: 0.6027685700202055\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1088] Loss: 0.6025796793949079\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1089] Loss: 0.6022735544582153\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1090] Loss: 0.6025433050929954\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1091] Loss: 0.6023496716640937\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1092] Loss: 0.602080551095498\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1093] Loss: 0.6019650854218039\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1094] Loss: 0.6019720942926146\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1095] Loss: 0.6020186060639822\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1096] Loss: 0.6017895765113135\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1097] Loss: 0.6020775287935923\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1098] Loss: 0.6018505754366599\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1099] Loss: 0.6020566863401897\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1100] Loss: 0.6019166728312318\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1101] Loss: 0.6016889160649544\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1102] Loss: 0.601854710932652\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1103] Loss: 0.6017401021713575\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1104] Loss: 0.6017717252606931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1105] Loss: 0.6016081900348491\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1106] Loss: 0.6017614638341917\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1107] Loss: 0.6018330178340492\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1108] Loss: 0.6019358957986539\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1109] Loss: 0.6017259794167295\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1110] Loss: 0.6018590785898604\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1111] Loss: 0.6017363056419778\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1112] Loss: 0.6014809550302063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1113] Loss: 0.6012412862850542\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1114] Loss: 0.6014417186780721\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1115] Loss: 0.601163040041389\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1116] Loss: 0.6011253017464846\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1117] Loss: 0.6011840447636726\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1118] Loss: 0.6015142059496775\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1119] Loss: 0.6021105616725482\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1120] Loss: 0.6019172600071345\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1121] Loss: 0.6018976079205335\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1122] Loss: 0.601652571330521\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1123] Loss: 0.6015684479384792\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1124] Loss: 0.6013917361130918\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1125] Loss: 0.601218998697069\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1126] Loss: 0.6011293613571892\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1127] Loss: 0.6014906932213926\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1128] Loss: 0.6016973165121484\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1129] Loss: 0.6015501362333475\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1130] Loss: 0.6018093052691063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1131] Loss: 0.6018209017345486\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1132] Loss: 0.6016326260229724\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1133] Loss: 0.6017039745441076\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1134] Loss: 0.6019206990535507\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1135] Loss: 0.6020091667574408\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1136] Loss: 0.602303261645663\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1137] Loss: 0.6023421871001613\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1138] Loss: 0.6025279327729465\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1139] Loss: 0.6024141391449795\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1140] Loss: 0.6021124538883829\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1141] Loss: 0.6023407119549126\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1142] Loss: 0.6025968684363073\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1143] Loss: 0.6027625014619251\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1144] Loss: 0.6025136018080728\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1145] Loss: 0.6027128895557603\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1146] Loss: 0.6024173163462684\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1147] Loss: 0.6022274457015675\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1148] Loss: 0.602164721421456\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1149] Loss: 0.6028122814506733\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1150] Loss: 0.6029393505272658\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1151] Loss: 0.6028326281923299\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1152] Loss: 0.6026256754994392\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1153] Loss: 0.6025127257250333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1154] Loss: 0.6024127752880083\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1155] Loss: 0.6022537717571507\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1156] Loss: 0.6023608215127437\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1157] Loss: 0.6022024710011462\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1158] Loss: 0.6020919245141776\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1159] Loss: 0.6022614459728145\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1160] Loss: 0.6026600749328219\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1161] Loss: 0.6024363456770431\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1162] Loss: 0.6022718618022801\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1163] Loss: 0.6020595641968481\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1164] Loss: 0.6019650659047041\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1165] Loss: 0.6019521334396412\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1166] Loss: 0.6017600350324736\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1167] Loss: 0.6015062446816926\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1168] Loss: 0.6015278722274385\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1169] Loss: 0.6016153429847584\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1170] Loss: 0.6015341679000447\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1171] Loss: 0.601518839037795\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1172] Loss: 0.6015327185544951\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1173] Loss: 0.6015952403029111\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1174] Loss: 0.6015017674109395\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1175] Loss: 0.6016736952548332\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1176] Loss: 0.6019499259082233\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1177] Loss: 0.6025080889235539\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1178] Loss: 0.602338615849184\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1179] Loss: 0.6024187388462572\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1180] Loss: 0.6023430994254048\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1181] Loss: 0.6021032035098451\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1182] Loss: 0.6022583212445028\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1183] Loss: 0.6023315385248534\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1184] Loss: 0.6021634833132093\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1185] Loss: 0.6021320143329443\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1186] Loss: 0.6018130477473869\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1187] Loss: 0.6016013660949122\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1188] Loss: 0.6016827372689841\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1189] Loss: 0.6019316647511956\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1190] Loss: 0.601656071628843\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1191] Loss: 0.602061894388383\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1192] Loss: 0.6021600153122172\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1193] Loss: 0.6019936489739143\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1194] Loss: 0.6021161636016277\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1195] Loss: 0.6021108810871715\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1196] Loss: 0.6020388596731684\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1197] Loss: 0.601898017234372\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1198] Loss: 0.6021394553984545\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1199] Loss: 0.6022743634425968\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1200] Loss: 0.6024695339798928\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1201] Loss: 0.6025071719802488\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1202] Loss: 0.6023368903384629\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1203] Loss: 0.602534095991282\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1204] Loss: 0.602738004932768\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1205] Loss: 0.6026746723167135\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1206] Loss: 0.6025941939792823\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1207] Loss: 0.6023496934077714\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1208] Loss: 0.6024744153910915\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1209] Loss: 0.6024510806705263\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1210] Loss: 0.6025216320822061\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1211] Loss: 0.6023018541757378\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1212] Loss: 0.6020968600664989\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1213] Loss: 0.602074527288407\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1214] Loss: 0.6021447650094008\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1215] Loss: 0.6019664679289846\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1216] Loss: 0.6017782952097294\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1217] Loss: 0.60166592556821\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1218] Loss: 0.6018689199915073\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1219] Loss: 0.6019597998694184\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1220] Loss: 0.6021748254533674\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1221] Loss: 0.6020324323433135\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1222] Loss: 0.6018183139654306\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1223] Loss: 0.6019760540344631\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1224] Loss: 0.6017848614335449\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1225] Loss: 0.601910017874776\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1226] Loss: 0.6017539932910614\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1227] Loss: 0.6015932144629051\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1228] Loss: 0.6017478447686577\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1229] Loss: 0.6019140979543365\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1230] Loss: 0.602263659771865\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1231] Loss: 0.6024595729516445\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1232] Loss: 0.6025522200318126\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1233] Loss: 0.6023470581012921\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1234] Loss: 0.602339005547559\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1235] Loss: 0.6022501875997073\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1236] Loss: 0.6021183767750811\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1237] Loss: 0.6020150324367378\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1238] Loss: 0.601724829663175\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1239] Loss: 0.6015612402445275\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1240] Loss: 0.6017580163334647\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1241] Loss: 0.601830781826946\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1242] Loss: 0.6016974402846538\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1243] Loss: 0.6016107089367971\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1244] Loss: 0.6013242101650146\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1245] Loss: 0.6017820026501115\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1246] Loss: 0.6016101421456467\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1247] Loss: 0.6017276905686165\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1248] Loss: 0.6015064065368512\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1249] Loss: 0.6011851602096\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1250] Loss: 0.6012598642230034\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1251] Loss: 0.6011186646495601\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1252] Loss: 0.6012273155057583\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1253] Loss: 0.6018935479431845\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1254] Loss: 0.6022546942890926\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1255] Loss: 0.6020899222310321\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1256] Loss: 0.6021480989422957\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1257] Loss: 0.6019059820908256\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1258] Loss: 0.6017320564635608\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1259] Loss: 0.6015333182594906\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1260] Loss: 0.6012959033369072\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1261] Loss: 0.6014444006165278\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1262] Loss: 0.6014726683025126\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1263] Loss: 0.6012756035545943\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1264] Loss: 0.6012414967924168\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1265] Loss: 0.6012653584654624\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1266] Loss: 0.6009978862099737\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1267] Loss: 0.6011938305590787\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1268] Loss: 0.6012819755458118\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1269] Loss: 0.6011012985750481\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1270] Loss: 0.6009802606279456\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1271] Loss: 0.6007876696664456\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1272] Loss: 0.6006242259282548\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1273] Loss: 0.6006740176551284\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1274] Loss: 0.6007219738147135\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1275] Loss: 0.6006718517635383\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1276] Loss: 0.6006126576526598\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1277] Loss: 0.6009742294029043\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1278] Loss: 0.6007420928428804\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1279] Loss: 0.6005093901650433\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1280] Loss: 0.6004820641479455\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1281] Loss: 0.6004109362039968\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1282] Loss: 0.600169269452322\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1283] Loss: 0.6002099663948325\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1284] Loss: 0.6001691835297045\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1285] Loss: 0.6000673654826235\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1286] Loss: 0.6004462469120048\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1287] Loss: 0.6003103389953955\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1288] Loss: 0.6000538831287474\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1289] Loss: 0.5999339605899076\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1290] Loss: 0.59964293745137\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1291] Loss: 0.59954155110094\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1292] Loss: 0.5996802633760884\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1293] Loss: 0.5998986547341756\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1294] Loss: 0.600079444866092\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1295] Loss: 0.5999510314934042\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1296] Loss: 0.5997936061043062\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1297] Loss: 0.5998622092174951\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1298] Loss: 0.599697215646184\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1299] Loss: 0.5998126665980564\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1300] Loss: 0.6000833512498782\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1301] Loss: 0.5999227194122678\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1302] Loss: 0.599789716726807\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1303] Loss: 0.5998157924720167\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1304] Loss: 0.5996787239071781\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1305] Loss: 0.5997630728615655\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1306] Loss: 0.5995681034158602\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1307] Loss: 0.5993934263230829\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1308] Loss: 0.599520769596829\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1309] Loss: 0.5993604507721317\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1310] Loss: 0.5994664559610018\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1311] Loss: 0.5994613755985947\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1312] Loss: 0.599578774806748\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1313] Loss: 0.5998390110185468\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1314] Loss: 0.6000019960343566\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1315] Loss: 0.5998372605771619\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1316] Loss: 0.5996433032455778\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1317] Loss: 0.5995597822383759\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1318] Loss: 0.5995040417214988\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1319] Loss: 0.5995792717848699\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1320] Loss: 0.5993639991590471\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1321] Loss: 0.5997455483309524\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1322] Loss: 0.5996631262161728\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1323] Loss: 0.5995709439028598\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1324] Loss: 0.5996497933192916\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1325] Loss: 0.599590168741514\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1326] Loss: 0.5993910414555853\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1327] Loss: 0.5999956948243323\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1328] Loss: 0.6000471362642136\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1329] Loss: 0.5999716348536845\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1330] Loss: 0.600138710450409\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1331] Loss: 0.6003742278473078\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1332] Loss: 0.6001513267870064\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1333] Loss: 0.6002474488035147\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1334] Loss: 0.6001969446753455\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1335] Loss: 0.6003712670186933\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1336] Loss: 0.6005745788891158\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1337] Loss: 0.6004246046673297\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1338] Loss: 0.6008247615956048\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1339] Loss: 0.6007020672459136\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1340] Loss: 0.6005162583803063\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1341] Loss: 0.6004571399521597\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1342] Loss: 0.6005381035289536\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1343] Loss: 0.6003964508946761\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1344] Loss: 0.6002815181744241\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1345] Loss: 0.6005285209439502\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1346] Loss: 0.6005593409421363\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1347] Loss: 0.6003728983308443\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1348] Loss: 0.6002693137358487\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1349] Loss: 0.6000590914704342\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1350] Loss: 0.5999220992017675\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1351] Loss: 0.5997687407681714\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1352] Loss: 0.6000354819264285\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1353] Loss: 0.5999182517979643\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1354] Loss: 0.6000086366910173\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1355] Loss: 0.6001245469844649\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1356] Loss: 0.6000377693403084\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1357] Loss: 0.5999820180341613\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1358] Loss: 0.6000566242238032\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1359] Loss: 0.5998930883942675\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1360] Loss: 0.5999917479341521\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1361] Loss: 0.6002277261320936\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1362] Loss: 0.6000320123243262\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1363] Loss: 0.5999883118134076\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1364] Loss: 0.6000419728829365\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1365] Loss: 0.6001776297013838\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1366] Loss: 0.6001584088732522\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1367] Loss: 0.6003418906640204\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1368] Loss: 0.600100350789508\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1369] Loss: 0.6000632333703246\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1370] Loss: 0.5999788482476325\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1371] Loss: 0.5999154269608331\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1372] Loss: 0.599776707741679\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1373] Loss: 0.5998532566291437\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1374] Loss: 0.6001423315363333\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1375] Loss: 0.6002542457580566\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1376] Loss: 0.6004162437260844\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1377] Loss: 0.6005226483618599\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1378] Loss: 0.6006651540626117\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1379] Loss: 0.6007794723552237\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1380] Loss: 0.6006481888933458\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1381] Loss: 0.6006358131216023\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1382] Loss: 0.6004754087514367\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1383] Loss: 0.6004391955191556\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1384] Loss: 0.6004420974092677\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1385] Loss: 0.6002288207895919\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1386] Loss: 0.600409657644675\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1387] Loss: 0.6006113969557734\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1388] Loss: 0.60044250031799\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1389] Loss: 0.6003637519605388\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1390] Loss: 0.6003715887558546\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1391] Loss: 0.6004396754361845\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1392] Loss: 0.6005077908650555\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1393] Loss: 0.6007168938466652\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1394] Loss: 0.6005585073270278\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1395] Loss: 0.600836151026483\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1396] Loss: 0.6008103403414902\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1397] Loss: 0.6006461017329776\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1398] Loss: 0.6008668649989648\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1399] Loss: 0.6010770002077783\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1400] Loss: 0.6010476748645306\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1401] Loss: 0.6010075284488536\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1402] Loss: 0.601114301406878\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1403] Loss: 0.601044085245853\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1404] Loss: 0.6008689551908746\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1405] Loss: 0.6006816829014503\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1406] Loss: 0.600735307015362\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1407] Loss: 0.6006473671610506\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1408] Loss: 0.6005364988549527\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1409] Loss: 0.6005369502022556\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1410] Loss: 0.6003954144022989\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1411] Loss: 0.600255040329116\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1412] Loss: 0.6001925631597764\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1413] Loss: 0.6001731359992395\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1414] Loss: 0.6000996987207607\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1415] Loss: 0.6000099538703689\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1416] Loss: 0.599994485513807\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1417] Loss: 0.599816467447355\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1418] Loss: 0.5999596034438048\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1419] Loss: 0.5997913722382036\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1420] Loss: 0.5998839562417756\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1421] Loss: 0.6000851335909734\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1422] Loss: 0.5999832328739045\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1423] Loss: 0.6000943559412376\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1424] Loss: 0.6003808357616823\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1425] Loss: 0.6005599672961653\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1426] Loss: 0.6005597823674348\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1427] Loss: 0.6007194977042218\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1428] Loss: 0.6007229343307119\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1429] Loss: 0.6008021978542804\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1430] Loss: 0.6005955618786645\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1431] Loss: 0.6006142033262739\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1432] Loss: 0.6007995762180682\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1433] Loss: 0.6007042573368474\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1434] Loss: 0.6004896743360756\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1435] Loss: 0.6003195649240075\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1436] Loss: 0.6004540875429563\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1437] Loss: 0.6004374996190612\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1438] Loss: 0.6002350671317879\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1439] Loss: 0.6002832860313744\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1440] Loss: 0.6000927026280098\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1441] Loss: 0.6001387942714215\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1442] Loss: 0.6000408965696409\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1443] Loss: 0.59990801502662\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1444] Loss: 0.5997162455708366\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1445] Loss: 0.5994652645191931\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1446] Loss: 0.5993578302703623\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1447] Loss: 0.599305263802193\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1448] Loss: 0.5993214509146318\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1449] Loss: 0.5995503098204515\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1450] Loss: 0.5996007729604327\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1451] Loss: 0.5993943311155951\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1452] Loss: 0.5993847775763059\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1453] Loss: 0.599272262533205\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1454] Loss: 0.5994636651328374\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1455] Loss: 0.599258563608648\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1456] Loss: 0.5993402613797686\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1457] Loss: 0.5991734409463185\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1458] Loss: 0.5990885326278553\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1459] Loss: 0.5988940647442591\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1460] Loss: 0.5987904098548301\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1461] Loss: 0.5987098079524082\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1462] Loss: 0.598547788920383\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1463] Loss: 0.5985920232448851\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1464] Loss: 0.5984624627305836\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1465] Loss: 0.5988011036106344\n",
      "\n",
      "CUDA Memory Allocated: 7312062976\n",
      "[Epoch 0, Batch 1466] Loss: 0.5986801604009748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_weights = True\n",
    "\n",
    "print(\"Pre-Training CUDA Memory Allocation:\", torch.cuda.max_memory_allocated())\n",
    "\n",
    "if learn_weights:\n",
    "\n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.forward(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.unsqueeze(-1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sched.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # update mini-batch count\n",
    "        mini_batch += 1\n",
    "        epoch = mini_batch // 12204\n",
    "\n",
    "        # print every mini-batch\n",
    "        print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "        print(f'[Epoch {epoch}, Batch {mini_batch % 12204}] Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "        # save and outoput every 100 mini-batch\n",
    "        if i % 100 == 0:\n",
    "            print(\"*********** Saving network weights and optimizer state *********** \\n\\n\")\n",
    "            # save the weights and optimizer\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "            \n",
    "        # eval every 500 mini-batch\n",
    "        if i % 500 == 0:\n",
    "            \n",
    "            print(\"******************************************************************\")\n",
    "            print(\"*********************** Performance Update ***********************\")\n",
    "            print(\"******************************************************************\\n\")\n",
    "            \n",
    "            net.eval()\n",
    "            \n",
    "            ground_truths = []\n",
    "            probs = []\n",
    "\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            with torch.no_grad():\n",
    "                for j, valdata in enumerate(val_loader, 0):\n",
    "                    image, label = valdata\n",
    "                    image = image.to(device)\n",
    "\n",
    "                    # save for analysis\n",
    "                    ground_truths.append(label)\n",
    "\n",
    "                    # calculate outputs by running images through the network \n",
    "                    outputs = net(image)\n",
    "                    outputs = outputs.to(\"cpu\")\n",
    "\n",
    "                    # # save for analysis\n",
    "                    probs.append(outputs)\n",
    "\n",
    "            print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "            \n",
    "            net.train()\n",
    "\n",
    "            print(\"\\n******************************************************************\")\n",
    "            print(\"****************** Performance Update Complete! ******************\")\n",
    "            print(\"******************************************************************\\n\\n\")\n",
    "\n",
    "        # save unique set of weights and optimizer for validation later\n",
    "        if mini_batch % 12204 == 0:\n",
    "\n",
    "            uPATH = f'./saved_weights4/melanoma_ResNeSt_{epoch}e_{mini_batch % 12204}b.pth'\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, uPATH)\n",
    "\n",
    "    print('*********** Finished Training this Epoch in', time.time() - start_time, 'seconds ***********')\n",
    "    \n",
    "    # save the weights and optimizer\n",
    "    torch.save({'mini_batch': mini_batch,\n",
    "                'model_state_dict': net.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict(), \n",
    "                'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998de40",
   "metadata": {},
   "source": [
    "# Formally test performance on our test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f63c0",
   "metadata": {},
   "source": [
    "First, let us see what the convolutional neural network thinks of a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b172eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "test_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data768x768\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data768x768\", \"val.csv\"), \n",
    "                            num_samples=8281, up_sample=False, start_ind=0, transform=val_transf)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate2d, \n",
    "                         num_workers=n_workers)\n",
    "\n",
    "\n",
    "\n",
    "testiter = iter(test_loader)\n",
    "images, labels = next(testiter)\n",
    "\n",
    "# print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072622c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_weights | create_new_weights:\n",
    "    \n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9271d8",
   "metadata": {},
   "source": [
    "Fortunately, we saved weights off at different epoch/batch values. Here is the list of saved weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc00fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./saved_weights4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_fnames = os.listdir('./saved_weights4/')\n",
    "#weight_fnames.sort() # isnt perfectly sorted, but too lazy to add the code (not important)\n",
    "batch_sizes = []\n",
    "losses = []\n",
    "\n",
    "for fname in weight_fnames:\n",
    "    \n",
    "    print(f'Loading: {fname}\\n')\n",
    "\n",
    "    checkpoint = torch.load(f'./saved_weights4/{fname}', map_location=device)\n",
    "    \n",
    "    # network weights load\n",
    "    net = torchvision.models.resnet152(weights='IMAGENET1K_V2').to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])  \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ground_truths = []\n",
    "    probs = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, testdata in enumerate(test_loader, 0):\n",
    "            \n",
    "            image, label = testdata\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = net(image)\n",
    "            \n",
    "            loss = criterion(outputs, label.unsqueeze(-1).float())\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # everything saved should be on RAM\n",
    "            outputs = outputs.to(\"cpu\")\n",
    "            label = label.to(\"cpu\")\n",
    "            \n",
    "            # save for analysis\n",
    "            ground_truths.append(label)\n",
    "            \n",
    "            # # save for analysis\n",
    "            probs += outputs.squeeze(-1).tolist()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"\\t Processing Batch #{i} ... Running Time {time.time() - start_time}\")\n",
    "                print(f'\\t Current Testing Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "                \n",
    "    print(f'******* Final Testing Loss: {running_loss / (i+1)} *******\\n')\n",
    "\n",
    "    batch_sizes.append(checkpoint['mini_batch'])\n",
    "    losses.append(running_loss / (i+1))\n",
    "                \n",
    "    # Save ground-truths and probability results¶\n",
    "    res = {}\n",
    "    res[\"ground_truths\"] = ground_truths\n",
    "    res[\"probs\"] = probs\n",
    "    res[\"num_batches\"] = checkpoint['mini_batch']\n",
    "    res[\"testing_loss\"] = running_loss / (i+1)\n",
    "\n",
    "    pkl_f_name = f'./saved_results3_tmp/results_ResNet152_{checkpoint[\"mini_batch\"]}b.pkl'\n",
    "    with open(pkl_f_name, 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "\n",
    "        \n",
    "plt.plot(batch_sizes, losses, 'o')\n",
    "plt.title(\"Testing Loss Over Time\")\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Overall Testing Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f86c7e",
   "metadata": {},
   "source": [
    "## Choose the results from the best performing model (training size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# in case pkl results were calculated in batch job\n",
    "# we may wont to visualize the test plot over time\n",
    "recalc_loss_plot = True\n",
    "\n",
    "if recalc_loss_plot:\n",
    "    \n",
    "    batch_sizes = []\n",
    "    losses = []\n",
    "    res_fnames = os.listdir('./saved_results3_tmp/')\n",
    "    \n",
    "    for fname in res_fnames:\n",
    "        with open(f'./saved_results3_tmp/{fname}', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            batch_sizes.append(res[\"num_batches\"])\n",
    "            losses.append(res[\"testing_loss\"]) \n",
    "            \n",
    "            \n",
    "            gt = res[\"ground_truths\"]\n",
    "            probs = np.array(res[\"probs\"])\n",
    "\n",
    "            # match formats (shouldve done this before, forgot to check)\n",
    "            ground_truths = []\n",
    "            for i in range(len(gt)):\n",
    "                if gt[i].size() > torch.Size([1]):\n",
    "                    ground_truths += gt[i].squeeze(-1).tolist()\n",
    "                else:\n",
    "                    ground_truths.append(gt[i].squeeze(-1).tolist())\n",
    "\n",
    "            ground_truths = np.array(ground_truths)\n",
    "            print(f\"[Batch {res['num_batches']}] Size Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs), \"\\n\")\n",
    "            \n",
    "    \n",
    "    plt.plot(batch_sizes, losses, 'o')\n",
    "    plt.title(\"Testing Loss Over Time\")\n",
    "    plt.xlabel(\"Batch Number\")\n",
    "    plt.ylabel(\"Overall Testing Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size = 21350\n",
    "\n",
    "\n",
    "with open(f'./saved_results3/results_ResNet50_{best_batch_size}b.pkl', 'rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    \n",
    "    \n",
    "gt = res[\"ground_truths\"]\n",
    "probs = np.array(res[\"probs\"])\n",
    "\n",
    "\n",
    "# match formats (shouldve done this before, forgot to check)\n",
    "ground_truths = []\n",
    "for i in range(len(gt)):\n",
    "    if gt[i].size() > torch.Size([1]):\n",
    "        ground_truths += gt[i].squeeze(-1).tolist()\n",
    "    else:\n",
    "        ground_truths.append(gt[i].squeeze(-1).tolist())\n",
    "        \n",
    "ground_truths = np.array(ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc478afa",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8fc4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(ground_truths, probs)\n",
    "recall = tpr\n",
    "\n",
    "# compute other metrics using the same thresholds\n",
    "specificity = np.zeros_like(tpr)\n",
    "precision = np.zeros_like(tpr)\n",
    "fbetascores = np.zeros_like(tpr)\n",
    "CKappas = np.zeros_like(tpr)\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    preds = probs > thresholds[i]\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(ground_truths, preds).ravel()\n",
    "    \n",
    "    specificity[i] = tn / (tn + fp)\n",
    "    precision[i] = tp / (tp + fp)\n",
    "    \n",
    "    # more attention put on recall, such as when false negatives are more important to\n",
    "    # minimize, but false positives are still important.\n",
    "    fbetascores[i] = metrics.fbeta_score(ground_truths, preds, beta = 2)\n",
    "    \n",
    "    CKappas[i] = metrics.cohen_kappa_score(ground_truths, preds,)\n",
    "    \n",
    "\n",
    "\n",
    "gmeans = np.sqrt(specificity * recall)\n",
    "\n",
    "\n",
    "print(\"Max F2-Score is:\", np.nanmax(fbetascores))\n",
    "print(\"Max G-Mean is:\", np.nanmax(gmeans))\n",
    "print(\"Max Cohen's Kappa is:\", np.nanmax(CKappas))\n",
    "\n",
    "\n",
    "print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs), \"\\n\")\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr[np.nanargmax(fbetascores)], tpr[np.nanargmax(fbetascores)], 'ro')\n",
    "plt.plot(fpr[np.nanargmax(gmeans)], tpr[np.nanargmax(gmeans)], 'go')\n",
    "plt.plot(fpr[np.nanargmax(CKappas)], tpr[np.nanargmax(CKappas)], 'yo')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(['ROC Curve', 'F2-Score Optimal Coordinates', 'G-Mean Optimal Coordinates', \n",
    "            \"Kappa's Optimal Coordinates\"], loc='lower right', prop={'size': 8}, \n",
    "           frameon=True, facecolor = 'white')\n",
    "plt.show()\n",
    "\n",
    "fb_opt_thresh = thresholds[np.nanargmax(fbetascores)]\n",
    "fb_opt_preds = probs > fb_opt_thresh\n",
    "\n",
    "print('\\n********************* USING F2-SCORE OPTIMAL THRESHOLD *************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, fb_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(fbetascores)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(fbetascores)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(fbetascores)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(fbetascores)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(fbetascores)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(fbetascores)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "gm_opt_thresh = thresholds[np.nanargmax(gmeans)]\n",
    "gm_opt_preds = probs > gm_opt_thresh\n",
    "\n",
    "print('\\n********************** USING G-MEAN OPTIMAL THRESHOLD **************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, gm_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(gmeans)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(gmeans)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(gmeans)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(gmeans)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(gmeans)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(gmeans)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "\n",
    "ck_opt_thresh = thresholds[np.nanargmax(CKappas)]\n",
    "ck_opt_preds = probs > ck_opt_thresh\n",
    "\n",
    "print('\\n********************** USING KAPPA OPTIMAL THRESHOLD ***************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, ck_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(CKappas)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(CKappas)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(CKappas)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(CKappas)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(CKappas)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(CKappas)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "\n",
    "accuracy_scores = []\n",
    "for thresh in thresholds:\n",
    "    accuracy_scores.append(metrics.accuracy_score(ground_truths, [m > thresh for m in probs]))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(thresholds, fbetascores, \"-r\")\n",
    "plt.plot(thresholds, gmeans, \"-g\")\n",
    "plt.plot(thresholds, CKappas, \"-y\")\n",
    "plt.title(\"F2-Score, G-Means, and Cohen's Kappa Curves\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Performance Metrics\")\n",
    "plt.legend(['F2-Score', 'G-Mean', \"Cohen's Kappa\"], loc='upper right',\n",
    "           frameon=True, facecolor = 'white')\n",
    "plt.show()    \n",
    "    \n",
    "\n",
    "plt.plot(thresholds, accuracy_scores)\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAS Pytorch CUDA",
   "language": "python",
   "name": "mas_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
