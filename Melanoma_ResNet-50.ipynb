{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030ccd3",
   "metadata": {},
   "source": [
    "# Melanoma Detection with the ResNet-50 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce87f3",
   "metadata": {},
   "source": [
    "This code was used in the Hoffman2 Linux Compute Cluster, making use of UCLA's high performance cloud computing resources like the Tesla P4 - GPU (6.1 Compute Capability, 2560 CUDA Cores, 8GB) with additional 32GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460317",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad9aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1e190",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a1310",
   "metadata": {},
   "source": [
    "General histograms and bar charts for frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262eb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of positives: 0.017589052123163616\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXqUlEQVR4nO3df/BddX3n8eeLRBChFCiBjQkY3EYtsKNIZENxXCt2yYoa2so0rEjsspNZSl3t2O0GZ7fV6WYHZxynsi1sqVpCccUs/iALotJU12UXxS9VF8OPkgUkWQKJOgi4LQq894/7Qa7JN9/vDST3m3w/z8fMnXvO+3zOPZ9zku/rnu/nnnu+qSokSX04YKY7IEkaH0Nfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr5mXJKNSV4/0/2YSUl+LcnmJI8nOXmm+6PZy9DXXpXk/iRv3KH2ziQ3PzNfVSdW1VemeZ1FSSrJ3L3U1Zn2IeB3qurQqvrmZA0ycG+SO8bcN80ihr4E7ANvJi8BNk7T5nXA0cBLk7xm73dJs5Ghrxk3/NtAklOTTCR5NMnDST7cmn21PT/ShkBOS3JAkn+X5LtJtiW5KsnPD73u+W3Z95P8+x228/4k1ya5OsmjwDvbtm9J8kiSrUn+JMmBQ69XSX47yT1JHkvyR0n+YVvn0STrhtvvsI+T9jXJQUkeB+YA307yf6Y4VCuB64DPt+nh1z8+yVdbv/4qyZ8muXpo+dIk/6vt27eHh9Pab173tnXvS/L2af7JtD+rKh8+9toDuB944w61dwI3T9YGuAV4R5s+FFjaphcBBcwdWu9fAJuAl7a2nwH+si07AXgceC1wIIPhk58Mbef9bf5sBic/BwOnAEuBuW17dwLvGdpeAeuBw4ATgSeADW37Pw/cAazcxXHYZV+HXvsXpziOLwIeBd4E/AbwPeDAoeW3tH08sO3zo8DVbdkC4Ptt3QOAX23z84BDWtuXt7bzgRNn+v+Nj7338Exf4/C5dob5SJJHgMumaPsT4BeTHFVVj1fV16Zo+3bgw1V1b1U9DlwMrGhDNW8D/ltV3VxVPwb+gEGwDrulqj5XVU9X1d9V1W1V9bWqerKq7gf+DPgnO6zzwap6tKo2At8BvtS2/0PgRmBXH8JO1ddR/DqDN5kvAdczeGM6CyDJccBrgD+oqh9X1c0M3pyecR7w+ar6fNvXm4AJBm8CAE8DJyU5uKq2tn3TLGXoaxzOrqrDn3kAvz1F2wuAlwF3JflGkjdP0fbFwHeH5r/LIAyPacs2P7Ogqv4fg7PbYZuHZ5K8LMn1SR5qQz7/EThqh3UeHpr+u0nmD30OfR3FSmBde0N6gsFvCs8M8bwY+EHbx2cM79tLgHN2eON9LTC/qn4E/Cbwr4CtSW5I8ooR+6T9kKGvfUpV3VNV5zL4wPKDwLVJDmHns3SABxkE2jOOA55kEMRbgYXPLEhyMPALO25uh/nLgbuAxVV1GPA+IM99b0bu65SSLATeAJzX3pAeYvCbzJuSHMVgX49M8qKh1Y4dmt7MYCjp8KHHIVV1CUBVfbGqfpXB0M5dwJ8/993Uvs7Q1z4lyXlJ5lXV08AjrfwUsJ3BMMRLh5p/Evjd9iHmoQzOzD9VVU8C1wJvSfLL7cPVDzB9gP8cg/Htx9vZ7oV7ar+m6et03gH8LfBy4FXt8TJgC3BuVX2XwXDN+5McmOQ04C1D61/N4FicmWROkhcmeX2ShUmOSfLW9sb6BIPPQZ7aI3usfZKhr33NMmBju6LlI8CKqvr7NnSxBvifbYhiKfBx4C8ZXNlzH/D3wLsA2rj0u4BrGJwJPwZsYxBsu/J7wD9vbf8c+NQe3K9d9nUEK4HLquqh4Qfwn3l2iOftwGkMhrD+Q+v7EwBVtRlYzuA3l+0Mzvz/DYOf/wOA9zL4TeQHDD7DmGr4Tfu5VPlHVDT7tbPrRxgM3dw3w93Z65J8Crirqv5wpvuifYtn+pq1krwlyYva0MWHgNsZXB466yR5TfvOwAFJljE4s//cDHdL+yBDX7PZcgbDFg8CixkMFc3WX23/AfAVBmPylwIX1i5u56C+ObwjSR3xTF+SOjLTN5ma1lFHHVWLFi2a6W5I0n7ltttu+15Vzduxvs+H/qJFi5iYmJjpbkjSfiXJdyerO7wjSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kd2ee/kSvtqxatvmHGtn3/JWfN2La1f/NMX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZKTQT3J4kmuT3JXkziSnJTkyyU1J7mnPRwy1vzjJpiR3JzlzqH5KktvbskuTZG/slCRpcqOe6X8E+EJVvQJ4JXAnsBrYUFWLgQ1tniQnACuAE4FlwGVJ5rTXuRxYBSxuj2V7aD8kSSOYNvSTHAa8DvgYQFX9uKoeAZYDa1uztcDZbXo5cE1VPVFV9wGbgFOTzAcOq6pbqqqAq4bWkSSNwShn+i8FtgN/keSbST6a5BDgmKraCtCej27tFwCbh9bf0moL2vSO9Z0kWZVkIsnE9u3bd2uHJEm7NkrozwVeDVxeVScDP6IN5ezCZOP0NUV952LVFVW1pKqWzJs3b4QuSpJGMUrobwG2VNXX2/y1DN4EHm5DNrTnbUPtjx1afyHwYKsvnKQuSRqTaUO/qh4CNid5eSudAdwBrAdWttpK4Lo2vR5YkeSgJMcz+MD21jYE9FiSpe2qnfOH1pEkjcHcEdu9C/hEkgOBe4HfYvCGsS7JBcADwDkAVbUxyToGbwxPAhdV1VPtdS4ErgQOBm5sD0nSmIwU+lX1LWDJJIvO2EX7NcCaSeoTwEm70T9J0h7kN3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI6P+uURJ+5BFq2+Yke3ef8lZM7Jd7Tme6UtSRwx9SeqIoS9JHTH0JakjI4V+kvuT3J7kW0kmWu3IJDcluac9HzHU/uIkm5LcneTMofop7XU2Jbk0Sfb8LkmSdmV3zvR/papeVVVL2vxqYENVLQY2tHmSnACsAE4ElgGXJZnT1rkcWAUsbo9lz38XJEmjej7DO8uBtW16LXD2UP2aqnqiqu4DNgGnJpkPHFZVt1RVAVcNrSNJGoNRQ7+ALyW5LcmqVjumqrYCtOejW30BsHlo3S2ttqBN71iXJI3JqF/OOr2qHkxyNHBTkrumaDvZOH1NUd/5BQZvLKsAjjvuuBG7KEmazkhn+lX1YHveBnwWOBV4uA3Z0J63teZbgGOHVl8IPNjqCyepT7a9K6pqSVUtmTdv3uh7I0ma0rShn+SQJD/3zDTwT4HvAOuBla3ZSuC6Nr0eWJHkoCTHM/jA9tY2BPRYkqXtqp3zh9aRJI3BKMM7xwCfbVdXzgX+S1V9Ick3gHVJLgAeAM4BqKqNSdYBdwBPAhdV1VPttS4ErgQOBm5sD0nSmEwb+lV1L/DKSerfB87YxTprgDWT1CeAk3a/m5KkPcFv5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkZFDP8mcJN9Mcn2bPzLJTUnuac9HDLW9OMmmJHcnOXOofkqS29uyS5Nkz+6OJGkqu3Om/27gzqH51cCGqloMbGjzJDkBWAGcCCwDLksyp61zObAKWNwey55X7yVJu2Wk0E+yEDgL+OhQeTmwtk2vBc4eql9TVU9U1X3AJuDUJPOBw6rqlqoq4KqhdSRJYzDqmf4fA78PPD1UO6aqtgK056NbfQGweajdllZb0KZ3rO8kyaokE0kmtm/fPmIXJUnTmTb0k7wZ2FZVt434mpON09cU9Z2LVVdU1ZKqWjJv3rwRNytJms7cEdqcDrw1yZuAFwKHJbkaeDjJ/Kra2oZutrX2W4Bjh9ZfCDzY6gsnqUuSxmTaM/2quriqFlbVIgYf0P51VZ0HrAdWtmYrgeva9HpgRZKDkhzP4APbW9sQ0GNJlrards4fWkeSNAajnOnvyiXAuiQXAA8A5wBU1cYk64A7gCeBi6rqqbbOhcCVwMHAje0hSRqT3Qr9qvoK8JU2/X3gjF20WwOsmaQ+AZy0u52UJO0Zz+dMX/qpRatvmLFt33/JWTO2bWl/420YJKkjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRb7gmaWQzdWM9b6q353imL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerItKGf5IVJbk3y7SQbk3yg1Y9MclOSe9rzEUPrXJxkU5K7k5w5VD8lye1t2aVJsnd2S5I0mVHO9J8A3lBVrwReBSxLshRYDWyoqsXAhjZPkhOAFcCJwDLgsiRz2mtdDqwCFrfHsj23K5Kk6Uwb+jXweJt9QXsUsBxY2+prgbPb9HLgmqp6oqruAzYBpyaZDxxWVbdUVQFXDa0jSRqDkcb0k8xJ8i1gG3BTVX0dOKaqtgK056Nb8wXA5qHVt7Tagja9Y32y7a1KMpFkYvv27buxO5KkqYwU+lX1VFW9CljI4Kz9pCmaTzZOX1PUJ9veFVW1pKqWzJs3b5QuSpJGsFtX71TVI8BXGIzFP9yGbGjP21qzLcCxQ6stBB5s9YWT1CVJYzLK1Tvzkhzepg8G3gjcBawHVrZmK4Hr2vR6YEWSg5Icz+AD21vbENBjSZa2q3bOH1pHkjQGo9xPfz6wtl2BcwCwrqquT3ILsC7JBcADwDkAVbUxyTrgDuBJ4KKqeqq91oXAlcDBwI3tIUkak2lDv6r+N3DyJPXvA2fsYp01wJpJ6hPAVJ8HSJL2Ir+RK0kdMfQlqSOGviR1xNCXpI6McvWOtE9btPqGme6CtN/wTF+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkemDf0kxyb5cpI7k2xM8u5WPzLJTUnuac9HDK1zcZJNSe5OcuZQ/ZQkt7dllybJ3tktSdJkRjnTfxJ4b1X9ErAUuCjJCcBqYENVLQY2tHnashXAicAy4LIkc9prXQ6sAha3x7I9uC+SpGlMG/pVtbWq/qZNPwbcCSwAlgNrW7O1wNltejlwTVU9UVX3AZuAU5PMBw6rqluqqoCrhtaRJI3Bbo3pJ1kEnAx8HTimqrbC4I0BOLo1WwBsHlptS6staNM71ifbzqokE0kmtm/fvjtdlCRNYeTQT3Io8GngPVX16FRNJ6nVFPWdi1VXVNWSqloyb968UbsoSZrGSKGf5AUMAv8TVfWZVn64DdnQnre1+hbg2KHVFwIPtvrCSeqSpDEZ5eqdAB8D7qyqDw8tWg+sbNMrgeuG6iuSHJTkeAYf2N7ahoAeS7K0veb5Q+tIksZg7ghtTgfeAdye5Fut9j7gEmBdkguAB4BzAKpqY5J1wB0Mrvy5qKqeautdCFwJHAzc2B6SpDGZNvSr6mYmH48HOGMX66wB1kxSnwBO2p0OSpL2HL+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUkVEu2dR+ZNHqG2a6C5L2YZ7pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6Mm3oJ/l4km1JvjNUOzLJTUnuac9HDC27OMmmJHcnOXOofkqS29uyS5Nkz++OJGkqo/zlrCuBPwGuGqqtBjZU1SVJVrf5f5vkBGAFcCLwYuCvkrysqp4CLgdWAV8DPg8sA27cUzsiafaayb8Id/8lZ83YtveGac/0q+qrwA92KC8H1rbptcDZQ/VrquqJqroP2AScmmQ+cFhV3VJVxeAN5GwkSWP1XMf0j6mqrQDt+ehWXwBsHmq3pdUWtOkd65NKsirJRJKJ7du3P8cuSpJ2tKc/yJ1snL6mqE+qqq6oqiVVtWTevHl7rHOS1LvnGvoPtyEb2vO2Vt8CHDvUbiHwYKsvnKQuSRqj5xr664GVbXolcN1QfUWSg5IcDywGbm1DQI8lWdqu2jl/aB1J0phMe/VOkk8CrweOSrIF+EPgEmBdkguAB4BzAKpqY5J1wB3Ak8BF7codgAsZXAl0MIOrdrxyR5LGbNrQr6pzd7HojF20XwOsmaQ+AZy0W72TJO1RfiNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdmfYPo0tSzxatvmFGtnv/JWftldf1TF+SOuKZ/l4wU2cGkjSdsZ/pJ1mW5O4km5KsHvf2JalnYw39JHOAPwX+GXACcG6SE8bZB0nq2bjP9E8FNlXVvVX1Y+AaYPmY+yBJ3Rr3mP4CYPPQ/BbgH+/YKMkqYFWbfTzJ3c9xe0cB33uO685GHo9neSx+lsfjWfvEscgHn/dLvGSy4rhDP5PUaqdC1RXAFc97Y8lEVS15vq8zW3g8nuWx+Fkej2fN9mMx7uGdLcCxQ/MLgQfH3AdJ6ta4Q/8bwOIkxyc5EFgBrB9zHySpW2Md3qmqJ5P8DvBFYA7w8arauBc3+byHiGYZj8ezPBY/y+PxrFl9LFK105C6JGmW8jYMktQRQ1+SOjIrQ7/3Wz0kOTbJl5PcmWRjkne3+pFJbkpyT3s+Yqb7Oi5J5iT5ZpLr23zPx+LwJNcmuav9Hzmt8+Pxu+3n5DtJPpnkhbP5eMy60PdWDwA8Cby3qn4JWApc1I7BamBDVS0GNrT5XrwbuHNovudj8RHgC1X1CuCVDI5Ll8cjyQLgXwNLquokBheYrGAWH49ZF/p4qweqamtV/U2bfozBD/UCBsdhbWu2Fjh7Rjo4ZkkWAmcBHx0q93osDgNeB3wMoKp+XFWP0OnxaOYCByeZC7yIwXeHZu3xmI2hP9mtHhbMUF9mXJJFwMnA14FjqmorDN4YgKNnsGvj9MfA7wNPD9V6PRYvBbYDf9GGuz6a5BA6PR5V9X+BDwEPAFuBH1bVl5jFx2M2hv5It3roQZJDgU8D76mqR2e6PzMhyZuBbVV120z3ZR8xF3g1cHlVnQz8iFk0dLG72lj9cuB44MXAIUnOm9le7V2zMfS91QOQ5AUMAv8TVfWZVn44yfy2fD6wbab6N0anA29Ncj+Dob43JLmaPo8FDH4+tlTV19v8tQzeBHo9Hm8E7quq7VX1E+AzwC8zi4/HbAz97m/1kCQMxmzvrKoPDy1aD6xs0yuB68bdt3GrqouramFVLWLwf+Gvq+o8OjwWAFX1ELA5yctb6QzgDjo9HgyGdZYmeVH7uTmDwWdgs/Z4zMpv5CZ5E4Nx3Gdu9bBmZns0XkleC/wP4HaeHcd+H4Nx/XXAcQz+s59TVT+YkU7OgCSvB36vqt6c5Bfo9FgkeRWDD7UPBO4FfovBCWCvx+MDwG8yuOrtm8C/BA5llh6PWRn6kqTJzcbhHUnSLhj6ktQRQ1+SOmLoS1JHDH1J6oihL+1Ckl9LUkleMdN9kfYUQ1/atXOBmxl8qUuaFQx9aRLtvkWnAxfQQj/JAUkua/devz7J55O8rS07Jcl/T3Jbki8+8xV+aV9j6EuTO5vBPef/FvhBklcDvw4sAv4Rg29tngY/vc/RfwLeVlWnAB8HuvoWuPYfc2e6A9I+6lwGt/KAwY3azgVeAPzXqnoaeCjJl9vylwMnATcNbt/CHAa36ZX2OYa+tIN2X543ACclKQYhXsBnd7UKsLGqThtTF6XnzOEdaWdvA66qqpdU1aKqOha4D/ge8BttbP8Y4PWt/d3AvCQ/He5JcuJMdFyajqEv7excdj6r/zSDP7KxBfgO8GcM7lr6w/ZnOd8GfDDJt4FvMbgnu7TP8S6b0m5IcmhVPd6GgG4FTm/3qJf2C47pS7vn+iSHM7gX/R8Z+NrfeKYvSR1xTF+SOmLoS1JHDH1J6oihL0kdMfQlqSP/HzlWtn5toYSmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mel_df = pd.read_csv(os.path.join('train_data', 'train.csv'))\n",
    "gt = mel_df['target']\n",
    "isic_id = mel_df['image_name']\n",
    "\n",
    "# proportion of postives\n",
    "print(\"Proportion of positives:\", np.mean(gt))\n",
    "\n",
    "plt.hist(mel_df['age_approx'])\n",
    "plt.title('Histogram of Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = mel_df['benign_malignant'],\n",
    "            y = mel_df['age_approx'])\n",
    "plt.title('Ages Grouped By Benign / Malignant Status')\n",
    "plt.xlabel('Benign / Malignant Status')\n",
    "plt.ylabel('Approximate Age')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(mel_df.sex.value_counts().index,  mel_df.sex.value_counts().values)\n",
    "plt.title('Sex / Gender in Dataset')\n",
    "plt.show()\n",
    "\n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, mel_df.anatom_site_general_challenge.value_counts().values)\n",
    "plt.title('Lesion Locations in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb11e5",
   "metadata": {},
   "source": [
    "Tests to find potential correlation between target variables and other categorical variables such as sex/gender or lesion location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101b246a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\n",
      "benign_malignant  benign  malignant\n",
      "sex                                \n",
      "female             11824        170\n",
      "male               12535        267\n",
      "Chi-Squared test of independence (P-value): 7.87631386486258e-05 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\n",
      "anatom_site_general_challenge  head/neck  lower extremity  oral/genital  \\\n",
      "sex                                                                       \n",
      "female                               629             3363            33   \n",
      "male                                 767             2966            57   \n",
      "\n",
      "anatom_site_general_challenge  palms/soles  torso  upper extremity  \n",
      "sex                                                                 \n",
      "female                                 111   5683             2001  \n",
      "male                                   169   6926             1698  \n",
      "Chi-Squared test of independence (P-value): 3.917186815096256e-37 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['benign_malignant'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df1 = mel_df.groupby(['sex']).mean()\n",
    "plt.bar(mel_df.sex.value_counts().index,  g_df1['target'].values)\n",
    "plt.title(\"Proportion of positives by Sex / Gender\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\\n******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['anatom_site_general_challenge'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df2 = mel_df.groupby(['anatom_site_general_challenge']).mean() \n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, g_df2['target'].values)\n",
    "plt.title(\"Proportion of positives by Lesion Location\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713af71",
   "metadata": {},
   "source": [
    "## ResNet-50 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efcaad",
   "metadata": {},
   "source": [
    "Set device as CPU, or GPU if available. Code will have to change if using multiple GPUs (cuda:0, cuda:1, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eba207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of devices: 36\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    n_workers = os.cpu_count()\n",
    "else:\n",
    "    n_workers = torch.cuda.device_count()\n",
    "\n",
    "# If on a CUDA machine, this should print a CUDA device:\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of devices:\", n_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cea86",
   "metadata": {},
   "source": [
    "We create a custom dataset loader class to use the ID and target information from the CSV to properly load our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset to load in with the benign \n",
    "# and malignant images in the same directory\n",
    "class ISICDatasetImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, patientfile, num_samples=100, start_ind=0, up_sample=False, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        mel_df = pd.read_csv(patientfile) \n",
    "        \n",
    "        if up_sample:\n",
    "            \n",
    "            # Separate majority and minority classes\n",
    "            df_benign = mel_df[mel_df['target']==0]\n",
    "            df_malignant = mel_df[mel_df['target']==1]\n",
    "            \n",
    "\n",
    "            # sample minority class\n",
    "            df_benign_sampled = resample(df_benign, \n",
    "                                         replace=True,     # sample with replacement\n",
    "                                         n_samples=num_samples//2)\n",
    "            \n",
    "\n",
    "            # Upsample minority class\n",
    "            df_malignant_upsampled = resample(df_malignant, \n",
    "                                              replace=True,     # sample with replacement\n",
    "                                              n_samples=num_samples//2)\n",
    "            \n",
    "            # Combine majority class with upsampled minority class\n",
    "            mel_df = pd.concat([df_benign_sampled, df_malignant_upsampled])\n",
    "            \n",
    "            # randomly mix them up (not necessary due to shuffling in dataloader)\n",
    "            mel_df = shuffle(mel_df)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.start_ind = start_ind\n",
    "            self.end_ind = start_ind+num_samples\n",
    "\n",
    "            if self.end_ind > len(mel_df):\n",
    "                self.end_ind = len(mel_df)\n",
    "        \n",
    "            mel_df = mel_df[self.start_ind:self.end_ind]\n",
    "            \n",
    "        self.gt = mel_df['target'].reset_index(drop=True)\n",
    "        self.isic_id = mel_df['image_name'].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{self.isic_id[idx]}.jpg\")\n",
    "        img = read_image(img_path).float()\n",
    "        class_id = torch.tensor([self.gt[idx]])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        \n",
    "        return img, class_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c73fa",
   "metadata": {},
   "source": [
    "We create a custom collate function to pad lower resolution images with zeros to maintain a constant high resolution of 3x4000x6000 for the CNN to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364d0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that a CNN needs the inputs to be the same dimension so we \n",
    "# custom collate function to pad small res images with 0s if they are not 3x4000x6000\n",
    "def pad_collate2d(batch):\n",
    "    \n",
    "    # init lists\n",
    "    image_list, label_list = [], []\n",
    "   \n",
    "    for _image, _label in batch:\n",
    "        \n",
    "        image_list.append(torch.unsqueeze(_image, dim=0))\n",
    "        label_list.append(_label)\n",
    "        \n",
    "\n",
    "    image_out = torch.cat(image_list, dim=0) \n",
    "    label_out = torch.tensor(label_list, dtype=torch.int64)\n",
    "   \n",
    "    return image_out, label_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "# set our batch size\n",
    "batch_size = 16\n",
    "\n",
    "tr_transf = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.RandomHorizontalFlip(p=0.3),\n",
    "     transforms.RandomVerticalFlip(p=0.3),\n",
    "     transforms.RandomApply(torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=(5, 7), sigma=(0.1, 2))]), p=0.2),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "     transforms.RandomErasing(scale=(0.02, 0.05), p=0.2)\n",
    "    ])\n",
    "\n",
    "val_transf = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "train_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data256x256\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data256x256\", \"train.csv\"), \n",
    "                            num_samples=5*2*24408, up_sample=True, start_ind=0, transform=tr_transf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=pad_collate2d, \n",
    "                          num_workers=n_workers)\n",
    "\n",
    "\n",
    "val_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data256x256\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data256x256\", \"val.csv\"), \n",
    "                            num_samples=2*100, up_sample=True, start_ind=0, transform=val_transf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=pad_collate2d, \n",
    "                        num_workers=n_workers)\n",
    "\n",
    "\n",
    "\n",
    "# test DataLoader with custom settings\n",
    "if testing:\n",
    "    for imgs, labels in train_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ef7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show the image\n",
    "def imshow(img):\n",
    "    mean=[0.485, 0.456, 0.406]\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    \n",
    "    img = img * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg.astype('int'), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "label_id = [\"Benign\", \"Malignant\"]\n",
    "\n",
    "if testing:\n",
    "    # get some random training images\n",
    "    trainiter = iter(train_loader)\n",
    "    images, labels = next(trainiter)\n",
    "    print(\"Size:\", images.shape)\n",
    "\n",
    "\n",
    "    # show images\n",
    "    imshow(images[0,])\n",
    "\n",
    "    # print labels\n",
    "    print(\"Label:\", label_id[labels[0,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e4f1",
   "metadata": {},
   "source": [
    "Sample and image from the data loader object to confirm it worked. Continue to run the cell for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d401950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the pre-trained CNN weights.\n",
      "CUDA Memory Allocated: 0\n"
     ]
    }
   ],
   "source": [
    "load_weights = True\n",
    "create_new_weights = False\n",
    "PATH = './melanoma_ResNet50.pth'\n",
    "\n",
    "if load_weights:\n",
    "    print('Loading the pre-trained CNN weights.')\n",
    "    \n",
    "    # network weights load\n",
    "    net = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # optimizer state load\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.fc.parameters(), weight_decay=0.01)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
    "    lr_sched.load_state_dict(checkpoint['lr_sched'])\n",
    "    \n",
    "    # total mini_batch state load\n",
    "    mini_batch = checkpoint['mini_batch']\n",
    "    \n",
    "    print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "    \n",
    "elif create_new_weights:\n",
    "    print('Creating new ResNet-50 FC Layer weights.')\n",
    "    \n",
    "    net = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "    \n",
    "    \n",
    "    mini_batch = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.fc.parameters(), weight_decay=0.001)\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b13966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Training CUDA Memory Allocation: 0\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 514] Loss: 0.434357225894928\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8971000000000001\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 515] Loss: 0.33932800590991974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 516] Loss: 0.2845689505338669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 517] Loss: 0.34869641438126564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 518] Loss: 0.3305444806814194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 519] Loss: 0.33791696776946384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 520] Loss: 0.3252251275948116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 521] Loss: 0.349957387894392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 522] Loss: 0.3526595201757219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 523] Loss: 0.3479181110858917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 524] Loss: 0.34271072257648816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 525] Loss: 0.33451936890681583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 526] Loss: 0.3266209570261148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 527] Loss: 0.33688919246196747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 528] Loss: 0.35385819474856056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 529] Loss: 0.3524349480867386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 530] Loss: 0.3516888758715461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 531] Loss: 0.35749996536307865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 532] Loss: 0.35309699020887675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 533] Loss: 0.3516256019473076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 534] Loss: 0.3543063870498112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 535] Loss: 0.3525621565905484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 536] Loss: 0.34674179489197937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 537] Loss: 0.34718877635896206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 538] Loss: 0.3394222581386566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 539] Loss: 0.3385220548281303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 540] Loss: 0.3444531670323125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 541] Loss: 0.34811024154935566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 542] Loss: 0.3435314431272704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 543] Loss: 0.3446688582499822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 544] Loss: 0.3453873626647457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 545] Loss: 0.3416208829730749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 546] Loss: 0.3357958247264226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 547] Loss: 0.3379860998076551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 548] Loss: 0.3365385264158249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 549] Loss: 0.3312852780024211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 550] Loss: 0.3365699793841388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 551] Loss: 0.33337122201919556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 552] Loss: 0.3304779017582918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 553] Loss: 0.3265955042093992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 554] Loss: 0.32183194996380227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 555] Loss: 0.3215762089405741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 556] Loss: 0.31947715961655904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 557] Loss: 0.31746714223514905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 558] Loss: 0.32428238259421455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 559] Loss: 0.3352066071137138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 560] Loss: 0.33181324474355006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 561] Loss: 0.3335264927397172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 562] Loss: 0.33130425701335986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 563] Loss: 0.3313745331764221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 564] Loss: 0.3303210606762007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 565] Loss: 0.32903103816967744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 566] Loss: 0.3339413724980264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 567] Loss: 0.3319591361063498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 568] Loss: 0.33049652684818615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 569] Loss: 0.328614704310894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 570] Loss: 0.3304081255929512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 571] Loss: 0.3313406988464553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 572] Loss: 0.3323613339561527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 573] Loss: 0.3319058954715729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 574] Loss: 0.3319791052185121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 575] Loss: 0.33155492861424724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 576] Loss: 0.3327426328545525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 577] Loss: 0.3338930965401232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 578] Loss: 0.33382730392309334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 579] Loss: 0.3359606862068176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 580] Loss: 0.33858607242356487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 581] Loss: 0.3373490256421706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 582] Loss: 0.3402648378109586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 583] Loss: 0.3391511980976377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 584] Loss: 0.34229227816554864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 585] Loss: 0.3416610471904278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 586] Loss: 0.3424029015514949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 587] Loss: 0.34234306699520833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 588] Loss: 0.3419514052073161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 589] Loss: 0.3411722543992494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 590] Loss: 0.3433274154539232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 591] Loss: 0.3425514086698874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 592] Loss: 0.3411036260143111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 593] Loss: 0.3399791790172458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 594] Loss: 0.33862832133416776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 595] Loss: 0.3368106220917004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 596] Loss: 0.33715408771152955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 597] Loss: 0.33662240615203265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 598] Loss: 0.3370165451484568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 599] Loss: 0.33665582069823907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 600] Loss: 0.33630611276489564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 601] Loss: 0.3351592519743876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 602] Loss: 0.3356761329629448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 603] Loss: 0.3342491750915845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 604] Loss: 0.33540426456666256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 605] Loss: 0.3360514376798402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 606] Loss: 0.33751442788108704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 607] Loss: 0.33916575239693864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 608] Loss: 0.33977683453183427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 609] Loss: 0.34083916262413066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 610] Loss: 0.3390235914704726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 611] Loss: 0.33752492313482324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 612] Loss: 0.3388673187506319\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 613] Loss: 0.3386766776442528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 614] Loss: 0.3386979327343478\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 615] Loss: 0.338730968096677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 616] Loss: 0.33797351220279065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 617] Loss: 0.33718342878497565\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 618] Loss: 0.33580326565674373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 619] Loss: 0.33660800038081296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 620] Loss: 0.33924140871685243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 621] Loss: 0.3402805343546249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 622] Loss: 0.3403979984171894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 623] Loss: 0.33906391750682485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 624] Loss: 0.33926799463796187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 625] Loss: 0.33962944495890823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 626] Loss: 0.3397862423310238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 627] Loss: 0.3390412288799621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 628] Loss: 0.33837299606074456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 629] Loss: 0.3375872941366557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 630] Loss: 0.33614970756392193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 631] Loss: 0.3350543572993602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 632] Loss: 0.335814116757457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 633] Loss: 0.3354358423501253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 634] Loss: 0.3357160341394834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 635] Loss: 0.33686930881660493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 636] Loss: 0.3357018752069008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 637] Loss: 0.33580770163286117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 638] Loss: 0.3350491968393326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 639] Loss: 0.3348585945509729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 640] Loss: 0.3364555799350964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 641] Loss: 0.33544769778382033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 642] Loss: 0.33518914231496266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 643] Loss: 0.3365473714012366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 644] Loss: 0.33562910659167605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 645] Loss: 0.33651953879179375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 646] Loss: 0.3367481887116468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 647] Loss: 0.33649241312671063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 648] Loss: 0.33538877654958654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 649] Loss: 0.33586245358866806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 650] Loss: 0.3356629533924326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 651] Loss: 0.33538009960582293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 652] Loss: 0.3346313266016597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 653] Loss: 0.3339560067015035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 654] Loss: 0.3336823323728345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 655] Loss: 0.3335221755042882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 656] Loss: 0.3330633618406483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 657] Loss: 0.33357128428502214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 658] Loss: 0.3324949412510313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 659] Loss: 0.3323075095676396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 660] Loss: 0.3325281812220204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 661] Loss: 0.332447079387871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 662] Loss: 0.3340644252380269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 663] Loss: 0.33410312235355377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 664] Loss: 0.3347283455709748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 665] Loss: 0.3358233433805014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 666] Loss: 0.334800630515697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 667] Loss: 0.3354981031704259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 668] Loss: 0.33495807676546036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 669] Loss: 0.33459315630487907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 670] Loss: 0.33539098074102097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 671] Loss: 0.33585403755873067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 672] Loss: 0.33526872117189493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 673] Loss: 0.3357566551305354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 674] Loss: 0.3350676849762105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 675] Loss: 0.3346784865414655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 676] Loss: 0.3346692175587262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 677] Loss: 0.3340447002612963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 678] Loss: 0.3336295188376398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 679] Loss: 0.33403205252196416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 680] Loss: 0.3369779978505152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 681] Loss: 0.33619986350337666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 682] Loss: 0.3367073003356979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 683] Loss: 0.33833704941412984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 684] Loss: 0.33855263392130536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 685] Loss: 0.3378164756956489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 686] Loss: 0.33749598841791206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 687] Loss: 0.33690756927619037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 688] Loss: 0.3362033863578524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 689] Loss: 0.3358827107162638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 690] Loss: 0.33556311708048914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 691] Loss: 0.3363188239798117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 692] Loss: 0.3358549419894565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 693] Loss: 0.3356910497777992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 694] Loss: 0.3355254001544984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 695] Loss: 0.3349397844010657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 696] Loss: 0.33493281469319036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 697] Loss: 0.3353454838304416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 698] Loss: 0.33596716490951745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 699] Loss: 0.3371660964142892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 700] Loss: 0.33661472024445865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 701] Loss: 0.33726417249504553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 702] Loss: 0.33698993361500834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 703] Loss: 0.3373581943543334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 704] Loss: 0.33743866630561686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 705] Loss: 0.3373327940547218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 706] Loss: 0.3370599120546499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 707] Loss: 0.3376162850211576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 708] Loss: 0.33691462347140677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 709] Loss: 0.33733308657395594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 710] Loss: 0.33641394829084426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 711] Loss: 0.33717577016413813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 712] Loss: 0.3371204704645291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 713] Loss: 0.3370948202162981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 714] Loss: 0.337714084419445\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 715] Loss: 0.3375218884632139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 716] Loss: 0.33775189996059307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 717] Loss: 0.33756501074222955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 718] Loss: 0.3368777672692043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 719] Loss: 0.3367249374684778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 720] Loss: 0.33682759120556466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 721] Loss: 0.3363043617170591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 722] Loss: 0.33764402176204483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 723] Loss: 0.3373188734054565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 724] Loss: 0.33732338270869866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 725] Loss: 0.33736892606852187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 726] Loss: 0.33706765975191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 727] Loss: 0.3370385228473449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 728] Loss: 0.3368472344653551\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 729] Loss: 0.33646075441329565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 730] Loss: 0.33717059141479877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 731] Loss: 0.3377555420092486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 732] Loss: 0.3386374401719603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 733] Loss: 0.3379316218197346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 734] Loss: 0.3380278097423493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 735] Loss: 0.33722558221570004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 736] Loss: 0.337330436559536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 737] Loss: 0.3378371011598834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 738] Loss: 0.3378651358683904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 739] Loss: 0.3383478048232804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 740] Loss: 0.33845126845500545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 741] Loss: 0.33813917159772755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 742] Loss: 0.3383167419240985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 743] Loss: 0.33862688236910365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 744] Loss: 0.3384660046983075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 745] Loss: 0.33878728740944947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 746] Loss: 0.3383308117609679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 747] Loss: 0.3382378213553347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 748] Loss: 0.33935331746618796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 749] Loss: 0.3401724916519755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 750] Loss: 0.33995836577083494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 751] Loss: 0.339656134425592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 752] Loss: 0.3396768000709462\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 753] Loss: 0.3390710891534885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 754] Loss: 0.33900320270249457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 755] Loss: 0.3383897217837247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 756] Loss: 0.33919068668114305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 757] Loss: 0.33953235237324825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 758] Loss: 0.33876613938078587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 759] Loss: 0.3393181937981427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 760] Loss: 0.3389641275772682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 761] Loss: 0.33936584332296926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 762] Loss: 0.33880746969018116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 763] Loss: 0.3385175654292107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 764] Loss: 0.33782648648398805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 765] Loss: 0.3373758901679327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 766] Loss: 0.337189326173232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 767] Loss: 0.3372962275358636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 768] Loss: 0.33743636105574815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 769] Loss: 0.3368858206085861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 770] Loss: 0.337248499871228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 771] Loss: 0.33670344405858094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 772] Loss: 0.3367308298823456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 773] Loss: 0.33658439230460385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 774] Loss: 0.3364968651555964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 775] Loss: 0.3361651067060369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 776] Loss: 0.3367367508066924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 777] Loss: 0.33703836437427637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 778] Loss: 0.3373813476202623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 779] Loss: 0.33730665073358923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 780] Loss: 0.33784218316667536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 781] Loss: 0.3375855666487964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 782] Loss: 0.3375551388166208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 783] Loss: 0.3378592291363963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 784] Loss: 0.33765545751335874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 785] Loss: 0.33814064742011185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 786] Loss: 0.33798738910165027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 787] Loss: 0.3377673715135477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 788] Loss: 0.33708391785621644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 789] Loss: 0.33670860906873923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 790] Loss: 0.33708817530625135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 791] Loss: 0.3370085597681485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 792] Loss: 0.3363686629093676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 793] Loss: 0.3361946658364364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 794] Loss: 0.3362374399056214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 795] Loss: 0.3364768204748208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 796] Loss: 0.33713971989314884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 797] Loss: 0.3385621801438466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 798] Loss: 0.3389102738154562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 799] Loss: 0.3389390428791513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 800] Loss: 0.3388264140808624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 801] Loss: 0.33929548350473243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 802] Loss: 0.33868616097526155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 803] Loss: 0.33823819365994684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 804] Loss: 0.33795941531453344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 805] Loss: 0.33738956069701337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 806] Loss: 0.33715970341256046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 807] Loss: 0.33776717425203645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 808] Loss: 0.3375148186239146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 809] Loss: 0.3375555120811269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 810] Loss: 0.33768968299181773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 811] Loss: 0.3381858061024007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 812] Loss: 0.33876985461018155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 813] Loss: 0.3386099841197332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 814] Loss: 0.33864410731483535\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 815] Loss: 0.33849583072772876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 816] Loss: 0.33878763762637726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 817] Loss: 0.3387262205544271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 818] Loss: 0.338385608059461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 819] Loss: 0.3380453484315498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 820] Loss: 0.3375161517811909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 821] Loss: 0.3377840585232555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 822] Loss: 0.33761337375370815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 823] Loss: 0.33720242722380545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 824] Loss: 0.33784923230528446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 825] Loss: 0.3386015434964345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 826] Loss: 0.338656167871655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 827] Loss: 0.3382964556099503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 828] Loss: 0.338577026838348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 829] Loss: 0.3381251366455344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 830] Loss: 0.33816371543174284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 831] Loss: 0.3381083594553126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 832] Loss: 0.33808748456751664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 833] Loss: 0.33785803373903034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 834] Loss: 0.33760847044511005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 835] Loss: 0.33755527640351596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 836] Loss: 0.33821771268505063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 837] Loss: 0.3377240121272611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 838] Loss: 0.337153242459664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 839] Loss: 0.3370938038716287\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 840] Loss: 0.33771713419791755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 841] Loss: 0.337653227241301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 842] Loss: 0.337712946180877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 843] Loss: 0.3389788382884228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 844] Loss: 0.3396362254446727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 845] Loss: 0.33937454914831255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 846] Loss: 0.33926071275819886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 847] Loss: 0.33956356828441164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 848] Loss: 0.3395895820055435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 849] Loss: 0.340355832395809\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 850] Loss: 0.3406559355357988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 851] Loss: 0.342140899166553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 852] Loss: 0.3422888925293554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 853] Loss: 0.3417782140128753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 854] Loss: 0.34205588375018836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 855] Loss: 0.3416116802751669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 856] Loss: 0.34139459252183707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 857] Loss: 0.3410709045914023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 858] Loss: 0.3410887772190398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 859] Loss: 0.3408914132183687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 860] Loss: 0.3404958517389957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 861] Loss: 0.3400588810615156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 862] Loss: 0.33962177709385455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 863] Loss: 0.3397155499458313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 864] Loss: 0.3396866846288371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 865] Loss: 0.3400514536452564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 866] Loss: 0.33962082229660184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 867] Loss: 0.3391889855686554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 868] Loss: 0.3390254189430828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 869] Loss: 0.33879857794957213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 870] Loss: 0.3390200009533003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 871] Loss: 0.3394076535322147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 872] Loss: 0.3393423385440805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 873] Loss: 0.3391334963341554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 874] Loss: 0.33886372366110046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 875] Loss: 0.33855664071457164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 876] Loss: 0.33880946467073825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 877] Loss: 0.3392932862862126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 878] Loss: 0.33906086707768374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 879] Loss: 0.3389900153289076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 880] Loss: 0.3390190245669934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 881] Loss: 0.3386006198985421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 882] Loss: 0.33819838231656607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 883] Loss: 0.33773114387248016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 884] Loss: 0.3379563896884173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 885] Loss: 0.3377546732544258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 886] Loss: 0.3382366312812544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 887] Loss: 0.3385528299339952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 888] Loss: 0.3380315728187561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 889] Loss: 0.33781807164245464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 890] Loss: 0.3383129192442097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 891] Loss: 0.3379500461003137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 892] Loss: 0.3375191722743429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 893] Loss: 0.339281535109407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 894] Loss: 0.3395057888090454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 895] Loss: 0.33980328862735737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 896] Loss: 0.3393429998629398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 897] Loss: 0.33920408436097205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 898] Loss: 0.33946481656718563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 899] Loss: 0.33962243031034817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 900] Loss: 0.3392423929247129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 901] Loss: 0.33922463167727607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 902] Loss: 0.33962824569110084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 903] Loss: 0.3392345054409443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 904] Loss: 0.3390842500473837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 905] Loss: 0.3394969924904254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 906] Loss: 0.3393766500491829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 907] Loss: 0.33889550178637967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 908] Loss: 0.3390514147809789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 909] Loss: 0.33909667053758497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 910] Loss: 0.3396954422708723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 911] Loss: 0.3393681502746577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 912] Loss: 0.3389872846223955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 913] Loss: 0.3387854727730155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 914] Loss: 0.3386312693060188\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 915] Loss: 0.3383029109209924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 916] Loss: 0.33900969983922047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 917] Loss: 0.3387587023253488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 918] Loss: 0.3389048456409831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 919] Loss: 0.3387867415626648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 920] Loss: 0.3388704709543936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 921] Loss: 0.3384869858695596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 922] Loss: 0.33840105436687656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 923] Loss: 0.3384574872328014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 924] Loss: 0.33844306582807043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 925] Loss: 0.33863268427333787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 926] Loss: 0.338556141563247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 927] Loss: 0.33829520149651354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 928] Loss: 0.33826079724064795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 929] Loss: 0.3379105753265321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 930] Loss: 0.3378156447510639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 931] Loss: 0.33751501681274204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 932] Loss: 0.3373273538163283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 933] Loss: 0.3372888259589672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 934] Loss: 0.3369661902659296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 935] Loss: 0.3368224144617528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 936] Loss: 0.3366335796337601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 937] Loss: 0.33655569755103226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 938] Loss: 0.3366208165884018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 939] Loss: 0.33667419147743305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 940] Loss: 0.3364372402778554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 941] Loss: 0.3367481253971563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 942] Loss: 0.3366622210660459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 943] Loss: 0.33697570680185807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 944] Loss: 0.33686119532363873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 945] Loss: 0.3369619139228706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 946] Loss: 0.33693569471874635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 947] Loss: 0.33719598848698873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 948] Loss: 0.3373036768244601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 949] Loss: 0.33740440783424114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 950] Loss: 0.3374378171747282\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 951] Loss: 0.3370871078818356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 952] Loss: 0.33756656747879904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 953] Loss: 0.3372985165566206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 954] Loss: 0.3375022936772868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 955] Loss: 0.3372316676364765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 956] Loss: 0.3372175536427487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 957] Loss: 0.33753350387151176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 958] Loss: 0.33774919479750515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 959] Loss: 0.3380183956080488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 960] Loss: 0.3378667981099229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 961] Loss: 0.33769654938285903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 962] Loss: 0.33750428604522104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 963] Loss: 0.3374031892418861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 964] Loss: 0.3375792158746931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 965] Loss: 0.3374778817251193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 966] Loss: 0.33707367340986827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 967] Loss: 0.3369211427834591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 968] Loss: 0.33715413356875323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 969] Loss: 0.33727508665699707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 970] Loss: 0.3370377551805008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 971] Loss: 0.33685199408812294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 972] Loss: 0.3364101784356539\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 973] Loss: 0.3363355631089729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 974] Loss: 0.33652236854047424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 975] Loss: 0.3361661038744501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 976] Loss: 0.33583690940561356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 977] Loss: 0.33557581525809804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 978] Loss: 0.3352526863416036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 979] Loss: 0.33515044560759877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 980] Loss: 0.3351569025751355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 981] Loss: 0.33535571116158086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 982] Loss: 0.3352481970654876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 983] Loss: 0.33495132105147585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 984] Loss: 0.3346624844203329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 985] Loss: 0.3345835771159095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 986] Loss: 0.3348609610100377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 987] Loss: 0.3345409952701396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 988] Loss: 0.33447919007978943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 989] Loss: 0.33414971155404044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 990] Loss: 0.33398810631948944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 991] Loss: 0.33414298592127517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 992] Loss: 0.3342519802253281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 993] Loss: 0.33409785873567066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 994] Loss: 0.3344521340052452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 995] Loss: 0.3342544875142485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 996] Loss: 0.33404472667731605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 997] Loss: 0.3338169893634713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 998] Loss: 0.3341323481699855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 999] Loss: 0.333845463554555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1000] Loss: 0.3340148927617122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1001] Loss: 0.333665917642781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1002] Loss: 0.3333465240606257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1003] Loss: 0.33328350873626006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1004] Loss: 0.3331830462710192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1005] Loss: 0.33326981549825124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1006] Loss: 0.33295564135842587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1007] Loss: 0.33304163762311706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1008] Loss: 0.33373294921234403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1009] Loss: 0.33350907671715946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1010] Loss: 0.3337135832134627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1011] Loss: 0.3337155948262138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1012] Loss: 0.33365355312585354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1013] Loss: 0.3334957527220249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1014] Loss: 0.3334630201022306\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8919999999999999\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1015] Loss: 0.3335453506663026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1016] Loss: 0.3337107506649158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1017] Loss: 0.33397209605882094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1018] Loss: 0.33391757368451297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1019] Loss: 0.3339453565450054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1020] Loss: 0.3339593973914547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1021] Loss: 0.3338795690027278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1022] Loss: 0.33354904149862075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1023] Loss: 0.33349435992685017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1024] Loss: 0.3333563054319464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1025] Loss: 0.33366368236602284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1026] Loss: 0.33378127859233647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1027] Loss: 0.3336909027473008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1028] Loss: 0.3335277229547501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1029] Loss: 0.33388670894873235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1030] Loss: 0.33360626616261224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1031] Loss: 0.3340114462962482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1032] Loss: 0.33415132545666887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1033] Loss: 0.33398562039320284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1034] Loss: 0.33420947846203986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1035] Loss: 0.33423143396889116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1036] Loss: 0.33413665415452043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1037] Loss: 0.3340021451465956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1038] Loss: 0.3339927955468496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1039] Loss: 0.33396562718619865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1040] Loss: 0.3339847955124654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1041] Loss: 0.333862167924191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1042] Loss: 0.3340426050196974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1043] Loss: 0.33425198613472706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1044] Loss: 0.3339414884478359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1045] Loss: 0.33380639508254545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1046] Loss: 0.33378861690775313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1047] Loss: 0.3335063497392872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1048] Loss: 0.33352570102036555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1049] Loss: 0.3335386377606374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1050] Loss: 0.3335132299466284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1051] Loss: 0.33330155626548713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1052] Loss: 0.33332868791245795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1053] Loss: 0.33324223712638573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1054] Loss: 0.3332961472698148\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1055] Loss: 0.33301112432431473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1056] Loss: 0.33331494082732754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1057] Loss: 0.33310928318978233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1058] Loss: 0.3328576311605786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1059] Loss: 0.3330055745420875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1060] Loss: 0.3332124857514606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1061] Loss: 0.33328434052693584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1062] Loss: 0.3333312889700162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1063] Loss: 0.33361954987049103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1064] Loss: 0.33345977770005725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1065] Loss: 0.33339206750194234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1066] Loss: 0.33393019141383457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1067] Loss: 0.33380043420550626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1068] Loss: 0.333822932651451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1069] Loss: 0.33436185796912626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1070] Loss: 0.3343367941503679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1071] Loss: 0.33455397744118953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1072] Loss: 0.3346130702917819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1073] Loss: 0.3342832548277719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1074] Loss: 0.33443994084356515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1075] Loss: 0.33427274571831117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1076] Loss: 0.33415392861696586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1077] Loss: 0.33382114828795406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1078] Loss: 0.3337056368589401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1079] Loss: 0.3336444395222428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1080] Loss: 0.33407651928682175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1081] Loss: 0.3338902988799021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1082] Loss: 0.33407492115962695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1083] Loss: 0.33401117999302715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1084] Loss: 0.33373586055798204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1085] Loss: 0.33374656947863685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1086] Loss: 0.3338931142295634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1087] Loss: 0.33371348624549263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1088] Loss: 0.33355335038641226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1089] Loss: 0.3334573846724298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1090] Loss: 0.3333351808362858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1091] Loss: 0.3337101161892439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1092] Loss: 0.33371681294087097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1093] Loss: 0.33354767966887044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1094] Loss: 0.3335676907774914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1095] Loss: 0.3338524910694955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1096] Loss: 0.3342733731298463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1097] Loss: 0.3343061542470161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1098] Loss: 0.3344272235010424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1099] Loss: 0.33441829574596355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1100] Loss: 0.33425661957040553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1101] Loss: 0.33401528588768575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1102] Loss: 0.33390509667339874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1103] Loss: 0.3341636077832367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1104] Loss: 0.3342852932345847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1105] Loss: 0.33523745240794645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1106] Loss: 0.3353237761011815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1107] Loss: 0.33511371278401575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1108] Loss: 0.33498263754764523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1109] Loss: 0.3347210000525385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1110] Loss: 0.3344821965125338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1111] Loss: 0.3343460933370734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1112] Loss: 0.3341019846411898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1113] Loss: 0.3339743498216073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1114] Loss: 0.33381942407957926\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1115] Loss: 0.3336452102641331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1116] Loss: 0.3336405758043229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1117] Loss: 0.3336614266235307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1118] Loss: 0.3335766179995103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1119] Loss: 0.3338419987325228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1120] Loss: 0.3339472226491674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1121] Loss: 0.33388917010865715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1122] Loss: 0.3338175232970264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1123] Loss: 0.3337063917859656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1124] Loss: 0.33375109802876674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1125] Loss: 0.33346763046251404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1126] Loss: 0.33333818463769666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1127] Loss: 0.3334775031923471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1128] Loss: 0.3335195467481768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1129] Loss: 0.333577972897268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1130] Loss: 0.33347053173778507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1131] Loss: 0.3332094175915888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1132] Loss: 0.3332004609227373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1133] Loss: 0.33388401909220605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1134] Loss: 0.3337008073422068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1135] Loss: 0.3336523338625285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1136] Loss: 0.3335947533576102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1137] Loss: 0.3334918605306974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1138] Loss: 0.33349482913017275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1139] Loss: 0.333378731395109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1140] Loss: 0.33349164122599734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1141] Loss: 0.333601607970751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1142] Loss: 0.3335937725910132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1143] Loss: 0.3338580950858101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1144] Loss: 0.3337928538466029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1145] Loss: 0.3338958441362351\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1146] Loss: 0.33375404537383224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1147] Loss: 0.3337724756461213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1148] Loss: 0.3341785671673422\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1149] Loss: 0.3343148094678075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1150] Loss: 0.33417663668257475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1151] Loss: 0.33398969805446166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1152] Loss: 0.3343211441579186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1153] Loss: 0.3341017511440441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1154] Loss: 0.333899299086721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1155] Loss: 0.33368065349780884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1156] Loss: 0.33365467598612536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1157] Loss: 0.33345548813202364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1158] Loss: 0.33347034874812576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1159] Loss: 0.33378461303172097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1160] Loss: 0.33357657743200453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1161] Loss: 0.33352080700390135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1162] Loss: 0.3332823372125993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1163] Loss: 0.33310959403331464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1164] Loss: 0.3331247801604908\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1165] Loss: 0.3333218856914643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1166] Loss: 0.33311929840132437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1167] Loss: 0.33293861804661035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1168] Loss: 0.3328976962175078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1169] Loss: 0.3331632867410052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1170] Loss: 0.3331521161388226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1171] Loss: 0.3329867817076506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1172] Loss: 0.3330667738397132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1173] Loss: 0.3328300803448215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1174] Loss: 0.3327896572006993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1175] Loss: 0.3327295297132158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1176] Loss: 0.332795621627776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1177] Loss: 0.33273188491542655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1178] Loss: 0.3327458361485847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1179] Loss: 0.3327323635061224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1180] Loss: 0.33329852946337196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1181] Loss: 0.333027378683854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1182] Loss: 0.33307415672392765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1183] Loss: 0.33339951045032756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1184] Loss: 0.33322533176748304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1185] Loss: 0.33326067764400724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1186] Loss: 0.333770108944771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1187] Loss: 0.3338690701020931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1188] Loss: 0.3341929742362764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1189] Loss: 0.3342156870257572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1190] Loss: 0.3339506386169831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1191] Loss: 0.33377363378934805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1192] Loss: 0.3336748564849019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1193] Loss: 0.33397062585196075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1194] Loss: 0.33440670119420723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1195] Loss: 0.33435647292308446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1196] Loss: 0.3344790343178837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1197] Loss: 0.33434789965462963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1198] Loss: 0.33430300478952646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1199] Loss: 0.33435269388704186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1200] Loss: 0.3343017415578709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1201] Loss: 0.3344225153803479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1202] Loss: 0.3343591537158963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1203] Loss: 0.3342625528358031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1204] Loss: 0.33436488482006727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1205] Loss: 0.33445651026044276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1206] Loss: 0.3343321658230103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1207] Loss: 0.3340921696780051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1208] Loss: 0.33405183525823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1209] Loss: 0.3339880708947606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1210] Loss: 0.333894117597699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1211] Loss: 0.3338783501852891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1212] Loss: 0.3337974532351473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1213] Loss: 0.33399956351944377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1214] Loss: 0.33403455418203765\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1215] Loss: 0.3337939498558683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1216] Loss: 0.3336232561263048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1217] Loss: 0.3336196535224603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1218] Loss: 0.33359907258909643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1219] Loss: 0.33357702075337553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1220] Loss: 0.33372282566663397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1221] Loss: 0.33382122906840456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1222] Loss: 0.33358776233092013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1223] Loss: 0.333434787917305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1224] Loss: 0.333540396620788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1225] Loss: 0.3332922387072879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1226] Loss: 0.3331597069327995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1227] Loss: 0.3331420473983976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1228] Loss: 0.33304342454546815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1229] Loss: 0.33287791343790857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1230] Loss: 0.33273491053484805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1231] Loss: 0.3328060167206031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1232] Loss: 0.3326937466942717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1233] Loss: 0.33247726820409296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1234] Loss: 0.3324639139575535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1235] Loss: 0.3324543398668231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1236] Loss: 0.3322206503952522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1237] Loss: 0.3320525810534124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1238] Loss: 0.33182365384595147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1239] Loss: 0.33183888175599174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1240] Loss: 0.33171083615193503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1241] Loss: 0.3316093068160526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1242] Loss: 0.3314827560192927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1243] Loss: 0.3316511744301613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1244] Loss: 0.3315563009677279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1245] Loss: 0.3316959194594719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1246] Loss: 0.33190695705631745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1247] Loss: 0.3320166506989775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1248] Loss: 0.33187582912493724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1249] Loss: 0.33181991701459757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1250] Loss: 0.331706480121839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1251] Loss: 0.33207337851042995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1252] Loss: 0.33188690356053263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1253] Loss: 0.3317828025769543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1254] Loss: 0.3319053151990399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1255] Loss: 0.3318275963119419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1256] Loss: 0.3316445548994865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1257] Loss: 0.3316224898582184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1258] Loss: 0.33148406964020444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1259] Loss: 0.3313292911121417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1260] Loss: 0.3316492205124144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1261] Loss: 0.331854839037287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1262] Loss: 0.33167375472979804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1263] Loss: 0.3315225320458412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1264] Loss: 0.33154950651046283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1265] Loss: 0.33175601725010795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1266] Loss: 0.33162764696327657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1267] Loss: 0.33161562799775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1268] Loss: 0.33183559420093006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1269] Loss: 0.3316237108890342\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1270] Loss: 0.3314873034053309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1271] Loss: 0.33160214031749163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1272] Loss: 0.33144155119169055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1273] Loss: 0.33124406492631686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1274] Loss: 0.3311039297480464\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1275] Loss: 0.33095419592666503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1276] Loss: 0.33084442106174455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1277] Loss: 0.3307618681360914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1278] Loss: 0.330703089985193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1279] Loss: 0.3307460088175831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1280] Loss: 0.3309309376886957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1281] Loss: 0.3308579761069268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1282] Loss: 0.33067291211554845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1283] Loss: 0.3307945388091075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1284] Loss: 0.3305873194402603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1285] Loss: 0.3304690974595633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1286] Loss: 0.3304150535943129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1287] Loss: 0.3306175178104593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1288] Loss: 0.3308146563268477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1289] Loss: 0.3306117443579067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1290] Loss: 0.3307111344013742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1291] Loss: 0.3305909449383042\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1292] Loss: 0.33056445456132655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1293] Loss: 0.33070086401242477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1294] Loss: 0.33098260518378086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1295] Loss: 0.33099990389536105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1296] Loss: 0.3308108425003359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1297] Loss: 0.3306324612349272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1298] Loss: 0.33054483365860715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1299] Loss: 0.33065753083192667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1300] Loss: 0.3308511218470267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1301] Loss: 0.3309171456597783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1302] Loss: 0.3307578983528986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1303] Loss: 0.33078909416364716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1304] Loss: 0.3305895392948999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1305] Loss: 0.3306004708689271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1306] Loss: 0.3306778665974943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1307] Loss: 0.3305214957453742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1308] Loss: 0.3308200742651082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1309] Loss: 0.3307752766688565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1310] Loss: 0.33087945730428925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1311] Loss: 0.3307734252068034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1312] Loss: 0.33070647343526943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1313] Loss: 0.3305484265834093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1314] Loss: 0.33051348275757314\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1315] Loss: 0.3305444073795975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1316] Loss: 0.3305806426301246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1317] Loss: 0.33052869589619377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1318] Loss: 0.3304811765318332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1319] Loss: 0.3304316384842615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1320] Loss: 0.3303367374037869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1321] Loss: 0.3303451024290949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1322] Loss: 0.33019673247788245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1323] Loss: 0.330072645990201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1324] Loss: 0.3299931122584937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1325] Loss: 0.3298555998489481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1326] Loss: 0.32978171551872737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1327] Loss: 0.3296543501628705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1328] Loss: 0.32952213576234923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1329] Loss: 0.32966694951641795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1330] Loss: 0.3296840934304012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1331] Loss: 0.329602905801864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1332] Loss: 0.32954115246824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1333] Loss: 0.32948610517309934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1334] Loss: 0.32939354333023785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1335] Loss: 0.32921962407383604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1336] Loss: 0.3293284124910904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1337] Loss: 0.32966505591441125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1338] Loss: 0.3298113197630102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1339] Loss: 0.3299591438100644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1340] Loss: 0.32997067260050283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1341] Loss: 0.32998355182904554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1342] Loss: 0.32986683818198226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1343] Loss: 0.3300186426165592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1344] Loss: 0.3299078784264382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1345] Loss: 0.3300385233014822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1346] Loss: 0.33007723776375403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1347] Loss: 0.3298902625052763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1348] Loss: 0.3297983987424188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1349] Loss: 0.3297752751723716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1350] Loss: 0.32986595256425433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1351] Loss: 0.3299305742886584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1352] Loss: 0.32996478639498655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1353] Loss: 0.33005721627601553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1354] Loss: 0.32992360580548663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1355] Loss: 0.32986151333234653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1356] Loss: 0.32981320427264466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1357] Loss: 0.3299732979440011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1358] Loss: 0.3302710490113885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1359] Loss: 0.3302296450797548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1360] Loss: 0.33032414654914155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1361] Loss: 0.33024322301289943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1362] Loss: 0.3301206909128859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1363] Loss: 0.3301115607338793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1364] Loss: 0.33005670793398284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1365] Loss: 0.3307720687012997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1366] Loss: 0.33057939770422956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1367] Loss: 0.33079983061942897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1368] Loss: 0.33063559884216354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1369] Loss: 0.33044764232412677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1370] Loss: 0.3302550165454315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1371] Loss: 0.3301512808267609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1372] Loss: 0.3301237553219301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1373] Loss: 0.329981829988402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1374] Loss: 0.32990575248632975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1375] Loss: 0.3297744931311729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1376] Loss: 0.3297104301623922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1377] Loss: 0.3297118802934333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1378] Loss: 0.3297172532605298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1379] Loss: 0.3295989159761345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1380] Loss: 0.32954424148749867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1381] Loss: 0.3294630483273537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1382] Loss: 0.3292985241967323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1383] Loss: 0.32948140166271694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1384] Loss: 0.32936316988635145\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1385] Loss: 0.3292434548087623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1386] Loss: 0.3290802784528656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1387] Loss: 0.32905992875792067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1388] Loss: 0.3288472447395325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1389] Loss: 0.32866106480019824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1390] Loss: 0.3292179855442645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1391] Loss: 0.3291360879304197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1392] Loss: 0.32918552389798583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1393] Loss: 0.32911797303029083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1394] Loss: 0.32897072267654126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1395] Loss: 0.3287653056672371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1396] Loss: 0.328694669536124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1397] Loss: 0.3288138376641597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1398] Loss: 0.32887853804954703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1399] Loss: 0.3286677121981541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1400] Loss: 0.32875611279432776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1401] Loss: 0.3289634985429747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1402] Loss: 0.3288347666456675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1403] Loss: 0.32903266344847304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1404] Loss: 0.32925472031404945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1405] Loss: 0.3294404323793313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1406] Loss: 0.3292940028537428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1407] Loss: 0.3292968362669817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1408] Loss: 0.3291883401198094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1409] Loss: 0.32918612564182176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1410] Loss: 0.3291854775835705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1411] Loss: 0.32931408294391523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1412] Loss: 0.3292124340345915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1413] Loss: 0.3296014661259121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1414] Loss: 0.32957484769106704\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1415] Loss: 0.3295801118710089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1416] Loss: 0.32955987079859045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1417] Loss: 0.32950818288115274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1418] Loss: 0.32934143971343066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1419] Loss: 0.32946985608036683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1420] Loss: 0.32951586732133614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1421] Loss: 0.32945599154228683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1422] Loss: 0.3295731429088496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1423] Loss: 0.3297998704753079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1424] Loss: 0.3297047049265138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1425] Loss: 0.3296895922047266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1426] Loss: 0.33017737125449476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1427] Loss: 0.3300543041243595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1428] Loss: 0.3298906369124605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1429] Loss: 0.3299259026595859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1430] Loss: 0.3301493618942009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1431] Loss: 0.3300758139078134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1432] Loss: 0.3299090322492172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1433] Loss: 0.32989281356010747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1434] Loss: 0.32971547704177884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1435] Loss: 0.3304488879028473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1436] Loss: 0.330552167455915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1437] Loss: 0.33048089854903034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1438] Loss: 0.3305048020788141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1439] Loss: 0.33047102311259985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1440] Loss: 0.3304139197901486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1441] Loss: 0.3304730449514142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1442] Loss: 0.33038251283222686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1443] Loss: 0.3303561165127703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1444] Loss: 0.3304049635804173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1445] Loss: 0.33052559587065244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1446] Loss: 0.33049079111406915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1447] Loss: 0.3306778230618614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1448] Loss: 0.33085881538569606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1449] Loss: 0.3308495857522019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1450] Loss: 0.33089293668338815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1451] Loss: 0.33075449785698197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1452] Loss: 0.33108491479906155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1453] Loss: 0.3310774254355025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1454] Loss: 0.331146291699597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1455] Loss: 0.3311599989415734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1456] Loss: 0.33123687567033294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1457] Loss: 0.3313787026109837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1458] Loss: 0.3312683444174509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1459] Loss: 0.3312263383232766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1460] Loss: 0.33122625024920405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1461] Loss: 0.3311081598453884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1462] Loss: 0.3309892207478321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1463] Loss: 0.3310245656967163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1464] Loss: 0.3308754497051991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1465] Loss: 0.3307560526241525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1466] Loss: 0.33075540036682316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1467] Loss: 0.33067039644005913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1468] Loss: 0.3308593448700081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1469] Loss: 0.33085868156916426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1470] Loss: 0.33102649828670166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1471] Loss: 0.33094699732134886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1472] Loss: 0.3310154680943464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1473] Loss: 0.3311197057211151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1474] Loss: 0.3310598677855749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1475] Loss: 0.331059949205348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1476] Loss: 0.3310352744435967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1477] Loss: 0.330969615765998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1478] Loss: 0.33096944595556804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1479] Loss: 0.33118144524578724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1480] Loss: 0.33124581637340594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1481] Loss: 0.3313134372203557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1482] Loss: 0.3313916880249116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1483] Loss: 0.33141141559967063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1484] Loss: 0.33127847079084044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1485] Loss: 0.33122953712756253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1486] Loss: 0.33116450879764947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1487] Loss: 0.33122211858415995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1488] Loss: 0.33111008236041434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1489] Loss: 0.33100335474019166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1490] Loss: 0.33089800307121103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1491] Loss: 0.3307666950735334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1492] Loss: 0.330725543741308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1493] Loss: 0.33079236271430035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1494] Loss: 0.33090401877564635\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1495] Loss: 0.33089660047392255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1496] Loss: 0.3307657756009883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1497] Loss: 0.33073626543448226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1498] Loss: 0.33068919868638674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1499] Loss: 0.330678120678627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1500] Loss: 0.33064904356075275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1501] Loss: 0.33071419328209845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1502] Loss: 0.33071329074754513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1503] Loss: 0.33087973329755993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1504] Loss: 0.33071906058687256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1505] Loss: 0.3305396816182521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1506] Loss: 0.3304042870184446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1507] Loss: 0.33046080414917867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1508] Loss: 0.3305517764247243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1509] Loss: 0.33053870935995416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1510] Loss: 0.3304787273392634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1511] Loss: 0.33057891534182254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1512] Loss: 0.33055763395579607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1513] Loss: 0.3307600476443768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1514] Loss: 0.3308913075661921\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.9001999999999999\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1515] Loss: 0.33090058804867034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1516] Loss: 0.330772790452419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1517] Loss: 0.3307082038595382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1518] Loss: 0.3306262409360848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1519] Loss: 0.33101584184655614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1520] Loss: 0.3310256372645216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1521] Loss: 0.3310152808618214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1522] Loss: 0.33121479368363427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1523] Loss: 0.3313254243223974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 20, Batch 1524] Loss: 0.3314062823733991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 0] Loss: 0.33127951222976204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1] Loss: 0.3314609910781621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 2] Loss: 0.33156257263831135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 3] Loss: 0.33155060611628545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 4] Loss: 0.3313888292759657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 5] Loss: 0.3313936367704219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 6] Loss: 0.3315068970933879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 7] Loss: 0.3315588018113895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 8] Loss: 0.3316562182616954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 9] Loss: 0.3316488740464032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 10] Loss: 0.331921913021348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 11] Loss: 0.33178796242642145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 12] Loss: 0.3317552480730228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 13] Loss: 0.33184375291917384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 14] Loss: 0.33186850532686035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 15] Loss: 0.3319789286423565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 16] Loss: 0.33188746424558563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 17] Loss: 0.3322166498276189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 18] Loss: 0.33205690043933184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 19] Loss: 0.3319755411778227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 20] Loss: 0.3318021934219571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 21] Loss: 0.33182475074678514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 22] Loss: 0.33181518739957644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 23] Loss: 0.3317082568931119\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 24] Loss: 0.3315796520719197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 25] Loss: 0.3315398468633282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 26] Loss: 0.3315282460869163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 27] Loss: 0.3315591290951693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 28] Loss: 0.33146445458898177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 29] Loss: 0.33147760836352075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 30] Loss: 0.33133137836737736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 31] Loss: 0.3315312836537082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 32] Loss: 0.33153693322306393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 33] Loss: 0.33149067940609306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 34] Loss: 0.331396379588211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 35] Loss: 0.33151726480199817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 36] Loss: 0.3316687813298848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 37] Loss: 0.33167074434636773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 38] Loss: 0.3315291187734831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 39] Loss: 0.3315494356979993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 40] Loss: 0.3317010850139217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 41] Loss: 0.3317270251335921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 42] Loss: 0.33162329487318787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 43] Loss: 0.3315783583581165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 44] Loss: 0.3314090432091193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 45] Loss: 0.3314559976222274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 46] Loss: 0.33149550672064204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 47] Loss: 0.3315021804304366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 48] Loss: 0.3315171801256684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 49] Loss: 0.33150707540592983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 50] Loss: 0.33145273402473574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 51] Loss: 0.3313350151533915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 52] Loss: 0.33121499357591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 53] Loss: 0.33119850595232464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 54] Loss: 0.3313958019745059\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 55] Loss: 0.3313030732800833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 56] Loss: 0.33128699893306257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 57] Loss: 0.33116456514992815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 58] Loss: 0.3311779544732281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 59] Loss: 0.33154989340726065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 60] Loss: 0.33150555415829613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 61] Loss: 0.3313825874965211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 62] Loss: 0.33133388493813615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 63] Loss: 0.33135194405566815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 64] Loss: 0.3313414472047946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 65] Loss: 0.33124816583723743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 66] Loss: 0.33121520134314536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 67] Loss: 0.3311513147219339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 68] Loss: 0.33108308627097693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 69] Loss: 0.33093733241941836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 70] Loss: 0.3309354730459987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 71] Loss: 0.33091357712215114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 72] Loss: 0.3307841577845526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 73] Loss: 0.33064865950615174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 74] Loss: 0.3305079618376263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 75] Loss: 0.33041578994613235\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 76] Loss: 0.3302592498195522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 77] Loss: 0.3303858602780394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 78] Loss: 0.3303153433930983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 79] Loss: 0.3301794777541506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 80] Loss: 0.33010477127828003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 81] Loss: 0.3301469867423599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 82] Loss: 0.33004118935281657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 83] Loss: 0.3302376740599332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 84] Loss: 0.3301657608771411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 85] Loss: 0.33016707050659055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 86] Loss: 0.33039826480417306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 87] Loss: 0.330484182917063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 88] Loss: 0.330475421981378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 89] Loss: 0.33056168573537165\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 90] Loss: 0.3305197009536186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 91] Loss: 0.3304461500154013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 92] Loss: 0.3303595704390951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 93] Loss: 0.3306047595733971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 94] Loss: 0.33059987417720327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 95] Loss: 0.33072563973545704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 96] Loss: 0.3306477367608986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 97] Loss: 0.3307897649819621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 98] Loss: 0.33087306095136176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 99] Loss: 0.3309280691814251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 100] Loss: 0.3307860901297854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 101] Loss: 0.33080491565522696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 102] Loss: 0.3308586995092286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 103] Loss: 0.3308877647190351\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 104] Loss: 0.33087270479902997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 105] Loss: 0.3307782582998703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 106] Loss: 0.3306589541100432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 107] Loss: 0.3305245322292676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 108] Loss: 0.3306318635919264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 109] Loss: 0.3304911018826938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 110] Loss: 0.33065023785872044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 111] Loss: 0.33052267518992523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 112] Loss: 0.3306459263629973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 113] Loss: 0.33058743170897165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 114] Loss: 0.3305836344670445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 115] Loss: 0.33055552061458765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 116] Loss: 0.33061577391592745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 117] Loss: 0.33060110342565946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 118] Loss: 0.3306015396408275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 119] Loss: 0.3306312170917223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 120] Loss: 0.3308339550064436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 121] Loss: 0.3308720639582135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 122] Loss: 0.33078223140992397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 123] Loss: 0.33076627742876563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 124] Loss: 0.33069452390232135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 125] Loss: 0.3305846547729212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 126] Loss: 0.3305269106960674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 127] Loss: 0.3303900905954304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 128] Loss: 0.3303627559621083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 129] Loss: 0.33049455978544423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 130] Loss: 0.3304383056776536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 131] Loss: 0.330511614706364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 132] Loss: 0.3306597943671725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 133] Loss: 0.33071308061805876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 134] Loss: 0.33065757466184326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 135] Loss: 0.3305264007764582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 136] Loss: 0.33038274582981647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 137] Loss: 0.33035527744222665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 138] Loss: 0.3303275372152743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 139] Loss: 0.3302918510992148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 140] Loss: 0.3302947713010427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 141] Loss: 0.3303330347575215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 142] Loss: 0.3302800080236984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 143] Loss: 0.3301616341649712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 144] Loss: 0.33012087327334705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 145] Loss: 0.3300187571123951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 146] Loss: 0.3300012774340847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 147] Loss: 0.33000711196707283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 148] Loss: 0.32994167587623513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 149] Loss: 0.3298492775227262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 150] Loss: 0.329935646546995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 151] Loss: 0.3298921194936526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 152] Loss: 0.3297427300607011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 153] Loss: 0.3297263129458407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 154] Loss: 0.3296214237962538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 155] Loss: 0.32975812274212496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 156] Loss: 0.3296978331923689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 157] Loss: 0.32959950712116687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 158] Loss: 0.32947065310600476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 159] Loss: 0.329340451451879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 160] Loss: 0.32936964593446294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 161] Loss: 0.3293413423058932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 162] Loss: 0.32922405719097064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 163] Loss: 0.32924461566387336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 164] Loss: 0.32936322880389335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 165] Loss: 0.32977442787730704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 166] Loss: 0.32980325563806023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 167] Loss: 0.3297284950104884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 168] Loss: 0.3297842829030449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 169] Loss: 0.32981719114485686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 170] Loss: 0.3298381238343752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 171] Loss: 0.3298952483894053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 172] Loss: 0.3298428202727558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 173] Loss: 0.32984205576186443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 174] Loss: 0.32986130580481954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 175] Loss: 0.3300739368949503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 176] Loss: 0.3299360459275318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 177] Loss: 0.32983281512888063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 178] Loss: 0.3298154407814771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 179] Loss: 0.3296941483876567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 180] Loss: 0.3297036948595071\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 181] Loss: 0.32968484774569157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 182] Loss: 0.3296144740216097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 183] Loss: 0.3297558960555488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 184] Loss: 0.32969336318830184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 185] Loss: 0.32960767142704955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 186] Loss: 0.3296555465146377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 187] Loss: 0.32958376719565863\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 188] Loss: 0.3298841643209259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 189] Loss: 0.330006525863418\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 190] Loss: 0.32989495100078486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 191] Loss: 0.32978740063242784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 192] Loss: 0.33007903158219154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 193] Loss: 0.3301233160668884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 194] Loss: 0.3300337647250043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 195] Loss: 0.33013315888950423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 196] Loss: 0.3300418917040359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 197] Loss: 0.3300015322549763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 198] Loss: 0.3299494109493642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 199] Loss: 0.3299465017388617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 200] Loss: 0.32990842242494667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 201] Loss: 0.3299692191693376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 202] Loss: 0.32991488551631987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 203] Loss: 0.32993966575267386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 204] Loss: 0.3298101160234134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 205] Loss: 0.32983833984850663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 206] Loss: 0.32973449779995556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 207] Loss: 0.32967855290519693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 208] Loss: 0.32961920481480533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 209] Loss: 0.3295873579165664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 210] Loss: 0.32948011256230053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 211] Loss: 0.3293538462745295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 212] Loss: 0.32933629927487157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 213] Loss: 0.32920443635814045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 214] Loss: 0.3290642036723663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 215] Loss: 0.3289444565092925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 216] Loss: 0.329028395298832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 217] Loss: 0.3289222719831327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 218] Loss: 0.32885558968637046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 219] Loss: 0.328978904759758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 220] Loss: 0.32892502776601096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 221] Loss: 0.32882531838067064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 222] Loss: 0.3288325938476156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 223] Loss: 0.3287734138700161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 224] Loss: 0.32881065796831666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 225] Loss: 0.32876013106122165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 226] Loss: 0.3287371974649067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 227] Loss: 0.3288616379414767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 228] Loss: 0.329036270286287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 229] Loss: 0.3290646585675615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 230] Loss: 0.329101984495606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 231] Loss: 0.3290642696887566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 232] Loss: 0.328977644191965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 233] Loss: 0.32913997057211924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 234] Loss: 0.3290356218479992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 235] Loss: 0.32897818045512905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 236] Loss: 0.3290715280394906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 237] Loss: 0.32910825389685683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 238] Loss: 0.32903575506210325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 239] Loss: 0.3289643778360719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 240] Loss: 0.3290989536780138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 241] Loss: 0.3290526158126563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 242] Loss: 0.328992208843216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 243] Loss: 0.329022044703305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 244] Loss: 0.3290070212997828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 245] Loss: 0.3291701075332736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 246] Loss: 0.32909078199552616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 247] Loss: 0.32914116159614065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 248] Loss: 0.32908908431492156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 249] Loss: 0.3291861850481767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 250] Loss: 0.3295171692282575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 251] Loss: 0.32947608620895813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 252] Loss: 0.3293917814057462\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 253] Loss: 0.3294256928174392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 254] Loss: 0.3293702503516211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 255] Loss: 0.3294603876599008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 256] Loss: 0.32939939999994045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 257] Loss: 0.3293092011630394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 258] Loss: 0.3292451918946476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 259] Loss: 0.3291609064858322\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 260] Loss: 0.32916157686813446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 261] Loss: 0.32933389198236923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 262] Loss: 0.32926226816662063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 263] Loss: 0.32913627562569636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 264] Loss: 0.32906814484760677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 265] Loss: 0.3291882764294265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 266] Loss: 0.329226736148385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 267] Loss: 0.3292336383771859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 268] Loss: 0.3294977333396673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 269] Loss: 0.32959820168452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 270] Loss: 0.3297893853855207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 271] Loss: 0.3297863381269474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 272] Loss: 0.32980117549963084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 273] Loss: 0.3298255876808315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 274] Loss: 0.32974919399846214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 275] Loss: 0.32977281770181915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 276] Loss: 0.3297151744666492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 277] Loss: 0.32972202154672636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 278] Loss: 0.3296036293109258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 279] Loss: 0.3295802312198302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 280] Loss: 0.3295600498008654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 281] Loss: 0.32972057953142697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 282] Loss: 0.3297252409747432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 283] Loss: 0.3296780177985379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 284] Loss: 0.32956273744549647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 285] Loss: 0.32947184335018176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 286] Loss: 0.32964284125663834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 287] Loss: 0.3296163805270764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 288] Loss: 0.32958088861061974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 289] Loss: 0.3296558432263837\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 290] Loss: 0.3296748810832585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 291] Loss: 0.3296516827684316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 292] Loss: 0.32968853370635054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 293] Loss: 0.32962264231338356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 294] Loss: 0.32957508044166184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 295] Loss: 0.3296431945130947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 296] Loss: 0.32989106179195077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 297] Loss: 0.32986327124698367\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 298] Loss: 0.32974899893498605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 299] Loss: 0.32983908889222746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 300] Loss: 0.32985648390178274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 301] Loss: 0.32979109975234844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 302] Loss: 0.3298065402350832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 303] Loss: 0.3297415994645978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 304] Loss: 0.3297448031445767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 305] Loss: 0.32970586559404996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 306] Loss: 0.3299325497224588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 307] Loss: 0.3299261570835403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 308] Loss: 0.32991401221264494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 309] Loss: 0.3298098125031823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 310] Loss: 0.3299994444342136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 311] Loss: 0.33001510257173106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 312] Loss: 0.3299560400564505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 313] Loss: 0.33007562257208917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 314] Loss: 0.330018077748034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 315] Loss: 0.3301290978186995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 316] Loss: 0.3299782569688487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 317] Loss: 0.3300243389166953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 318] Loss: 0.3300904303565061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 319] Loss: 0.3301409830463103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 320] Loss: 0.33034030050486773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 321] Loss: 0.3303264828660125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 322] Loss: 0.3303869102356852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 323] Loss: 0.33029794102527676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 324] Loss: 0.3303374488040537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 325] Loss: 0.3303269803769212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 326] Loss: 0.33030322360039116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 327] Loss: 0.33022991059830686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 328] Loss: 0.33014420901439084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 329] Loss: 0.33011937824805043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 330] Loss: 0.3301710158741954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 331] Loss: 0.33020862163622167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 332] Loss: 0.3302826667315371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 333] Loss: 0.3303677315937985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 334] Loss: 0.33039573039776504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 335] Loss: 0.3303526564602863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 336] Loss: 0.33029960360079563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 337] Loss: 0.33017995131731565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 338] Loss: 0.33021029975679184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 339] Loss: 0.33023858769658226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 340] Loss: 0.33015974751017857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 341] Loss: 0.33030973973973804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 342] Loss: 0.33023040200221837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 343] Loss: 0.3301492325384239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 344] Loss: 0.3301734470578246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 345] Loss: 0.33008977984934057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 346] Loss: 0.3300363165881918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 347] Loss: 0.32990017849088504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 348] Loss: 0.3299790097290979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 349] Loss: 0.3299449388154021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 350] Loss: 0.3300154281564046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 351] Loss: 0.3300453710232425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 352] Loss: 0.33016670722503466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 353] Loss: 0.3301206248147147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 354] Loss: 0.33012760281126463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 355] Loss: 0.3300311581750115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 356] Loss: 0.3301105867657397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 357] Loss: 0.33006938456008694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 358] Loss: 0.32996224304185295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 359] Loss: 0.329895177498775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 360] Loss: 0.32989028326450215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 361] Loss: 0.3298056547605288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 362] Loss: 0.3296871150381527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 363] Loss: 0.3296574682972648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 364] Loss: 0.3296389027910177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 365] Loss: 0.32978255747017343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 366] Loss: 0.3297886226018039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 367] Loss: 0.32984722976757186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 368] Loss: 0.3297771540780862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 369] Loss: 0.32967122478557614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 370] Loss: 0.3296290289734621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 371] Loss: 0.32955096219211755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 372] Loss: 0.3294971760771523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 373] Loss: 0.3293821924860297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 374] Loss: 0.3294281469924109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 375] Loss: 0.3293571854312384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 376] Loss: 0.3295715786301952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 377] Loss: 0.3295887459453016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 378] Loss: 0.3297224928256419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 379] Loss: 0.32967750426036346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 380] Loss: 0.32978806142620315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 381] Loss: 0.3297866315762088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 382] Loss: 0.3297420594215906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 383] Loss: 0.329791421734304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 384] Loss: 0.3298396850618558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 385] Loss: 0.3299641915428357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 386] Loss: 0.33005518368172204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 387] Loss: 0.3299945535895823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 388] Loss: 0.3300835405822311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 389] Loss: 0.3301651038649591\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 390] Loss: 0.3300866945493918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 391] Loss: 0.33010709143415656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 392] Loss: 0.33022050854572205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 393] Loss: 0.33013635263960556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 394] Loss: 0.33010561034019775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 395] Loss: 0.3300669497327764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 396] Loss: 0.33021769527642225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 397] Loss: 0.33009868242623874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 398] Loss: 0.32999265414814577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 399] Loss: 0.3300541204966019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 400] Loss: 0.3300469049883125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 401] Loss: 0.3299758146290904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 402] Loss: 0.3299679819078223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 403] Loss: 0.3298495376383879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 404] Loss: 0.32985827464631384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 405] Loss: 0.32973038640212404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 406] Loss: 0.3297554150181698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 407] Loss: 0.32967004286016355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 408] Loss: 0.3297618175791183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 409] Loss: 0.3297472982382288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 410] Loss: 0.3296815657728835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 411] Loss: 0.32977174293676564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 412] Loss: 0.3297472604226028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 413] Loss: 0.3296877949802499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 414] Loss: 0.32958521442109034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 415] Loss: 0.32966007232749556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 416] Loss: 0.3296270980095329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 417] Loss: 0.32966126091752207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 418] Loss: 0.329604868757558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 419] Loss: 0.3295359558820891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 420] Loss: 0.32947962391892627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 421] Loss: 0.3294280000857681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 422] Loss: 0.32940363867346045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 423] Loss: 0.32934721897288066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 424] Loss: 0.32928351484093826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 425] Loss: 0.32925670993726286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 426] Loss: 0.32917396020615713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 427] Loss: 0.32910010847182136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 428] Loss: 0.32902946166901126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 429] Loss: 0.3291538070362529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 430] Loss: 0.3291415273626535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 431] Loss: 0.329087288705574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 432] Loss: 0.32900824202766377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 433] Loss: 0.32902309965716103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 434] Loss: 0.32915902654041396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 435] Loss: 0.3291552006147941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 436] Loss: 0.32913895057339365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 437] Loss: 0.3290936494692183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 438] Loss: 0.32906214624643326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 439] Loss: 0.3290298340507083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 440] Loss: 0.32897038260069433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 441] Loss: 0.3289574228704017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 442] Loss: 0.32891700494691134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 443] Loss: 0.3288734936529828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 444] Loss: 0.3289427895733452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 445] Loss: 0.32891232156761724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 446] Loss: 0.3288898402096803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 447] Loss: 0.32915603304620145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 448] Loss: 0.3293195920345718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 449] Loss: 0.32923753162837044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 450] Loss: 0.32918925707708796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 451] Loss: 0.32916092139274716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 452] Loss: 0.32909807381652745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 453] Loss: 0.32912328379552924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 454] Loss: 0.32902106864309244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 455] Loss: 0.32897135800216665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 456] Loss: 0.3289798292298408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 457] Loss: 0.32891320460016343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 458] Loss: 0.3290272860705447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 459] Loss: 0.3291716612495588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 460] Loss: 0.3290930015399404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 461] Loss: 0.3290462581300444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 462] Loss: 0.3289461379195974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 463] Loss: 0.32894975952172684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 464] Loss: 0.3289376863437455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 465] Loss: 0.32895365862847986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 466] Loss: 0.3289015463809199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 467] Loss: 0.3288428929506564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 468] Loss: 0.328786319453974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 469] Loss: 0.32869604948322007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 470] Loss: 0.3287528759112403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 471] Loss: 0.32883675781280225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 472] Loss: 0.3287708019672057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 473] Loss: 0.3288093641350165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 474] Loss: 0.32890282440955676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 475] Loss: 0.32888334089665905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 476] Loss: 0.32889321943124133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 477] Loss: 0.3289611523106564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 478] Loss: 0.3289678194778878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 479] Loss: 0.3289135466239182\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 480] Loss: 0.3288779327840652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 481] Loss: 0.3288548023247192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 482] Loss: 0.32903367143318835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 483] Loss: 0.3289519721947386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 484] Loss: 0.3290039603424104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 485] Loss: 0.3289787518177816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 486] Loss: 0.32890210264873443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 487] Loss: 0.3289442757135872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 488] Loss: 0.329021387586991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 489] Loss: 0.3290342229414113\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8955\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 490] Loss: 0.3291041894397945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 491] Loss: 0.32906288163351044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 492] Loss: 0.32906821848666096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 493] Loss: 0.3290135131226822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 494] Loss: 0.32909842754700586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 495] Loss: 0.32907407377323095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 496] Loss: 0.32904033940927735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 497] Loss: 0.32899397976000316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 498] Loss: 0.32893214041231483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 499] Loss: 0.32886370403099185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 500] Loss: 0.32886518735103504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 501] Loss: 0.32883154587562874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 502] Loss: 0.3288267282781387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 503] Loss: 0.3287010907733401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 504] Loss: 0.32876036565819644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 505] Loss: 0.32866621005668717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 506] Loss: 0.3286498157560276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 507] Loss: 0.3287927540138099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 508] Loss: 0.3288495827662317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 509] Loss: 0.328764595184414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 510] Loss: 0.328949784089012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 511] Loss: 0.32901106928417106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 512] Loss: 0.329029091015419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 513] Loss: 0.3290959741053034\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 514] Loss: 0.3290935768642088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 515] Loss: 0.3291162966940242\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 516] Loss: 0.3291846451334928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 517] Loss: 0.3292329193642905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 518] Loss: 0.3292530919991288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 519] Loss: 0.3292606190907885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 520] Loss: 0.3292441381525744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 521] Loss: 0.329176041332243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 522] Loss: 0.32907767997959914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 523] Loss: 0.32905149838435144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 524] Loss: 0.32900753132222843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 525] Loss: 0.3289340128740399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 526] Loss: 0.3290143488907535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 527] Loss: 0.32892867428982236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 528] Loss: 0.32892086594909814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 529] Loss: 0.3288387878713942\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 530] Loss: 0.32873704118216857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 531] Loss: 0.32866190874143925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 532] Loss: 0.32864500042726646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 533] Loss: 0.32857612836322353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 534] Loss: 0.3285581091898379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 535] Loss: 0.32848583933377773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 536] Loss: 0.32847626859596535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 537] Loss: 0.3284481839067017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 538] Loss: 0.3284834237637058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 539] Loss: 0.3286159283725928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 540] Loss: 0.32858495823270883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 541] Loss: 0.3285347592500587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 542] Loss: 0.32850587517598423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 543] Loss: 0.32849141625729406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 544] Loss: 0.3284699898069499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 545] Loss: 0.32837758005124756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 546] Loss: 0.3285030641799867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 547] Loss: 0.32860478671832755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 548] Loss: 0.3286385220117294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 549] Loss: 0.32864736154207735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 550] Loss: 0.3290057606546735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 551] Loss: 0.3289912475066847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 552] Loss: 0.3289636708033817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 553] Loss: 0.3289606203381627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 554] Loss: 0.3289157818731677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 555] Loss: 0.3289515076641376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 556] Loss: 0.32898355474011326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 557] Loss: 0.328899593272355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 558] Loss: 0.32882050589011735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 559] Loss: 0.32889949935852986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 560] Loss: 0.32884318227038434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 561] Loss: 0.32882094062102196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 562] Loss: 0.32886221070491073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 563] Loss: 0.32901361916746413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 564] Loss: 0.32892030332861516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 565] Loss: 0.3290093887264243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 566] Loss: 0.3289328107305806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 567] Loss: 0.3290444507279526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 568] Loss: 0.329000579528039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 569] Loss: 0.3289428033514312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 570] Loss: 0.328841601504312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 571] Loss: 0.32884549152339027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 572] Loss: 0.32897379782728176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 573] Loss: 0.32895352696582725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 574] Loss: 0.3291419378727261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 575] Loss: 0.3291124095218919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 576] Loss: 0.32911139631864406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 577] Loss: 0.32909061117806926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 578] Loss: 0.32906480220691214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 579] Loss: 0.32915496265153926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 580] Loss: 0.3291380739110948\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 581] Loss: 0.3291234032152138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 582] Loss: 0.3291371502963782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 583] Loss: 0.3291274495726469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 584] Loss: 0.32915666827320456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 585] Loss: 0.32908437370731447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 586] Loss: 0.32915098901758805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 587] Loss: 0.3290978937390598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 588] Loss: 0.32906873621046545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 589] Loss: 0.3290669041860856\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 590] Loss: 0.3291514064749231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 591] Loss: 0.3291821456557873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 592] Loss: 0.32910651560324683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 593] Loss: 0.329041462700315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 594] Loss: 0.32906500272369327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 595] Loss: 0.32909838979520184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 596] Loss: 0.32911309576709175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 597] Loss: 0.32908475718526387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 598] Loss: 0.32910770560088365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 599] Loss: 0.3290814682147578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 600] Loss: 0.32909319975942597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 601] Loss: 0.32905719858367327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 602] Loss: 0.3290330233534768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 603] Loss: 0.32897046092124915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 604] Loss: 0.32898167194337535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 605] Loss: 0.32901551464345624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 606] Loss: 0.3289647272825978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 607] Loss: 0.32907100504125025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 608] Loss: 0.3290169454375167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 609] Loss: 0.32896668939661056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 610] Loss: 0.3289435976971533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 611] Loss: 0.329027042408013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 612] Loss: 0.32895499768809144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 613] Loss: 0.32891011647077706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 614] Loss: 0.32888722489387495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 615] Loss: 0.3288434199672868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 616] Loss: 0.32890740086390874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 617] Loss: 0.32899853578003146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 618] Loss: 0.32900930478528967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 619] Loss: 0.32899668840160406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 620] Loss: 0.3289993562388654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 621] Loss: 0.32904847969106565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 622] Loss: 0.3290103964844999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 623] Loss: 0.32891351447557454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 624] Loss: 0.3288340988890029\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 625] Loss: 0.3288248665152924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 626] Loss: 0.3287347106397225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 627] Loss: 0.3287365663026149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 628] Loss: 0.3287742031874453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 629] Loss: 0.3287832247800467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 630] Loss: 0.3289018812862732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 631] Loss: 0.3288977541487462\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 632] Loss: 0.3288621040210672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 633] Loss: 0.3288584089840799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 634] Loss: 0.3288325404211933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 635] Loss: 0.3287870103779459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 636] Loss: 0.32881328155223316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 637] Loss: 0.3288241628356382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 638] Loss: 0.32871682385603584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 639] Loss: 0.32877028084104526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 640] Loss: 0.3287315395712564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 641] Loss: 0.328955769971581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 642] Loss: 0.32892856437897594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 643] Loss: 0.32892223524543096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 644] Loss: 0.32889725449652485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 645] Loss: 0.3288699033286245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 646] Loss: 0.3289442392576158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 647] Loss: 0.3289461129576848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 648] Loss: 0.32900681246116936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 649] Loss: 0.32908247666930235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 650] Loss: 0.3290449503168159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 651] Loss: 0.3290535557255713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 652] Loss: 0.32897178310220343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 653] Loss: 0.3289832724733754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 654] Loss: 0.3289650491073209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 655] Loss: 0.3289501430052229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 656] Loss: 0.3290189817208323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 657] Loss: 0.3290741464258169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 658] Loss: 0.32907624234874805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 659] Loss: 0.32908529468562914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 660] Loss: 0.3290989327213268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 661] Loss: 0.3291882397935409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 662] Loss: 0.3291577073426087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 663] Loss: 0.32916323822825705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 664] Loss: 0.3291428775608824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 665] Loss: 0.32917729783392263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 666] Loss: 0.32933450193633906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 667] Loss: 0.329354383082458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 668] Loss: 0.3293126175002683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 669] Loss: 0.3292888676407506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 670] Loss: 0.3292718983203279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 671] Loss: 0.32927473379930994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 672] Loss: 0.3292582895066987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 673] Loss: 0.3291780769471245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 674] Loss: 0.3290997177256384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 675] Loss: 0.3290785169841696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 676] Loss: 0.32901050390507935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 677] Loss: 0.3289281162303746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 678] Loss: 0.3288780690033055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 679] Loss: 0.328836475274818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 680] Loss: 0.3288215893820527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 681] Loss: 0.32892499140607345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 682] Loss: 0.32887203260429354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 683] Loss: 0.32891958430629215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 684] Loss: 0.32889170481665236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 685] Loss: 0.32891479247833044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 686] Loss: 0.3288353747645452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 687] Loss: 0.32880946452685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 688] Loss: 0.3288768213724389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 689] Loss: 0.32888306717638544\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 690] Loss: 0.3288144198466272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 691] Loss: 0.3287934964272252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 692] Loss: 0.32892517517255226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 693] Loss: 0.3288544924552839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 694] Loss: 0.32892517990062553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 695] Loss: 0.3288862883485963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 696] Loss: 0.32893488980149216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 697] Loss: 0.3289106329363504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 698] Loss: 0.32888469570561457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 699] Loss: 0.3289131272055126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 700] Loss: 0.3289540702842663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 701] Loss: 0.3289173758315261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 702] Loss: 0.3288863894367719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 703] Loss: 0.32878378162231114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 704] Loss: 0.3286733193223154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 705] Loss: 0.32859604366136697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 706] Loss: 0.3286113092226949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 707] Loss: 0.3285481604276666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 708] Loss: 0.32852736708903035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 709] Loss: 0.3286007309656099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 710] Loss: 0.32857104247213104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 711] Loss: 0.3286882075143289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 712] Loss: 0.32869075011384186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 713] Loss: 0.3286436567531116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 714] Loss: 0.3285298739686211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 715] Loss: 0.32845376214507555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 716] Loss: 0.32838792434928044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 717] Loss: 0.3284295442098824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 718] Loss: 0.3285022026024802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 719] Loss: 0.32853123392416933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 720] Loss: 0.3285242930123492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 721] Loss: 0.32863655596954316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 722] Loss: 0.3285802585752778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 723] Loss: 0.32855064262574274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 724] Loss: 0.32851020627856803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 725] Loss: 0.3285596879755689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 726] Loss: 0.3284994003258997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 727] Loss: 0.32847075885811916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 728] Loss: 0.3285531868109073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 729] Loss: 0.32853574508192346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 730] Loss: 0.32853836983647605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 731] Loss: 0.3285080531908053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 732] Loss: 0.32856784643895853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 733] Loss: 0.32862664976058514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 734] Loss: 0.328632089493952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 735] Loss: 0.32860217229359207\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 736] Loss: 0.32857528077417164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 737] Loss: 0.32865608734461565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 738] Loss: 0.32864767865623745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 739] Loss: 0.32890537584563245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 740] Loss: 0.328835074360308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 741] Loss: 0.32884020215942733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 742] Loss: 0.32885615373860744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 743] Loss: 0.3288954428203425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 744] Loss: 0.3289840438048905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 745] Loss: 0.3291462174805987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 746] Loss: 0.32906702913521907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 747] Loss: 0.3290257704501941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 748] Loss: 0.32907904013991357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 749] Loss: 0.3290592916711767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 750] Loss: 0.32903118834119377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 751] Loss: 0.3290853931426461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 752] Loss: 0.329219424197463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 753] Loss: 0.3291426370400545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 754] Loss: 0.32919526081595524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 755] Loss: 0.32914302444552457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 756] Loss: 0.329124782908691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 757] Loss: 0.32940056225955655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 758] Loss: 0.3293391700181584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 759] Loss: 0.3293768700437314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 760] Loss: 0.32949569913859295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 761] Loss: 0.32955316998362877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 762] Loss: 0.329535776927748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 763] Loss: 0.32959714886168356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 764] Loss: 0.3296004894382513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 765] Loss: 0.32952707184957664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 766] Loss: 0.3295321221912806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 767] Loss: 0.3295988722873444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 768] Loss: 0.3295468073463842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 769] Loss: 0.32950587202530773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 770] Loss: 0.32946360717484713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 771] Loss: 0.32951431818812066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 772] Loss: 0.32948077257071107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 773] Loss: 0.3295228403572943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 774] Loss: 0.3294823335156195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 775] Loss: 0.32966572555771206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 776] Loss: 0.3297597660330985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 777] Loss: 0.32979926504423795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 778] Loss: 0.329836759029487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 779] Loss: 0.330075286482713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 780] Loss: 0.3301450995412389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 781] Loss: 0.33013452669295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 782] Loss: 0.3300924515860402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 783] Loss: 0.3301168170729055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 784] Loss: 0.33007516221605854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 785] Loss: 0.3300617443450504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 786] Loss: 0.3300125280165168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 787] Loss: 0.3300746337051455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 788] Loss: 0.33020238710774313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 789] Loss: 0.3301695039178318\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 790] Loss: 0.3300861261875992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 791] Loss: 0.3301019048151941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 792] Loss: 0.3301429506102185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 793] Loss: 0.330122820269368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 794] Loss: 0.33016993396669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 795] Loss: 0.3302381156011385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 796] Loss: 0.33031397518100203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 797] Loss: 0.3304036606685966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 798] Loss: 0.330360956984001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 799] Loss: 0.3304672730044724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 800] Loss: 0.33062215567983805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 801] Loss: 0.3305061759948073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 802] Loss: 0.3304358930742859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 803] Loss: 0.33039275005500834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 804] Loss: 0.33040753049603644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 805] Loss: 0.3306523742555063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 806] Loss: 0.330683456182611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 807] Loss: 0.3307185628671054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 808] Loss: 0.3308127304191118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 809] Loss: 0.3307478930402234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 810] Loss: 0.33082984921928293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 811] Loss: 0.3307707920727727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 812] Loss: 0.3307148142995542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 813] Loss: 0.33069038422140357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 814] Loss: 0.33060134464195495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 815] Loss: 0.3305797270888113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 816] Loss: 0.33057587535102206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 817] Loss: 0.33063022597622127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 818] Loss: 0.33063606040073873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 819] Loss: 0.3307029956159274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 820] Loss: 0.33072238049457686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 821] Loss: 0.33084203794688005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 822] Loss: 0.33081501494837173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 823] Loss: 0.3308302260711992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 824] Loss: 0.33077443631321257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 825] Loss: 0.3307782851066288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 826] Loss: 0.33073102076405153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 827] Loss: 0.330660258357521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 828] Loss: 0.33070614858651937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 829] Loss: 0.3306702942562647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 830] Loss: 0.3309964686713053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 831] Loss: 0.3309753689585467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 832] Loss: 0.3309203724249583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 833] Loss: 0.33092917318589643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 834] Loss: 0.3309627071362017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 835] Loss: 0.33094123764236877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 836] Loss: 0.33107265918737366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 837] Loss: 0.33115191299119723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 838] Loss: 0.3310715993030651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 839] Loss: 0.3310839363621867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 840] Loss: 0.3310700068431333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 841] Loss: 0.3310539282082353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 842] Loss: 0.33109761340525545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 843] Loss: 0.3310886302566271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 844] Loss: 0.33105206030324613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 845] Loss: 0.33102080625555624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 846] Loss: 0.3309832414525959\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 847] Loss: 0.3310497931699204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 848] Loss: 0.33100154762787204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 849] Loss: 0.3309243958301278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 850] Loss: 0.3308918747718813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 851] Loss: 0.3308289223263101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 852] Loss: 0.3307337675147686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 853] Loss: 0.3306514337459135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 854] Loss: 0.33065492641440286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 855] Loss: 0.3308367902062829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 856] Loss: 0.33082722965029626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 857] Loss: 0.3307248174410698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 858] Loss: 0.3306819633207219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 859] Loss: 0.33063314912441516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 860] Loss: 0.33057484743941545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 861] Loss: 0.33064246779129713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 862] Loss: 0.3307052193609093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 863] Loss: 0.3307288323879242\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 864] Loss: 0.3307312319972622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 865] Loss: 0.3307032106274547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 866] Loss: 0.3310353923212098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 867] Loss: 0.331012749002613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 868] Loss: 0.33101289403882433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 869] Loss: 0.33126854777716375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 870] Loss: 0.33132073932449063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 871] Loss: 0.3312852911599697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 872] Loss: 0.3312164853918198\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 873] Loss: 0.3311939055233482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 874] Loss: 0.33110977887064375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 875] Loss: 0.33105466035888126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 876] Loss: 0.3312447063735355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 877] Loss: 0.33127546336456476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 878] Loss: 0.3313288247380307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 879] Loss: 0.3313315605073931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 880] Loss: 0.3313025364112778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 881] Loss: 0.3312841483401169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 882] Loss: 0.3312907464479695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 883] Loss: 0.3312972094657239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 884] Loss: 0.33131223674156246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 885] Loss: 0.3313545248243893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 886] Loss: 0.3313243155877005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 887] Loss: 0.33126486489463947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 888] Loss: 0.33128456238853304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 889] Loss: 0.3313090548601231\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 890] Loss: 0.3313373890005201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 891] Loss: 0.3312931421300454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 892] Loss: 0.33128045064185846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 893] Loss: 0.3313170403946103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 894] Loss: 0.3313152489231866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 895] Loss: 0.3312955054551691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 896] Loss: 0.33135516354247957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 897] Loss: 0.3314617751093046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 898] Loss: 0.3315074322891485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 899] Loss: 0.33144058191233566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 900] Loss: 0.33163127642919826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 901] Loss: 0.33161357983019857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 902] Loss: 0.33164897680967703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 903] Loss: 0.3317268139855357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 904] Loss: 0.33167026162396396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 905] Loss: 0.33180150425427896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 906] Loss: 0.33176205497588557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 907] Loss: 0.3317232510272012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 908] Loss: 0.3317682081833482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 909] Loss: 0.3318280809903629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 910] Loss: 0.33182619736916563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 911] Loss: 0.33180214248469764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 912] Loss: 0.3318839139942072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 913] Loss: 0.33187833756595464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 914] Loss: 0.3318940164484587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 915] Loss: 0.3320330005732607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 916] Loss: 0.3320274125645517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 917] Loss: 0.3319788093298689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 918] Loss: 0.33191907029077794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 919] Loss: 0.3319129938445889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 920] Loss: 0.33182995127780096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 921] Loss: 0.33176463941835826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 922] Loss: 0.3317403513880402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 923] Loss: 0.3316914445131016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 924] Loss: 0.3317537793951217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 925] Loss: 0.331698468152124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 926] Loss: 0.3317665061514567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 927] Loss: 0.33177475130176837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 928] Loss: 0.33177147468494383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 929] Loss: 0.331793447174343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 930] Loss: 0.3317747847412077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 931] Loss: 0.3316928682272666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 932] Loss: 0.33170062463745903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 933] Loss: 0.3317173894312817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 934] Loss: 0.3317965918966212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 935] Loss: 0.3317871755539116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 936] Loss: 0.33181473604370926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 937] Loss: 0.3317711620666603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 938] Loss: 0.3317664984479929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 939] Loss: 0.33180633322481373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 940] Loss: 0.3318156886647349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 941] Loss: 0.3318268039854624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 942] Loss: 0.3319240355122541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 943] Loss: 0.33185302274458855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 944] Loss: 0.3317759637787542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 945] Loss: 0.3317780963273212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 946] Loss: 0.3318052590349965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 947] Loss: 0.33176457834767104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 948] Loss: 0.33181917203628286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 949] Loss: 0.33178478324370747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 950] Loss: 0.3317230321641605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 951] Loss: 0.331680793893987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 952] Loss: 0.33164982446099495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 953] Loss: 0.33158274078338806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 954] Loss: 0.33151268921906196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 955] Loss: 0.3316352188541735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 956] Loss: 0.33160930597109767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 957] Loss: 0.33153233003985644\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 958] Loss: 0.33151022774465194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 959] Loss: 0.3314467967161365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 960] Loss: 0.3313802233377649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 961] Loss: 0.3314457434917306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 962] Loss: 0.3314400823841583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 963] Loss: 0.3315577929306634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 964] Loss: 0.331658296415258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 965] Loss: 0.33160662655584366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 966] Loss: 0.3317674420871918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 967] Loss: 0.3317187861654721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 968] Loss: 0.33163122264574274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 969] Loss: 0.33159583251112823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 970] Loss: 0.3315565848251284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 971] Loss: 0.3315451184923578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 972] Loss: 0.3314486163473057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 973] Loss: 0.3314208062755071\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 974] Loss: 0.33137800044043425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 975] Loss: 0.3313473247527836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 976] Loss: 0.331395439893547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 977] Loss: 0.3313786544920872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 978] Loss: 0.3315577603015468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 979] Loss: 0.33151096401952246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 980] Loss: 0.33146266378911143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 981] Loss: 0.3314363882730669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 982] Loss: 0.33145294366114836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 983] Loss: 0.3314040880603599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 984] Loss: 0.33138820434918626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 985] Loss: 0.3313391849913475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 986] Loss: 0.33131761021084255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 987] Loss: 0.3313588836212168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 988] Loss: 0.3312755477875471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 989] Loss: 0.33126479813243553\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8946\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 990] Loss: 0.3313166182506811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 991] Loss: 0.33138449806245757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 992] Loss: 0.33139054706234655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 993] Loss: 0.33150095404532187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 994] Loss: 0.3314399234022006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 995] Loss: 0.33136184679137337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 996] Loss: 0.3314828033674048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 997] Loss: 0.33149580573667753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 998] Loss: 0.33146720762869614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 999] Loss: 0.3314113757211376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1000] Loss: 0.33135921005937263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1001] Loss: 0.33135504347734407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1002] Loss: 0.3313284755167445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1003] Loss: 0.3312736285383589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1004] Loss: 0.33119737369466634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1005] Loss: 0.3311051295264026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1006] Loss: 0.33104562596210285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1007] Loss: 0.3310500706567689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1008] Loss: 0.33107845375295913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1009] Loss: 0.331005290769988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1010] Loss: 0.33101306375923073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1011] Loss: 0.33097733869537294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1012] Loss: 0.33096409508803853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1013] Loss: 0.33101436767313214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1014] Loss: 0.3309882985242263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1015] Loss: 0.3309895726234147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1016] Loss: 0.33092975426149324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1017] Loss: 0.3309549614309736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1018] Loss: 0.3309128305374695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1019] Loss: 0.33088648198186205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1020] Loss: 0.3310162069745303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1021] Loss: 0.33107955766996605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1022] Loss: 0.33117334387148845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1023] Loss: 0.33108181731560304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1024] Loss: 0.33116062539529006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1025] Loss: 0.3311238180686869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1026] Loss: 0.3311041729329145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1027] Loss: 0.33108289422884823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1028] Loss: 0.3311516849798899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1029] Loss: 0.33113979174044134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1030] Loss: 0.3311040685689998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1031] Loss: 0.33104009416484975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1032] Loss: 0.33111157109359474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1033] Loss: 0.33107366002276356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1034] Loss: 0.33102476296041483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1035] Loss: 0.33099374215109034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1036] Loss: 0.33092773353564553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1037] Loss: 0.33085658540517426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1038] Loss: 0.3308570153320708\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1039] Loss: 0.3308230703528598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1040] Loss: 0.3307973636245286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1041] Loss: 0.3307578108743871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1042] Loss: 0.3307535974372327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1043] Loss: 0.3307394258442296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1044] Loss: 0.3307968626661291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1045] Loss: 0.3307530153533702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1046] Loss: 0.3307516569356761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1047] Loss: 0.3307548796829522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1048] Loss: 0.3308101689497244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1049] Loss: 0.3307964102062769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1050] Loss: 0.3308522115045098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1051] Loss: 0.33086357011820466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1052] Loss: 0.33105887829275554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1053] Loss: 0.33099431477072166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1054] Loss: 0.33093562637819096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1055] Loss: 0.33091152673853036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1056] Loss: 0.33096021515401924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1057] Loss: 0.33101481622028256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1058] Loss: 0.3309741538575882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1059] Loss: 0.3309241469386463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1060] Loss: 0.3308433813751319\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1061] Loss: 0.3307733136820897\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1062] Loss: 0.33071888855361203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1063] Loss: 0.3308345651052084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1064] Loss: 0.33081068642624084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1065] Loss: 0.33073321777607995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1066] Loss: 0.3307022008116252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1067] Loss: 0.330613543360551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1068] Loss: 0.3306935894374664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1069] Loss: 0.3307530022853272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1070] Loss: 0.3307845192701054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1071] Loss: 0.3307590530116685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1072] Loss: 0.3308136330742296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1073] Loss: 0.3307915693993191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1074] Loss: 0.33084338483394393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1075] Loss: 0.33084391530872703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1076] Loss: 0.33080509757458937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1077] Loss: 0.330795284062838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1078] Loss: 0.3307552140223923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1079] Loss: 0.33089248703490715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1080] Loss: 0.3308398870833175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1081] Loss: 0.3308150137561506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1082] Loss: 0.3307422487760797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1083] Loss: 0.3307297911023752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1084] Loss: 0.33069173906368154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1085] Loss: 0.3306629527422378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1086] Loss: 0.3305715662138705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1087] Loss: 0.33078243987738604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1088] Loss: 0.3308133342294466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1089] Loss: 0.3307871793009791\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1090] Loss: 0.33076523995819146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1091] Loss: 0.33078905282505794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1092] Loss: 0.330729434514567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1093] Loss: 0.3307362875575974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1094] Loss: 0.33068292848376696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1095] Loss: 0.3306448420515884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1096] Loss: 0.3306588672695282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1097] Loss: 0.33058770679223587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1098] Loss: 0.33049259218983174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1099] Loss: 0.3304390325570547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1100] Loss: 0.33061834141809604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1101] Loss: 0.3305955210244887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1102] Loss: 0.33071590011962315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1103] Loss: 0.33070050591413575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1104] Loss: 0.3307895238787668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1105] Loss: 0.33070987745253727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1106] Loss: 0.3308391940900467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1107] Loss: 0.330781933614644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1108] Loss: 0.3307498522735429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1109] Loss: 0.3307092269669159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1110] Loss: 0.3306772103085482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1111] Loss: 0.33071160670922606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1112] Loss: 0.3308210855388484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1113] Loss: 0.3307882898344713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1114] Loss: 0.3308020139696569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1115] Loss: 0.33086110169499705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1116] Loss: 0.3308280749750653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1117] Loss: 0.33081785396630353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1118] Loss: 0.3307497535443082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1119] Loss: 0.3307118252765847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1120] Loss: 0.3306263365815996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1121] Loss: 0.3305544963449701\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1122] Loss: 0.330486399450644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1123] Loss: 0.3305027106536914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1124] Loss: 0.33054670174553824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1125] Loss: 0.3305700923454332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1126] Loss: 0.33054019122535205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1127] Loss: 0.33054967953284914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1128] Loss: 0.33065825659677245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1129] Loss: 0.33070990424437924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1130] Loss: 0.33070881821277764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1131] Loss: 0.33071950324856675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1132] Loss: 0.3307573490414713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1133] Loss: 0.33071522147227556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1134] Loss: 0.33068350307428157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1135] Loss: 0.3306387167200134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1136] Loss: 0.3307370700677458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1137] Loss: 0.3307212465665905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1138] Loss: 0.33066666193479716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1139] Loss: 0.3306204340780463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1140] Loss: 0.33062016905794356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1141] Loss: 0.33064451914746096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1142] Loss: 0.3305839925949067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1143] Loss: 0.33058845320599817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1144] Loss: 0.33062128936923724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1145] Loss: 0.33062990018765465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1146] Loss: 0.33060048082783006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1147] Loss: 0.33066185603488535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1148] Loss: 0.33069883347661405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1149] Loss: 0.33075574714792155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1150] Loss: 0.3307019537943695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1151] Loss: 0.33071903533065866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1152] Loss: 0.3307636690269226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1153] Loss: 0.3307699168870961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1154] Loss: 0.3307364417699235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1155] Loss: 0.3307608727229923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1156] Loss: 0.33073964194700506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1157] Loss: 0.3308172345010297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1158] Loss: 0.3308233390549361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1159] Loss: 0.33078303902943196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1160] Loss: 0.33078844026142723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1161] Loss: 0.3308527432330676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1162] Loss: 0.33079835453791256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1163] Loss: 0.3307549294110002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1164] Loss: 0.3306820198400494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1165] Loss: 0.33071709852400427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1166] Loss: 0.3307231380317712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1167] Loss: 0.33076000965861563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1168] Loss: 0.33079788087431444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1169] Loss: 0.33077649397076075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1170] Loss: 0.33074750110001655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1171] Loss: 0.3307384593438731\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1172] Loss: 0.33073308250624617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1173] Loss: 0.3307085374672844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1174] Loss: 0.33069749111062546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1175] Loss: 0.33083665535828266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1176] Loss: 0.3308306984889442\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1177] Loss: 0.33085817693574837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1178] Loss: 0.330851497171132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1179] Loss: 0.3309683208866024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1180] Loss: 0.33092084529055077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1181] Loss: 0.33084868080829083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1182] Loss: 0.3308580227148674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1183] Loss: 0.331024156025439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1184] Loss: 0.33096778486432926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1185] Loss: 0.3310022879770033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1186] Loss: 0.33099415128181153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1187] Loss: 0.33093701830881733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1188] Loss: 0.330895482911305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1189] Loss: 0.3308301678249805\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1190] Loss: 0.33081235439532675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1191] Loss: 0.3307512224031696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1192] Loss: 0.3306778432791224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1193] Loss: 0.3306439780121217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1194] Loss: 0.33071905943959384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1195] Loss: 0.3307754765026268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1196] Loss: 0.3307346621784719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1197] Loss: 0.33078623742823043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1198] Loss: 0.3307589581851506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1199] Loss: 0.33070767068016427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1200] Loss: 0.3306877627955315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1201] Loss: 0.33072548833331855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1202] Loss: 0.3306770046807778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1203] Loss: 0.33070586998494966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1204] Loss: 0.3307021380963631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1205] Loss: 0.33067791220380427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1206] Loss: 0.3306599114194338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1207] Loss: 0.3306238817344006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1208] Loss: 0.33058140794704627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1209] Loss: 0.330543287658627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1210] Loss: 0.3305036751176193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1211] Loss: 0.3305317923272455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1212] Loss: 0.33049307015168367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1213] Loss: 0.330502562248305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1214] Loss: 0.33043288243373875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1215] Loss: 0.33046715480091865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1216] Loss: 0.33046022247476253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1217] Loss: 0.33057002665056356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1218] Loss: 0.3304921159562509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1219] Loss: 0.33044580697799575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1220] Loss: 0.33046579057864817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1221] Loss: 0.3305606599538464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1222] Loss: 0.3304905076723816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1223] Loss: 0.3304267514938743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1224] Loss: 0.33045980865419017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1225] Loss: 0.3304560935665147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1226] Loss: 0.33042531126279506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1227] Loss: 0.33034461028557793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1228] Loss: 0.330364339931735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1229] Loss: 0.33035466560345045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1230] Loss: 0.3303650312132329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1231] Loss: 0.33032877884748735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1232] Loss: 0.33029482404762833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1233] Loss: 0.3303215057255165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1234] Loss: 0.3303468548630564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1235] Loss: 0.3303650982071147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1236] Loss: 0.3303578118677665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1237] Loss: 0.33028880359995044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1238] Loss: 0.3302156908975707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1239] Loss: 0.3301490166223298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1240] Loss: 0.33012131010025053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1241] Loss: 0.3301374777867114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1242] Loss: 0.3300574859000987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1243] Loss: 0.330107738873911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1244] Loss: 0.3301500324820373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1245] Loss: 0.3301942946507332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1246] Loss: 0.33025408412789325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1247] Loss: 0.3302779129222728\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1248] Loss: 0.33020680146539105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1249] Loss: 0.3301671079398256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1250] Loss: 0.3301599192985595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1251] Loss: 0.3301067139411784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1252] Loss: 0.3300660541906374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1253] Loss: 0.33004273078825824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1254] Loss: 0.3299929588993671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1255] Loss: 0.3299852429072027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1256] Loss: 0.32994597320439956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1257] Loss: 0.3299096920328447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1258] Loss: 0.32989108767278397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1259] Loss: 0.3298411321884102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1260] Loss: 0.3297848757815508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1261] Loss: 0.3297527907666161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1262] Loss: 0.32970343463339086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1263] Loss: 0.32978171558170527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1264] Loss: 0.32973372048464306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1265] Loss: 0.32968633069927145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1266] Loss: 0.32972296034954846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1267] Loss: 0.32971240597735796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1268] Loss: 0.3296603187526527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1269] Loss: 0.3296295227266518\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1270] Loss: 0.3295657085507821\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1271] Loss: 0.3295875137840715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1272] Loss: 0.3295226482097092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1273] Loss: 0.32947683766060376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1274] Loss: 0.3294566938049003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1275] Loss: 0.32945931752696533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1276] Loss: 0.3295325070906144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1277] Loss: 0.32949004002328836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1278] Loss: 0.3294876619262466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1279] Loss: 0.3294217424497288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1280] Loss: 0.3294363641367013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1281] Loss: 0.32935589458996484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1282] Loss: 0.32932285853412324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1283] Loss: 0.32932730195698917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1284] Loss: 0.329286585545706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1285] Loss: 0.32930359210613036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1286] Loss: 0.3292427196696699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1287] Loss: 0.3292503792625658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1288] Loss: 0.3292497852574224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1289] Loss: 0.3292888957798248\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1290] Loss: 0.32921444948319245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1291] Loss: 0.32920246500452344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1292] Loss: 0.32921195848353413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1293] Loss: 0.3291638658258765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1294] Loss: 0.32915471794030404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1295] Loss: 0.32910759444096205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1296] Loss: 0.3291000950971757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1297] Loss: 0.329072224211001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1298] Loss: 0.32902599054497556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1299] Loss: 0.329012747800799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1300] Loss: 0.32902349438840545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1301] Loss: 0.32902880693945696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1302] Loss: 0.32902274567347306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1303] Loss: 0.32896090865650135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1304] Loss: 0.3289702855346528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1305] Loss: 0.32903416786000395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1306] Loss: 0.3289717215469318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1307] Loss: 0.3290058240236625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1308] Loss: 0.32903262121153287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1309] Loss: 0.3290503132784998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1310] Loss: 0.3289948515305223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1311] Loss: 0.32898870093192306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1312] Loss: 0.3289149557200233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1313] Loss: 0.3288953374919071\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1314] Loss: 0.32896298965757914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1315] Loss: 0.32894905498727584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1316] Loss: 0.32902109507740157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1317] Loss: 0.32898594145357174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1318] Loss: 0.32908180705211704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1319] Loss: 0.32909820800633555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1320] Loss: 0.32910723796379504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1321] Loss: 0.3292569664865413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1322] Loss: 0.32918431494950023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1323] Loss: 0.3292252471985603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1324] Loss: 0.32937457655518226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1325] Loss: 0.3295064973854131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1326] Loss: 0.32953349695922574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1327] Loss: 0.3296209910566759\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1328] Loss: 0.32957291721533505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1329] Loss: 0.32957174019495783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1330] Loss: 0.3295676638233061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1331] Loss: 0.3295144700642788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1332] Loss: 0.3294695628482734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1333] Loss: 0.3294436132729943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1334] Loss: 0.329508711970574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1335] Loss: 0.32950030779604916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1336] Loss: 0.3294928932159479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1337] Loss: 0.3294769199465934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1338] Loss: 0.32943568613935026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1339] Loss: 0.32940368351151417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1340] Loss: 0.3293366883089449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1341] Loss: 0.3293143417915789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1342] Loss: 0.32932920895118073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1343] Loss: 0.3292646273242946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1344] Loss: 0.32920652633004766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1345] Loss: 0.3291470174712046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1346] Loss: 0.3290870265183659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1347] Loss: 0.3290261980927865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1348] Loss: 0.3289679472224187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1349] Loss: 0.3290648951665772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1350] Loss: 0.32905033836417236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1351] Loss: 0.3290235362237558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1352] Loss: 0.3290568060933434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1353] Loss: 0.3289970234130956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1354] Loss: 0.32906164134445576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1355] Loss: 0.3290063781505604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1356] Loss: 0.32896350830088594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1357] Loss: 0.3289544160806866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1358] Loss: 0.32894755872241555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1359] Loss: 0.32903121827222886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1360] Loss: 0.32900078719070347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1361] Loss: 0.3290092221579369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1362] Loss: 0.3290845611287248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1363] Loss: 0.32914464628069023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1364] Loss: 0.3291278387159611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1365] Loss: 0.3290890258778832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1366] Loss: 0.32909585603201863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1367] Loss: 0.3290141665569721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1368] Loss: 0.3290495056565068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1369] Loss: 0.3290728928160637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1370] Loss: 0.3291973977605402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1371] Loss: 0.32915328586246606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1372] Loss: 0.3291636822657697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1373] Loss: 0.3291848095208094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1374] Loss: 0.3292560861426447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1375] Loss: 0.32929005123952665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1376] Loss: 0.329271148933937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1377] Loss: 0.3292766917121116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1378] Loss: 0.3292451394277636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1379] Loss: 0.32921924327068974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1380] Loss: 0.3291628312780506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1381] Loss: 0.32919828041397875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1382] Loss: 0.3292673191829035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1383] Loss: 0.3293047161465647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1384] Loss: 0.32924741599864277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1385] Loss: 0.3292587623279891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1386] Loss: 0.32927670068199977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1387] Loss: 0.3292569483553881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1388] Loss: 0.3292068726445238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1389] Loss: 0.3291653327982111\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1390] Loss: 0.3291290849943542\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1391] Loss: 0.3291089118668004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1392] Loss: 0.3291906354803214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1393] Loss: 0.32914872991691757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1394] Loss: 0.32915061144336305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1395] Loss: 0.3290885743148405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1396] Loss: 0.329164230973271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1397] Loss: 0.32919478006336195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1398] Loss: 0.3291555468843191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1399] Loss: 0.3291090837174162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1400] Loss: 0.3291507624336835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1401] Loss: 0.32911162904644725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1402] Loss: 0.3291236767306146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1403] Loss: 0.32910218984814166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1404] Loss: 0.3290606261668912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1405] Loss: 0.32922171820748874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1406] Loss: 0.3291744742083392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1407] Loss: 0.32917255715749244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1408] Loss: 0.3291274403429721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1409] Loss: 0.32912036375854686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1410] Loss: 0.3290723725525827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1411] Loss: 0.32905575224696926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1412] Loss: 0.329045572886766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1413] Loss: 0.3291869334830451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1414] Loss: 0.3291607114861843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1415] Loss: 0.3290998075275594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1416] Loss: 0.3290528365191459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1417] Loss: 0.3289935561537301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1418] Loss: 0.3289795550728531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1419] Loss: 0.32896149145605535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1420] Loss: 0.3289548807569142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1421] Loss: 0.3288790644182867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1422] Loss: 0.3289071987264452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1423] Loss: 0.3288324842585186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1424] Loss: 0.32883047494786516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1425] Loss: 0.32881091340037216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1426] Loss: 0.3287713344134788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1427] Loss: 0.3287396870917011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1428] Loss: 0.3287328860371328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1429] Loss: 0.3286958540172081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1430] Loss: 0.32873034206913887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1431] Loss: 0.3287398452049779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1432] Loss: 0.32875520823166726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1433] Loss: 0.3288120868564383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1434] Loss: 0.3287834142832023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1435] Loss: 0.32873387640843743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1436] Loss: 0.32868711642458354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1437] Loss: 0.32865341827912253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1438] Loss: 0.32874360063246316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1439] Loss: 0.3287266753233972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1440] Loss: 0.32867694519107726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1441] Loss: 0.32861848919065056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1442] Loss: 0.3286827201814601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1443] Loss: 0.32866927716129907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1444] Loss: 0.32865134964572684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1445] Loss: 0.32862277128830353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1446] Loss: 0.3286670865725947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1447] Loss: 0.32868564327032695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1448] Loss: 0.3286334584156672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1449] Loss: 0.32861456043688275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1450] Loss: 0.3286031252189345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1451] Loss: 0.3285642305054028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1452] Loss: 0.3285685316417608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1453] Loss: 0.3285634890712541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1454] Loss: 0.32862823159227694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1455] Loss: 0.3286228530202552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1456] Loss: 0.32856355223508865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1457] Loss: 0.3285007358031893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1458] Loss: 0.3284552819333096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1459] Loss: 0.32846036017881813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1460] Loss: 0.32843268290162086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1461] Loss: 0.3285244391772412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1462] Loss: 0.32848068486323934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1463] Loss: 0.3285818104310469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1464] Loss: 0.32852110561579223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1465] Loss: 0.32857182565407256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1466] Loss: 0.32857196407033323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1467] Loss: 0.3285520773782226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1468] Loss: 0.3285628220006343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1469] Loss: 0.32860598431773264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1470] Loss: 0.32858209543704603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1471] Loss: 0.3285594953676409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1472] Loss: 0.3285460432394499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1473] Loss: 0.32853541730395264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1474] Loss: 0.3284924168046789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1475] Loss: 0.3284214033112739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1476] Loss: 0.3285327264649788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1477] Loss: 0.32853633828098966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1478] Loss: 0.32849402043474724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1479] Loss: 0.32856230839147765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1480] Loss: 0.3285146862459795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1481] Loss: 0.3284998777110654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1482] Loss: 0.32845010634126337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1483] Loss: 0.3284720151720639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1484] Loss: 0.3284433161099561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1485] Loss: 0.32847938823566275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1486] Loss: 0.32840427473557293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1487] Loss: 0.3284768921439769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1488] Loss: 0.3284726709961891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1489] Loss: 0.328420059114206\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8944000000000001\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1490] Loss: 0.328388903614619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1491] Loss: 0.3284195168609863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1492] Loss: 0.32841883884213224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1493] Loss: 0.32838816119287306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1494] Loss: 0.3283556634047368\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1495] Loss: 0.3283329963458217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1496] Loss: 0.3282868379706211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1497] Loss: 0.3282442161194971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1498] Loss: 0.3282226296416317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1499] Loss: 0.3282112379631451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1500] Loss: 0.3282187775512979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1501] Loss: 0.3283014408132255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1502] Loss: 0.3282732379251562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1503] Loss: 0.32824772498005667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1504] Loss: 0.3282898879700321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1505] Loss: 0.32829589640331686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1506] Loss: 0.3283263677590607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1507] Loss: 0.32826232004492184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1508] Loss: 0.3284162903411521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1509] Loss: 0.3284003879344449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1510] Loss: 0.32840152021606794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1511] Loss: 0.32838401696273745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1512] Loss: 0.328349228718107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1513] Loss: 0.32837595181890056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1514] Loss: 0.328350410160335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1515] Loss: 0.3283886388327512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1516] Loss: 0.328357396105045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1517] Loss: 0.3283767748746348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1518] Loss: 0.3283761383516515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1519] Loss: 0.32837483504693626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1520] Loss: 0.32835604079762154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1521] Loss: 0.32842913018212316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1522] Loss: 0.32838711051980435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1523] Loss: 0.3283903831443373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 21, Batch 1524] Loss: 0.32833416855744196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 0] Loss: 0.32834498283545427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1] Loss: 0.32830828149972513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 2] Loss: 0.32830759321859193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 3] Loss: 0.3283540273041237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 4] Loss: 0.3284414086882311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 5] Loss: 0.32841653485264394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 6] Loss: 0.32835742097598475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 7] Loss: 0.32834744467487875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 8] Loss: 0.3283545698890049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 9] Loss: 0.32836086522474683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 10] Loss: 0.3283334749794306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 11] Loss: 0.3283849154574156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 12] Loss: 0.3284038775291757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 13] Loss: 0.3284562683339212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 14] Loss: 0.32843551492980766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 15] Loss: 0.32837115706391284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 16] Loss: 0.328323194432436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 17] Loss: 0.32832415662151626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 18] Loss: 0.32825542229962207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 19] Loss: 0.32825980937117144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 20] Loss: 0.3282248686371159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 21] Loss: 0.32820438261582946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 22] Loss: 0.3281994399182635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 23] Loss: 0.3281861326366197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 24] Loss: 0.3281205439302243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 25] Loss: 0.32805226390176595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 26] Loss: 0.327993552671063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 27] Loss: 0.3280981237740022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 28] Loss: 0.3281109304397892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 29] Loss: 0.3281486561508822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 30] Loss: 0.32825864100321567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 31] Loss: 0.32825834052840314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 32] Loss: 0.32821403607383876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 33] Loss: 0.3282294947407589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 34] Loss: 0.3282836176909996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 35] Loss: 0.3282889162203294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 36] Loss: 0.3282291211428181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 37] Loss: 0.3282402894331581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 38] Loss: 0.32824679399578316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 39] Loss: 0.32824516144251414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 40] Loss: 0.328262684225666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 41] Loss: 0.3283227948750795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 42] Loss: 0.32835343471443346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 43] Loss: 0.32844706592980283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 44] Loss: 0.32839761030092024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 45] Loss: 0.328495924615703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 46] Loss: 0.32846707021987026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 47] Loss: 0.32847783565175237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 48] Loss: 0.32843416660044134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 49] Loss: 0.32838460093123545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 50] Loss: 0.3284234081887812\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 51] Loss: 0.3283646557727682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 52] Loss: 0.3284539781156863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 53] Loss: 0.32843347276384766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 54] Loss: 0.3284454756160815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 55] Loss: 0.32850300101563334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 56] Loss: 0.3285884872751258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 57] Loss: 0.32864738866951065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 58] Loss: 0.3286450499571817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 59] Loss: 0.3285785196191173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 60] Loss: 0.3285497636761994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 61] Loss: 0.3285578086318375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 62] Loss: 0.328529877747972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 63] Loss: 0.32852888711369954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 64] Loss: 0.32847092067196204\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 65] Loss: 0.32851467771794957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 66] Loss: 0.3285725958190237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 67] Loss: 0.32860751206859284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 68] Loss: 0.3286101306182638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 69] Loss: 0.32853693376114435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 70] Loss: 0.32851775753621537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 71] Loss: 0.32851321025083036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 72] Loss: 0.32848285623508744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 73] Loss: 0.3284869898096355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 74] Loss: 0.328504226105919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 75] Loss: 0.3285057322788202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 76] Loss: 0.3284645994880671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 77] Loss: 0.3284344457620049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 78] Loss: 0.32840699885702956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 79] Loss: 0.32836206687403563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 80] Loss: 0.3283479001841383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 81] Loss: 0.32834011492176396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 82] Loss: 0.3282855664411543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 83] Loss: 0.3282591119579231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 84] Loss: 0.3282743568856586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 85] Loss: 0.32827247841202695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 86] Loss: 0.3283419589016031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 87] Loss: 0.3283560751971403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 88] Loss: 0.32829732399327416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 89] Loss: 0.32826945677637964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 90] Loss: 0.32823902405415556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 91] Loss: 0.3283073676514753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 92] Loss: 0.32830506728125325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 93] Loss: 0.3282645357652309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 94] Loss: 0.3283105396762269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 95] Loss: 0.3283084205898108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 96] Loss: 0.3283070933895785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 97] Loss: 0.328323461539653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 98] Loss: 0.32834005162430896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 99] Loss: 0.3282824489478819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 100] Loss: 0.32826518394253584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 101] Loss: 0.32825938757393197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 102] Loss: 0.32823578628819744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 103] Loss: 0.328265796195377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 104] Loss: 0.3282770485148562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 105] Loss: 0.328283386540449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 106] Loss: 0.32824426261349426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 107] Loss: 0.3283250172835255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 108] Loss: 0.32833472820446036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 109] Loss: 0.32834991014147924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 110] Loss: 0.32832924622520215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 111] Loss: 0.3282897531018336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 112] Loss: 0.3282512748194173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 113] Loss: 0.3282440063357353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 114] Loss: 0.3282123939669928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 115] Loss: 0.32814805593403396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 116] Loss: 0.328138832686714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 117] Loss: 0.32810497724682025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 118] Loss: 0.3280570187754999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 119] Loss: 0.32805417723258035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 120] Loss: 0.3280039012353583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 121] Loss: 0.32800234932146904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 122] Loss: 0.3280071147058009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 123] Loss: 0.3279501692637017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 124] Loss: 0.3279007170846345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 125] Loss: 0.3278383832119803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 126] Loss: 0.3278558552209211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 127] Loss: 0.3278939070700257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 128] Loss: 0.32793681548303777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 129] Loss: 0.32791176958698487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 130] Loss: 0.3279872628457545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 131] Loss: 0.327958334270848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 132] Loss: 0.32791652084625184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 133] Loss: 0.32786902113353716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 134] Loss: 0.32783068763946427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 135] Loss: 0.32777024230579593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 136] Loss: 0.32773661102822244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 137] Loss: 0.32770275833362417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 138] Loss: 0.3277676469366127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 139] Loss: 0.3277467041873611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 140] Loss: 0.32774201318270957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 141] Loss: 0.32776412168619257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 142] Loss: 0.32769509560361465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 143] Loss: 0.3276451495267562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 144] Loss: 0.3277398937120228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 145] Loss: 0.32768042927842633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 146] Loss: 0.32764377704628184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 147] Loss: 0.3276581375702838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 148] Loss: 0.3277820899388866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 149] Loss: 0.3277784675825734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 150] Loss: 0.32770895293023355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 151] Loss: 0.3276635142364761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 152] Loss: 0.32763713750643286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 153] Loss: 0.32763728734839803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 154] Loss: 0.3276358372779284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 155] Loss: 0.3276645825320597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 156] Loss: 0.3277638435109238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 157] Loss: 0.32775514472190237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 158] Loss: 0.3277430831777806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 159] Loss: 0.32777598050895534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 160] Loss: 0.32776326274248596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 161] Loss: 0.3277548257788965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 162] Loss: 0.3277198421917566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 163] Loss: 0.3277384508373561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 164] Loss: 0.32770363201988223\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 165] Loss: 0.32767857704380543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 166] Loss: 0.3276678366800877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 167] Loss: 0.32766601967366316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 168] Loss: 0.32762347960538213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 169] Loss: 0.3276323713169482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 170] Loss: 0.32764303211382845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 171] Loss: 0.32757750527171126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 172] Loss: 0.3275486535419173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 173] Loss: 0.3275063393245764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 174] Loss: 0.32751588802612913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 175] Loss: 0.3274983256934403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 176] Loss: 0.327579050701437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 177] Loss: 0.3275691541344169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 178] Loss: 0.3277043069210281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 179] Loss: 0.32774430725707043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 180] Loss: 0.32772237349289235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 181] Loss: 0.3277122611296449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 182] Loss: 0.3277746641699467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 183] Loss: 0.3278144807993051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 184] Loss: 0.3277840202551736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 185] Loss: 0.32781511539159497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 186] Loss: 0.3277853159859826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 187] Loss: 0.3278068196077704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 188] Loss: 0.3278579388408486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 189] Loss: 0.3280466818800763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 190] Loss: 0.32807916789689606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 191] Loss: 0.32807424450375117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 192] Loss: 0.3280601294737851\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 193] Loss: 0.3280257588614038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 194] Loss: 0.32798796684826653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 195] Loss: 0.3280050824471309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 196] Loss: 0.3280087713025404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 197] Loss: 0.32794936362111665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 198] Loss: 0.32793467122196496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 199] Loss: 0.3279862894910818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 200] Loss: 0.32797716557435147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 201] Loss: 0.32797544886588703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 202] Loss: 0.3279658909390642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 203] Loss: 0.32797817137554613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 204] Loss: 0.3280486041983737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 205] Loss: 0.3279828209019681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 206] Loss: 0.32797336880412364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 207] Loss: 0.3279606696685271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 208] Loss: 0.3279663602293949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 209] Loss: 0.327952219831275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 210] Loss: 0.327945051299124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 211] Loss: 0.3279212617370933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 212] Loss: 0.3280098620177443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 213] Loss: 0.3279494977701794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 214] Loss: 0.3279169431624522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 215] Loss: 0.3279137107716917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 216] Loss: 0.3279073134340722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 217] Loss: 0.32787871856402034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 218] Loss: 0.32789791276147706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 219] Loss: 0.32794581664015143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 220] Loss: 0.3279867180780868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 221] Loss: 0.327965486397598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 222] Loss: 0.32793320879075527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 223] Loss: 0.3279015947295272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 224] Loss: 0.32786018688775453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 225] Loss: 0.3278406277773693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 226] Loss: 0.32788435907692653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 227] Loss: 0.327856163352771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 228] Loss: 0.32780982964616573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 229] Loss: 0.3278067921728047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 230] Loss: 0.327819742281212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 231] Loss: 0.3279812665483941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 232] Loss: 0.32796058550062657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 233] Loss: 0.32795420432671746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 234] Loss: 0.32801516285251514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 235] Loss: 0.328043314280233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 236] Loss: 0.32797522860617145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 237] Loss: 0.3279786019464491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 238] Loss: 0.327939217133565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 239] Loss: 0.32788599482187275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 240] Loss: 0.3278650532620478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 241] Loss: 0.32783061462267427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 242] Loss: 0.3277965235855992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 243] Loss: 0.32782135018341835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 244] Loss: 0.32780650933197786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 245] Loss: 0.32782773418575634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 246] Loss: 0.3277763475028465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 247] Loss: 0.32771960053400234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 248] Loss: 0.32772867213566814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 249] Loss: 0.32780924634653635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 250] Loss: 0.3278261305751619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 251] Loss: 0.32785741705313814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 252] Loss: 0.32791030750496064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 253] Loss: 0.3279766909270731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 254] Loss: 0.32793571779972247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 255] Loss: 0.3279400702437818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 256] Loss: 0.32791566011664947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 257] Loss: 0.32786972827692074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 258] Loss: 0.32783079746050997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 259] Loss: 0.32780484544467686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 260] Loss: 0.3277454029237282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 261] Loss: 0.32781052414202705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 262] Loss: 0.3278249608284237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 263] Loss: 0.3278429266650762\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 264] Loss: 0.32785392157076426\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 265] Loss: 0.3278471307242708\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 266] Loss: 0.32786347632254187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 267] Loss: 0.3279452931491948\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 268] Loss: 0.3279691526862177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 269] Loss: 0.3280137633574238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 270] Loss: 0.3281180425698026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 271] Loss: 0.3281025378845441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 272] Loss: 0.3281546062201357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 273] Loss: 0.3280924283153646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 274] Loss: 0.3280579309654762\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 275] Loss: 0.3280680331522082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 276] Loss: 0.3280005425882221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 277] Loss: 0.3280539638346277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 278] Loss: 0.32806757412202403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 279] Loss: 0.32808083653534675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 280] Loss: 0.3280401433354199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 281] Loss: 0.3280086176796447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 282] Loss: 0.328024750675196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 283] Loss: 0.32810722082219224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 284] Loss: 0.32809357972104514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 285] Loss: 0.3280616423113814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 286] Loss: 0.3280332201430023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 287] Loss: 0.3279907226657479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 288] Loss: 0.3279364622113979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 289] Loss: 0.3280561454515042\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 290] Loss: 0.3281607669140705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 291] Loss: 0.3281666895235023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 292] Loss: 0.32819864428287765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 293] Loss: 0.328176428988418\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 294] Loss: 0.32824503640137304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 295] Loss: 0.3282830976107616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 296] Loss: 0.32826915380709004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 297] Loss: 0.32822079304014196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 298] Loss: 0.32818979297155215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 299] Loss: 0.3281695570886051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 300] Loss: 0.3281782396901944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 301] Loss: 0.3281540998885798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 302] Loss: 0.3282074702483073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 303] Loss: 0.32816752118753717\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 304] Loss: 0.32810706326089584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 305] Loss: 0.3281051803125956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 306] Loss: 0.32812513710326224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 307] Loss: 0.32806949114162376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 308] Loss: 0.32807648322284744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 309] Loss: 0.3281131159417326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 310] Loss: 0.32811117976181625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 311] Loss: 0.32806524127889214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 312] Loss: 0.3280181235526896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 313] Loss: 0.3279711867842758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 314] Loss: 0.3279729233064889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 315] Loss: 0.3279672010604496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 316] Loss: 0.32803371807712445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 317] Loss: 0.328074813129272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 318] Loss: 0.3280787415554561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 319] Loss: 0.3280854919189666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 320] Loss: 0.3281035731420427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 321] Loss: 0.32807596685316615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 322] Loss: 0.32809282247212934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 323] Loss: 0.3281117561553325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 324] Loss: 0.3280908110434673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 325] Loss: 0.328085854529793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 326] Loss: 0.32806602399893836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 327] Loss: 0.3281407348717974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 328] Loss: 0.32812505945381276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 329] Loss: 0.3281061939390822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 330] Loss: 0.3281357629678787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 331] Loss: 0.32815980040981346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 332] Loss: 0.3281711959421281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 333] Loss: 0.32815234425902784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 334] Loss: 0.3281605817463206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 335] Loss: 0.32816738402341233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 336] Loss: 0.32815521999576386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 337] Loss: 0.32814704634057373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 338] Loss: 0.328168614724408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 339] Loss: 0.3281895211005327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 340] Loss: 0.3281413039369305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 341] Loss: 0.3280868631029725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 342] Loss: 0.32805391059190125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 343] Loss: 0.32800663153951365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 344] Loss: 0.32806441703011535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 345] Loss: 0.32812339047811495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 346] Loss: 0.3281171579059941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 347] Loss: 0.32810833699866904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 348] Loss: 0.3281049252692707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 349] Loss: 0.32809197456573996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 350] Loss: 0.328044703216713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 351] Loss: 0.3280368140251105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 352] Loss: 0.32801595538101547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 353] Loss: 0.3279619620848692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 354] Loss: 0.3279117344985244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 355] Loss: 0.3278903803822905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 356] Loss: 0.3279304342660531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 357] Loss: 0.3279646268241885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 358] Loss: 0.3279192173316277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 359] Loss: 0.3279145573631176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 360] Loss: 0.327909042866509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 361] Loss: 0.3278681069941583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 362] Loss: 0.32782354277037223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 363] Loss: 0.32776355539416446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 364] Loss: 0.32775086230736117\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 365] Loss: 0.3277332065774604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 366] Loss: 0.32771212379459347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 367] Loss: 0.3276864042449178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 368] Loss: 0.32765813660703713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 369] Loss: 0.3276540373964139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 370] Loss: 0.32766968743842945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 371] Loss: 0.3276926287061738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 372] Loss: 0.3276636410503299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 373] Loss: 0.3276265394083413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 374] Loss: 0.32762673860131075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 375] Loss: 0.327632389957556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 376] Loss: 0.3275673395010601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 377] Loss: 0.3275912634430066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 378] Loss: 0.3276281635358444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 379] Loss: 0.32766711702174284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 380] Loss: 0.32763540655384743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 381] Loss: 0.32759665106975355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 382] Loss: 0.3276122810804668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 383] Loss: 0.3276281534298642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 384] Loss: 0.32758984926199103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 385] Loss: 0.32759211125702664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 386] Loss: 0.3275706175303076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 387] Loss: 0.32753890327772917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 388] Loss: 0.3275006200666102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 389] Loss: 0.3274915747838483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 390] Loss: 0.3274569992914027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 391] Loss: 0.327462839614091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 392] Loss: 0.32744960607461615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 393] Loss: 0.3274242809201263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 394] Loss: 0.32740509550712166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 395] Loss: 0.3273948421257092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 396] Loss: 0.32735734800003186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 397] Loss: 0.3273304908065952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 398] Loss: 0.3273284932823766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 399] Loss: 0.3273665301440847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 400] Loss: 0.3273174600370652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 401] Loss: 0.3274016075591963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 402] Loss: 0.3273726989213769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 403] Loss: 0.3274248704516969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 404] Loss: 0.32750707977242066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 405] Loss: 0.3275538600378503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 406] Loss: 0.3275688046749619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 407] Loss: 0.3275854535117421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 408] Loss: 0.3276395566091068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 409] Loss: 0.32763339631709615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 410] Loss: 0.3275744130965771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 411] Loss: 0.3276130085560813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 412] Loss: 0.32762186018520795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 413] Loss: 0.3275649367803234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 414] Loss: 0.3275423421420634\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 415] Loss: 0.3276051850711831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 416] Loss: 0.32755589569438487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 417] Loss: 0.32756609347577664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 418] Loss: 0.3275721388167738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 419] Loss: 0.3275623225704017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 420] Loss: 0.32755764045443614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 421] Loss: 0.32754300214838866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 422] Loss: 0.3275160171537232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 423] Loss: 0.3274478562981696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 424] Loss: 0.3274353663086368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 425] Loss: 0.3274457931095969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 426] Loss: 0.3274609974880618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 427] Loss: 0.32745913254265524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 428] Loss: 0.3275078649967155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 429] Loss: 0.3274567055284213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 430] Loss: 0.3274111425058987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 431] Loss: 0.32737755342675345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 432] Loss: 0.3273331526956722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 433] Loss: 0.3272889035970274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 434] Loss: 0.32727846124584686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 435] Loss: 0.3272912790735589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 436] Loss: 0.3272791825688491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 437] Loss: 0.3272811763073745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 438] Loss: 0.3272620097879602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 439] Loss: 0.32726773697262007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 440] Loss: 0.32724614582547895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 441] Loss: 0.3272991688950819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 442] Loss: 0.327290541901009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 443] Loss: 0.3272730228334865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 444] Loss: 0.3272927304225574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 445] Loss: 0.32724180353379423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 446] Loss: 0.3273547837798563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 447] Loss: 0.3273493631545644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 448] Loss: 0.3273455997457856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 449] Loss: 0.32729855898894966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 450] Loss: 0.3272603949626074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 451] Loss: 0.3272910111470315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 452] Loss: 0.3272730512049095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 453] Loss: 0.3272537668363306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 454] Loss: 0.3271962455316596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 455] Loss: 0.3271459939785023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 456] Loss: 0.32715870482324955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 457] Loss: 0.32719656443826817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 458] Loss: 0.3272214912014931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 459] Loss: 0.32726503851934174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 460] Loss: 0.32722529549180246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 461] Loss: 0.3272133996838168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 462] Loss: 0.3272105320845894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 463] Loss: 0.327172961940368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 464] Loss: 0.327180986452484\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8946000000000001\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 465] Loss: 0.3271661283948436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 466] Loss: 0.3272080613083733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 467] Loss: 0.3271738623483441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 468] Loss: 0.32721683964653936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 469] Loss: 0.32717261207615306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 470] Loss: 0.32713312519163557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 471] Loss: 0.32712790744498055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 472] Loss: 0.3270819939304008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 473] Loss: 0.32704795461853475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 474] Loss: 0.3270998833950316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 475] Loss: 0.3271283845096866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 476] Loss: 0.32714281602333917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 477] Loss: 0.32718400789181284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 478] Loss: 0.3272135450027475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 479] Loss: 0.32726108414721267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 480] Loss: 0.32726431882239193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 481] Loss: 0.32724313637904573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 482] Loss: 0.3272689029835991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 483] Loss: 0.3272845567308909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 484] Loss: 0.3272739226052162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 485] Loss: 0.3272826256764243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 486] Loss: 0.327260916132703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 487] Loss: 0.3272585398394358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 488] Loss: 0.32724595511747784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 489] Loss: 0.32722179182440103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 490] Loss: 0.32718212474266767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 491] Loss: 0.3272455034720929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 492] Loss: 0.32725561793171637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 493] Loss: 0.3272216549997676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 494] Loss: 0.3272702384215304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 495] Loss: 0.32727263398999273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 496] Loss: 0.3272568230144741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 497] Loss: 0.3272092464228327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 498] Loss: 0.32722964842099533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 499] Loss: 0.32721042055366695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 500] Loss: 0.3272041295276962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 501] Loss: 0.327178694317614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 502] Loss: 0.3271715413361013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 503] Loss: 0.3271869148029701\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 504] Loss: 0.3271764323816061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 505] Loss: 0.3271969084742428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 506] Loss: 0.3271770737857126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 507] Loss: 0.3272094639867505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 508] Loss: 0.32731883786679883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 509] Loss: 0.32728178836821104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 510] Loss: 0.3273455236665843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 511] Loss: 0.32739922826195483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 512] Loss: 0.32742328517610575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 513] Loss: 0.32738580702269665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 514] Loss: 0.3273787758450788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 515] Loss: 0.3273374778200258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 516] Loss: 0.32729208981389496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 517] Loss: 0.32730700591360734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 518] Loss: 0.3273203615129677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 519] Loss: 0.32728218242857626\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 520] Loss: 0.3272659568262911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 521] Loss: 0.32725377646418\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 522] Loss: 0.3272557408494394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 523] Loss: 0.3272824648597272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 524] Loss: 0.3272501338164972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 525] Loss: 0.32724421802277975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 526] Loss: 0.3272045499849195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 527] Loss: 0.32717978281720345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 528] Loss: 0.32727318833449925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 529] Loss: 0.3273585956283667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 530] Loss: 0.32733934387482067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 531] Loss: 0.3273340992027265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 532] Loss: 0.3273552098047776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 533] Loss: 0.32737470618191294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 534] Loss: 0.3273672078524145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 535] Loss: 0.3273275784837703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 536] Loss: 0.32738426540094206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 537] Loss: 0.3274032156150994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 538] Loss: 0.32738359755616847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 539] Loss: 0.32734781383053535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 540] Loss: 0.3273033906654526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 541] Loss: 0.3272664703869293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 542] Loss: 0.32723313808131427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 543] Loss: 0.3272129447042168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 544] Loss: 0.32721768597703754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 545] Loss: 0.3272347899031747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 546] Loss: 0.3272083267410042\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 547] Loss: 0.32721129103277447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 548] Loss: 0.3271940285904481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 549] Loss: 0.3271445835314628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 550] Loss: 0.3271274235079039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 551] Loss: 0.3270981413326733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 552] Loss: 0.3270899121546753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 553] Loss: 0.32707874023605704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 554] Loss: 0.32707312667458543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 555] Loss: 0.3270496603241251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 556] Loss: 0.32705509805232236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 557] Loss: 0.3270189233639584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 558] Loss: 0.3270129045637051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 559] Loss: 0.32706743164483737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 560] Loss: 0.3270265857923943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 561] Loss: 0.32708040162622737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 562] Loss: 0.32708209304895736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 563] Loss: 0.32713300159861963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 564] Loss: 0.32712582096827486\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 565] Loss: 0.32718948503988626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 566] Loss: 0.32723915220613137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 567] Loss: 0.3272161351555248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 568] Loss: 0.3271840301208834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 569] Loss: 0.3271877701848227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 570] Loss: 0.3273067559062533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 571] Loss: 0.3272857346800917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 572] Loss: 0.32727537285710273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 573] Loss: 0.3272784255325219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 574] Loss: 0.32727375078607474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 575] Loss: 0.3272939764039835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 576] Loss: 0.32726902538390545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 577] Loss: 0.3273717050626635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 578] Loss: 0.3273495107937012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 579] Loss: 0.3273199004179706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 580] Loss: 0.32737786262357393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 581] Loss: 0.32742861221049213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 582] Loss: 0.3274689957704939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 583] Loss: 0.32747844263720205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 584] Loss: 0.3274403117914606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 585] Loss: 0.3274182478045898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 586] Loss: 0.3273905426779123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 587] Loss: 0.32738564653314944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 588] Loss: 0.3274381442785263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 589] Loss: 0.3274624526681842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 590] Loss: 0.3274939189589668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 591] Loss: 0.3274675944481817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 592] Loss: 0.32742149273059207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 593] Loss: 0.3274402940044769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 594] Loss: 0.3274213023857353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 595] Loss: 0.3274287021365659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 596] Loss: 0.32745158916801226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 597] Loss: 0.3274139711620249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 598] Loss: 0.3274366635549962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 599] Loss: 0.32745538600625435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 600] Loss: 0.32747295756305067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 601] Loss: 0.3274699997624597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 602] Loss: 0.3274713434129431\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 603] Loss: 0.32747933856051437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 604] Loss: 0.327483813594155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 605] Loss: 0.32754037026991745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 606] Loss: 0.32759684360296604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 607] Loss: 0.327581454561336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 608] Loss: 0.3275437326707976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 609] Loss: 0.3275269614858227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 610] Loss: 0.3274931067942361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 611] Loss: 0.3274647622230774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 612] Loss: 0.3274427157057471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 613] Loss: 0.3274321178831751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 614] Loss: 0.32741088549491526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 615] Loss: 0.3274297855822795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 616] Loss: 0.32742189652591597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 617] Loss: 0.32748859811316733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 618] Loss: 0.32754622305346365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 619] Loss: 0.3275335038031235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 620] Loss: 0.32754472068472307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 621] Loss: 0.327510960777588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 622] Loss: 0.32753620505917863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 623] Loss: 0.3275414622612769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 624] Loss: 0.3274985010612241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 625] Loss: 0.32750303548943915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 626] Loss: 0.3275681282810271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 627] Loss: 0.32761139703817976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 628] Loss: 0.32759531078651244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 629] Loss: 0.3275701181324162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 630] Loss: 0.3275302473513305\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 631] Loss: 0.3275013674483305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 632] Loss: 0.3274639613265756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 633] Loss: 0.32746463808163484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 634] Loss: 0.32743018409762986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 635] Loss: 0.3274371524965026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 636] Loss: 0.32745718633831766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 637] Loss: 0.32742806888351517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 638] Loss: 0.32740140615016455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 639] Loss: 0.32740041294067124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 640] Loss: 0.3274500502808724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 641] Loss: 0.327484071943991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 642] Loss: 0.3274469273331856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 643] Loss: 0.32743175284667586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 644] Loss: 0.32743087118618597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 645] Loss: 0.3274009269571469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 646] Loss: 0.3274199288716452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 647] Loss: 0.327410830442218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 648] Loss: 0.3273632260235363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 649] Loss: 0.327322656923656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 650] Loss: 0.32736859222564874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 651] Loss: 0.3274088808133207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 652] Loss: 0.32742491528489964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 653] Loss: 0.32736684608515526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 654] Loss: 0.3273201341849067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 655] Loss: 0.32728973788706434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 656] Loss: 0.327289925294911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 657] Loss: 0.3273084020859089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 658] Loss: 0.327278147033869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 659] Loss: 0.3272517085383099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 660] Loss: 0.32723055314767874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 661] Loss: 0.327182259878902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 662] Loss: 0.3271601929883355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 663] Loss: 0.32721481307875366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 664] Loss: 0.32721672374935534\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 665] Loss: 0.3271911622192024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 666] Loss: 0.3271520213711608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 667] Loss: 0.32715870535812724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 668] Loss: 0.3271147041025102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 669] Loss: 0.3270667494365891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 670] Loss: 0.3270973464131987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 671] Loss: 0.32709545597545525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 672] Loss: 0.3271070885283065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 673] Loss: 0.32709594609395737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 674] Loss: 0.32706057556653384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 675] Loss: 0.32705987114946394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 676] Loss: 0.32703190365295487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 677] Loss: 0.32701550289181797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 678] Loss: 0.32704706535461714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 679] Loss: 0.3270486937557806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 680] Loss: 0.32707675663829033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 681] Loss: 0.3270735965290375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 682] Loss: 0.3270502351860928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 683] Loss: 0.3270147981897274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 684] Loss: 0.3270233686584303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 685] Loss: 0.32702959350164007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 686] Loss: 0.32707330346421876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 687] Loss: 0.3270967403570047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 688] Loss: 0.32706486578597577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 689] Loss: 0.32710557984348715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 690] Loss: 0.3271236400514481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 691] Loss: 0.3272030115579953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 692] Loss: 0.3271657989033607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 693] Loss: 0.32717219064756076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 694] Loss: 0.32734199761145255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 695] Loss: 0.32731421681877115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 696] Loss: 0.3273088950842407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 697] Loss: 0.3272714540684894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 698] Loss: 0.32725758271571104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 699] Loss: 0.32727227260546277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 700] Loss: 0.3272688004625849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 701] Loss: 0.3272785463769028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 702] Loss: 0.327236891404719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 703] Loss: 0.3272064130477331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 704] Loss: 0.3271919557918409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 705] Loss: 0.3272092561022063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 706] Loss: 0.32727503231139304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 707] Loss: 0.3272850650480952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 708] Loss: 0.3272601136578985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 709] Loss: 0.32728020957477727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 710] Loss: 0.32732694765164516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 711] Loss: 0.3273474038647387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 712] Loss: 0.32732086906381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 713] Loss: 0.32731986535053986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 714] Loss: 0.3273192990682412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 715] Loss: 0.3272679486113794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 716] Loss: 0.32725962356552873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 717] Loss: 0.327289009765569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 718] Loss: 0.32730358971337203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 719] Loss: 0.3272924170822491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 720] Loss: 0.32726846941417076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 721] Loss: 0.32723932850024245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 722] Loss: 0.3272134300370493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 723] Loss: 0.3272410697183726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 724] Loss: 0.3272006773932219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 725] Loss: 0.32719858653573886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 726] Loss: 0.327228160452302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 727] Loss: 0.3272567632032887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 728] Loss: 0.32728558624959103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 729] Loss: 0.32726438492719045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 730] Loss: 0.3272422093306253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 731] Loss: 0.3272484445322027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 732] Loss: 0.3272045196132873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 733] Loss: 0.32718475245463374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 734] Loss: 0.3271381198421453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 735] Loss: 0.3271074841586841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 736] Loss: 0.32709921057840535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 737] Loss: 0.3270696799339648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 738] Loss: 0.3271037513290653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 739] Loss: 0.32715399219894437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 740] Loss: 0.32709750933257187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 741] Loss: 0.32715433249573944\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 742] Loss: 0.3271391543810525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 743] Loss: 0.32713872324221016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 744] Loss: 0.3272087127924038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 745] Loss: 0.3271984964572824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 746] Loss: 0.32720069939902086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 747] Loss: 0.32719457266573204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 748] Loss: 0.3271908463136246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 749] Loss: 0.32718852555976724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 750] Loss: 0.32718127909713435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 751] Loss: 0.32723081441836344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 752] Loss: 0.3272402833826675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 753] Loss: 0.3272508385333609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 754] Loss: 0.3272430606704829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 755] Loss: 0.3272406207454161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 756] Loss: 0.3272096482392614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 757] Loss: 0.3272167503761391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 758] Loss: 0.3272177862922049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 759] Loss: 0.3272189042594248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 760] Loss: 0.32723471022462136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 761] Loss: 0.3272188199676117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 762] Loss: 0.32724134958704587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 763] Loss: 0.3272215777184024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 764] Loss: 0.32722036083226347\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 765] Loss: 0.3272525212805896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 766] Loss: 0.3272404327668315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 767] Loss: 0.3272069312145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 768] Loss: 0.327354256991359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 769] Loss: 0.32735523816786316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 770] Loss: 0.3274201205445807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 771] Loss: 0.3274266377469793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 772] Loss: 0.32737817433565614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 773] Loss: 0.3273219203120632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 774] Loss: 0.3273333469318573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 775] Loss: 0.3272962821692516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 776] Loss: 0.32728312017692385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 777] Loss: 0.3273357099880997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 778] Loss: 0.32731261306398773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 779] Loss: 0.3273047883472483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 780] Loss: 0.3272707284637916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 781] Loss: 0.32726664830845764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 782] Loss: 0.32730241064189897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 783] Loss: 0.3273581466177501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 784] Loss: 0.32731865873648364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 785] Loss: 0.32728313180533325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 786] Loss: 0.3272865951922225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 787] Loss: 0.3272500197514085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 788] Loss: 0.32723380243419703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 789] Loss: 0.32723174750428563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 790] Loss: 0.32721398537908547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 791] Loss: 0.32728297215474483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 792] Loss: 0.32735933290028507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 793] Loss: 0.3273529600407984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 794] Loss: 0.32736197313060633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 795] Loss: 0.32733589595033913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 796] Loss: 0.3273044794154103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 797] Loss: 0.32734737053611856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 798] Loss: 0.3273207306459747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 799] Loss: 0.32728105913445676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 800] Loss: 0.327288279298147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 801] Loss: 0.32728691877202404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 802] Loss: 0.3272884605788799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 803] Loss: 0.3272900800995841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 804] Loss: 0.3272729215017874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 805] Loss: 0.32724721446178545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 806] Loss: 0.32722306039798343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 807] Loss: 0.32722624797267064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 808] Loss: 0.3272715340859865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 809] Loss: 0.327244589260005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 810] Loss: 0.3272817078671742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 811] Loss: 0.32730455275540427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 812] Loss: 0.3273387566969693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 813] Loss: 0.3273676908727902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 814] Loss: 0.3274740599867338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 815] Loss: 0.32746115341106863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 816] Loss: 0.3274971570607409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 817] Loss: 0.32746549596655705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 818] Loss: 0.32743103989634537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 819] Loss: 0.3274450862249615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 820] Loss: 0.32742551590116525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 821] Loss: 0.32743632817832824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 822] Loss: 0.3274791351641243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 823] Loss: 0.32742459242276495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 824] Loss: 0.32742657977727435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 825] Loss: 0.32740197985797037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 826] Loss: 0.3273846237539997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 827] Loss: 0.3273345735876441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 828] Loss: 0.327386852301779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 829] Loss: 0.32742834447557134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 830] Loss: 0.3274104490783259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 831] Loss: 0.3273682308266041\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 832] Loss: 0.32733558612837216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 833] Loss: 0.3273272396858439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 834] Loss: 0.3273853092183348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 835] Loss: 0.3274151577458475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 836] Loss: 0.3273849824381058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 837] Loss: 0.3274076501681526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 838] Loss: 0.32738248747366444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 839] Loss: 0.32739785744398125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 840] Loss: 0.3274283434623157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 841] Loss: 0.32741833826259015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 842] Loss: 0.32742375945967306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 843] Loss: 0.3274809232036743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 844] Loss: 0.3274968341764209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 845] Loss: 0.32754242136448813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 846] Loss: 0.3275478040805555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 847] Loss: 0.3274927313569449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 848] Loss: 0.3274673423791742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 849] Loss: 0.32747686061539455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 850] Loss: 0.32745877395768697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 851] Loss: 0.32749804328366183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 852] Loss: 0.327586223432609\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 853] Loss: 0.32754175180794565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 854] Loss: 0.32749239232504274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 855] Loss: 0.32746591674655956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 856] Loss: 0.3274928704409202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 857] Loss: 0.327498620074148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 858] Loss: 0.3274959821237556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 859] Loss: 0.327470134504938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 860] Loss: 0.32747978560269003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 861] Loss: 0.32754006412202574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 862] Loss: 0.32760111966547667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 863] Loss: 0.32756233742131907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 864] Loss: 0.327552074011688\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 865] Loss: 0.32758204125608154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 866] Loss: 0.32761395658915654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 867] Loss: 0.32760458245225577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 868] Loss: 0.3276394367918219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 869] Loss: 0.3276422604769731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 870] Loss: 0.3277087550307426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 871] Loss: 0.3277000941318665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 872] Loss: 0.3276593691051164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 873] Loss: 0.3276303115478359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 874] Loss: 0.3276071751774738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 875] Loss: 0.32757556859451886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 876] Loss: 0.32756435035471687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 877] Loss: 0.327538646940921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 878] Loss: 0.32754986816321774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 879] Loss: 0.32751012814669617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 880] Loss: 0.327509705957384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 881] Loss: 0.32747402134138354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 882] Loss: 0.32747097976307454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 883] Loss: 0.3274778604158881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 884] Loss: 0.3274946188724588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 885] Loss: 0.3275415485606146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 886] Loss: 0.32753970047168973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 887] Loss: 0.32753491724588885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 888] Loss: 0.32753222994560743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 889] Loss: 0.327591983950493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 890] Loss: 0.32755213114969717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 891] Loss: 0.3275468996448862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 892] Loss: 0.3275355076383105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 893] Loss: 0.32753264863185216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 894] Loss: 0.3275137554796609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 895] Loss: 0.32750675706561905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 896] Loss: 0.327465339761554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 897] Loss: 0.3274238892138247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 898] Loss: 0.3274655619910017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 899] Loss: 0.3274884468011723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 900] Loss: 0.3275124540691775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 901] Loss: 0.3274683400017706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 902] Loss: 0.3274272546956414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 903] Loss: 0.3274140338435076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 904] Loss: 0.32742442725893717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 905] Loss: 0.3274463401768597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 906] Loss: 0.32743343434342803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 907] Loss: 0.32754816692517197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 908] Loss: 0.327569550764578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 909] Loss: 0.3275944535694562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 910] Loss: 0.32760388191226325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 911] Loss: 0.3275759232958688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 912] Loss: 0.32759778179113813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 913] Loss: 0.3277487776547238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 914] Loss: 0.3277437396021519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 915] Loss: 0.32770398200456125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 916] Loss: 0.3277156142231488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 917] Loss: 0.327718965256221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 918] Loss: 0.32769189003407523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 919] Loss: 0.3276583689170096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 920] Loss: 0.32772271504955963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 921] Loss: 0.32772601028702864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 922] Loss: 0.32773679800290667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 923] Loss: 0.3277268353009844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 924] Loss: 0.327731561377468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 925] Loss: 0.3277746946144696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 926] Loss: 0.32775669094199844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 927] Loss: 0.3277187231523748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 928] Loss: 0.32773340702228904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 929] Loss: 0.32771080237503214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 930] Loss: 0.32772796071758525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 931] Loss: 0.32776248694377097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 932] Loss: 0.327815520695528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 933] Loss: 0.32786956898846614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 934] Loss: 0.32783772854992516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 935] Loss: 0.3277973391433259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 936] Loss: 0.32781520977148637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 937] Loss: 0.3278506162072916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 938] Loss: 0.32792976677417757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 939] Loss: 0.3279064864914766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 940] Loss: 0.3278857844037711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 941] Loss: 0.3278595325571837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 942] Loss: 0.3278710988617108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 943] Loss: 0.3278648841312562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 944] Loss: 0.3278916047003652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 945] Loss: 0.32791068990774225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 946] Loss: 0.32792535171815457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 947] Loss: 0.3279162135603918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 948] Loss: 0.3278935305571111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 949] Loss: 0.32790266507002247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 950] Loss: 0.3278693041035327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 951] Loss: 0.3279003185954868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 952] Loss: 0.32791359846470314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 953] Loss: 0.32789097657603317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 954] Loss: 0.3278414132567061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 955] Loss: 0.3278284341882048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 956] Loss: 0.3278038824292264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 957] Loss: 0.32779983007181146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 958] Loss: 0.32775606377441996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 959] Loss: 0.32777816298453977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 960] Loss: 0.3277530765956151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 961] Loss: 0.3277521567848357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 962] Loss: 0.3277061282353389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 963] Loss: 0.3277823767704623\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 964] Loss: 0.32776573173099505\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8961\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 965] Loss: 0.32781725632998004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 966] Loss: 0.32780767885355006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 967] Loss: 0.3277781341037794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 968] Loss: 0.3277764332022374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 969] Loss: 0.32775315420922047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 970] Loss: 0.3277844316324754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 971] Loss: 0.32779982864873713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 972] Loss: 0.32777568231232995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 973] Loss: 0.32781259345787545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 974] Loss: 0.3277804368337109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 975] Loss: 0.3277998647540129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 976] Loss: 0.3277537619884354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 977] Loss: 0.3277770212905001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 978] Loss: 0.32772709771376074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 979] Loss: 0.32771337548518753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 980] Loss: 0.3276881374331879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 981] Loss: 0.3276940157225079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 982] Loss: 0.32766865346708834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 983] Loss: 0.3276916784403676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 984] Loss: 0.3276918987782968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 985] Loss: 0.3277029099364906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 986] Loss: 0.32770720564131367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 987] Loss: 0.32769598490500423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 988] Loss: 0.32776414182169217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 989] Loss: 0.32777384908207424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 990] Loss: 0.32776728575784625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 991] Loss: 0.3277283856759266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 992] Loss: 0.32785068442646526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 993] Loss: 0.3278377897931901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 994] Loss: 0.32787125892525726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 995] Loss: 0.32789142952128686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 996] Loss: 0.32784128900614196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 997] Loss: 0.32784064074036895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 998] Loss: 0.327848150086875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 999] Loss: 0.3279169132612747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1000] Loss: 0.32791050293282464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1001] Loss: 0.3278742835237321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1002] Loss: 0.3278659017502369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1003] Loss: 0.32782468417775157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1004] Loss: 0.32782735186793377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1005] Loss: 0.32780110976963245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1006] Loss: 0.3277992415429844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1007] Loss: 0.3277834747322997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1008] Loss: 0.3277528083416908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1009] Loss: 0.3277500141065334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1010] Loss: 0.32772535042827283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1011] Loss: 0.32772412107419535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1012] Loss: 0.3276998568803836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1013] Loss: 0.327686056150517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1014] Loss: 0.32770512578051647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1015] Loss: 0.32776704772904114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1016] Loss: 0.32773657965133335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1017] Loss: 0.32771771417099504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1018] Loss: 0.32773844951399606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1019] Loss: 0.32770114513983606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1020] Loss: 0.3277397909114493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1021] Loss: 0.327742833256755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1022] Loss: 0.32769561648352086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1023] Loss: 0.3276973512777117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1024] Loss: 0.3276449964266418\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1025] Loss: 0.32763528630999217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1026] Loss: 0.32759574195775226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1027] Loss: 0.3276031403671678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1028] Loss: 0.32762439818151534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1029] Loss: 0.32764543760494774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1030] Loss: 0.3276728856394797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1031] Loss: 0.32762146049133195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1032] Loss: 0.3276907586314893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1033] Loss: 0.3276643377600932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1034] Loss: 0.3276214740859531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1035] Loss: 0.3276672705148596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1036] Loss: 0.327631048655897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1037] Loss: 0.32766746954755804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1038] Loss: 0.32773012345070607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1039] Loss: 0.3277539073279173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1040] Loss: 0.32777689404000376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1041] Loss: 0.3277542097041099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1042] Loss: 0.32776891755121784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1043] Loss: 0.3277264676405398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1044] Loss: 0.32772957258752455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1045] Loss: 0.32771458802926745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1046] Loss: 0.3277036509856877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1047] Loss: 0.32767349665768314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1048] Loss: 0.32763376854037973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1049] Loss: 0.3276764739219596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1050] Loss: 0.32766026307072915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1051] Loss: 0.32764394736226854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1052] Loss: 0.3276531481375831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1053] Loss: 0.3276632582701348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1054] Loss: 0.3276513470137096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1055] Loss: 0.3276102766228678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1056] Loss: 0.32766615991104026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1057] Loss: 0.327640914753635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1058] Loss: 0.32769518705584905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1059] Loss: 0.32769503262519706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1060] Loss: 0.32768068809972595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1061] Loss: 0.3276528492818414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1062] Loss: 0.3277075296020998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1063] Loss: 0.32770683797283306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1064] Loss: 0.32768216600884204\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1065] Loss: 0.3276988610186754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1066] Loss: 0.32773809022880945\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1067] Loss: 0.3277033961333591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1068] Loss: 0.3276869199436349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1069] Loss: 0.32762903203186694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1070] Loss: 0.32760327155896757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1071] Loss: 0.32757229761875123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1072] Loss: 0.32758168203575055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1073] Loss: 0.32756726904423944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1074] Loss: 0.3275821520429805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1075] Loss: 0.327579952058602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1076] Loss: 0.32761036273253913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1077] Loss: 0.327627115450515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1078] Loss: 0.3276283357235736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1079] Loss: 0.3276189293596992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1080] Loss: 0.3275825508373496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1081] Loss: 0.327536966517823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1082] Loss: 0.3275314533198265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1083] Loss: 0.3275059651604015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1084] Loss: 0.32752826191779166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1085] Loss: 0.32750094730112844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1086] Loss: 0.32747491547211144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1087] Loss: 0.3274316063179546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1088] Loss: 0.3274726869114514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1089] Loss: 0.32754032929020566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1090] Loss: 0.3275652929240756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1091] Loss: 0.3275403389922839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1092] Loss: 0.3275135412430362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1093] Loss: 0.3275105487627103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1094] Loss: 0.3275451485987899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1095] Loss: 0.3275463008916719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1096] Loss: 0.32757504463622367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1097] Loss: 0.3275862384462462\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1098] Loss: 0.3275772435957005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1099] Loss: 0.3276024317600415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1100] Loss: 0.3276035412265142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1101] Loss: 0.327604840423066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1102] Loss: 0.32759183567446254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1103] Loss: 0.3275616186701662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1104] Loss: 0.32759448371477684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1105] Loss: 0.32756108345892454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1106] Loss: 0.32754822072503725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1107] Loss: 0.3275043546098451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1108] Loss: 0.32746962032118615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1109] Loss: 0.32743519609584565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1110] Loss: 0.32739064346233854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1111] Loss: 0.3273664045212954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1112] Loss: 0.327362010579594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1113] Loss: 0.3273897315214758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1114] Loss: 0.32739370098116627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1115] Loss: 0.32736146277447126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1116] Loss: 0.32735788132388594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1117] Loss: 0.3273802505623596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1118] Loss: 0.3273733493526722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1119] Loss: 0.32733615808987776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1120] Loss: 0.32728577735875847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1121] Loss: 0.3273179492561331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1122] Loss: 0.327272058262236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1123] Loss: 0.32725986012262726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1124] Loss: 0.32725879097776117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1125] Loss: 0.32724842435264767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1126] Loss: 0.327233079175073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1127] Loss: 0.32721238765117255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1128] Loss: 0.32719268169035526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1129] Loss: 0.3271898808607103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1130] Loss: 0.3271426683774851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1131] Loss: 0.32713546401200533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1132] Loss: 0.3271377028033856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1133] Loss: 0.3271900718194263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1134] Loss: 0.3271593022528347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1135] Loss: 0.32713868511203587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1136] Loss: 0.32715535377274735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1137] Loss: 0.32716124579026507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1138] Loss: 0.3271465190170574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1139] Loss: 0.3271801543540612\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1140] Loss: 0.3271561938360524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1141] Loss: 0.3271121336729582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1142] Loss: 0.3271064829789092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1143] Loss: 0.32708904865886207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1144] Loss: 0.3270955499594576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1145] Loss: 0.32709855914909125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1146] Loss: 0.3271508559669582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1147] Loss: 0.32714877339498616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1148] Loss: 0.3271198365630094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1149] Loss: 0.3271145847865051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1150] Loss: 0.32708124618786344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1151] Loss: 0.3270774248769252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1152] Loss: 0.3271177718635496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1153] Loss: 0.32711148222449027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1154] Loss: 0.32708446682306913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1155] Loss: 0.32708206249326305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1156] Loss: 0.32707306568760747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1157] Loss: 0.32707926456306713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1158] Loss: 0.3270807721981015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1159] Loss: 0.32704437978452805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1160] Loss: 0.3270256394247832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1161] Loss: 0.3270274763649834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1162] Loss: 0.3270927855141197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1163] Loss: 0.3270676524695512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1164] Loss: 0.3270691021757492\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1165] Loss: 0.3270508680494652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1166] Loss: 0.3270461060350211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1167] Loss: 0.32702905245801156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1168] Loss: 0.326983676028316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1169] Loss: 0.3269461869220443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1170] Loss: 0.3269652352319884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1171] Loss: 0.3269475393897443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1172] Loss: 0.3269658541905973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1173] Loss: 0.3269313558855789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1174] Loss: 0.3269461812203029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1175] Loss: 0.32693573499724654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1176] Loss: 0.3269202211435805\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1177] Loss: 0.32696724065173743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1178] Loss: 0.32700738166013926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1179] Loss: 0.3270124165367323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1180] Loss: 0.32704384905582545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1181] Loss: 0.32707626897603226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1182] Loss: 0.3270300788427752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1183] Loss: 0.3270059753449694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1184] Loss: 0.32705023263657934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1185] Loss: 0.32702822558489747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1186] Loss: 0.3270122894645538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1187] Loss: 0.32698050416229746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1188] Loss: 0.3269898121668988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1189] Loss: 0.3270253191991513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1190] Loss: 0.3270470883696272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1191] Loss: 0.32701282041315227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1192] Loss: 0.32698059771344823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1193] Loss: 0.3269658839135323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1194] Loss: 0.32692921364540645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1195] Loss: 0.3269247988125136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1196] Loss: 0.32695753451266113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1197] Loss: 0.3269423131851443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1198] Loss: 0.32695163462854615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1199] Loss: 0.32695105972618055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1200] Loss: 0.326999148942584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1201] Loss: 0.32699289471469123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1202] Loss: 0.32702161399206714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1203] Loss: 0.32706977914680135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1204] Loss: 0.3270877401830678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1205] Loss: 0.3270967146854615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1206] Loss: 0.32707177538095294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1207] Loss: 0.3270732830119375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1208] Loss: 0.32705684518702677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1209] Loss: 0.3270386727183691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1210] Loss: 0.3271301788212555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1211] Loss: 0.3271380868663846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1212] Loss: 0.32711244051569016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1213] Loss: 0.32709108994007113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1214] Loss: 0.32705675728144373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1215] Loss: 0.3270841263004267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1216] Loss: 0.32705012859978616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1217] Loss: 0.32700980409828984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1218] Loss: 0.3269793186063932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1219] Loss: 0.3269358696902014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1220] Loss: 0.3269087284573349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1221] Loss: 0.32698793858369024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1222] Loss: 0.3269866702483036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1223] Loss: 0.3270015612244606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1224] Loss: 0.3270445825079913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1225] Loss: 0.3270110958263254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1226] Loss: 0.3269977333489929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1227] Loss: 0.32696677219443315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1228] Loss: 0.3269807718031277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1229] Loss: 0.3269827518368806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1230] Loss: 0.32695307595868434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1231] Loss: 0.3269845974372577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1232] Loss: 0.32694737052579054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1233] Loss: 0.32694282143201375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1234] Loss: 0.3269257864951139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1235] Loss: 0.3269715962273761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1236] Loss: 0.3269335162511657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1237] Loss: 0.32692794375828355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1238] Loss: 0.3269431437364477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1239] Loss: 0.32696848875306295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1240] Loss: 0.3269675817278475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1241] Loss: 0.32698528934418053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1242] Loss: 0.32698627780767053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1243] Loss: 0.326991118455217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1244] Loss: 0.32698440010649793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1245] Loss: 0.32698079308919464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1246] Loss: 0.3269750614023511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1247] Loss: 0.32699650649304246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1248] Loss: 0.32702500823703123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1249] Loss: 0.32698510005101916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1250] Loss: 0.32698310712553563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1251] Loss: 0.3269799976887962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1252] Loss: 0.3269573686053049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1253] Loss: 0.32695306631537413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1254] Loss: 0.32695349164953713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1255] Loss: 0.3269474743099152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1256] Loss: 0.32692741180138823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1257] Loss: 0.3268896939255529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1258] Loss: 0.32687414201351966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1259] Loss: 0.32689715148557225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1260] Loss: 0.3268724859804739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1261] Loss: 0.3268235798546551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1262] Loss: 0.3268653065138787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1263] Loss: 0.3268690819057979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1264] Loss: 0.3268200188004886\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1265] Loss: 0.3268740053383192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1266] Loss: 0.32685317547735715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1267] Loss: 0.32683826686832057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1268] Loss: 0.32682176639623306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1269] Loss: 0.3267797608666525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1270] Loss: 0.3267500685180051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1271] Loss: 0.3267232867294312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1272] Loss: 0.32668701393628063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1273] Loss: 0.326682667223018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1274] Loss: 0.3266746448902782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1275] Loss: 0.32669933766111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1276] Loss: 0.326686162340369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1277] Loss: 0.3266546962363719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1278] Loss: 0.32667389155059157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1279] Loss: 0.32666880319547104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1280] Loss: 0.3266836770282917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1281] Loss: 0.3266948355842848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1282] Loss: 0.32674391165426436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1283] Loss: 0.32673014112948123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1284] Loss: 0.32677387781743444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1285] Loss: 0.3268195271476409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1286] Loss: 0.3268172594770037\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1287] Loss: 0.3268105926919557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1288] Loss: 0.32679658285932606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1289] Loss: 0.32690205128636585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1290] Loss: 0.32690127987072926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1291] Loss: 0.32690746806632015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1292] Loss: 0.32698671847044813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1293] Loss: 0.32699658080118443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1294] Loss: 0.32698270798320717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1295] Loss: 0.3269827926613095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1296] Loss: 0.32695768989317414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1297] Loss: 0.32692408139623574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1298] Loss: 0.3269062951071166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1299] Loss: 0.3270115437096799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1300] Loss: 0.3269904913584143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1301] Loss: 0.326979022044077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1302] Loss: 0.3270646077514036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1303] Loss: 0.32709412804494303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1304] Loss: 0.32716742931508486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1305] Loss: 0.3271977302619779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1306] Loss: 0.3271921874876293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1307] Loss: 0.3271717680240211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1308] Loss: 0.327200094803257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1309] Loss: 0.32724857213701114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1310] Loss: 0.3272540948245009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1311] Loss: 0.3272835132540078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1312] Loss: 0.32726777952176994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1313] Loss: 0.32732095692451896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1314] Loss: 0.3273068987194887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1315] Loss: 0.32727497666377886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1316] Loss: 0.3272473583036109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1317] Loss: 0.3272407734578115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1318] Loss: 0.3272042377874854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1319] Loss: 0.32719563617452174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1320] Loss: 0.3272380899596406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1321] Loss: 0.32721750828702567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1322] Loss: 0.3272447597373486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1323] Loss: 0.3272650338940979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1324] Loss: 0.3272302529488287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1325] Loss: 0.32727780188846195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1326] Loss: 0.3272501929510513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1327] Loss: 0.32724265421800486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1328] Loss: 0.32729686983652595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1329] Loss: 0.3273534723824932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1330] Loss: 0.3273970478722252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1331] Loss: 0.32737727030233366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1332] Loss: 0.32737707027972407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1333] Loss: 0.3273815969087049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1334] Loss: 0.32744081969317834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1335] Loss: 0.3274468078762909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1336] Loss: 0.3274332048463292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1337] Loss: 0.32740932376838927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1338] Loss: 0.3273834608293349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1339] Loss: 0.3273597208761886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1340] Loss: 0.3274112457362899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1341] Loss: 0.3274104909614966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1342] Loss: 0.3274254070733681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1343] Loss: 0.32743644414411993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1344] Loss: 0.32739764896980483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1345] Loss: 0.3273649675592143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1346] Loss: 0.3273463824108155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1347] Loss: 0.3273828918522897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1348] Loss: 0.32737094033869074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1349] Loss: 0.32735006177986764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1350] Loss: 0.3273488468204699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1351] Loss: 0.32733271914484446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1352] Loss: 0.32731999154184677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1353] Loss: 0.32729529229718185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1354] Loss: 0.32731708971555173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1355] Loss: 0.327332398139193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1356] Loss: 0.3273634687200047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1357] Loss: 0.32735029281593925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1358] Loss: 0.32731358931903204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1359] Loss: 0.32736370286060923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1360] Loss: 0.32740385084006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1361] Loss: 0.3274016811021662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1362] Loss: 0.32740511605528017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1363] Loss: 0.32737984373401374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1364] Loss: 0.32741009469782195\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1365] Loss: 0.3274190567361276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1366] Loss: 0.3274270024989588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1367] Loss: 0.32743067064200393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1368] Loss: 0.32743246866325715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1369] Loss: 0.32739906499416965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1370] Loss: 0.3273869173123094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1371] Loss: 0.3274628112441503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1372] Loss: 0.32748283572393966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1373] Loss: 0.32745123177461916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1374] Loss: 0.32748308557968436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1375] Loss: 0.3274689828119943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1376] Loss: 0.32749614173224173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1377] Loss: 0.3274716570303339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1378] Loss: 0.3274504174255929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1379] Loss: 0.3274211845607083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1380] Loss: 0.3274354285272616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1381] Loss: 0.32749135181832645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1382] Loss: 0.32748866969832174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1383] Loss: 0.3275413704351807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1384] Loss: 0.3275401091482894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1385] Loss: 0.3275534654190989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1386] Loss: 0.32754636526092595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1387] Loss: 0.3275271287637931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1388] Loss: 0.32752151187438117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1389] Loss: 0.32749352917280117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1390] Loss: 0.3274930452219791\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1391] Loss: 0.3274874069752616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1392] Loss: 0.32751334916547103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1393] Loss: 0.327595011863393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1394] Loss: 0.32757181444716377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1395] Loss: 0.32754309652022645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1396] Loss: 0.32754441638075305\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1397] Loss: 0.3275240210633503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1398] Loss: 0.32752048012716495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1399] Loss: 0.32753917955740436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1400] Loss: 0.32751530030747494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1401] Loss: 0.3275861449846161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1402] Loss: 0.32754270028011784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1403] Loss: 0.3275484209700587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1404] Loss: 0.3275109120195392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1405] Loss: 0.3274700020788165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1406] Loss: 0.32745917284667053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1407] Loss: 0.3274360425075097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1408] Loss: 0.32742705305870645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1409] Loss: 0.32742709093630407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1410] Loss: 0.3274338377527808\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1411] Loss: 0.3274717656055724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1412] Loss: 0.327441095890773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1413] Loss: 0.3274105035466484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1414] Loss: 0.32739824833175374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1415] Loss: 0.32737448446166056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1416] Loss: 0.3273906593583006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1417] Loss: 0.32740274586865076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1418] Loss: 0.3274263785363148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1419] Loss: 0.32753588144335033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1420] Loss: 0.32752258548433505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1421] Loss: 0.32752181094529476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1422] Loss: 0.3274950961266903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1423] Loss: 0.3274831319848696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1424] Loss: 0.3274913322546361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1425] Loss: 0.3274800329196941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1426] Loss: 0.32745353060104976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1427] Loss: 0.3274997134855549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1428] Loss: 0.32747855822345495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1429] Loss: 0.3275025916923132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1430] Loss: 0.3275181187064635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1431] Loss: 0.32749862656477957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1432] Loss: 0.32747610791500226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1433] Loss: 0.3274342624193775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1434] Loss: 0.32743152901361405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1435] Loss: 0.32744177794393453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1436] Loss: 0.32746672665940824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1437] Loss: 0.3274575900577035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1438] Loss: 0.32755122916878393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1439] Loss: 0.3275285750979809\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1440] Loss: 0.3275272286407367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1441] Loss: 0.3275137537347725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1442] Loss: 0.3275001737251447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1443] Loss: 0.3274703194672738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1444] Loss: 0.327467546282447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1445] Loss: 0.327547252260519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1446] Loss: 0.327531896170557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1447] Loss: 0.327492680415571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1448] Loss: 0.32750885072286934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1449] Loss: 0.32752363569941045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1450] Loss: 0.32755700681393146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1451] Loss: 0.327565055336792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1452] Loss: 0.3275635749004514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1453] Loss: 0.32759587763993064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1454] Loss: 0.3276436226659477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1455] Loss: 0.3276193877887391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1456] Loss: 0.3276137325538599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1457] Loss: 0.3276893248185553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1458] Loss: 0.3277342452722437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1459] Loss: 0.32770471198034956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1460] Loss: 0.32774615735151125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1461] Loss: 0.3277415579157868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1462] Loss: 0.3277245447557549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1463] Loss: 0.3278441492766142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1464] Loss: 0.32782950012632023\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8939000000000001\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1465] Loss: 0.3277947562507008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1466] Loss: 0.32781466036893536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1467] Loss: 0.3277866200773747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1468] Loss: 0.3277960271350156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1469] Loss: 0.3278122670461223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1470] Loss: 0.3277731538413914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1471] Loss: 0.3278175295440261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1472] Loss: 0.3277968473901592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1473] Loss: 0.3277782171704525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1474] Loss: 0.32775863155822926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1475] Loss: 0.3277598312523881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1476] Loss: 0.3277443900626406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1477] Loss: 0.327747934075155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1478] Loss: 0.3278094284635404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1479] Loss: 0.3278213935826285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1480] Loss: 0.32783914056766794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1481] Loss: 0.3278544004533705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1482] Loss: 0.32782178637799886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1483] Loss: 0.32779861152246226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1484] Loss: 0.3277555655978029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1485] Loss: 0.3277391495432266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1486] Loss: 0.32775002178300117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1487] Loss: 0.32775115413187633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1488] Loss: 0.32774282886745026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1489] Loss: 0.32772847594414783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1490] Loss: 0.32769572714851075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1491] Loss: 0.32768265570790434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1492] Loss: 0.32770838788378825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1493] Loss: 0.32770869619497295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1494] Loss: 0.3277120951741483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1495] Loss: 0.3277203989998689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1496] Loss: 0.32771575541050535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1497] Loss: 0.32769573173297767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1498] Loss: 0.3277441814006335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1499] Loss: 0.32776862302771054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1500] Loss: 0.32777039482285253\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1501] Loss: 0.3277557394354281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1502] Loss: 0.3277558054766699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1503] Loss: 0.3277739212691489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1504] Loss: 0.3278297902045938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1505] Loss: 0.3277854226393195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1506] Loss: 0.32781100003709895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1507] Loss: 0.3277976378746898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1508] Loss: 0.3277740681827142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1509] Loss: 0.3277335414940098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1510] Loss: 0.3277239033122519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1511] Loss: 0.32779489685100294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1512] Loss: 0.32780546651383513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1513] Loss: 0.3278298389249378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1514] Loss: 0.32782635218536255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1515] Loss: 0.32780322612346924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1516] Loss: 0.3279200126300939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1517] Loss: 0.32792750654855146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1518] Loss: 0.3279000741081673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1519] Loss: 0.32787857720852487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1520] Loss: 0.32786162198324464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1521] Loss: 0.32786556719602655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1522] Loss: 0.32788453328033834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1523] Loss: 0.32790605641277554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 22, Batch 1524] Loss: 0.32787214623930655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 0] Loss: 0.32788133640658496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1] Loss: 0.3278455784351345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 2] Loss: 0.3278051418890282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 3] Loss: 0.32779403842096694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 4] Loss: 0.3277989921975007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 5] Loss: 0.32780003140973374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 6] Loss: 0.3277554601474849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 7] Loss: 0.3277770941850447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 8] Loss: 0.3278201920467747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 9] Loss: 0.3278022823638864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 10] Loss: 0.32778464054985224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 11] Loss: 0.32777502054287766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 12] Loss: 0.32774221244239315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 13] Loss: 0.32771684408553536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 14] Loss: 0.3277372177708547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 15] Loss: 0.32774959954892063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 16] Loss: 0.327703175473412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 17] Loss: 0.3276797548232344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 18] Loss: 0.32772554936362247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 19] Loss: 0.32769381367555583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 20] Loss: 0.3277354112505504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 21] Loss: 0.32770872137256324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 22] Loss: 0.3276993004672674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 23] Loss: 0.3276626210646063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 24] Loss: 0.32769797658853184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 25] Loss: 0.32769417873959045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 26] Loss: 0.32772194998386206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 27] Loss: 0.32770947306641274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 28] Loss: 0.32776478692561317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 29] Loss: 0.3277809191955036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 30] Loss: 0.3277890100703736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 31] Loss: 0.32777163479909494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 32] Loss: 0.3277650879842512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 33] Loss: 0.32776840776387006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 34] Loss: 0.32777220278876484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 35] Loss: 0.3277628379265855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 36] Loss: 0.3277671508065603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 37] Loss: 0.3277699474366184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 38] Loss: 0.3277708074995657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 39] Loss: 0.327764276138052\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 40] Loss: 0.3277515750078676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 41] Loss: 0.327737377328667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 42] Loss: 0.32775457982213524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 43] Loss: 0.32772361611477785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 44] Loss: 0.32772295376584404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 45] Loss: 0.32778690624387996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 46] Loss: 0.32773869557935514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 47] Loss: 0.3277207391776723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 48] Loss: 0.32768420071279913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 49] Loss: 0.327669171112148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 50] Loss: 0.3276378323110219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 51] Loss: 0.32759562657895586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 52] Loss: 0.32759435741456316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 53] Loss: 0.3275999323638068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 54] Loss: 0.3276412897210195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 55] Loss: 0.32766456048205433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 56] Loss: 0.32766536121347567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 57] Loss: 0.3276845106701736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 58] Loss: 0.32769355005720285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 59] Loss: 0.32767810725494656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 60] Loss: 0.3276574054515113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 61] Loss: 0.32777371958508933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 62] Loss: 0.3277606306350081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 63] Loss: 0.3277523961572936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 64] Loss: 0.32776478836534095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 65] Loss: 0.32773893211882715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 66] Loss: 0.32770685074388867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 67] Loss: 0.32770828307974165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 68] Loss: 0.32772254999050504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 69] Loss: 0.3277361160493653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 70] Loss: 0.32777976682130155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 71] Loss: 0.3277521016210959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 72] Loss: 0.3278129400589008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 73] Loss: 0.3278180743323272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 74] Loss: 0.3277848972875906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 75] Loss: 0.3277833747754271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 76] Loss: 0.3277969296900992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 77] Loss: 0.32783171008911416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 78] Loss: 0.32783267077616446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 79] Loss: 0.3278565989531517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 80] Loss: 0.32786725290957885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 81] Loss: 0.32783790587328665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 82] Loss: 0.3278248112210033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 83] Loss: 0.32780724363749797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 84] Loss: 0.32781505002112304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 85] Loss: 0.3278271875662892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 86] Loss: 0.3278415044060151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 87] Loss: 0.32787944500016486\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 88] Loss: 0.32786581691130096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 89] Loss: 0.3279167402188366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 90] Loss: 0.32794316032244636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 91] Loss: 0.32792271064070083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 92] Loss: 0.32788788246732525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 93] Loss: 0.3278447303925467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 94] Loss: 0.327886586221826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 95] Loss: 0.32784725303385504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 96] Loss: 0.3278143005467998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 97] Loss: 0.32779016901621827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 98] Loss: 0.32780116446172963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 99] Loss: 0.3277897879971933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 100] Loss: 0.3278519786690245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 101] Loss: 0.32782421961745306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 102] Loss: 0.32779406777991915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 103] Loss: 0.3277876902921718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 104] Loss: 0.3277771038450819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 105] Loss: 0.32775843718125147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 106] Loss: 0.3277756369524348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 107] Loss: 0.3278031617789052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 108] Loss: 0.3278500902531244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 109] Loss: 0.32782316131075634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 110] Loss: 0.3278532802722884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 111] Loss: 0.3278167301442107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 112] Loss: 0.3278066645477683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 113] Loss: 0.32783415083756706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 114] Loss: 0.3278393791703029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 115] Loss: 0.3278446612009627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 116] Loss: 0.32787278267100645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 117] Loss: 0.3278974591295067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 118] Loss: 0.32795053631708954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 119] Loss: 0.32792323286369124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 120] Loss: 0.32790146883539695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 121] Loss: 0.32790647484513524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 122] Loss: 0.32793645798647153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 123] Loss: 0.32790100697334523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 124] Loss: 0.3279102049906802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 125] Loss: 0.3278923608684756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 126] Loss: 0.327877500276824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 127] Loss: 0.32789456442720594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 128] Loss: 0.32789785865880994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 129] Loss: 0.3278990432324941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 130] Loss: 0.32792013568291795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 131] Loss: 0.3279352702170205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 132] Loss: 0.32794551023015195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 133] Loss: 0.3279071713055132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 134] Loss: 0.32789695442248457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 135] Loss: 0.32790734291374896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 136] Loss: 0.3279253574476008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 137] Loss: 0.32794076977570474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 138] Loss: 0.3279128137479226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 139] Loss: 0.3278955646148326\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 140] Loss: 0.3278814605740863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 141] Loss: 0.3278395683211484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 142] Loss: 0.32780879354201875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 143] Loss: 0.32781100438622035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 144] Loss: 0.3277909856394139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 145] Loss: 0.3277660153924866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 146] Loss: 0.3277852835041602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 147] Loss: 0.3277538187835471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 148] Loss: 0.3277375943056195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 149] Loss: 0.32772658881383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 150] Loss: 0.3277238676853386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 151] Loss: 0.3277490454326467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 152] Loss: 0.32774705615196964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 153] Loss: 0.3277301770476967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 154] Loss: 0.327754350449798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 155] Loss: 0.32775104307707154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 156] Loss: 0.3277847884976225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 157] Loss: 0.327802553617522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 158] Loss: 0.327812878021273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 159] Loss: 0.3277865402952977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 160] Loss: 0.32776677365313767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 161] Loss: 0.3277577844108983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 162] Loss: 0.32780015621348424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 163] Loss: 0.32780353112686317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 164] Loss: 0.32776481190311135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 165] Loss: 0.3277727237950833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 166] Loss: 0.32772793474562234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 167] Loss: 0.327732966308561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 168] Loss: 0.3277882928226856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 169] Loss: 0.3277713215870937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 170] Loss: 0.3277637656876687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 171] Loss: 0.32777423592019866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 172] Loss: 0.3277916351247915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 173] Loss: 0.3278002826881803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 174] Loss: 0.32777731991227893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 175] Loss: 0.3277534324273991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 176] Loss: 0.3277331832840286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 177] Loss: 0.3277193988710958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 178] Loss: 0.32770941282780663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 179] Loss: 0.3276885898537412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 180] Loss: 0.32765376253799133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 181] Loss: 0.3276412885775691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 182] Loss: 0.32765494799636424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 183] Loss: 0.32763564616827856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 184] Loss: 0.3276097738674043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 185] Loss: 0.3276152906451249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 186] Loss: 0.32767331928169097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 187] Loss: 0.32766602605153433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 188] Loss: 0.32766114689672693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 189] Loss: 0.3276525129958675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 190] Loss: 0.32761635447686727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 191] Loss: 0.3276353765663584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 192] Loss: 0.32762396857527765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 193] Loss: 0.3276165783895589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 194] Loss: 0.32763544437860637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 195] Loss: 0.3276114867611169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 196] Loss: 0.32762692255585224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 197] Loss: 0.32761038342645177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 198] Loss: 0.32758569899299333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 199] Loss: 0.32761646026290375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 200] Loss: 0.32764277225757976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 201] Loss: 0.32768744224677643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 202] Loss: 0.32771380318374166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 203] Loss: 0.32770211301822594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 204] Loss: 0.3276998999319443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 205] Loss: 0.32773059128820964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 206] Loss: 0.32776369492417756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 207] Loss: 0.3278064681289067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 208] Loss: 0.32778301509468005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 209] Loss: 0.3277695096054057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 210] Loss: 0.3277527168637302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 211] Loss: 0.3277571009140285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 212] Loss: 0.32774124615971706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 213] Loss: 0.3277742144970866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 214] Loss: 0.32773775566923385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 215] Loss: 0.32770046859331603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 216] Loss: 0.32771680000063524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 217] Loss: 0.3276981784065184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 218] Loss: 0.3277277050278733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 219] Loss: 0.3277080617470876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 220] Loss: 0.3276849793760034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 221] Loss: 0.3276833645858526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 222] Loss: 0.3276744951797522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 223] Loss: 0.3276693282459831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 224] Loss: 0.3276849752983032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 225] Loss: 0.3276627376407962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 226] Loss: 0.3276744033105727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 227] Loss: 0.3276957217651693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 228] Loss: 0.3276798430682618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 229] Loss: 0.3276991846642831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 230] Loss: 0.32767863888276144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 231] Loss: 0.327639853957092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 232] Loss: 0.3276197132977653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 233] Loss: 0.32765685146429485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 234] Loss: 0.32768271354268164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 235] Loss: 0.32765707576138936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 236] Loss: 0.3277191767905024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 237] Loss: 0.32772393888250345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 238] Loss: 0.32775924660438716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 239] Loss: 0.32781243367240587\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 240] Loss: 0.3278193467858225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 241] Loss: 0.3278168688714158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 242] Loss: 0.3278069531676605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 243] Loss: 0.3278299300374331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 244] Loss: 0.3278037953829411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 245] Loss: 0.327788322786873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 246] Loss: 0.3277859364358662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 247] Loss: 0.3277652229855248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 248] Loss: 0.327768525380961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 249] Loss: 0.32774649986643384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 250] Loss: 0.32778287759821356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 251] Loss: 0.32782312459274593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 252] Loss: 0.32783284188560385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 253] Loss: 0.3278549487455419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 254] Loss: 0.32787055893696715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 255] Loss: 0.3278542657140949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 256] Loss: 0.3278578535074324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 257] Loss: 0.32786395467522794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 258] Loss: 0.327837037998769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 259] Loss: 0.32788813613515516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 260] Loss: 0.3278798273747743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 261] Loss: 0.32788646810589195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 262] Loss: 0.3278873545650968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 263] Loss: 0.32787789062957545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 264] Loss: 0.327875184133766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 265] Loss: 0.327887206305415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 266] Loss: 0.3279257331339577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 267] Loss: 0.32788444053124377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 268] Loss: 0.32788106891698704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 269] Loss: 0.3278765733076612\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 270] Loss: 0.32791689162453014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 271] Loss: 0.3279401721695458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 272] Loss: 0.32795990564455124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 273] Loss: 0.3279195896791339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 274] Loss: 0.3279528101644998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 275] Loss: 0.3279839268451136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 276] Loss: 0.32796424263534374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 277] Loss: 0.3279436070864364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 278] Loss: 0.3279337524440706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 279] Loss: 0.3279773277590775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 280] Loss: 0.32799783227205936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 281] Loss: 0.3279835662649931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 282] Loss: 0.3279754897171347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 283] Loss: 0.3280138751133951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 284] Loss: 0.32805208445239936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 285] Loss: 0.32808289272924496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 286] Loss: 0.3280701316111715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 287] Loss: 0.3280525595689812\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 288] Loss: 0.32802027175138737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 289] Loss: 0.32801054099583676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 290] Loss: 0.3279838769641869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 291] Loss: 0.32794716248711087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 292] Loss: 0.32793123165524546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 293] Loss: 0.32794686549361346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 294] Loss: 0.32793001731031524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 295] Loss: 0.3279207572802672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 296] Loss: 0.32796762723299605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 297] Loss: 0.32794327962477837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 298] Loss: 0.3279711477868601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 299] Loss: 0.32795025239130743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 300] Loss: 0.3279243617231886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 301] Loss: 0.32788340466956384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 302] Loss: 0.327895491086049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 303] Loss: 0.3278992809244311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 304] Loss: 0.32790954073825346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 305] Loss: 0.32793818314915696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 306] Loss: 0.3279231267302355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 307] Loss: 0.32794517085628067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 308] Loss: 0.3279286320613233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 309] Loss: 0.3279161485292578\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 310] Loss: 0.3279831500388239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 311] Loss: 0.327985318164217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 312] Loss: 0.3279795843714386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 313] Loss: 0.3279907552719116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 314] Loss: 0.3279644019724682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 315] Loss: 0.32798549451865044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 316] Loss: 0.3279797784088953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 317] Loss: 0.3280051941399597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 318] Loss: 0.3279794513192623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 319] Loss: 0.3280046533413114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 320] Loss: 0.32801305330585856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 321] Loss: 0.3280718577029143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 322] Loss: 0.32809371389380665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 323] Loss: 0.3281123855128935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 324] Loss: 0.32809020133457173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 325] Loss: 0.32807439252825893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 326] Loss: 0.3280888932605114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 327] Loss: 0.32808855944286586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 328] Loss: 0.3280643728266816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 329] Loss: 0.3280402151585657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 330] Loss: 0.3280588325981614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 331] Loss: 0.32814860277110236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 332] Loss: 0.32814393119956886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 333] Loss: 0.32813338375945955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 334] Loss: 0.3281241827580851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 335] Loss: 0.3281350044335781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 336] Loss: 0.3281131317468869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 337] Loss: 0.32808690685986336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 338] Loss: 0.32806785123592075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 339] Loss: 0.328032397040181\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 340] Loss: 0.32801001431629473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 341] Loss: 0.3280103278551323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 342] Loss: 0.32803615879311443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 343] Loss: 0.3280319439465017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 344] Loss: 0.328035177846443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 345] Loss: 0.3280087357607996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 346] Loss: 0.32799056945486965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 347] Loss: 0.32802170779016127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 348] Loss: 0.3279991119593179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 349] Loss: 0.32803974682864245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 350] Loss: 0.328033226277892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 351] Loss: 0.3280027234923021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 352] Loss: 0.3279840511282105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 353] Loss: 0.32797831117026804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 354] Loss: 0.32806576423657435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 355] Loss: 0.32809783616148563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 356] Loss: 0.32808061020643586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 357] Loss: 0.32806278205775763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 358] Loss: 0.32807438110604004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 359] Loss: 0.3280638367631969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 360] Loss: 0.3280720747484982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 361] Loss: 0.32804970545666856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 362] Loss: 0.3280291675605136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 363] Loss: 0.32811317212164065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 364] Loss: 0.3281880002780247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 365] Loss: 0.3281555966515559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 366] Loss: 0.32814440119745714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 367] Loss: 0.32814067658007506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 368] Loss: 0.3281319499621273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 369] Loss: 0.3281792981566492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 370] Loss: 0.32822047857843367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 371] Loss: 0.3281940716620683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 372] Loss: 0.3281748646960153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 373] Loss: 0.3281670607937229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 374] Loss: 0.328159474165618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 375] Loss: 0.3282143607154633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 376] Loss: 0.3282517112418841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 377] Loss: 0.32824534013293355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 378] Loss: 0.3282271008368011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 379] Loss: 0.3282314420578529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 380] Loss: 0.3282298330101866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 381] Loss: 0.3282111546235554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 382] Loss: 0.32819307647799717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 383] Loss: 0.32818089473502304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 384] Loss: 0.3281467399696911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 385] Loss: 0.3281196238037868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 386] Loss: 0.3281671393749793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 387] Loss: 0.32818916530107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 388] Loss: 0.3281969710313872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 389] Loss: 0.32819374458049555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 390] Loss: 0.32820197803646944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 391] Loss: 0.32817352775466757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 392] Loss: 0.3281817562714199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 393] Loss: 0.32817134896312095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 394] Loss: 0.3282031169465511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 395] Loss: 0.32821236400358716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 396] Loss: 0.3281810147250752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 397] Loss: 0.3281973456656032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 398] Loss: 0.3282283897323726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 399] Loss: 0.32823332660175764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 400] Loss: 0.3281969273607328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 401] Loss: 0.3281885167922296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 402] Loss: 0.3282394775132712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 403] Loss: 0.32820880752127757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 404] Loss: 0.3281986287661961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 405] Loss: 0.3281925230090827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 406] Loss: 0.32817409984307194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 407] Loss: 0.3281675763653279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 408] Loss: 0.32814210018588924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 409] Loss: 0.32812248593314175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 410] Loss: 0.3281425520617761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 411] Loss: 0.3281275481418718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 412] Loss: 0.3281181801908188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 413] Loss: 0.3281187645616478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 414] Loss: 0.32813000851464763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 415] Loss: 0.3281792850467225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 416] Loss: 0.32820504204989437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 417] Loss: 0.328216507222456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 418] Loss: 0.32824335267900356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 419] Loss: 0.32824700194872586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 420] Loss: 0.3282086619744073\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 421] Loss: 0.3281873907597236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 422] Loss: 0.3281776217027608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 423] Loss: 0.3281607052421357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 424] Loss: 0.32818098479862784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 425] Loss: 0.3281848689203728\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 426] Loss: 0.3281641005838884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 427] Loss: 0.328144913471656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 428] Loss: 0.32813789527572873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 429] Loss: 0.3281343471291229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 430] Loss: 0.32819720884106673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 431] Loss: 0.3281677704086395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 432] Loss: 0.3282043838340492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 433] Loss: 0.32819356164823515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 434] Loss: 0.3282045048903475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 435] Loss: 0.3281707804859652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 436] Loss: 0.3281738087336134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 437] Loss: 0.32822119369920716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 438] Loss: 0.32824713184105025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 439] Loss: 0.32828476540024243\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.889\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 440] Loss: 0.32831847196695596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 441] Loss: 0.328290657569058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 442] Loss: 0.3283125133738319\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 443] Loss: 0.32831463924920257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 444] Loss: 0.3283138024478926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 445] Loss: 0.3283705888049471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 446] Loss: 0.3283643247865425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 447] Loss: 0.32836457283910875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 448] Loss: 0.32834001659289697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 449] Loss: 0.32830625232057226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 450] Loss: 0.3282785767042045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 451] Loss: 0.32831282478173396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 452] Loss: 0.32829247838596776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 453] Loss: 0.3282986179175699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 454] Loss: 0.3282711496782894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 455] Loss: 0.3282512003324558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 456] Loss: 0.3282375263331368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 457] Loss: 0.32822516646288113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 458] Loss: 0.328295174590518\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 459] Loss: 0.3282938616132346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 460] Loss: 0.32827554009805365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 461] Loss: 0.3282617692158809\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 462] Loss: 0.3283139320731058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 463] Loss: 0.3282995379827299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 464] Loss: 0.3282849097207116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 465] Loss: 0.3282950861066389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 466] Loss: 0.3283560252534522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 467] Loss: 0.328341375658859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 468] Loss: 0.3283160334588676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 469] Loss: 0.32833329233158187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 470] Loss: 0.32830183993817846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 471] Loss: 0.32829420266891984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 472] Loss: 0.3283032197414856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 473] Loss: 0.3283790734268996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 474] Loss: 0.328348738274404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 475] Loss: 0.3283277580509213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 476] Loss: 0.3283407408473196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 477] Loss: 0.3283430037814422\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 478] Loss: 0.32833680537763144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 479] Loss: 0.32830489951066316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 480] Loss: 0.3283215261789105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 481] Loss: 0.3283398887894895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 482] Loss: 0.3283610387416688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 483] Loss: 0.3283538957568023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 484] Loss: 0.3283780561608467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 485] Loss: 0.3283798951735097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 486] Loss: 0.32837967493996456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 487] Loss: 0.3283804391119134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 488] Loss: 0.3283538266459664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 489] Loss: 0.3283228849453131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 490] Loss: 0.3282892243488183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 491] Loss: 0.32829366991893294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 492] Loss: 0.3282895646220401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 493] Loss: 0.328289724776826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 494] Loss: 0.32825699909095496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 495] Loss: 0.3282520991486626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 496] Loss: 0.3282450623957407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 497] Loss: 0.32824112757644935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 498] Loss: 0.32823537139777553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 499] Loss: 0.3282165357618838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 500] Loss: 0.32820081078120356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 501] Loss: 0.3281863770338884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 502] Loss: 0.32820206359159415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 503] Loss: 0.32823676313197103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 504] Loss: 0.3282754345357653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 505] Loss: 0.32829193947728674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 506] Loss: 0.3283107207367122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 507] Loss: 0.3283055531369385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 508] Loss: 0.3283020909133834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 509] Loss: 0.32830044875270664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 510] Loss: 0.3283277191873558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 511] Loss: 0.3283399689967852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 512] Loss: 0.32838448584014585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 513] Loss: 0.32838065573100833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 514] Loss: 0.3284247376877893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 515] Loss: 0.32840687697087934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 516] Loss: 0.3284449970822451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 517] Loss: 0.3284368323828097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 518] Loss: 0.32840398973317647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 519] Loss: 0.3284278086695029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 520] Loss: 0.32844095550955565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 521] Loss: 0.32849075912635917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 522] Loss: 0.3285222980787045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 523] Loss: 0.32851547360615224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 524] Loss: 0.3285047628872529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 525] Loss: 0.32854283915344135\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 526] Loss: 0.3285256645073034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 527] Loss: 0.3285086613110297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 528] Loss: 0.3285370348520528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 529] Loss: 0.32853757182878235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 530] Loss: 0.3285248648141631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 531] Loss: 0.3285272307977836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 532] Loss: 0.3285087184298542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 533] Loss: 0.3284881388142267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 534] Loss: 0.32846210173309315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 535] Loss: 0.32847463226925167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 536] Loss: 0.3284382222332919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 537] Loss: 0.32843797651159423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 538] Loss: 0.328403192334201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 539] Loss: 0.3283766162503001\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 540] Loss: 0.32835313008822137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 541] Loss: 0.3283633383724603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 542] Loss: 0.3283835312822505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 543] Loss: 0.32838396159497196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 544] Loss: 0.32842730753094646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 545] Loss: 0.32841095173076873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 546] Loss: 0.3284360498202861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 547] Loss: 0.3284162886038238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 548] Loss: 0.32844071982998135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 549] Loss: 0.3284342606448734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 550] Loss: 0.3284264298580774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 551] Loss: 0.3284130848697073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 552] Loss: 0.3284510998406553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 553] Loss: 0.3284922771696667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 554] Loss: 0.32853510578129075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 555] Loss: 0.3285388649478216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 556] Loss: 0.32851210484041593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 557] Loss: 0.32851720880535573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 558] Loss: 0.3285222587357094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 559] Loss: 0.3285135396519824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 560] Loss: 0.32848731412587356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 561] Loss: 0.32846901004458307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 562] Loss: 0.32844856652112153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 563] Loss: 0.32843578616992847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 564] Loss: 0.3284148942216928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 565] Loss: 0.3283955045922003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 566] Loss: 0.3283783638545585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 567] Loss: 0.3283639824893877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 568] Loss: 0.3283751624545835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 569] Loss: 0.3283825374961131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 570] Loss: 0.3284003035372866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 571] Loss: 0.32836794146908915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 572] Loss: 0.3283876826665913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 573] Loss: 0.32839257749281786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 574] Loss: 0.3284853960004112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 575] Loss: 0.3284722519108569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 576] Loss: 0.3284697763335864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 577] Loss: 0.3284781983210162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 578] Loss: 0.3284841125574091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 579] Loss: 0.3285262175056858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 580] Loss: 0.32850290730897336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 581] Loss: 0.32848695175364795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 582] Loss: 0.3284860753183936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 583] Loss: 0.3285099406416886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 584] Loss: 0.3285250737782034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 585] Loss: 0.32853188398886374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 586] Loss: 0.3285357608698732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 587] Loss: 0.32853063014687506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 588] Loss: 0.3285592956055877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 589] Loss: 0.32853097209582355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 590] Loss: 0.32851183338544027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 591] Loss: 0.32851926721080055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 592] Loss: 0.32849773266730925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 593] Loss: 0.3285029383370239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 594] Loss: 0.32848964000114356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 595] Loss: 0.32847590768813373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 596] Loss: 0.3284564743249546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 597] Loss: 0.3284273372843532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 598] Loss: 0.328418994176925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 599] Loss: 0.3283884151251473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 600] Loss: 0.32838577119667917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 601] Loss: 0.3283642979297622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 602] Loss: 0.3283426613829659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 603] Loss: 0.32831762996836616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 604] Loss: 0.32833925429595884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 605] Loss: 0.32834102853235453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 606] Loss: 0.3283397516246882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 607] Loss: 0.3283480679798647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 608] Loss: 0.32832225673778154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 609] Loss: 0.3283954755961576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 610] Loss: 0.3283895190058863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 611] Loss: 0.3283618555898307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 612] Loss: 0.32837789157580044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 613] Loss: 0.3283479046375356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 614] Loss: 0.32836058119533407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 615] Loss: 0.3283611234753005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 616] Loss: 0.32832925050316736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 617] Loss: 0.32832816268012266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 618] Loss: 0.32828939530011425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 619] Loss: 0.3282905429015937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 620] Loss: 0.32828571562110637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 621] Loss: 0.3282712485904549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 622] Loss: 0.3282875951179116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 623] Loss: 0.32830134921229126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 624] Loss: 0.3282934985498409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 625] Loss: 0.32831511477849773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 626] Loss: 0.32834315651856083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 627] Loss: 0.32839949844068594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 628] Loss: 0.3283708729946029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 629] Loss: 0.3283613318860518\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 630] Loss: 0.32833760778299786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 631] Loss: 0.3283750932245348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 632] Loss: 0.3283491774656999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 633] Loss: 0.32832392518576214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 634] Loss: 0.32834548218527987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 635] Loss: 0.32836963542793973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 636] Loss: 0.32839032691392356\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 637] Loss: 0.3283762470391944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 638] Loss: 0.3283786068286033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 639] Loss: 0.3283931602222872\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 640] Loss: 0.32837318403068777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 641] Loss: 0.32833619422730603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 642] Loss: 0.3283424981692362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 643] Loss: 0.3283855207129822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 644] Loss: 0.32840035406455453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 645] Loss: 0.32841910709297933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 646] Loss: 0.32844530880615785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 647] Loss: 0.32845032866035556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 648] Loss: 0.3284482005390392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 649] Loss: 0.3284384677508054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 650] Loss: 0.328424096920216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 651] Loss: 0.3284157092008979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 652] Loss: 0.3284715923323032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 653] Loss: 0.3284560371589307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 654] Loss: 0.32842789740444644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 655] Loss: 0.32839596601633897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 656] Loss: 0.3283803094748523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 657] Loss: 0.328422962245635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 658] Loss: 0.3284327112232982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 659] Loss: 0.32844376006297604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 660] Loss: 0.3284108291101223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 661] Loss: 0.3284664189483613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 662] Loss: 0.3284646120587968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 663] Loss: 0.32846501027780867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 664] Loss: 0.3284832200652656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 665] Loss: 0.3284668159586999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 666] Loss: 0.3284963396127303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 667] Loss: 0.32848227238662653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 668] Loss: 0.3284664594188301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 669] Loss: 0.3284990278044505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 670] Loss: 0.3285161545019934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 671] Loss: 0.32849689112287883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 672] Loss: 0.3284730758623428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 673] Loss: 0.328460059702837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 674] Loss: 0.32848291088059245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 675] Loss: 0.3284685631700022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 676] Loss: 0.3284660256068734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 677] Loss: 0.32843802888186124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 678] Loss: 0.32845976779921143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 679] Loss: 0.32845787803939663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 680] Loss: 0.32845398069421033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 681] Loss: 0.32845139173912946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 682] Loss: 0.32844663997813683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 683] Loss: 0.3284187323363739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 684] Loss: 0.32847541484634835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 685] Loss: 0.32845444618487873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 686] Loss: 0.3284445320834306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 687] Loss: 0.32844775492805106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 688] Loss: 0.3284688640268225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 689] Loss: 0.3284394134504874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 690] Loss: 0.32841707460946007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 691] Loss: 0.32842574846222855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 692] Loss: 0.3284250565866838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 693] Loss: 0.32841829968113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 694] Loss: 0.3284401657158482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 695] Loss: 0.32845387884253385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 696] Loss: 0.32844511415150146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 697] Loss: 0.32841394861084144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 698] Loss: 0.3284132533182367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 699] Loss: 0.32838173107962176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 700] Loss: 0.3283543372757542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 701] Loss: 0.3283458821930706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 702] Loss: 0.3284164641043101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 703] Loss: 0.32839623318138805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 704] Loss: 0.3283819084439116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 705] Loss: 0.32837171616583266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 706] Loss: 0.32841615428860554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 707] Loss: 0.32844550815436496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 708] Loss: 0.3284341043771188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 709] Loss: 0.32843095047297505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 710] Loss: 0.3284612987174872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 711] Loss: 0.328453545528664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 712] Loss: 0.32845705898051786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 713] Loss: 0.3285115367392595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 714] Loss: 0.32854394322039693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 715] Loss: 0.32855857306378194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 716] Loss: 0.3285682586233403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 717] Loss: 0.32858139192317165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 718] Loss: 0.32856139954039243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 719] Loss: 0.3285827469162501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 720] Loss: 0.3285621573103865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 721] Loss: 0.3285487605990562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 722] Loss: 0.32857411839441714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 723] Loss: 0.32865936738694845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 724] Loss: 0.3286661419704575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 725] Loss: 0.32864390946465544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 726] Loss: 0.3286136534864841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 727] Loss: 0.328608272960077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 728] Loss: 0.32858089277975744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 729] Loss: 0.3285973588445196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 730] Loss: 0.32861631046762946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 731] Loss: 0.3285907922452908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 732] Loss: 0.3285951655564778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 733] Loss: 0.3286109549689716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 734] Loss: 0.3285748509502192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 735] Loss: 0.3285570591377521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 736] Loss: 0.3285930128663269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 737] Loss: 0.3285653224262652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 738] Loss: 0.32864667939643066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 739] Loss: 0.3286638350889996\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 740] Loss: 0.3286495172061408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 741] Loss: 0.3286694054823976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 742] Loss: 0.3286638507723411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 743] Loss: 0.3286928374921122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 744] Loss: 0.3286665736624364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 745] Loss: 0.32864245066207287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 746] Loss: 0.3286218443411261\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 747] Loss: 0.32861890771652263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 748] Loss: 0.3286103518428029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 749] Loss: 0.3286169314862685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 750] Loss: 0.328589253638525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 751] Loss: 0.3286061564113255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 752] Loss: 0.3286106963628399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 753] Loss: 0.32860758634804443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 754] Loss: 0.3286137670012457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 755] Loss: 0.3285878704114898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 756] Loss: 0.32856145798665154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 757] Loss: 0.32858754397304407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 758] Loss: 0.32858792018469934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 759] Loss: 0.3286044242853842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 760] Loss: 0.3285918292453901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 761] Loss: 0.3285791287277834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 762] Loss: 0.32856924597105974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 763] Loss: 0.32855826268542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 764] Loss: 0.328576802762771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 765] Loss: 0.3285848389186547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 766] Loss: 0.3285641018810505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 767] Loss: 0.32857286675200004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 768] Loss: 0.32858170077790877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 769] Loss: 0.3285410340171353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 770] Loss: 0.328536727693894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 771] Loss: 0.3285125364292588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 772] Loss: 0.3285131105674561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 773] Loss: 0.32848570215541795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 774] Loss: 0.3284741393710287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 775] Loss: 0.3284650384233785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 776] Loss: 0.32845268641537306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 777] Loss: 0.3284540966193177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 778] Loss: 0.3284652995176552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 779] Loss: 0.32845298504809706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 780] Loss: 0.3285180454298959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 781] Loss: 0.3285067191971695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 782] Loss: 0.3284732271001223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 783] Loss: 0.32849035508492413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 784] Loss: 0.32851717854476004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 785] Loss: 0.3285541321743339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 786] Loss: 0.32854474304557435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 787] Loss: 0.32853257706495237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 788] Loss: 0.3285290117730799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 789] Loss: 0.32850482298083905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 790] Loss: 0.3285225260471472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 791] Loss: 0.32852369678307874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 792] Loss: 0.3285559811094046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 793] Loss: 0.3285307772741504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 794] Loss: 0.32849207305068634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 795] Loss: 0.3284928828803065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 796] Loss: 0.32850966802248005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 797] Loss: 0.32848811646404763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 798] Loss: 0.32847174203076973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 799] Loss: 0.3284402087965367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 800] Loss: 0.32843254615082657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 801] Loss: 0.32839941308316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 802] Loss: 0.3283834069336176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 803] Loss: 0.32836506664140375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 804] Loss: 0.3283355617003827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 805] Loss: 0.32831348900080265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 806] Loss: 0.32831196567455373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 807] Loss: 0.32829713155158763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 808] Loss: 0.32830937550359196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 809] Loss: 0.328312437723633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 810] Loss: 0.3283290491333883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 811] Loss: 0.3283427384124506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 812] Loss: 0.32831093665880406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 813] Loss: 0.32831969141960143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 814] Loss: 0.32836980592700865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 815] Loss: 0.3283476844378028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 816] Loss: 0.3283887696087776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 817] Loss: 0.32840373610028184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 818] Loss: 0.3283704300273637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 819] Loss: 0.32847043460960446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 820] Loss: 0.32847041253646053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 821] Loss: 0.32846998751541884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 822] Loss: 0.3284420054665264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 823] Loss: 0.32844783619213985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 824] Loss: 0.32847068184621503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 825] Loss: 0.3284824209965054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 826] Loss: 0.32847863366239005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 827] Loss: 0.3285098559628676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 828] Loss: 0.32849769338752105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 829] Loss: 0.32846486063316493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 830] Loss: 0.3284366587550057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 831] Loss: 0.3284409482823104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 832] Loss: 0.3284489339439051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 833] Loss: 0.32847454774976387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 834] Loss: 0.32848905965539754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 835] Loss: 0.32850184171862423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 836] Loss: 0.3285347796876171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 837] Loss: 0.328511194644789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 838] Loss: 0.32850450714023743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 839] Loss: 0.32847266053939395\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 840] Loss: 0.3284379013311323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 841] Loss: 0.32845044277673735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 842] Loss: 0.32845393720206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 843] Loss: 0.3284419430079932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 844] Loss: 0.32842042858120474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 845] Loss: 0.32840813314061995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 846] Loss: 0.3284121941602026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 847] Loss: 0.3284150419628142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 848] Loss: 0.328423677284703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 849] Loss: 0.3284568193790942\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 850] Loss: 0.32845353218650974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 851] Loss: 0.32850589292150834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 852] Loss: 0.3285537356397802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 853] Loss: 0.32855583155264323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 854] Loss: 0.3285358266903435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 855] Loss: 0.32855138235674514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 856] Loss: 0.32856846182035593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 857] Loss: 0.3285790111147841\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 858] Loss: 0.328557842876005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 859] Loss: 0.3285434658699127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 860] Loss: 0.32853838170158434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 861] Loss: 0.3285209092272023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 862] Loss: 0.32852726828558093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 863] Loss: 0.32853122860647094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 864] Loss: 0.32853819965904824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 865] Loss: 0.3285404009620147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 866] Loss: 0.3285297465982375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 867] Loss: 0.32852922809561746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 868] Loss: 0.32850196806763055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 869] Loss: 0.3285464871107408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 870] Loss: 0.32856226115149884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 871] Loss: 0.32858356693599083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 872] Loss: 0.32858019589737547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 873] Loss: 0.32856862980121293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 874] Loss: 0.32857057901712156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 875] Loss: 0.32853980951580125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 876] Loss: 0.3285718667194543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 877] Loss: 0.32863517979917606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 878] Loss: 0.3286010423863706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 879] Loss: 0.32864411885174777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 880] Loss: 0.32867015760432655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 881] Loss: 0.32866322394628505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 882] Loss: 0.3286336490245458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 883] Loss: 0.32870323104431703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 884] Loss: 0.3286987717575599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 885] Loss: 0.328704726766499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 886] Loss: 0.3286800043583639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 887] Loss: 0.3286686831259877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 888] Loss: 0.3286997750582117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 889] Loss: 0.32871625707128316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 890] Loss: 0.3287094381813905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 891] Loss: 0.32874181004707054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 892] Loss: 0.32874067439624366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 893] Loss: 0.3287333269502994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 894] Loss: 0.3287244736095943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 895] Loss: 0.32871080640405087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 896] Loss: 0.328678263672156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 897] Loss: 0.3287373001650231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 898] Loss: 0.3287543030425666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 899] Loss: 0.328744989916505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 900] Loss: 0.3287310994852219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 901] Loss: 0.32872368372509897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 902] Loss: 0.3287151183281619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 903] Loss: 0.3287092125938018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 904] Loss: 0.32870070292699544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 905] Loss: 0.32868903140043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 906] Loss: 0.3286920484251398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 907] Loss: 0.3286683388814573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 908] Loss: 0.3286602350697671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 909] Loss: 0.3286695967189888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 910] Loss: 0.3286664757431033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 911] Loss: 0.32867357770957484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 912] Loss: 0.3286697739816882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 913] Loss: 0.32867303622128374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 914] Loss: 0.3286600586751602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 915] Loss: 0.3286569477810255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 916] Loss: 0.32866445018817453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 917] Loss: 0.32865786358196347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 918] Loss: 0.3286479712998771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 919] Loss: 0.32865645093112267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 920] Loss: 0.32868837145247265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 921] Loss: 0.3286866938346556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 922] Loss: 0.32869777185947036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 923] Loss: 0.32867462059918234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 924] Loss: 0.3286913123013167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 925] Loss: 0.3287417769599396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 926] Loss: 0.3287522241222256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 927] Loss: 0.3287290832512028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 928] Loss: 0.3287123319769431\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 929] Loss: 0.32872382771023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 930] Loss: 0.32878374921169895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 931] Loss: 0.32883158508496463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 932] Loss: 0.3288225913714971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 933] Loss: 0.32879684018838157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 934] Loss: 0.3288117913131097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 935] Loss: 0.32880069306487436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 936] Loss: 0.32881309882420545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 937] Loss: 0.3288053160197593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 938] Loss: 0.3288152249902487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 939] Loss: 0.32879701298764885\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.893\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 940] Loss: 0.32883195754517464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 941] Loss: 0.32882329118971393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 942] Loss: 0.3288090704507727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 943] Loss: 0.32880006738892803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 944] Loss: 0.328786253860675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 945] Loss: 0.3287602185381609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 946] Loss: 0.32874745192428745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 947] Loss: 0.3287785157909363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 948] Loss: 0.3287682284257131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 949] Loss: 0.32874426739321955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 950] Loss: 0.32874187655265297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 951] Loss: 0.32873595590817817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 952] Loss: 0.32876438235304584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 953] Loss: 0.3287754614236704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 954] Loss: 0.32876339743724853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 955] Loss: 0.3287650907636045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 956] Loss: 0.3287797516895604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 957] Loss: 0.3287583675326805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 958] Loss: 0.32880528424662425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 959] Loss: 0.3288658527240789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 960] Loss: 0.3288876802554077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 961] Loss: 0.32888456162420515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 962] Loss: 0.3288969953046151\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 963] Loss: 0.3288613951977213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 964] Loss: 0.3288401324247109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 965] Loss: 0.32886956046109933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 966] Loss: 0.32890391332010666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 967] Loss: 0.3288932637929869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 968] Loss: 0.32889529098691805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 969] Loss: 0.3288800449535781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 970] Loss: 0.3289297436717868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 971] Loss: 0.3289276648948616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 972] Loss: 0.32892865031945784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 973] Loss: 0.32895245225924363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 974] Loss: 0.3289209676165255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 975] Loss: 0.32892145080677165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 976] Loss: 0.3288975150996184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 977] Loss: 0.328894715353264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 978] Loss: 0.3288954254032837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 979] Loss: 0.3288724080269073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 980] Loss: 0.3289256535650765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 981] Loss: 0.32889528047192224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 982] Loss: 0.32895587817496197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 983] Loss: 0.3289626655688489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 984] Loss: 0.3289629432903931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 985] Loss: 0.3289393427727693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 986] Loss: 0.32892748257720905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 987] Loss: 0.32894379163784754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 988] Loss: 0.3289689625843917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 989] Loss: 0.32897643460846965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 990] Loss: 0.32895620802000036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 991] Loss: 0.3289359496939944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 992] Loss: 0.32892930310412644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 993] Loss: 0.32896268586199784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 994] Loss: 0.3289487725624791\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 995] Loss: 0.32896421642873463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 996] Loss: 0.32899796320202795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 997] Loss: 0.3290348459306878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 998] Loss: 0.3290647815309259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 999] Loss: 0.3290548263372722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1000] Loss: 0.3290838325114318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1001] Loss: 0.32908349814573673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1002] Loss: 0.3290997275591226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1003] Loss: 0.329076031385852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1004] Loss: 0.3291074446907309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1005] Loss: 0.32915199050271393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1006] Loss: 0.32917660874944554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1007] Loss: 0.3291825593828943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1008] Loss: 0.3291988991685873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1009] Loss: 0.3292894107195029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1010] Loss: 0.3292744097972659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1011] Loss: 0.3292816929385527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1012] Loss: 0.32924850219857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1013] Loss: 0.3292443156888332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1014] Loss: 0.3292358364231761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1015] Loss: 0.32922532975450614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1016] Loss: 0.32919872399858247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1017] Loss: 0.32921662961293635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1018] Loss: 0.32919232396511583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1019] Loss: 0.32919781051665586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1020] Loss: 0.3291737553390496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1021] Loss: 0.3291509405772282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1022] Loss: 0.3291443700570229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1023] Loss: 0.329148926873826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1024] Loss: 0.3291727167430048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1025] Loss: 0.32918821051438524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1026] Loss: 0.32917491462280823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1027] Loss: 0.32920013295512557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1028] Loss: 0.3292045866254505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1029] Loss: 0.3292232606990987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1030] Loss: 0.329230036820634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1031] Loss: 0.3292190050642265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1032] Loss: 0.3292216161974608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1033] Loss: 0.3292303319855925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1034] Loss: 0.32923613070821744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1035] Loss: 0.3292895103725284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1036] Loss: 0.329254607036096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1037] Loss: 0.329273180403787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1038] Loss: 0.32926606873671216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1039] Loss: 0.32924039362458896\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1040] Loss: 0.3292856858857049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1041] Loss: 0.3293107654063486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1042] Loss: 0.329286875936048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1043] Loss: 0.32932770212822166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1044] Loss: 0.32929981476271614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1045] Loss: 0.32928884175278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1046] Loss: 0.32927013945619205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1047] Loss: 0.3292590755000229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1048] Loss: 0.3292455059470729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1049] Loss: 0.3292226410033395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1050] Loss: 0.3293025009042594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1051] Loss: 0.3292680303020625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1052] Loss: 0.329273239171477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1053] Loss: 0.3292750531248566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1054] Loss: 0.3292983350510752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1055] Loss: 0.32932199388655087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1056] Loss: 0.3293155069175806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1057] Loss: 0.3292916092347018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1058] Loss: 0.32927126515423877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1059] Loss: 0.3292501690395408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1060] Loss: 0.3292235980848231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1061] Loss: 0.3292033436555265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1062] Loss: 0.3291804899580073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1063] Loss: 0.32919995258203366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1064] Loss: 0.32919258115594385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1065] Loss: 0.32917611137605074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1066] Loss: 0.3291889956183208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1067] Loss: 0.3291772192572497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1068] Loss: 0.3291538877242025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1069] Loss: 0.32915132974432915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1070] Loss: 0.32913948437278845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1071] Loss: 0.3291496319883914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1072] Loss: 0.3291210082367231\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1073] Loss: 0.32911915310750106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1074] Loss: 0.32909005663337365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1075] Loss: 0.32905822332113754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1076] Loss: 0.3290398160583688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1077] Loss: 0.3290984150436189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1078] Loss: 0.3290814723312159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1079] Loss: 0.3290885954405449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1080] Loss: 0.3290728246601163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1081] Loss: 0.32906312513288855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1082] Loss: 0.32906894088312866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1083] Loss: 0.32906375942992516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1084] Loss: 0.3290583308405372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1085] Loss: 0.329042166813105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1086] Loss: 0.3290283952802767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1087] Loss: 0.3290771527078736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1088] Loss: 0.3290836000268899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1089] Loss: 0.32910448823639826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1090] Loss: 0.32911469046350406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1091] Loss: 0.32909015914710454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1092] Loss: 0.32907185578905984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1093] Loss: 0.32903907128494997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1094] Loss: 0.32902916163044255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1095] Loss: 0.32904576856497764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1096] Loss: 0.3290655970538758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1097] Loss: 0.3290578839759952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1098] Loss: 0.32903810302878533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1099] Loss: 0.3290340152389203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1100] Loss: 0.3290614043555487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1101] Loss: 0.3290632261732117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1102] Loss: 0.32905441868868474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1103] Loss: 0.32903704833949754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1104] Loss: 0.32904443154893914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1105] Loss: 0.3290416698881937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1106] Loss: 0.32902676987262797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1107] Loss: 0.3290824895123952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1108] Loss: 0.32905397317741547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1109] Loss: 0.3290225942587627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1110] Loss: 0.32905392303244607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1111] Loss: 0.32907425078874675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1112] Loss: 0.3290604324323771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1113] Loss: 0.3290522195118061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1114] Loss: 0.3290293119197144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1115] Loss: 0.3290087119829984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1116] Loss: 0.3289953114219548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1117] Loss: 0.328988431931854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1118] Loss: 0.32897301257289513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1119] Loss: 0.32896080706034864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1120] Loss: 0.3289551978973245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1121] Loss: 0.3289434799736539\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1122] Loss: 0.3289606045258956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1123] Loss: 0.32896765462745237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1124] Loss: 0.32896876271068476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1125] Loss: 0.32896916278127486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1126] Loss: 0.3289451514505016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1127] Loss: 0.32892308638467566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1128] Loss: 0.3289427715516963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1129] Loss: 0.32897126391039166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1130] Loss: 0.3290097658366011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1131] Loss: 0.32899895553159136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1132] Loss: 0.32896498695423293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1133] Loss: 0.3289586128066433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1134] Loss: 0.3289648007380678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1135] Loss: 0.3289587534526827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1136] Loss: 0.32894012916771526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1137] Loss: 0.32891297892128696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1138] Loss: 0.3289707511806717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1139] Loss: 0.3289667875422718\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1140] Loss: 0.3289991708723731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1141] Loss: 0.32904571590058374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1142] Loss: 0.32902838341278995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1143] Loss: 0.3290008203784052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1144] Loss: 0.32898755517548156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1145] Loss: 0.32899820381628475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1146] Loss: 0.3290052647014276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1147] Loss: 0.3289916296681737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1148] Loss: 0.3289537386822151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1149] Loss: 0.3289499635220352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1150] Loss: 0.3289468917947088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1151] Loss: 0.3289465467034112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1152] Loss: 0.3289375845692969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1153] Loss: 0.32892547393519495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1154] Loss: 0.3288931432922879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1155] Loss: 0.32890315145362675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1156] Loss: 0.32891568698877116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1157] Loss: 0.32889756758474803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1158] Loss: 0.32891345634428476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1159] Loss: 0.32892353676603436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1160] Loss: 0.32891724545441564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1161] Loss: 0.32888782085722806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1162] Loss: 0.3288610572933831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1163] Loss: 0.3288584044418837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1164] Loss: 0.32888103122518203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1165] Loss: 0.3288956627218359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1166] Loss: 0.32887009550071256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1167] Loss: 0.3288811131197582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1168] Loss: 0.3288625221663862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1169] Loss: 0.3288324793223509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1170] Loss: 0.3288380676846302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1171] Loss: 0.32883711973624863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1172] Loss: 0.32884742459371247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1173] Loss: 0.3288319590924007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1174] Loss: 0.32884129902633935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1175] Loss: 0.32883451230851024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1176] Loss: 0.32882916581692156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1177] Loss: 0.32888765730380465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1178] Loss: 0.32886919125288955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1179] Loss: 0.32886715554037843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1180] Loss: 0.3288653657602154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1181] Loss: 0.3288304586771356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1182] Loss: 0.32887902021305787\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1183] Loss: 0.3288506428665838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1184] Loss: 0.32885064922622537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1185] Loss: 0.32881518717047964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1186] Loss: 0.3288858794215385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1187] Loss: 0.32888421266674883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1188] Loss: 0.32886625691822596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1189] Loss: 0.32888372088359485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1190] Loss: 0.32890164944068767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1191] Loss: 0.3289281955258678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1192] Loss: 0.32894809509485357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1193] Loss: 0.32896256826243775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1194] Loss: 0.3289694388423971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1195] Loss: 0.3289608532980592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1196] Loss: 0.32895511526510984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1197] Loss: 0.3289623302093226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1198] Loss: 0.3289949156372266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1199] Loss: 0.3289724862738676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1200] Loss: 0.32895772442283944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1201] Loss: 0.32894850689468336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1202] Loss: 0.32896035305000726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1203] Loss: 0.3289730467687645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1204] Loss: 0.3289621113553683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1205] Loss: 0.32894249842948653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1206] Loss: 0.32891676913248197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1207] Loss: 0.3289307303165299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1208] Loss: 0.3289216351124548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1209] Loss: 0.328913486353294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1210] Loss: 0.3289012785701361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1211] Loss: 0.32893955439651307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1212] Loss: 0.3289225156114189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1213] Loss: 0.32893694687793607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1214] Loss: 0.328966145367673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1215] Loss: 0.32899748634067655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1216] Loss: 0.32900851746994964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1217] Loss: 0.32900069781292746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1218] Loss: 0.3289791111298131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1219] Loss: 0.3289886475218853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1220] Loss: 0.32899838062521636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1221] Loss: 0.32900412731858425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1222] Loss: 0.32897800233928565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1223] Loss: 0.328954581982591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1224] Loss: 0.32896078031226805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1225] Loss: 0.32896010513981644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1226] Loss: 0.3289571897170412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1227] Loss: 0.3289468991613316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1228] Loss: 0.3289339768835863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1229] Loss: 0.3289238890945247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1230] Loss: 0.32892851352139757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1231] Loss: 0.3289070000849846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1232] Loss: 0.32889353762854706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1233] Loss: 0.3288787400362287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1234] Loss: 0.3288819086301813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1235] Loss: 0.3289038893781294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1236] Loss: 0.3289080353481178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1237] Loss: 0.32894134573788886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1238] Loss: 0.32891155163915653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1239] Loss: 0.32890822988448337\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1240] Loss: 0.3289000734360836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1241] Loss: 0.3288865150645299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1242] Loss: 0.3288690343830695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1243] Loss: 0.32885790601808096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1244] Loss: 0.3288603122649757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1245] Loss: 0.32885789149883937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1246] Loss: 0.3288630201946593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1247] Loss: 0.32889250982647494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1248] Loss: 0.3288870414182291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1249] Loss: 0.32891573075284347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1250] Loss: 0.3288887426711574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1251] Loss: 0.32887303319586303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1252] Loss: 0.32890804265904433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1253] Loss: 0.3289729302235628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1254] Loss: 0.3289545689274307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1255] Loss: 0.328966212074784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1256] Loss: 0.3289682957469498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1257] Loss: 0.3289824312685531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1258] Loss: 0.32899076607834576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1259] Loss: 0.329030762406427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1260] Loss: 0.3290332889829037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1261] Loss: 0.32906258462594234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1262] Loss: 0.3290492934556181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1263] Loss: 0.3290802071883645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1264] Loss: 0.3291143549006772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1265] Loss: 0.3291087268367592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1266] Loss: 0.3291029133680123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1267] Loss: 0.32911966856849373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1268] Loss: 0.3291182284591122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1269] Loss: 0.32912720712448595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1270] Loss: 0.329104719251752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1271] Loss: 0.329140037837472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1272] Loss: 0.32917305259198165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1273] Loss: 0.32914852906636466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1274] Loss: 0.329131253895865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1275] Loss: 0.32910371632785507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1276] Loss: 0.3291024671523434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1277] Loss: 0.32909838491878074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1278] Loss: 0.3290932531465082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1279] Loss: 0.32907495333380166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1280] Loss: 0.3290770087727265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1281] Loss: 0.32906728051986317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1282] Loss: 0.32907644828257265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1283] Loss: 0.3290687910187902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1284] Loss: 0.32909078928936386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1285] Loss: 0.3290778776017309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1286] Loss: 0.3291403582081388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1287] Loss: 0.329165730075895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1288] Loss: 0.3291601471978927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1289] Loss: 0.3292080579606468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1290] Loss: 0.32924961263622937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1291] Loss: 0.32925736905814507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1292] Loss: 0.32926260028973775\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1293] Loss: 0.3292702022720786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1294] Loss: 0.3292324649611011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1295] Loss: 0.3292527295035704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1296] Loss: 0.32924022400121095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1297] Loss: 0.3292376782594276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1298] Loss: 0.32923532986262843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1299] Loss: 0.3292359592776271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1300] Loss: 0.32924204401141094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1301] Loss: 0.32922977301893497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1302] Loss: 0.3292090378223872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1303] Loss: 0.3292189799589413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1304] Loss: 0.32921949097004305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1305] Loss: 0.32921303712624245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1306] Loss: 0.32918363611939766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1307] Loss: 0.32919497059963115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1308] Loss: 0.3291814747302892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1309] Loss: 0.32920515633255293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1310] Loss: 0.32921346336359064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1311] Loss: 0.3292144799773839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1312] Loss: 0.32922336410358133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1313] Loss: 0.3292347357938456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1314] Loss: 0.3292932052642018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1315] Loss: 0.3292919258291402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1316] Loss: 0.32926746661743295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1317] Loss: 0.3292456145849696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1318] Loss: 0.32922454952473534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1319] Loss: 0.32921320257843084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1320] Loss: 0.3292250730947286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1321] Loss: 0.32918968838252877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1322] Loss: 0.3291901594130281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1323] Loss: 0.3291720343195075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1324] Loss: 0.3291552460884189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1325] Loss: 0.3291415875002739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1326] Loss: 0.3291373123548256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1327] Loss: 0.3291596060981333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1328] Loss: 0.32917571928704603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1329] Loss: 0.3291730082138994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1330] Loss: 0.32917417620670725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1331] Loss: 0.3291740810994909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1332] Loss: 0.329172734937758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1333] Loss: 0.3292227965852969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1334] Loss: 0.32924169442271906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1335] Loss: 0.32922175575488805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1336] Loss: 0.32921163713757573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1337] Loss: 0.3291940674514191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1338] Loss: 0.3292284901384954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1339] Loss: 0.3292490387819273\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1340] Loss: 0.32924932485838726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1341] Loss: 0.32929308518047534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1342] Loss: 0.3292764544784802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1343] Loss: 0.32940911138973006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1344] Loss: 0.32943604630736834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1345] Loss: 0.32941335964956897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1346] Loss: 0.3294400052613849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1347] Loss: 0.3294355017979323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1348] Loss: 0.32942788528757044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1349] Loss: 0.32941653503879914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1350] Loss: 0.32942939935154325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1351] Loss: 0.32946150377874517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1352] Loss: 0.32947505130884963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1353] Loss: 0.32945575032207775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1354] Loss: 0.3294443372455446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1355] Loss: 0.3294383984156062\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1356] Loss: 0.3294357857544865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1357] Loss: 0.32944109100414654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1358] Loss: 0.32945491514852565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1359] Loss: 0.3294513577509797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1360] Loss: 0.32943677987418285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1361] Loss: 0.3294419021584903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1362] Loss: 0.32946630163464397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1363] Loss: 0.32945981192149326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1364] Loss: 0.32943099095093736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1365] Loss: 0.32942807299888266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1366] Loss: 0.32941287120168666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1367] Loss: 0.32941003147904485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1368] Loss: 0.3294081225634499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1369] Loss: 0.3294030169693503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1370] Loss: 0.3294182025741056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1371] Loss: 0.32940304530011383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1372] Loss: 0.3293903321411665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1373] Loss: 0.32939748365942667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1374] Loss: 0.3293854155090471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1375] Loss: 0.32939176059983905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1376] Loss: 0.32937165165307025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1377] Loss: 0.32935973273127545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1378] Loss: 0.32933635840411574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1379] Loss: 0.32931663722561205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1380] Loss: 0.3292939433446705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1381] Loss: 0.3292811419893533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1382] Loss: 0.3293475373063037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1383] Loss: 0.32935915578659575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1384] Loss: 0.3293767776415491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1385] Loss: 0.3293860573106147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1386] Loss: 0.329371252858932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1387] Loss: 0.32935121883808266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1388] Loss: 0.3293227729802832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1389] Loss: 0.3292989811887874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1390] Loss: 0.32928916424108357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1391] Loss: 0.32927374891265915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1392] Loss: 0.3292575872420915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1393] Loss: 0.3292359329083991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1394] Loss: 0.3292491944189951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1395] Loss: 0.3292242478888529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1396] Loss: 0.32919749812236326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1397] Loss: 0.3291754644363436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1398] Loss: 0.32917509487260393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1399] Loss: 0.32918764714944976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1400] Loss: 0.3291791675674396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1401] Loss: 0.32917362790873217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1402] Loss: 0.3292134726968203\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1403] Loss: 0.3292033418317727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1404] Loss: 0.3292079783548072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1405] Loss: 0.3292354631897124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1406] Loss: 0.3292532234991565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1407] Loss: 0.32930118572474354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1408] Loss: 0.3292969742847753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1409] Loss: 0.32930485865268383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1410] Loss: 0.3293671111538135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1411] Loss: 0.32935581951870596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1412] Loss: 0.329350726248184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1413] Loss: 0.3293273996381455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1414] Loss: 0.329343058136234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1415] Loss: 0.329359773809683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1416] Loss: 0.3293298630383207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1417] Loss: 0.32932170004408645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1418] Loss: 0.32932223307281516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1419] Loss: 0.3293105084962206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1420] Loss: 0.3292837741110978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1421] Loss: 0.3293068869399172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1422] Loss: 0.3293066411167057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1423] Loss: 0.3293156840688224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1424] Loss: 0.329325877034964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1425] Loss: 0.32931041956512747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1426] Loss: 0.32934386849012387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1427] Loss: 0.32935211420232946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1428] Loss: 0.32932866417645107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1429] Loss: 0.3293421189493222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1430] Loss: 0.3293995909821527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1431] Loss: 0.3293713401971175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1432] Loss: 0.32936265987615654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1433] Loss: 0.3293867736865001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1434] Loss: 0.32938206199627085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1435] Loss: 0.32941048890108277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1436] Loss: 0.32941086731767083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1437] Loss: 0.32939219016024235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1438] Loss: 0.32935888800024987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1439] Loss: 0.32936537762302376\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8978999999999999\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1440] Loss: 0.32934621322300167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1441] Loss: 0.3293319989497415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1442] Loss: 0.329336789921251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1443] Loss: 0.32937501570130345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1444] Loss: 0.32935873178181285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1445] Loss: 0.3293652646209749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1446] Loss: 0.32937319111687685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1447] Loss: 0.3293516140063979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1448] Loss: 0.329348490012644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1449] Loss: 0.3293255453770789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1450] Loss: 0.32934907037651245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1451] Loss: 0.32936004697789995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1452] Loss: 0.3293471419004846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1453] Loss: 0.3293695832801103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1454] Loss: 0.32938521710360197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1455] Loss: 0.3293642780287922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1456] Loss: 0.3293360162603332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1457] Loss: 0.32931991119135506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1458] Loss: 0.32930466197431085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1459] Loss: 0.32931244720412517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1460] Loss: 0.32929988839582275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1461] Loss: 0.32929403757500775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1462] Loss: 0.3292732180610763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1463] Loss: 0.3292587370705281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1464] Loss: 0.32925295621868583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1465] Loss: 0.32922721637595903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1466] Loss: 0.3292096201492158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1467] Loss: 0.32918988754961026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1468] Loss: 0.3291769371703132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1469] Loss: 0.3292031245903218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1470] Loss: 0.3291873291770531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1471] Loss: 0.329167559732155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1472] Loss: 0.32920211330890914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1473] Loss: 0.32917834778519073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1474] Loss: 0.3291592122933079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1475] Loss: 0.3291286267118159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1476] Loss: 0.32914475595619586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1477] Loss: 0.32913790339488674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1478] Loss: 0.32919051080189027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1479] Loss: 0.32920030170863035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1480] Loss: 0.32920581655182246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1481] Loss: 0.32921912921543867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1482] Loss: 0.32921180099485414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1483] Loss: 0.32920496687360234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1484] Loss: 0.3292135134677873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1485] Loss: 0.3292093636088271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1486] Loss: 0.32924823454368346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1487] Loss: 0.3292521591239372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1488] Loss: 0.3292318428287635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1489] Loss: 0.32927403903301716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1490] Loss: 0.32930703466269656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1491] Loss: 0.3292995698464232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1492] Loss: 0.32930264742169657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1493] Loss: 0.32932051887767577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1494] Loss: 0.3293226412205794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1495] Loss: 0.32932483139807356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1496] Loss: 0.3292947447811498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1497] Loss: 0.32929770534824265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1498] Loss: 0.32930487633126676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1499] Loss: 0.3292949895858979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1500] Loss: 0.32927812918543775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1501] Loss: 0.32927978115128503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1502] Loss: 0.3292625487938063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1503] Loss: 0.32928919572875187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1504] Loss: 0.32929067029622744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1505] Loss: 0.32928095794364326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1506] Loss: 0.3292883604513374\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1507] Loss: 0.3292697471864006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1508] Loss: 0.3292376298905489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1509] Loss: 0.329248617946021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1510] Loss: 0.32923685105976147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1511] Loss: 0.32922135244820333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1512] Loss: 0.32920745682675734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1513] Loss: 0.3292144649525929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1514] Loss: 0.32920296961866546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1515] Loss: 0.3292136477279432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1516] Loss: 0.3292095815170491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1517] Loss: 0.3291881166520053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1518] Loss: 0.3291706427718149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1519] Loss: 0.3291627234764113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1520] Loss: 0.3291650151841233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1521] Loss: 0.3291425039835265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1522] Loss: 0.3291422078188477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1523] Loss: 0.32915301789315343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 23, Batch 1524] Loss: 0.32915091348663267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 0] Loss: 0.3291320587625567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1] Loss: 0.32913549609199627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 2] Loss: 0.32911778567333855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 3] Loss: 0.3290943009828839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 4] Loss: 0.3290880610911498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 5] Loss: 0.3290836315186367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 6] Loss: 0.3290685044111004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 7] Loss: 0.3290382468560827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 8] Loss: 0.3290175140037187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 9] Loss: 0.3289987706739703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 10] Loss: 0.32899659528079706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 11] Loss: 0.32897724492575875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 12] Loss: 0.32895576641173807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 13] Loss: 0.32897601261468873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 14] Loss: 0.32895961793336115\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 15] Loss: 0.3289448747099489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 16] Loss: 0.32894581199947603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 17] Loss: 0.3289617769297832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 18] Loss: 0.32893797717490014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 19] Loss: 0.32892688318337454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 20] Loss: 0.3289367047747933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 21] Loss: 0.3289725979293209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 22] Loss: 0.32895998778690055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 23] Loss: 0.3289305706447034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 24] Loss: 0.3289292480904796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 25] Loss: 0.3289315185575339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 26] Loss: 0.3289293995753937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 27] Loss: 0.3289358116657147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 28] Loss: 0.3289419030994575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 29] Loss: 0.3289345287295998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 30] Loss: 0.3289292909315054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 31] Loss: 0.32893619892456305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 32] Loss: 0.32894746778613415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 33] Loss: 0.3289389188073284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 34] Loss: 0.3289624180600347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 35] Loss: 0.32894715617206416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 36] Loss: 0.32894889338307376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 37] Loss: 0.3289879346412115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 38] Loss: 0.32898550556235845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 39] Loss: 0.328969270745779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 40] Loss: 0.32897041343988015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 41] Loss: 0.32895590140409475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 42] Loss: 0.3289496894150861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 43] Loss: 0.3289579232463193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 44] Loss: 0.3289540899020066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 45] Loss: 0.3289588951579803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 46] Loss: 0.3289524746918877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 47] Loss: 0.32894936942402503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 48] Loss: 0.328932619010228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 49] Loss: 0.32892030452142124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 50] Loss: 0.3289503658655287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 51] Loss: 0.3289278847802696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 52] Loss: 0.3289322740015017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 53] Loss: 0.32891532021264236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 54] Loss: 0.32889789938556874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 55] Loss: 0.3289003941484353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 56] Loss: 0.3288781918676403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 57] Loss: 0.32886742319697865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 58] Loss: 0.328897139567311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 59] Loss: 0.32892516353822454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 60] Loss: 0.32892768940493683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 61] Loss: 0.3289462292999578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 62] Loss: 0.32898646381802843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 63] Loss: 0.32903241583467585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 64] Loss: 0.32905658080955036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 65] Loss: 0.3290307860813576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 66] Loss: 0.32906054611145324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 67] Loss: 0.32904015089572003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 68] Loss: 0.3290131542874479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 69] Loss: 0.3290081706050852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 70] Loss: 0.3289817507262362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 71] Loss: 0.32897129738107506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 72] Loss: 0.3289751375041722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 73] Loss: 0.32899812431512365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 74] Loss: 0.32898581623925777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 75] Loss: 0.32901479820192847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 76] Loss: 0.32900909370338666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 77] Loss: 0.3289973452887208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 78] Loss: 0.3290041673162398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 79] Loss: 0.3290109448305844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 80] Loss: 0.3290025269162703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 81] Loss: 0.32898979687678115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 82] Loss: 0.32899213064324606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 83] Loss: 0.32898573461243297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 84] Loss: 0.3289920148753212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 85] Loss: 0.32898374751462417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 86] Loss: 0.3289641887790077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 87] Loss: 0.3289368072702593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 88] Loss: 0.32893139753310163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 89] Loss: 0.32895293235096235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 90] Loss: 0.3289683588939757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 91] Loss: 0.3289452036367037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 92] Loss: 0.328953758973663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 93] Loss: 0.32892991264783583\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 94] Loss: 0.32894303485858695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 95] Loss: 0.32893855042889353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 96] Loss: 0.3289433534839047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 97] Loss: 0.32896810937030563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 98] Loss: 0.3289491244440238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 99] Loss: 0.328937572553214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 100] Loss: 0.3289822182798713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 101] Loss: 0.3289707702664467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 102] Loss: 0.3289904828743391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 103] Loss: 0.3289874892347936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 104] Loss: 0.32899076612694067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 105] Loss: 0.3289882881502743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 106] Loss: 0.32903708125195186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 107] Loss: 0.3290388100987616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 108] Loss: 0.32902676255897645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 109] Loss: 0.3290070576038672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 110] Loss: 0.3290105023487882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 111] Loss: 0.3290044834798744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 112] Loss: 0.3290096259123402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 113] Loss: 0.3290016537381892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 114] Loss: 0.3290070668529406\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 115] Loss: 0.32900746511141904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 116] Loss: 0.3290042071808185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 117] Loss: 0.32898365256871615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 118] Loss: 0.32897289484660946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 119] Loss: 0.3289706284566131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 120] Loss: 0.32900798763601335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 121] Loss: 0.32902342618326247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 122] Loss: 0.329114636834688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 123] Loss: 0.3291316698238436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 124] Loss: 0.3291565534780873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 125] Loss: 0.3291509565727717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 126] Loss: 0.32917855568614873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 127] Loss: 0.32918048648200837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 128] Loss: 0.32916411654217037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 129] Loss: 0.3291794818762802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 130] Loss: 0.3292122295431601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 131] Loss: 0.32920398177717813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 132] Loss: 0.32921669555723426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 133] Loss: 0.32922146682972675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 134] Loss: 0.32919942055615775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 135] Loss: 0.32917936398344666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 136] Loss: 0.32917737164594024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 137] Loss: 0.3291504076603282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 138] Loss: 0.3291224839619674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 139] Loss: 0.32910901599785186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 140] Loss: 0.3291021686600873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 141] Loss: 0.3291087478747872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 142] Loss: 0.32912121222611807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 143] Loss: 0.3290952076800623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 144] Loss: 0.3290756320094297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 145] Loss: 0.32905932802080445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 146] Loss: 0.32903349428937506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 147] Loss: 0.32905228522531155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 148] Loss: 0.32903549140343585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 149] Loss: 0.3290173346215711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 150] Loss: 0.32903379890194373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 151] Loss: 0.3290300719484131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 152] Loss: 0.32902059567620645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 153] Loss: 0.32904321447482093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 154] Loss: 0.3290287584710092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 155] Loss: 0.32899768927690254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 156] Loss: 0.32900793114834376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 157] Loss: 0.3289887607408931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 158] Loss: 0.32895921526835004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 159] Loss: 0.32896709745037317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 160] Loss: 0.3289557693210792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 161] Loss: 0.3289401500084662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 162] Loss: 0.3289194167733379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 163] Loss: 0.32890254978770794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 164] Loss: 0.32889287000665496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 165] Loss: 0.32890274627224875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 166] Loss: 0.3288943621333363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 167] Loss: 0.328918942308256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 168] Loss: 0.32889132609738153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 169] Loss: 0.32892431516803494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 170] Loss: 0.32892386133324586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 171] Loss: 0.32890795990074206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 172] Loss: 0.3289008082501444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 173] Loss: 0.3288736759478019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 174] Loss: 0.32892472693084573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 175] Loss: 0.3289098355017864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 176] Loss: 0.3289067288736244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 177] Loss: 0.3289495094224945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 178] Loss: 0.3289333263223107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 179] Loss: 0.32898328989547776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 180] Loss: 0.3289617519713945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 181] Loss: 0.32894705800435164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 182] Loss: 0.32895947335693776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 183] Loss: 0.32895172344491636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 184] Loss: 0.32895496809085967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 185] Loss: 0.3289369658121035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 186] Loss: 0.32895653091516897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 187] Loss: 0.32898213526741793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 188] Loss: 0.3290235852421104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 189] Loss: 0.32901399774048634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 190] Loss: 0.32900938232278915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 191] Loss: 0.32902002722984286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 192] Loss: 0.32900262182714785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 193] Loss: 0.32899410314729055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 194] Loss: 0.3290200154997036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 195] Loss: 0.329028564396716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 196] Loss: 0.3290054789494215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 197] Loss: 0.32898154525269196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 198] Loss: 0.32896270322562704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 199] Loss: 0.3289549653114145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 200] Loss: 0.32892088321941554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 201] Loss: 0.32891409047097275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 202] Loss: 0.32891815281486775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 203] Loss: 0.3289062162909483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 204] Loss: 0.32889742935965705\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 205] Loss: 0.3288822152461466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 206] Loss: 0.32889868696386615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 207] Loss: 0.32889257823038315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 208] Loss: 0.3288869156880663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 209] Loss: 0.3288788699472337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 210] Loss: 0.3288908368897105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 211] Loss: 0.3288808758452499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 212] Loss: 0.3288955265621745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 213] Loss: 0.3288998890591079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 214] Loss: 0.32891132411433177\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 215] Loss: 0.3288945683433203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 216] Loss: 0.32889396162273843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 217] Loss: 0.32888116080090557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 218] Loss: 0.3288749179072056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 219] Loss: 0.3288521128525374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 220] Loss: 0.32882731967155465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 221] Loss: 0.32883256455221455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 222] Loss: 0.32885878952404457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 223] Loss: 0.32884292787200614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 224] Loss: 0.3288606312379146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 225] Loss: 0.32885437892046127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 226] Loss: 0.32883967819105997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 227] Loss: 0.32882637347568544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 228] Loss: 0.3288255886255618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 229] Loss: 0.32885030366767304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 230] Loss: 0.3288447248944921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 231] Loss: 0.328835836508279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 232] Loss: 0.32883008089717425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 233] Loss: 0.3288286564609234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 234] Loss: 0.3288312940366324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 235] Loss: 0.328817264724949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 236] Loss: 0.32884803971698884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 237] Loss: 0.3288220177189662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 238] Loss: 0.32883582606336076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 239] Loss: 0.32884371240770044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 240] Loss: 0.3288413141570411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 241] Loss: 0.3288594150203667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 242] Loss: 0.32884100866391375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 243] Loss: 0.3288240133872572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 244] Loss: 0.32880414016014553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 245] Loss: 0.3288394486549501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 246] Loss: 0.3288768970131486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 247] Loss: 0.32887880106954326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 248] Loss: 0.32887587669116364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 249] Loss: 0.32887832020971774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 250] Loss: 0.32888357340778945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 251] Loss: 0.3288534227229014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 252] Loss: 0.32887421328638855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 253] Loss: 0.32888736828447207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 254] Loss: 0.3288773454749978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 255] Loss: 0.32886297275904963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 256] Loss: 0.32886622841281066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 257] Loss: 0.32887935365596754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 258] Loss: 0.32889145377153406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 259] Loss: 0.32890629782645703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 260] Loss: 0.32890491576730563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 261] Loss: 0.3288903735200945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 262] Loss: 0.3288806749268625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 263] Loss: 0.3288565723967348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 264] Loss: 0.3288428475231905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 265] Loss: 0.3288503014396619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 266] Loss: 0.32886861631315467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 267] Loss: 0.3288372977448072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 268] Loss: 0.32884039561988754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 269] Loss: 0.3288480079977117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 270] Loss: 0.32884536114684626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 271] Loss: 0.3288494010439054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 272] Loss: 0.3288341339898203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 273] Loss: 0.32883538437225307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 274] Loss: 0.32882670101208644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 275] Loss: 0.32881450647737986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 276] Loss: 0.32879308279862324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 277] Loss: 0.3287876215528336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 278] Loss: 0.32879275777150907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 279] Loss: 0.3287826155309502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 280] Loss: 0.3287806106381752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 281] Loss: 0.3287851958806692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 282] Loss: 0.32875998692692066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 283] Loss: 0.32873096632084203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 284] Loss: 0.32874259332886874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 285] Loss: 0.32872423923470345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 286] Loss: 0.32871924345545683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 287] Loss: 0.32871721289191963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 288] Loss: 0.3287173581275534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 289] Loss: 0.32873876491235665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 290] Loss: 0.3287312073104739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 291] Loss: 0.3287476563370524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 292] Loss: 0.32872801727635415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 293] Loss: 0.32873991793718466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 294] Loss: 0.3287219992681864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 295] Loss: 0.328687906244992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 296] Loss: 0.3286779991688421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 297] Loss: 0.3286954765920328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 298] Loss: 0.32868108268298635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 299] Loss: 0.3286552224415846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 300] Loss: 0.32863636474587504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 301] Loss: 0.3286455162173218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 302] Loss: 0.32867488672421974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 303] Loss: 0.3286564309497843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 304] Loss: 0.32866040745851566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 305] Loss: 0.32865332883390047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 306] Loss: 0.328659783695421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 307] Loss: 0.3286727103169263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 308] Loss: 0.3286929715832378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 309] Loss: 0.3286913158763781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 310] Loss: 0.32867387837477813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 311] Loss: 0.328690803768009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 312] Loss: 0.3287050440884744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 313] Loss: 0.3287547219380484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 314] Loss: 0.3287245861869043\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 315] Loss: 0.32876758206722817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 316] Loss: 0.32875156922348875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 317] Loss: 0.32872888184881954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 318] Loss: 0.32871946342207436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 319] Loss: 0.32871243624092966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 320] Loss: 0.32871292089778237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 321] Loss: 0.32871679820942573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 322] Loss: 0.32871202077734873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 323] Loss: 0.32870757070995626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 324] Loss: 0.32880612274068116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 325] Loss: 0.3287989309912041\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 326] Loss: 0.32879416134763484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 327] Loss: 0.32878040410968795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 328] Loss: 0.3287830700560938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 329] Loss: 0.3287825186669504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 330] Loss: 0.3287578924712205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 331] Loss: 0.32876761502643903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 332] Loss: 0.3287869788848542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 333] Loss: 0.32876216912440753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 334] Loss: 0.3287677737939118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 335] Loss: 0.32876369077051787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 336] Loss: 0.32876729848727815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 337] Loss: 0.3287735693458566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 338] Loss: 0.3287756876779508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 339] Loss: 0.32879887310799977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 340] Loss: 0.32882772599271043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 341] Loss: 0.32884947860339475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 342] Loss: 0.32882629577959543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 343] Loss: 0.32880349340668014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 344] Loss: 0.3288495930194694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 345] Loss: 0.328861611382188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 346] Loss: 0.328913962179988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 347] Loss: 0.328896859990333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 348] Loss: 0.32887284537022515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 349] Loss: 0.3289011523976038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 350] Loss: 0.3288932425171232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 351] Loss: 0.32888745495961064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 352] Loss: 0.32886437009151265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 353] Loss: 0.3288736753792875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 354] Loss: 0.3288841662714325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 355] Loss: 0.32887921367719575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 356] Loss: 0.3288725087754196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 357] Loss: 0.32886902625957054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 358] Loss: 0.3288602465035236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 359] Loss: 0.32885353193012823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 360] Loss: 0.32885916263732023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 361] Loss: 0.32883646843733205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 362] Loss: 0.3288446730236022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 363] Loss: 0.3288687269727723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 364] Loss: 0.32884788301597623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 365] Loss: 0.3288381161313424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 366] Loss: 0.3288362418030283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 367] Loss: 0.32883319872105166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 368] Loss: 0.32886091373879606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 369] Loss: 0.32885574063322465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 370] Loss: 0.32884843371819783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 371] Loss: 0.32884783839501164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 372] Loss: 0.328850191445994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 373] Loss: 0.3288618947160524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 374] Loss: 0.3288342506043404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 375] Loss: 0.32881395505033295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 376] Loss: 0.32882151660624515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 377] Loss: 0.3288303882328357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 378] Loss: 0.3288131754161526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 379] Loss: 0.32879108404837476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 380] Loss: 0.32881714879857127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 381] Loss: 0.32880405293672715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 382] Loss: 0.328803287896105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 383] Loss: 0.32877819997631325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 384] Loss: 0.3287587137258027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 385] Loss: 0.32873924149166633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 386] Loss: 0.3287458442976062\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 387] Loss: 0.3287417529481967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 388] Loss: 0.32871288788368513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 389] Loss: 0.3287273274767032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 390] Loss: 0.32870592076193633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 391] Loss: 0.32870247521630575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 392] Loss: 0.3287047191838752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 393] Loss: 0.3287051577307907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 394] Loss: 0.32875550386947927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 395] Loss: 0.3287756004184235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 396] Loss: 0.32879074822943805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 397] Loss: 0.32884511092857005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 398] Loss: 0.3288403468796285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 399] Loss: 0.3288614928269323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 400] Loss: 0.32884210761787697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 401] Loss: 0.32882976410045733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 402] Loss: 0.32882290347567145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 403] Loss: 0.3288240924054673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 404] Loss: 0.3288112546899764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 405] Loss: 0.3287939338214964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 406] Loss: 0.32879419241149654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 407] Loss: 0.32876250085917796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 408] Loss: 0.3287566064818886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 409] Loss: 0.3287371380516813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 410] Loss: 0.32876283405462026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 411] Loss: 0.328752613864608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 412] Loss: 0.3287794038710504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 413] Loss: 0.32879322486619156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 414] Loss: 0.3287755355097377\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8937999999999999\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 415] Loss: 0.3288460033922464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 416] Loss: 0.32885030444941676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 417] Loss: 0.3288709409832756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 418] Loss: 0.3288716168154487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 419] Loss: 0.32885656257470447\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 420] Loss: 0.3289387019170349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 421] Loss: 0.32895416275817607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 422] Loss: 0.3289551907717279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 423] Loss: 0.32894474473253466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 424] Loss: 0.3289223145132671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 425] Loss: 0.32893790151733043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 426] Loss: 0.32894039167186967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 427] Loss: 0.3289365964199286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 428] Loss: 0.3289918943062883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 429] Loss: 0.32898292569394044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 430] Loss: 0.32896622948785625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 431] Loss: 0.3289788916370289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 432] Loss: 0.3289562815902122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 433] Loss: 0.32895543414888984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 434] Loss: 0.32894992010178825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 435] Loss: 0.3289360944286845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 436] Loss: 0.328907213688253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 437] Loss: 0.3289012695065295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 438] Loss: 0.32887242430225944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 439] Loss: 0.32885876322184293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 440] Loss: 0.32887068329530705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 441] Loss: 0.32887189943088785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 442] Loss: 0.32889195516900765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 443] Loss: 0.32892558168416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 444] Loss: 0.32891862911483066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 445] Loss: 0.32896445966288645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 446] Loss: 0.32897151082620757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 447] Loss: 0.3289653537020132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 448] Loss: 0.3289619355233326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 449] Loss: 0.3289660602027885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 450] Loss: 0.3289654957541216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 451] Loss: 0.3289508435575328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 452] Loss: 0.3289367863724891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 453] Loss: 0.32895825730747735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 454] Loss: 0.32895690728113997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 455] Loss: 0.3289608166475084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 456] Loss: 0.32895966779903607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 457] Loss: 0.32896601024603384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 458] Loss: 0.32900278864072513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 459] Loss: 0.3290023198545354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 460] Loss: 0.32898637566395744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 461] Loss: 0.3290868359568613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 462] Loss: 0.3290808533125425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 463] Loss: 0.3290878488628332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 464] Loss: 0.32908133764470676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 465] Loss: 0.3290611739096189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 466] Loss: 0.32903858543663367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 467] Loss: 0.32905545352727694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 468] Loss: 0.3290541997485472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 469] Loss: 0.3290481171232391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 470] Loss: 0.3290793562616396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 471] Loss: 0.3291378132519292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 472] Loss: 0.32913678486092607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 473] Loss: 0.3291932936745508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 474] Loss: 0.32918846232528004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 475] Loss: 0.3291666298509824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 476] Loss: 0.329146286965144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 477] Loss: 0.3291437672352846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 478] Loss: 0.329147308492405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 479] Loss: 0.3291215684438082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 480] Loss: 0.32908951752078147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 481] Loss: 0.3291159186269118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 482] Loss: 0.3291392334334676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 483] Loss: 0.32914970878763294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 484] Loss: 0.3291359805399063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 485] Loss: 0.32910901007189736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 486] Loss: 0.3290946571355437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 487] Loss: 0.32908191517422297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 488] Loss: 0.3290712267920804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 489] Loss: 0.3290897658520266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 490] Loss: 0.32909972648666114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 491] Loss: 0.32909752941417947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 492] Loss: 0.32911477697427033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 493] Loss: 0.32910000364492203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 494] Loss: 0.32908697033022566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 495] Loss: 0.32910106601349737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 496] Loss: 0.32907681316798715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 497] Loss: 0.3290827908821987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 498] Loss: 0.32908176258634914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 499] Loss: 0.329075087191163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 500] Loss: 0.3291034848354751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 501] Loss: 0.32910496200117895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 502] Loss: 0.3290821476525167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 503] Loss: 0.32907273736835896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 504] Loss: 0.3290663475430358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 505] Loss: 0.3291038775587857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 506] Loss: 0.32909888487652217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 507] Loss: 0.3291219094536482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 508] Loss: 0.32912408669186577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 509] Loss: 0.3291241531908082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 510] Loss: 0.329108966082183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 511] Loss: 0.3290883779340042\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 512] Loss: 0.32907699550110936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 513] Loss: 0.3290844922720409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 514] Loss: 0.32906501861971493\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 515] Loss: 0.3290552511562171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 516] Loss: 0.3290465242859186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 517] Loss: 0.32901276501083593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 518] Loss: 0.3290092104043656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 519] Loss: 0.32901639589668297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 520] Loss: 0.3289978532997465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 521] Loss: 0.3290147188423932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 522] Loss: 0.3289844155223773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 523] Loss: 0.3289612831489934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 524] Loss: 0.3289738668345562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 525] Loss: 0.3289678903901218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 526] Loss: 0.3289596471266994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 527] Loss: 0.32898308093500245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 528] Loss: 0.3289733093484737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 529] Loss: 0.32895518945830954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 530] Loss: 0.3289348429712338\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 531] Loss: 0.328934886676983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 532] Loss: 0.32895342333047173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 533] Loss: 0.3289579941580693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 534] Loss: 0.3289744698145366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 535] Loss: 0.32901894162922896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 536] Loss: 0.32901635913264415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 537] Loss: 0.32900672082093946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 538] Loss: 0.32901765785655196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 539] Loss: 0.3290342254101393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 540] Loss: 0.3290503706685166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 541] Loss: 0.3290785642671484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 542] Loss: 0.3291041634200078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 543] Loss: 0.32910621384277233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 544] Loss: 0.3291080365720921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 545] Loss: 0.3291280566358092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 546] Loss: 0.32911496913522487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 547] Loss: 0.3291134630789343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 548] Loss: 0.3291024133283721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 549] Loss: 0.3291042814397944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 550] Loss: 0.3290924074785978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 551] Loss: 0.32912151605065615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 552] Loss: 0.32914153621326464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 553] Loss: 0.32913489454586653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 554] Loss: 0.32912541467297873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 555] Loss: 0.3291286740855998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 556] Loss: 0.32911979819079595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 557] Loss: 0.3291118192646536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 558] Loss: 0.3291128005095863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 559] Loss: 0.3291424310342171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 560] Loss: 0.32911116071196905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 561] Loss: 0.3291215481928555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 562] Loss: 0.32910625613798145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 563] Loss: 0.32911114811170394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 564] Loss: 0.32909474357020235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 565] Loss: 0.3291053512486083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 566] Loss: 0.329086788065275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 567] Loss: 0.3290702268471569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 568] Loss: 0.3290428770014564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 569] Loss: 0.32902422530638314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 570] Loss: 0.32905411929138995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 571] Loss: 0.32904929461059884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 572] Loss: 0.32902907198233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 573] Loss: 0.3290221001759365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 574] Loss: 0.3290267259806438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 575] Loss: 0.32904980715433135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 576] Loss: 0.3290531507622358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 577] Loss: 0.32902982010518783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 578] Loss: 0.329014220901456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 579] Loss: 0.32904080281223214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 580] Loss: 0.3290592374297311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 581] Loss: 0.3290369935266084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 582] Loss: 0.3290156443393642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 583] Loss: 0.3290150492200009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 584] Loss: 0.3289943373830136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 585] Loss: 0.32902680835502535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 586] Loss: 0.3290226087734531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 587] Loss: 0.3290423853524997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 588] Loss: 0.3290259774735099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 589] Loss: 0.3290394328949597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 590] Loss: 0.3290544682834765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 591] Loss: 0.3290728466985063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 592] Loss: 0.32912947211205373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 593] Loss: 0.32911598529775166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 594] Loss: 0.3291270812460181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 595] Loss: 0.32914629685853686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 596] Loss: 0.32916010015849134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 597] Loss: 0.32915771182236125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 598] Loss: 0.32914597577352916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 599] Loss: 0.329156756923783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 600] Loss: 0.32913299762308645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 601] Loss: 0.3291204622847346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 602] Loss: 0.3291210097336465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 603] Loss: 0.32923718186062256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 604] Loss: 0.3292482582028781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 605] Loss: 0.32923508153443803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 606] Loss: 0.3292568579217488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 607] Loss: 0.32929447515572047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 608] Loss: 0.32927931359787926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 609] Loss: 0.3292536927042006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 610] Loss: 0.32926394714306145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 611] Loss: 0.32926513598681884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 612] Loss: 0.3292612693981502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 613] Loss: 0.3292821592645299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 614] Loss: 0.32929136420839966\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 615] Loss: 0.3292919528946612\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 616] Loss: 0.32931653951063056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 617] Loss: 0.32929724205806515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 618] Loss: 0.3292867193459312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 619] Loss: 0.3292791350494651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 620] Loss: 0.3292639893366362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 621] Loss: 0.3292733016255859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 622] Loss: 0.32924367952536876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 623] Loss: 0.3292472260609725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 624] Loss: 0.32923018835416606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 625] Loss: 0.32922633259970374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 626] Loss: 0.32924822020334993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 627] Loss: 0.32921778920247774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 628] Loss: 0.32922389944138686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 629] Loss: 0.3292197182515643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 630] Loss: 0.3292051900740853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 631] Loss: 0.32921669612785137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 632] Loss: 0.32921079019197486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 633] Loss: 0.3292554105209768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 634] Loss: 0.3292349763975096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 635] Loss: 0.3292296499789853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 636] Loss: 0.32923074269934555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 637] Loss: 0.3292330570164637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 638] Loss: 0.32923206239340297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 639] Loss: 0.3292290829995649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 640] Loss: 0.3292289034539592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 641] Loss: 0.32924836072484576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 642] Loss: 0.3292559471084823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 643] Loss: 0.3292855332167535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 644] Loss: 0.32928459175783603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 645] Loss: 0.32929535529101617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 646] Loss: 0.3292838918317403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 647] Loss: 0.3292784403064215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 648] Loss: 0.32926359562847074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 649] Loss: 0.32925021894051526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 650] Loss: 0.3292503990346429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 651] Loss: 0.3292353682986778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 652] Loss: 0.3292091454278202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 653] Loss: 0.32921568990852207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 654] Loss: 0.32920859167685096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 655] Loss: 0.3292131286039256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 656] Loss: 0.32919873215822615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 657] Loss: 0.3291981470348131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 658] Loss: 0.3291830757195898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 659] Loss: 0.3291909611672688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 660] Loss: 0.3291742029033777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 661] Loss: 0.3291833654317943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 662] Loss: 0.3291738938023365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 663] Loss: 0.3291546455001831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 664] Loss: 0.32920027150094766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 665] Loss: 0.32922234993025196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 666] Loss: 0.32923791973510397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 667] Loss: 0.3292514946053194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 668] Loss: 0.32923874528907376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 669] Loss: 0.3292667373057331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 670] Loss: 0.32923904536906684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 671] Loss: 0.3292295523285485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 672] Loss: 0.32921461246278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 673] Loss: 0.32923600005027587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 674] Loss: 0.32926327422573015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 675] Loss: 0.32924987473062567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 676] Loss: 0.32925808422342384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 677] Loss: 0.3292570677092287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 678] Loss: 0.3292373096904846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 679] Loss: 0.3292177088779837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 680] Loss: 0.32924549580238566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 681] Loss: 0.3292474960403109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 682] Loss: 0.3292451140806994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 683] Loss: 0.3292411209364827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 684] Loss: 0.32925353715711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 685] Loss: 0.3292380075364811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 686] Loss: 0.3292404470827787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 687] Loss: 0.3292446941218066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 688] Loss: 0.3292694199013995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 689] Loss: 0.3292619962532517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 690] Loss: 0.32926364287185655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 691] Loss: 0.32926577445702326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 692] Loss: 0.32925298438840733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 693] Loss: 0.3292525973716739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 694] Loss: 0.3292589878802504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 695] Loss: 0.3292714371608344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 696] Loss: 0.3292730313168577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 697] Loss: 0.3292581540035033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 698] Loss: 0.32924293348878364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 699] Loss: 0.32923046667561423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 700] Loss: 0.32926711969578876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 701] Loss: 0.3292716079256462\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 702] Loss: 0.32931997834223975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 703] Loss: 0.3293212123629778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 704] Loss: 0.3293197936984053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 705] Loss: 0.32931634050054454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 706] Loss: 0.3293537289571936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 707] Loss: 0.32935039814139005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 708] Loss: 0.32936256017071375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 709] Loss: 0.3293842870595343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 710] Loss: 0.329380268948938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 711] Loss: 0.3294117570292499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 712] Loss: 0.32940043716473055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 713] Loss: 0.3294126128866559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 714] Loss: 0.329405509381233\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 715] Loss: 0.3294101908769883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 716] Loss: 0.3293967331361718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 717] Loss: 0.3293925031386127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 718] Loss: 0.3294333853530657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 719] Loss: 0.3294278954631595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 720] Loss: 0.3293992932552163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 721] Loss: 0.32939539343052526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 722] Loss: 0.329378634400726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 723] Loss: 0.32938085567034936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 724] Loss: 0.32938342272876425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 725] Loss: 0.3293555220742492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 726] Loss: 0.329346235615505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 727] Loss: 0.3293250547105427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 728] Loss: 0.32932411164446473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 729] Loss: 0.32933433294683184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 730] Loss: 0.32933994480632084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 731] Loss: 0.32935264940341463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 732] Loss: 0.3293302334605714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 733] Loss: 0.3293072991827621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 734] Loss: 0.3292844619385673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 735] Loss: 0.32927740278527995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 736] Loss: 0.32929086884318437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 737] Loss: 0.329285393471981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 738] Loss: 0.32925910007105513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 739] Loss: 0.3292318890521958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 740] Loss: 0.32923217972713154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 741] Loss: 0.32921426768465306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 742] Loss: 0.32919250589954774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 743] Loss: 0.32919532150548025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 744] Loss: 0.32920489220271987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 745] Loss: 0.32921661301007094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 746] Loss: 0.3291938595230237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 747] Loss: 0.3291984017659596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 748] Loss: 0.3292236641649195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 749] Loss: 0.3292219655687046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 750] Loss: 0.3292258446202851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 751] Loss: 0.32921625094699275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 752] Loss: 0.32920346079630175\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 753] Loss: 0.32922730537055045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 754] Loss: 0.3291999968754307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 755] Loss: 0.3291898345752719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 756] Loss: 0.3291878168226397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 757] Loss: 0.32916237392978365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 758] Loss: 0.32914046961271076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 759] Loss: 0.3291277241864642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 760] Loss: 0.3291486443093917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 761] Loss: 0.329131450921898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 762] Loss: 0.32911792504288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 763] Loss: 0.32911638127771886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 764] Loss: 0.3291005495518629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 765] Loss: 0.329081369993237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 766] Loss: 0.3291062373716625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 767] Loss: 0.32911789752390536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 768] Loss: 0.32910324571687904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 769] Loss: 0.32909364553134424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 770] Loss: 0.32910311232624667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 771] Loss: 0.32909673364020325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 772] Loss: 0.3290932827713655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 773] Loss: 0.3291133391055858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 774] Loss: 0.32912188220925537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 775] Loss: 0.3291174733214354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 776] Loss: 0.32909888572406604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 777] Loss: 0.329077771613708\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 778] Loss: 0.32907633252108276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 779] Loss: 0.329063938268786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 780] Loss: 0.3290402827231798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 781] Loss: 0.3290502343598248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 782] Loss: 0.32904796465859343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 783] Loss: 0.32905994278014733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 784] Loss: 0.32903791365528423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 785] Loss: 0.32906538350957787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 786] Loss: 0.32907311904286357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 787] Loss: 0.3290837866958122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 788] Loss: 0.32907458115558996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 789] Loss: 0.32905415005262106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 790] Loss: 0.32908188526544785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 791] Loss: 0.3291132373658794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 792] Loss: 0.3291046692577906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 793] Loss: 0.3290904817583045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 794] Loss: 0.32908743024432835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 795] Loss: 0.32906164703362417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 796] Loss: 0.3290707039717277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 797] Loss: 0.32905464767849535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 798] Loss: 0.32904397949821423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 799] Loss: 0.32904270953083725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 800] Loss: 0.3290539790398081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 801] Loss: 0.3290255400903276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 802] Loss: 0.32901244345013947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 803] Loss: 0.32903712360372006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 804] Loss: 0.3290162304256877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 805] Loss: 0.3290190983316552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 806] Loss: 0.3290075625301843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 807] Loss: 0.3290207858780305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 808] Loss: 0.32900856392657596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 809] Loss: 0.32898803669877763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 810] Loss: 0.3289793594537237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 811] Loss: 0.32898681252384304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 812] Loss: 0.3289872252218312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 813] Loss: 0.3290035057766363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 814] Loss: 0.3289827134293181\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 815] Loss: 0.3289701765992611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 816] Loss: 0.32898153104010214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 817] Loss: 0.3290093804335572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 818] Loss: 0.3290412378325116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 819] Loss: 0.3290298165235339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 820] Loss: 0.3290009934304563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 821] Loss: 0.32899825136350486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 822] Loss: 0.3289821813809256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 823] Loss: 0.3289673683842333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 824] Loss: 0.3289926922269255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 825] Loss: 0.32901880917088805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 826] Loss: 0.32901176373430296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 827] Loss: 0.32901577766267986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 828] Loss: 0.32903527734991356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 829] Loss: 0.32904305542236256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 830] Loss: 0.3290576141943567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 831] Loss: 0.3290658069013546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 832] Loss: 0.3290482453884672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 833] Loss: 0.3290536235518916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 834] Loss: 0.3290598894405766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 835] Loss: 0.3290570271568334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 836] Loss: 0.3290312948830863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 837] Loss: 0.32901270870133253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 838] Loss: 0.3290275903133103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 839] Loss: 0.3290037583296558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 840] Loss: 0.32899892302115524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 841] Loss: 0.3290172461130527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 842] Loss: 0.32902421833225015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 843] Loss: 0.32905015522964637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 844] Loss: 0.32906465386690015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 845] Loss: 0.32906090934061216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 846] Loss: 0.3290518669930695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 847] Loss: 0.3290754337538871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 848] Loss: 0.32907731096551873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 849] Loss: 0.329070870291657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 850] Loss: 0.32905758468005086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 851] Loss: 0.3291069322507846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 852] Loss: 0.32916138264347555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 853] Loss: 0.329183023131412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 854] Loss: 0.3292293660001454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 855] Loss: 0.3292286392695709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 856] Loss: 0.3292348446885603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 857] Loss: 0.32922563666719445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 858] Loss: 0.329207323199099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 859] Loss: 0.3292643704627598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 860] Loss: 0.32929048576622355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 861] Loss: 0.32929889279332186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 862] Loss: 0.3292953162220841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 863] Loss: 0.3293142175605131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 864] Loss: 0.32930493115722775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 865] Loss: 0.3293234971545346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 866] Loss: 0.32931798932285583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 867] Loss: 0.3292983426794128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 868] Loss: 0.32928013721009175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 869] Loss: 0.3292534470216566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 870] Loss: 0.32923215339662715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 871] Loss: 0.32923293044948104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 872] Loss: 0.32922251747477294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 873] Loss: 0.3292008694757249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 874] Loss: 0.3292055987127239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 875] Loss: 0.3291951564444141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 876] Loss: 0.3291728455396365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 877] Loss: 0.3291768654189672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 878] Loss: 0.32921351248085823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 879] Loss: 0.32921916005128754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 880] Loss: 0.32920968296844183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 881] Loss: 0.329229838733752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 882] Loss: 0.3292144035068504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 883] Loss: 0.32921670693932953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 884] Loss: 0.32922429988758584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 885] Loss: 0.32929960460769303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 886] Loss: 0.3293397990353929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 887] Loss: 0.3293620677602155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 888] Loss: 0.32936538967156503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 889] Loss: 0.32935718284750737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 890] Loss: 0.3293712447252615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 891] Loss: 0.32936878867422076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 892] Loss: 0.3293657495428482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 893] Loss: 0.3293682711428882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 894] Loss: 0.32935745683032375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 895] Loss: 0.3293373668770369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 896] Loss: 0.3293223414807413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 897] Loss: 0.32931473359631064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 898] Loss: 0.3293079417833661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 899] Loss: 0.3293400658337635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 900] Loss: 0.32932566644755096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 901] Loss: 0.3293665572748268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 902] Loss: 0.3293664641442955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 903] Loss: 0.32936553747288433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 904] Loss: 0.32936078352023485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 905] Loss: 0.3293726312103311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 906] Loss: 0.32935149913050443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 907] Loss: 0.329366495630302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 908] Loss: 0.32936448131596885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 909] Loss: 0.3293540385515048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 910] Loss: 0.3293330170694674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 911] Loss: 0.3293224796859181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 912] Loss: 0.3293557263535891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 913] Loss: 0.3293411405957662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 914] Loss: 0.3293613614008768\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8926\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 915] Loss: 0.3293417829622565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 916] Loss: 0.329343280294263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 917] Loss: 0.3293293784698987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 918] Loss: 0.3293245462868234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 919] Loss: 0.32930976510405213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 920] Loss: 0.3292978669373473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 921] Loss: 0.329295283683748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 922] Loss: 0.3292795038224182\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 923] Loss: 0.3292743610369811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 924] Loss: 0.3292911092914793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 925] Loss: 0.32926995190276925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 926] Loss: 0.32926128735131205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 927] Loss: 0.3292387826291008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 928] Loss: 0.32924778179900976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 929] Loss: 0.32923469665255045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 930] Loss: 0.32926086859641235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 931] Loss: 0.32925406571371346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 932] Loss: 0.3292332906301703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 933] Loss: 0.3292346527514282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 934] Loss: 0.32922789849783085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 935] Loss: 0.3292412012952561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 936] Loss: 0.32924516120060043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 937] Loss: 0.32924073659098274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 938] Loss: 0.3292248236790471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 939] Loss: 0.3292276396013972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 940] Loss: 0.3292194648912787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 941] Loss: 0.3292180272800775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 942] Loss: 0.32923573846427384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 943] Loss: 0.32922128510374754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 944] Loss: 0.3292104746582241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 945] Loss: 0.3292234817819769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 946] Loss: 0.3292077550926563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 947] Loss: 0.3291868325431193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 948] Loss: 0.3291882689777183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 949] Loss: 0.32919388815915646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 950] Loss: 0.3291905458269452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 951] Loss: 0.3291847400182648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 952] Loss: 0.3291833712126177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 953] Loss: 0.32915749708674735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 954] Loss: 0.32915157207954626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 955] Loss: 0.32914845827876954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 956] Loss: 0.3291340379558826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 957] Loss: 0.32912767128130843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 958] Loss: 0.3291227922560697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 959] Loss: 0.32914419125070127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 960] Loss: 0.32913215948194513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 961] Loss: 0.3291630507694306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 962] Loss: 0.3291790932689956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 963] Loss: 0.329168477329134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 964] Loss: 0.3291632861008154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 965] Loss: 0.32916170422565444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 966] Loss: 0.32915416539315684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 967] Loss: 0.3291682601770796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 968] Loss: 0.32916824595560834\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 969] Loss: 0.3291544688841677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 970] Loss: 0.32915395399874003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 971] Loss: 0.32917471121191144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 972] Loss: 0.3291818560246633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 973] Loss: 0.32917804999004413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 974] Loss: 0.3291631314907472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 975] Loss: 0.3291485868859894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 976] Loss: 0.3291421290688556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 977] Loss: 0.32914654471974486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 978] Loss: 0.32919015334202695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 979] Loss: 0.32917816865709254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 980] Loss: 0.3291662635234315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 981] Loss: 0.3291553078303238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 982] Loss: 0.32913592047416595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 983] Loss: 0.329114083120177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 984] Loss: 0.329101604629626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 985] Loss: 0.3291061267991365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 986] Loss: 0.32907848436684073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 987] Loss: 0.329100177168012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 988] Loss: 0.32909006365351806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 989] Loss: 0.32909211379514414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 990] Loss: 0.3290881908817169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 991] Loss: 0.3290935829802827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 992] Loss: 0.32909893648007266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 993] Loss: 0.32908376373327974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 994] Loss: 0.3290701041674835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 995] Loss: 0.32907983009592806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 996] Loss: 0.32909262481384793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 997] Loss: 0.32911693823964017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 998] Loss: 0.3291862409089493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 999] Loss: 0.329196812360438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1000] Loss: 0.3291817916775213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1001] Loss: 0.3291875515461113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1002] Loss: 0.3291641945704322\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1003] Loss: 0.32913915258076193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1004] Loss: 0.3291422505287205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1005] Loss: 0.32912789009402965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1006] Loss: 0.32912380994496315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1007] Loss: 0.3291101319422171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1008] Loss: 0.32915325271893486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1009] Loss: 0.329157303460733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1010] Loss: 0.32917004900031405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1011] Loss: 0.3292008658391702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1012] Loss: 0.32921108411991123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1013] Loss: 0.3291996658615994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1014] Loss: 0.32917683453401675\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1015] Loss: 0.3291913633435396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1016] Loss: 0.3291658398356922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1017] Loss: 0.32916718956505003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1018] Loss: 0.3291880024824063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1019] Loss: 0.3292086621621793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1020] Loss: 0.3292021378232001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1021] Loss: 0.32920217041837246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1022] Loss: 0.329178619326595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1023] Loss: 0.32921888944375893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1024] Loss: 0.3292200529657393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1025] Loss: 0.32921955704517747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1026] Loss: 0.32922597240296647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1027] Loss: 0.3292193031690436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1028] Loss: 0.3292078604030501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1029] Loss: 0.32919817808182167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1030] Loss: 0.32920879874368875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1031] Loss: 0.3292347867999887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1032] Loss: 0.32922634413269714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1033] Loss: 0.32920597190448164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1034] Loss: 0.329206003010354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1035] Loss: 0.3291849635341167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1036] Loss: 0.32918003279331604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1037] Loss: 0.329166601292771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1038] Loss: 0.3291769346628549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1039] Loss: 0.3291723774979383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1040] Loss: 0.3291525234189601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1041] Loss: 0.3291608899310186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1042] Loss: 0.3291502825489841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1043] Loss: 0.3291616032475979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1044] Loss: 0.32914701651131795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1045] Loss: 0.32913037256952216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1046] Loss: 0.32914442304265135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1047] Loss: 0.3291186860860526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1048] Loss: 0.3291129452039536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1049] Loss: 0.32910065565341345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1050] Loss: 0.3291161949777883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1051] Loss: 0.3291023139737751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1052] Loss: 0.3290940664460598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1053] Loss: 0.329105543107333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1054] Loss: 0.3291232150113649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1055] Loss: 0.32910149783183207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1056] Loss: 0.3290816766076574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1057] Loss: 0.329078511098901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1058] Loss: 0.32907902096069513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1059] Loss: 0.3290639092364908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1060] Loss: 0.32905791520991684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1061] Loss: 0.32907266335877916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1062] Loss: 0.32904961542727124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1063] Loss: 0.32906865290457143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1064] Loss: 0.3290709911894214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1065] Loss: 0.329062686326969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1066] Loss: 0.3290401938672749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1067] Loss: 0.3290656654750366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1068] Loss: 0.3290621089921868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1069] Loss: 0.32908069233347376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1070] Loss: 0.32906870247589964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1071] Loss: 0.3290770955386016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1072] Loss: 0.32906640858858943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1073] Loss: 0.3290974708760644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1074] Loss: 0.3290751532867781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1075] Loss: 0.32906920620313246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1076] Loss: 0.3291299453386222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1077] Loss: 0.3291062897234475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1078] Loss: 0.3290943218189706\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1079] Loss: 0.32914080272520624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1080] Loss: 0.32914796543117764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1081] Loss: 0.32915617686924853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1082] Loss: 0.3291604863523025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1083] Loss: 0.32916723249376806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1084] Loss: 0.3291588434705204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1085] Loss: 0.3292017443154713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1086] Loss: 0.329177349598158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1087] Loss: 0.32917163677788225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1088] Loss: 0.32917205224546153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1089] Loss: 0.32917760573037375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1090] Loss: 0.32920382839263657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1091] Loss: 0.3291879369358204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1092] Loss: 0.32919187469206845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1093] Loss: 0.3291806217349932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1094] Loss: 0.32918773154141107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1095] Loss: 0.3291899830424047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1096] Loss: 0.329188113519037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1097] Loss: 0.32919383121688944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1098] Loss: 0.32920562319998076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1099] Loss: 0.3292051581050192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1100] Loss: 0.3292021672296403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1101] Loss: 0.32922447782508923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1102] Loss: 0.32927864245955657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1103] Loss: 0.32927763748507505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1104] Loss: 0.3293040352602779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1105] Loss: 0.329290815127498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1106] Loss: 0.3293024787035613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1107] Loss: 0.32931650651678385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1108] Loss: 0.32932266502837976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1109] Loss: 0.3293134908580189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1110] Loss: 0.32929918997916463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1111] Loss: 0.32928468725038096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1112] Loss: 0.3292814777833986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1113] Loss: 0.3292728671053452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1114] Loss: 0.3292775111040274\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1115] Loss: 0.3292700793962093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1116] Loss: 0.3292568665501895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1117] Loss: 0.32927282447960043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1118] Loss: 0.3292625903505429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1119] Loss: 0.3292455635287141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1120] Loss: 0.3292640719178965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1121] Loss: 0.329259407183974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1122] Loss: 0.3292727674314421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1123] Loss: 0.3292986716070225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1124] Loss: 0.32928522468954347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1125] Loss: 0.3292901584805301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1126] Loss: 0.3292723259538008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1127] Loss: 0.32926251644050575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1128] Loss: 0.32925291330798384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1129] Loss: 0.3292288272272731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1130] Loss: 0.3292286617003933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1131] Loss: 0.32923709221869646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1132] Loss: 0.329224451110022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1133] Loss: 0.32924670301643866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1134] Loss: 0.32924263615406724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1135] Loss: 0.32924888140032316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1136] Loss: 0.3292450159499994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1137] Loss: 0.3292380871205795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1138] Loss: 0.32923685087590415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1139] Loss: 0.32924984180161615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1140] Loss: 0.32926000841432645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1141] Loss: 0.3292398437144463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1142] Loss: 0.32921800582932226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1143] Loss: 0.32922496460433526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1144] Loss: 0.3292191596924506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1145] Loss: 0.32919989949489586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1146] Loss: 0.32921939062696853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1147] Loss: 0.3292057035556702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1148] Loss: 0.3291820172057297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1149] Loss: 0.32917031361068866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1150] Loss: 0.3291777370524403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1151] Loss: 0.3291813812908874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1152] Loss: 0.32915660397538377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1153] Loss: 0.3291430150321754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1154] Loss: 0.32916747473711927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1155] Loss: 0.32916929782126503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1156] Loss: 0.3291633386702455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1157] Loss: 0.3291625449056091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1158] Loss: 0.32916289018294476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1159] Loss: 0.32915872201133545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1160] Loss: 0.3291638430284715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1161] Loss: 0.32916896375559745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1162] Loss: 0.32918709240095373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1163] Loss: 0.32918625431149096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1164] Loss: 0.32920290821747433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1165] Loss: 0.3292336103007621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1166] Loss: 0.32924496669001746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1167] Loss: 0.329223022610611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1168] Loss: 0.3292286538751279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1169] Loss: 0.32924532848413063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1170] Loss: 0.3292430018697668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1171] Loss: 0.32925617283408054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1172] Loss: 0.3292390783213356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1173] Loss: 0.32923591474633246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1174] Loss: 0.32922367437750505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1175] Loss: 0.3292203857939436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1176] Loss: 0.32922266510954346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1177] Loss: 0.3292292145288498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1178] Loss: 0.3292279668961819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1179] Loss: 0.3292625544803614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1180] Loss: 0.3292649718904594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1181] Loss: 0.3292761540445488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1182] Loss: 0.32925184995644835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1183] Loss: 0.32926616248079027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1184] Loss: 0.3292661436290548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1185] Loss: 0.3292568540382125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1186] Loss: 0.3292911933683036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1187] Loss: 0.3292929623743444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1188] Loss: 0.32931170540322235\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1189] Loss: 0.32929910821433334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1190] Loss: 0.32934464404975944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1191] Loss: 0.3293430992690959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1192] Loss: 0.32933957048495766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1193] Loss: 0.32937799163800074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1194] Loss: 0.32940255702992244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1195] Loss: 0.32939460582699404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1196] Loss: 0.3293927692082293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1197] Loss: 0.3294256817294671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1198] Loss: 0.32946167287794914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1199] Loss: 0.3294618450897899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1200] Loss: 0.32945576968821155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1201] Loss: 0.32943998809967523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1202] Loss: 0.32945196679097105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1203] Loss: 0.3294299891204827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1204] Loss: 0.32944353253961467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1205] Loss: 0.3294499432086699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1206] Loss: 0.3294687012206924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1207] Loss: 0.3294733541680147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1208] Loss: 0.32949413003467126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1209] Loss: 0.32947133517242516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1210] Loss: 0.32950328346585744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1211] Loss: 0.3295359867513969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1212] Loss: 0.3295432297069898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1213] Loss: 0.3295243518821457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1214] Loss: 0.32950392861722794\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1215] Loss: 0.3294900092801533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1216] Loss: 0.3294810484971577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1217] Loss: 0.3294704947543978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1218] Loss: 0.3294873823079881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1219] Loss: 0.32947440657358534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1220] Loss: 0.329501528698424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1221] Loss: 0.3294929241811907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1222] Loss: 0.3294716728256214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1223] Loss: 0.32946524235601815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1224] Loss: 0.32945394641352616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1225] Loss: 0.3294540835906496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1226] Loss: 0.3294438084312145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1227] Loss: 0.32943610094940345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1228] Loss: 0.32943805001583154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1229] Loss: 0.32942435303440604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1230] Loss: 0.32941795545439573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1231] Loss: 0.32943888057769655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1232] Loss: 0.32943932047327656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1233] Loss: 0.3294319011183603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1234] Loss: 0.32943752329163567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1235] Loss: 0.32941743680604985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1236] Loss: 0.32939392070336615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1237] Loss: 0.3293969434601935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1238] Loss: 0.32937270583468914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1239] Loss: 0.3293574609641731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1240] Loss: 0.3293328850684376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1241] Loss: 0.3293504901797749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1242] Loss: 0.3293286491595105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1243] Loss: 0.3293176329087897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1244] Loss: 0.32934464604565594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1245] Loss: 0.3293591343298275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1246] Loss: 0.32936159644881613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1247] Loss: 0.32938447188861825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1248] Loss: 0.3293632892181861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1249] Loss: 0.32934302782815333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1250] Loss: 0.32931632306320513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1251] Loss: 0.3293213758723329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1252] Loss: 0.3293326469254016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1253] Loss: 0.3293131633917665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1254] Loss: 0.3293256532129114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1255] Loss: 0.32940213404240853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1256] Loss: 0.329384426513245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1257] Loss: 0.3293842819374009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1258] Loss: 0.3294193000602757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1259] Loss: 0.3293926434478772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1260] Loss: 0.32940511899053987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1261] Loss: 0.3294009383458853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1262] Loss: 0.3293942754778449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1263] Loss: 0.32941572718159123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1264] Loss: 0.32946605752452657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1265] Loss: 0.32949356291762794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1266] Loss: 0.32953528030960993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1267] Loss: 0.32955419001293695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1268] Loss: 0.32954008216017966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1269] Loss: 0.3295142612960124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1270] Loss: 0.3295187607822638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1271] Loss: 0.32951413282294006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1272] Loss: 0.3295261314901045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1273] Loss: 0.3295262211526448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1274] Loss: 0.329549369802803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1275] Loss: 0.32954350354476214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1276] Loss: 0.329553451974764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1277] Loss: 0.32954773683283295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1278] Loss: 0.3295541889113574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1279] Loss: 0.3295302801886766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1280] Loss: 0.3295303466487733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1281] Loss: 0.329527486482365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1282] Loss: 0.3295195433428444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1283] Loss: 0.3295134298579315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1284] Loss: 0.3295201917798771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1285] Loss: 0.3295678411359976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1286] Loss: 0.3295461396458679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1287] Loss: 0.3295642103125163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1288] Loss: 0.3296119525410912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1289] Loss: 0.32961446017573015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1290] Loss: 0.3296090282225689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1291] Loss: 0.3296051405329072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1292] Loss: 0.32960601657442723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1293] Loss: 0.3296048075978666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1294] Loss: 0.3295927568154875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1295] Loss: 0.32957961513998896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1296] Loss: 0.3295796080789437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1297] Loss: 0.3295592768621057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1298] Loss: 0.329544573357855\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1299] Loss: 0.32953086465320164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1300] Loss: 0.3295594450631058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1301] Loss: 0.32954595838732903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1302] Loss: 0.32955832644866606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1303] Loss: 0.3295573319964035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1304] Loss: 0.32954402455630005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1305] Loss: 0.32953903066276535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1306] Loss: 0.3295310387806987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1307] Loss: 0.3295343615285445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1308] Loss: 0.3295257325207867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1309] Loss: 0.3295136727587149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1310] Loss: 0.3295077498047805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1311] Loss: 0.32950301096167345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1312] Loss: 0.32950983401147643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1313] Loss: 0.32949049962387567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1314] Loss: 0.3294758320269317\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1315] Loss: 0.3294809020772874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1316] Loss: 0.32947309135389075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1317] Loss: 0.3294776203423773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1318] Loss: 0.3294690375479989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1319] Loss: 0.32947526602875554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1320] Loss: 0.3294515049378158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1321] Loss: 0.3294548503428991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1322] Loss: 0.3294465813248215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1323] Loss: 0.3294341825455557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1324] Loss: 0.3294288133284649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1325] Loss: 0.32941661534089317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1326] Loss: 0.3294101235672722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1327] Loss: 0.32939834059758927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1328] Loss: 0.32941047044784716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1329] Loss: 0.3293975254358102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1330] Loss: 0.32938757445515104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1331] Loss: 0.32936906365041757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1332] Loss: 0.32936533236498433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1333] Loss: 0.3293546202318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1334] Loss: 0.32933715513125955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1335] Loss: 0.32933725241213235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1336] Loss: 0.32933273113576317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1337] Loss: 0.3293455593021084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1338] Loss: 0.3293531437750758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1339] Loss: 0.3293465585519116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1340] Loss: 0.32933412888736047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1341] Loss: 0.32936696781331615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1342] Loss: 0.32937180435937935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1343] Loss: 0.3293678586273138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1344] Loss: 0.32936783299836875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1345] Loss: 0.3293641932347367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1346] Loss: 0.32935524438601216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1347] Loss: 0.32933314558293725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1348] Loss: 0.32932203074067123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1349] Loss: 0.3292973534200843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1350] Loss: 0.3292906730013827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1351] Loss: 0.329277984112819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1352] Loss: 0.3292559547711388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1353] Loss: 0.32927274540582036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1354] Loss: 0.3292607055919827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1355] Loss: 0.3292737348824611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1356] Loss: 0.32928494125471564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1357] Loss: 0.3293197561819364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1358] Loss: 0.32932029052807155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1359] Loss: 0.3293117260919193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1360] Loss: 0.3293099636540441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1361] Loss: 0.32932851156010734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1362] Loss: 0.32933407038952023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1363] Loss: 0.3293256456689011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1364] Loss: 0.32933599119940316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1365] Loss: 0.3293497192837358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1366] Loss: 0.3293651732012434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1367] Loss: 0.32933558719508566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1368] Loss: 0.32934130506066434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1369] Loss: 0.32932555625593274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1370] Loss: 0.32935779931876996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1371] Loss: 0.32936280537273527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1372] Loss: 0.32935433394651265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1373] Loss: 0.32937094860592453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1374] Loss: 0.32935878704452526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1375] Loss: 0.32935131922967814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1376] Loss: 0.32934253546512965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1377] Loss: 0.32933827840318153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1378] Loss: 0.32933828388069997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1379] Loss: 0.3293417531043984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1380] Loss: 0.32932679197299564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1381] Loss: 0.3293174885354517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1382] Loss: 0.3293183950269251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1383] Loss: 0.32930249822362084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1384] Loss: 0.32928762582038945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1385] Loss: 0.3292966185504174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1386] Loss: 0.3292787788452111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1387] Loss: 0.32930275050862867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1388] Loss: 0.32931711871136904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1389] Loss: 0.32930844465544057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1390] Loss: 0.32931327317921844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1391] Loss: 0.3293143418908768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1392] Loss: 0.32930101486071595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1393] Loss: 0.3293118604189345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1394] Loss: 0.32933251074982345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1395] Loss: 0.3293219965428276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1396] Loss: 0.32932394448057994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1397] Loss: 0.3293244437680485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1398] Loss: 0.32932470073082143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1399] Loss: 0.3293267336993718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1400] Loss: 0.32931450752164737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1401] Loss: 0.3293650394180842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1402] Loss: 0.32933968490866194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1403] Loss: 0.32936554544516045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1404] Loss: 0.3293881428747316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1405] Loss: 0.32939625006953355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1406] Loss: 0.3294488261134843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1407] Loss: 0.32943401146921936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1408] Loss: 0.3294115912411535\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1409] Loss: 0.32942010441410535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1410] Loss: 0.329397764619681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1411] Loss: 0.32937775563345395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1412] Loss: 0.32941436013471637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1413] Loss: 0.3294266154340335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1414] Loss: 0.3294480253485097\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8909\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1415] Loss: 0.32943097495183166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1416] Loss: 0.32941318998826363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1417] Loss: 0.3294009189522995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1418] Loss: 0.32940537792116636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1419] Loss: 0.32940516746149656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1420] Loss: 0.3293833754913127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1421] Loss: 0.32936408371583786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1422] Loss: 0.32935228865162625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1423] Loss: 0.3293399391347774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1424] Loss: 0.32934599213653887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1425] Loss: 0.32935736387016024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1426] Loss: 0.32933548813146346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1427] Loss: 0.32934266663631007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1428] Loss: 0.32934169879744757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1429] Loss: 0.3293448586989632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1430] Loss: 0.3293251345045328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1431] Loss: 0.3293273162153006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1432] Loss: 0.3293113627674437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1433] Loss: 0.32930191525409364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1434] Loss: 0.32928969199467956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1435] Loss: 0.3292806711831992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1436] Loss: 0.32931101397072404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1437] Loss: 0.32931198758669283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1438] Loss: 0.32932372540553695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1439] Loss: 0.3293293469203458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1440] Loss: 0.3293109312833789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1441] Loss: 0.3293182303493988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1442] Loss: 0.32930809801699074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1443] Loss: 0.3292878143224404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1444] Loss: 0.32928130759265106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1445] Loss: 0.32925454386434727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1446] Loss: 0.3292633768641964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1447] Loss: 0.32931319346880755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1448] Loss: 0.3293064088116492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1449] Loss: 0.3293068707624642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1450] Loss: 0.3292971883491645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1451] Loss: 0.32930919455174323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1452] Loss: 0.32928890622607143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1453] Loss: 0.32927674538328905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1454] Loss: 0.3292538982708504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1455] Loss: 0.329237991560423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1456] Loss: 0.3292442972807659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1457] Loss: 0.32922953038916947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1458] Loss: 0.32924014890422376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1459] Loss: 0.32922654756083936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1460] Loss: 0.32920818062129387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1461] Loss: 0.32919817733093165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1462] Loss: 0.3291787736922194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1463] Loss: 0.329174473919767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1464] Loss: 0.3291684823321241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1465] Loss: 0.3291718506772479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1466] Loss: 0.32915582173930047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1467] Loss: 0.32915791496317615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1468] Loss: 0.3291457146786359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1469] Loss: 0.32915179372940406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1470] Loss: 0.3291616006171685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1471] Loss: 0.3291566476867671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1472] Loss: 0.32917262613351156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1473] Loss: 0.3291782771962729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1474] Loss: 0.329185410903527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1475] Loss: 0.3291790462994467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1476] Loss: 0.32916830771666117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1477] Loss: 0.3291571332312623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1478] Loss: 0.3291348476276614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1479] Loss: 0.32910803176764214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1480] Loss: 0.32909767527264483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1481] Loss: 0.3290862222626409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1482] Loss: 0.32908585124810763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1483] Loss: 0.32916189480831126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1484] Loss: 0.32917743929920096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1485] Loss: 0.3292251933656835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1486] Loss: 0.32920115134444006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1487] Loss: 0.32920315559213026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1488] Loss: 0.3292173786466619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1489] Loss: 0.3292233862104963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1490] Loss: 0.32920597585030525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1491] Loss: 0.3292232267400679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1492] Loss: 0.32922745034517514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1493] Loss: 0.3292158159285279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1494] Loss: 0.32919953302834737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1495] Loss: 0.3291853764040495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1496] Loss: 0.3291627329258903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1497] Loss: 0.32914309302909706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1498] Loss: 0.3291392374265842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1499] Loss: 0.3291197296609456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1500] Loss: 0.32910714084546655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1501] Loss: 0.3291063622127941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1502] Loss: 0.3291051957516126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1503] Loss: 0.3291194172983277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1504] Loss: 0.3291132163091971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1505] Loss: 0.3291094279598531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1506] Loss: 0.3290848541974887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1507] Loss: 0.32912469675440437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1508] Loss: 0.3291087636651919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1509] Loss: 0.329099910184657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1510] Loss: 0.3290955515307273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1511] Loss: 0.3291017903630651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1512] Loss: 0.32908410650648723\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1513] Loss: 0.32909087660237096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1514] Loss: 0.32909577221429576\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1515] Loss: 0.3290848165721129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1516] Loss: 0.32906550480734376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1517] Loss: 0.32907551344953945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1518] Loss: 0.329090665126669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1519] Loss: 0.32910112500643685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1520] Loss: 0.32910265654757404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1521] Loss: 0.32910129638806984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1522] Loss: 0.32909357627830954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1523] Loss: 0.3290757743345702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 24, Batch 1524] Loss: 0.3290726037560058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 0] Loss: 0.32910362241582275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1] Loss: 0.32908266002822156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 2] Loss: 0.3290748194966016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 3] Loss: 0.3290502782552408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 4] Loss: 0.32905967792620683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 5] Loss: 0.32905164525777547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 6] Loss: 0.32905280563470585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 7] Loss: 0.32906285404932933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 8] Loss: 0.3290615747881572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 9] Loss: 0.32907733627750774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 10] Loss: 0.3290865598489682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 11] Loss: 0.32909858518188695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 12] Loss: 0.32908361211653375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 13] Loss: 0.3290706900609167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 14] Loss: 0.3291150339924315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 15] Loss: 0.32909597009859465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 16] Loss: 0.32911022343828555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 17] Loss: 0.3290951353944457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 18] Loss: 0.3291128821200776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 19] Loss: 0.32910022320720295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 20] Loss: 0.32910681706688677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 21] Loss: 0.3291173545408931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 22] Loss: 0.32912858372138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 23] Loss: 0.32912549945175357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 24] Loss: 0.32913838867139855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 25] Loss: 0.32919017735884876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 26] Loss: 0.32918777302613145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 27] Loss: 0.32919282516581216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 28] Loss: 0.3291837125828787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 29] Loss: 0.3291844296936995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 30] Loss: 0.32919880476770064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 31] Loss: 0.32921580180899196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 32] Loss: 0.32920707973535823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 33] Loss: 0.3292074266954099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 34] Loss: 0.32927248667401154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 35] Loss: 0.3292658079837242\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 36] Loss: 0.32925124434315434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 37] Loss: 0.3292330242146277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 38] Loss: 0.3292959429479979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 39] Loss: 0.3293042432705917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 40] Loss: 0.32930175659832206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 41] Loss: 0.32930987359434843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 42] Loss: 0.3292859039319638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 43] Loss: 0.32926532739654946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 44] Loss: 0.3292536887773893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 45] Loss: 0.3292349599352825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 46] Loss: 0.3292288341338024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 47] Loss: 0.32922142030124074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 48] Loss: 0.32922328709723564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 49] Loss: 0.3292079551844869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 50] Loss: 0.32918970013040966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 51] Loss: 0.3291931105037816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 52] Loss: 0.32918517152601484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 53] Loss: 0.3292065006823117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 54] Loss: 0.329229768306358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 55] Loss: 0.3292166179915893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 56] Loss: 0.3292166384697858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 57] Loss: 0.3292279134116457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 58] Loss: 0.3292244489576195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 59] Loss: 0.32920713544831154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 60] Loss: 0.329198787692151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 61] Loss: 0.3292331062387127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 62] Loss: 0.3292209613442022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 63] Loss: 0.3292168577186737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 64] Loss: 0.3292162383791296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 65] Loss: 0.3292104361826154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 66] Loss: 0.3292362384786676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 67] Loss: 0.32922188264942714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 68] Loss: 0.3292344173847135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 69] Loss: 0.3292333499383601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 70] Loss: 0.329213161437467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 71] Loss: 0.32919802750184246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 72] Loss: 0.32922548369270127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 73] Loss: 0.3292258010942569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 74] Loss: 0.32923679458142785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 75] Loss: 0.32923154060807763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 76] Loss: 0.32920783195949355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 77] Loss: 0.32918772615242575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 78] Loss: 0.3291692969944945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 79] Loss: 0.3291558841163866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 80] Loss: 0.32913089812721835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 81] Loss: 0.32912971564522875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 82] Loss: 0.32911646039470355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 83] Loss: 0.3290960061044806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 84] Loss: 0.3290775841813309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 85] Loss: 0.3290983793597859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 86] Loss: 0.32908943172717103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 87] Loss: 0.3290765031557445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 88] Loss: 0.32905412182418836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 89] Loss: 0.32907644181371715\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 90] Loss: 0.329122254988595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 91] Loss: 0.3291063195596912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 92] Loss: 0.32910708027753743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 93] Loss: 0.32910799492075576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 94] Loss: 0.3290937441299599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 95] Loss: 0.32915634658294624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 96] Loss: 0.3291562658741855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 97] Loss: 0.3291609748249197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 98] Loss: 0.32917032406333413\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 99] Loss: 0.3291438283057008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 100] Loss: 0.3291884994158068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 101] Loss: 0.32920003087299465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 102] Loss: 0.32919954680193486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 103] Loss: 0.32919750282191107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 104] Loss: 0.3291941469085058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 105] Loss: 0.32919681611955703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 106] Loss: 0.3291770996446919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 107] Loss: 0.3291671767362285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 108] Loss: 0.3291419135318899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 109] Loss: 0.32915291066332186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 110] Loss: 0.3291437551647433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 111] Loss: 0.32912937382466406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 112] Loss: 0.32911894705398204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 113] Loss: 0.3291181705629124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 114] Loss: 0.3291179726110117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 115] Loss: 0.32915158565276653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 116] Loss: 0.3291438381024237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 117] Loss: 0.3291229385053457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 118] Loss: 0.3291306529364151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 119] Loss: 0.3291446942397625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 120] Loss: 0.3291595085355066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 121] Loss: 0.3291369236559685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 122] Loss: 0.3291196211748173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 123] Loss: 0.3291141926047715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 124] Loss: 0.32911662198500186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 125] Loss: 0.3291150940968481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 126] Loss: 0.3291178736923215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 127] Loss: 0.3291048472087214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 128] Loss: 0.32909923891295056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 129] Loss: 0.3291029257823578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 130] Loss: 0.3290978051543038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 131] Loss: 0.3291348242885613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 132] Loss: 0.329154215195622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 133] Loss: 0.3291668482757256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 134] Loss: 0.3291623785746318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 135] Loss: 0.32918146253660235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 136] Loss: 0.32917016153953654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 137] Loss: 0.32915337239853976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 138] Loss: 0.3291399618613309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 139] Loss: 0.3291308107585385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 140] Loss: 0.32912239748152394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 141] Loss: 0.32910406586220886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 142] Loss: 0.3290969397464928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 143] Loss: 0.32908388791537796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 144] Loss: 0.32910349211822926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 145] Loss: 0.32909645585542674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 146] Loss: 0.32907608497993585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 147] Loss: 0.3291017051767196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 148] Loss: 0.32908738045735136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 149] Loss: 0.32908388116917586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 150] Loss: 0.329089179503724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 151] Loss: 0.32908300326889117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 152] Loss: 0.3290607025846839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 153] Loss: 0.32907046160858744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 154] Loss: 0.329054818574535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 155] Loss: 0.32903841349910273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 156] Loss: 0.32905908542786183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 157] Loss: 0.3290781788451092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 158] Loss: 0.32907541322494965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 159] Loss: 0.3290702128587407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 160] Loss: 0.32910308119716947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 161] Loss: 0.3291020311582175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 162] Loss: 0.3291257825614267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 163] Loss: 0.3291194775669845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 164] Loss: 0.3291159773664267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 165] Loss: 0.3291099907007947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 166] Loss: 0.3290986262014129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 167] Loss: 0.32910935119508894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 168] Loss: 0.3291014006422771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 169] Loss: 0.3291211869916063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 170] Loss: 0.32914528821202893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 171] Loss: 0.32912558279537685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 172] Loss: 0.3291109768200189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 173] Loss: 0.32910932148861083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 174] Loss: 0.32911935310188045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 175] Loss: 0.32913177062597426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 176] Loss: 0.3291398489093316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 177] Loss: 0.32913152119156297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 178] Loss: 0.32914919894704764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 179] Loss: 0.3291399164681996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 180] Loss: 0.32912642888630805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 181] Loss: 0.329110067107379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 182] Loss: 0.32909374005636977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 183] Loss: 0.32910324318757034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 184] Loss: 0.3290899187497991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 185] Loss: 0.32910537589849376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 186] Loss: 0.3291200951587079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 187] Loss: 0.32910309244645986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 188] Loss: 0.3290995027757671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 189] Loss: 0.32908472181215565\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 190] Loss: 0.32907962537863195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 191] Loss: 0.3290714381182829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 192] Loss: 0.329071553740222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 193] Loss: 0.3290588075824179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 194] Loss: 0.3290509987605163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 195] Loss: 0.3290396033861054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 196] Loss: 0.3290363422217236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 197] Loss: 0.32903619696314673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 198] Loss: 0.32903165856806915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 199] Loss: 0.3290541866029145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 200] Loss: 0.3290412449634571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 201] Loss: 0.3290431456161266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 202] Loss: 0.3290309608084503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 203] Loss: 0.32902851034864855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 204] Loss: 0.32904436896535266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 205] Loss: 0.32904960517310144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 206] Loss: 0.32905176426298016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 207] Loss: 0.3290553889239253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 208] Loss: 0.32903840202695683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 209] Loss: 0.32902638121814515\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 210] Loss: 0.3290179535213372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 211] Loss: 0.32903768727155264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 212] Loss: 0.32901213067247526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 213] Loss: 0.3290179155039706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 214] Loss: 0.32899280827886057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 215] Loss: 0.32898586356975024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 216] Loss: 0.32903269704179144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 217] Loss: 0.32906443823821746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 218] Loss: 0.3290666590913581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 219] Loss: 0.3290547147126953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 220] Loss: 0.32905758694993037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 221] Loss: 0.3290573270791032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 222] Loss: 0.32903843880805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 223] Loss: 0.32903774097490734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 224] Loss: 0.3290451318350587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 225] Loss: 0.3290427187588424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 226] Loss: 0.3290401507980267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 227] Loss: 0.3290413058466833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 228] Loss: 0.32902011125061753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 229] Loss: 0.3289949275475077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 230] Loss: 0.3289860347166629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 231] Loss: 0.32898930954045147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 232] Loss: 0.3289975767208503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 233] Loss: 0.3290287096314563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 234] Loss: 0.3290218680249129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 235] Loss: 0.32900676446430244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 236] Loss: 0.32901693701289825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 237] Loss: 0.32907575415111523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 238] Loss: 0.3291022068221553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 239] Loss: 0.32909596080261744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 240] Loss: 0.32908900022928295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 241] Loss: 0.3291077255781177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 242] Loss: 0.3291260583434119\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 243] Loss: 0.3291302885027016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 244] Loss: 0.32910865456951643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 245] Loss: 0.3290900440826613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 246] Loss: 0.3290800747055825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 247] Loss: 0.32907153741142836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 248] Loss: 0.3290561205403798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 249] Loss: 0.3290642128801592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 250] Loss: 0.3290699218839804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 251] Loss: 0.329059399942673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 252] Loss: 0.32905168472174584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 253] Loss: 0.3290461100673319\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 254] Loss: 0.3290709552782209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 255] Loss: 0.3290690088229214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 256] Loss: 0.3290614137622193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 257] Loss: 0.3290570445458849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 258] Loss: 0.3290497494864011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 259] Loss: 0.3290840044502422\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 260] Loss: 0.32909197575951876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 261] Loss: 0.3290981634891488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 262] Loss: 0.3290846965012752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 263] Loss: 0.3290727809748407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 264] Loss: 0.329096813540736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 265] Loss: 0.32909950644880737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 266] Loss: 0.32909050119112226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 267] Loss: 0.32911018701301775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 268] Loss: 0.32914347154943924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 269] Loss: 0.3291449422957273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 270] Loss: 0.32914746637889863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 271] Loss: 0.3291281901847924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 272] Loss: 0.3291187604802498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 273] Loss: 0.3291096188223838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 274] Loss: 0.3291265879148169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 275] Loss: 0.3291274393296329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 276] Loss: 0.3291406845648707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 277] Loss: 0.32915990121560773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 278] Loss: 0.3291598917364429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 279] Loss: 0.3291487571871695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 280] Loss: 0.3291370818750264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 281] Loss: 0.32912863653526564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 282] Loss: 0.3291117998093471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 283] Loss: 0.32913723883191986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 284] Loss: 0.3291341889369578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 285] Loss: 0.3291582488157112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 286] Loss: 0.3291651745842708\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 287] Loss: 0.3291662743561557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 288] Loss: 0.32918024513165695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 289] Loss: 0.32917733899992296\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 290] Loss: 0.3291654635006368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 291] Loss: 0.32916611186051936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 292] Loss: 0.32915002388576764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 293] Loss: 0.32913541462798124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 294] Loss: 0.3291325739150011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 295] Loss: 0.32912012431541726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 296] Loss: 0.3291287327820906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 297] Loss: 0.32911479991004283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 298] Loss: 0.3291294187005715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 299] Loss: 0.3291405974399093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 300] Loss: 0.3291460438191698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 301] Loss: 0.32913891814320445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 302] Loss: 0.32912642935038194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 303] Loss: 0.32910707635969544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 304] Loss: 0.3291515765195268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 305] Loss: 0.32913791868537845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 306] Loss: 0.329148629547194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 307] Loss: 0.32912351947249163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 308] Loss: 0.32911994612281215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 309] Loss: 0.32910754117276886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 310] Loss: 0.3291240089089361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 311] Loss: 0.32911976007989324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 312] Loss: 0.3291553590157679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 313] Loss: 0.32918840379425973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 314] Loss: 0.3291821788375409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 315] Loss: 0.3292107748980475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 316] Loss: 0.32920871263768126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 317] Loss: 0.3291961194560993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 318] Loss: 0.3291837848773073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 319] Loss: 0.3291821093702682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 320] Loss: 0.32919863283040707\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 321] Loss: 0.3292061309385922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 322] Loss: 0.3291955583954101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 323] Loss: 0.3292085984327205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 324] Loss: 0.3292192070714372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 325] Loss: 0.32923852529387265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 326] Loss: 0.32925473101102526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 327] Loss: 0.32924276511024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 328] Loss: 0.329252967510813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 329] Loss: 0.3292375089996942\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 330] Loss: 0.3292327905111305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 331] Loss: 0.3292237462959638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 332] Loss: 0.3292888344327075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 333] Loss: 0.32926741499401246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 334] Loss: 0.3292548269605784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 335] Loss: 0.32924475013105214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 336] Loss: 0.3292316969155977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 337] Loss: 0.3292659649990248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 338] Loss: 0.3292680712534277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 339] Loss: 0.3292439969041782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 340] Loss: 0.32924322348629925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 341] Loss: 0.3292340566176113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 342] Loss: 0.32923276863766315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 343] Loss: 0.32923052755679805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 344] Loss: 0.3292178443089415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 345] Loss: 0.3292388625645807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 346] Loss: 0.32923168923578944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 347] Loss: 0.32926906506255127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 348] Loss: 0.32926826912700013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 349] Loss: 0.32928526499183197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 350] Loss: 0.32928083125922225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 351] Loss: 0.3292702045199316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 352] Loss: 0.32925954266248664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 353] Loss: 0.32924087046379225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 354] Loss: 0.3292263955847846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 355] Loss: 0.32921717611161583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 356] Loss: 0.32920076104452667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 357] Loss: 0.3291818246610482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 358] Loss: 0.329202689190546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 359] Loss: 0.32919648328174983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 360] Loss: 0.329201498950335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 361] Loss: 0.329211396777724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 362] Loss: 0.3292336411672478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 363] Loss: 0.3292326864331064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 364] Loss: 0.32921923474553694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 365] Loss: 0.3292075164563295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 366] Loss: 0.32919622832566986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 367] Loss: 0.329190547974898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 368] Loss: 0.32919610502487195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 369] Loss: 0.32920063302456704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 370] Loss: 0.32920363424726745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 371] Loss: 0.3291853171100308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 372] Loss: 0.32917128238311305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 373] Loss: 0.32917384211628453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 374] Loss: 0.3291718167514843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 375] Loss: 0.32918153489855656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 376] Loss: 0.32917965012284106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 377] Loss: 0.32920066352512317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 378] Loss: 0.3292444341630738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 379] Loss: 0.32922036953378847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 380] Loss: 0.3292913803034171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 381] Loss: 0.3293097101864884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 382] Loss: 0.3293013160912584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 383] Loss: 0.3293031703220995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 384] Loss: 0.32927726137798713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 385] Loss: 0.32934456818204283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 386] Loss: 0.32933815088143953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 387] Loss: 0.3293379952504899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 388] Loss: 0.3293205813964208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 389] Loss: 0.3293371266833052\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8939\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 390] Loss: 0.329324048835813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 391] Loss: 0.3293049601905269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 392] Loss: 0.32931071940634743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 393] Loss: 0.3293066522246754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 394] Loss: 0.3293083986833735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 395] Loss: 0.3292921068936098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 396] Loss: 0.32928573685516116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 397] Loss: 0.32930733676057694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 398] Loss: 0.3293062594298834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 399] Loss: 0.3293035383025144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 400] Loss: 0.3292924876466663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 401] Loss: 0.32927429416034315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 402] Loss: 0.3292647513134828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 403] Loss: 0.3292603137111632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 404] Loss: 0.32928794782812953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 405] Loss: 0.3292978869202734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 406] Loss: 0.3292868347121509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 407] Loss: 0.32929315726868663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 408] Loss: 0.3292790894931618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 409] Loss: 0.32928123243976315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 410] Loss: 0.3292785784493606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 411] Loss: 0.3292682215395117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 412] Loss: 0.3292666855587533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 413] Loss: 0.32925697828052053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 414] Loss: 0.3292495866516249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 415] Loss: 0.3292722430808208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 416] Loss: 0.32929139585490563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 417] Loss: 0.32926950754437223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 418] Loss: 0.32927507785845245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 419] Loss: 0.3292870597564878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 420] Loss: 0.32926437651626744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 421] Loss: 0.3292665893332379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 422] Loss: 0.32927587352651544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 423] Loss: 0.3292552903086916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 424] Loss: 0.32924873495549595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 425] Loss: 0.32925840460789113\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 426] Loss: 0.3293198470859478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 427] Loss: 0.32931145954304436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 428] Loss: 0.3293017602626936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 429] Loss: 0.3292772852584864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 430] Loss: 0.32928064295410064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 431] Loss: 0.3292641315985055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 432] Loss: 0.3292594748279544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 433] Loss: 0.32925598212351775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 434] Loss: 0.3292698915875024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 435] Loss: 0.3292855905751227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 436] Loss: 0.3292796272166551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 437] Loss: 0.3292843282700438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 438] Loss: 0.3292917194173036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 439] Loss: 0.32927894974533195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 440] Loss: 0.3292672205657177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 441] Loss: 0.32925402650363744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 442] Loss: 0.3292457728114335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 443] Loss: 0.3292578919035642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 444] Loss: 0.329236329477448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 445] Loss: 0.3292668305866867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 446] Loss: 0.3292596184070163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 447] Loss: 0.3292503587735016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 448] Loss: 0.3292583866054734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 449] Loss: 0.32928043061535034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 450] Loss: 0.32928216628014995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 451] Loss: 0.32930759028138173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 452] Loss: 0.3293032627582298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 453] Loss: 0.32930254058891467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 454] Loss: 0.3293078068841742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 455] Loss: 0.32930647134308266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 456] Loss: 0.32929557019817085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 457] Loss: 0.32929014348695546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 458] Loss: 0.3292843244211992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 459] Loss: 0.3293180780864395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 460] Loss: 0.32934129323340006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 461] Loss: 0.3293309546529924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 462] Loss: 0.32933761182004806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 463] Loss: 0.32933898895683855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 464] Loss: 0.32933333840854506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 465] Loss: 0.32939284905187527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 466] Loss: 0.32937288520266306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 467] Loss: 0.3293651214830635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 468] Loss: 0.32937001678748623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 469] Loss: 0.3293674440037023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 470] Loss: 0.32938716101303667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 471] Loss: 0.32938817484184196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 472] Loss: 0.3293833914586197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 473] Loss: 0.329368721837658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 474] Loss: 0.3293538961845339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 475] Loss: 0.32934210952938475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 476] Loss: 0.3293588880899239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 477] Loss: 0.3293668518547547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 478] Loss: 0.3293661639251414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 479] Loss: 0.32935683912532693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 480] Loss: 0.32935352419140906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 481] Loss: 0.32933471702263944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 482] Loss: 0.32933252505135907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 483] Loss: 0.3293261418144824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 484] Loss: 0.32932354951607923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 485] Loss: 0.32931757714303683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 486] Loss: 0.32933544575634616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 487] Loss: 0.32933384632653256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 488] Loss: 0.3293287318788077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 489] Loss: 0.3293462150458552\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 490] Loss: 0.32933851520628155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 491] Loss: 0.329319548639407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 492] Loss: 0.3293075360737933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 493] Loss: 0.32932359911672854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 494] Loss: 0.32933522582195196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 495] Loss: 0.3293598659588282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 496] Loss: 0.32936123562300995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 497] Loss: 0.3293581550005999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 498] Loss: 0.3293408685010147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 499] Loss: 0.32933465025182496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 500] Loss: 0.3293322628785827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 501] Loss: 0.32935756363310326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 502] Loss: 0.32934081550302985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 503] Loss: 0.3293638258546258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 504] Loss: 0.32935401698879646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 505] Loss: 0.329335318713719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 506] Loss: 0.32932541939171006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 507] Loss: 0.3293060160481972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 508] Loss: 0.32931536738210776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 509] Loss: 0.3293400054046948\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 510] Loss: 0.32932625247037994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 511] Loss: 0.32932567681467756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 512] Loss: 0.3293033394657646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 513] Loss: 0.3293033607807316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 514] Loss: 0.3292860617197282\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 515] Loss: 0.3292883496691956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 516] Loss: 0.32930512354949976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 517] Loss: 0.32930292285610613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 518] Loss: 0.3293554212736896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 519] Loss: 0.3293616437920579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 520] Loss: 0.32934456639796245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 521] Loss: 0.3293360902908416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 522] Loss: 0.3293237056478737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 523] Loss: 0.3293634667241191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 524] Loss: 0.32935255454270673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 525] Loss: 0.32935780793900604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 526] Loss: 0.32934900615525264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 527] Loss: 0.32937005786258117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 528] Loss: 0.3293765183382165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 529] Loss: 0.32935809751343875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 530] Loss: 0.32934110028461083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 531] Loss: 0.3293544176781223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 532] Loss: 0.3293346004616147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 533] Loss: 0.3293327353256368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 534] Loss: 0.32932822122144784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 535] Loss: 0.3293332684713516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 536] Loss: 0.3293196359516811\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 537] Loss: 0.3293351923886398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 538] Loss: 0.3293432773172466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 539] Loss: 0.3293376642260703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 540] Loss: 0.3293159545145606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 541] Loss: 0.3293196038959635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 542] Loss: 0.3293181869374388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 543] Loss: 0.32930834852426677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 544] Loss: 0.3293014314130743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 545] Loss: 0.3293187832558328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 546] Loss: 0.32930738658693637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 547] Loss: 0.32930763616801895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 548] Loss: 0.3293048775557905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 549] Loss: 0.32933310054523673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 550] Loss: 0.329338880231022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 551] Loss: 0.32931839204225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 552] Loss: 0.3293064124279486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 553] Loss: 0.3292957823103888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 554] Loss: 0.329288048977302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 555] Loss: 0.32931377728121897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 556] Loss: 0.329302080941421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 557] Loss: 0.3292935875038355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 558] Loss: 0.329316914845088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 559] Loss: 0.32932051981098415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 560] Loss: 0.32932757831162096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 561] Loss: 0.32932029065207397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 562] Loss: 0.3293108654742226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 563] Loss: 0.3293016536014476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 564] Loss: 0.3292830277539095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 565] Loss: 0.32926908584758763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 566] Loss: 0.32925605956939524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 567] Loss: 0.3292640137426368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 568] Loss: 0.32925362895281673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 569] Loss: 0.32928656921995414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 570] Loss: 0.3292672204896827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 571] Loss: 0.32925809894814617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 572] Loss: 0.329248959201503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 573] Loss: 0.32924884032256896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 574] Loss: 0.32926405142317083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 575] Loss: 0.3292943721352899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 576] Loss: 0.32929694083491173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 577] Loss: 0.32929289673531004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 578] Loss: 0.3292764853942844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 579] Loss: 0.3293204514982796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 580] Loss: 0.32932701450397245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 581] Loss: 0.32934865510837164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 582] Loss: 0.329329722907858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 583] Loss: 0.3293177580895402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 584] Loss: 0.3293036913921332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 585] Loss: 0.3292961278115989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 586] Loss: 0.3292753605327379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 587] Loss: 0.3292558375295532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 588] Loss: 0.3292487855004026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 589] Loss: 0.32926351898537876\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 590] Loss: 0.32924748593817993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 591] Loss: 0.3292277786219629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 592] Loss: 0.3292013187588097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 593] Loss: 0.32918385873554123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 594] Loss: 0.32920251746681056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 595] Loss: 0.3292054515339234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 596] Loss: 0.3292112605318574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 597] Loss: 0.3292239221934756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 598] Loss: 0.3292438524841644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 599] Loss: 0.3292398682972164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 600] Loss: 0.32927378142036157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 601] Loss: 0.3292546108100381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 602] Loss: 0.3292499870942731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 603] Loss: 0.3292315310402034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 604] Loss: 0.3292451916931669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 605] Loss: 0.3292613583605447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 606] Loss: 0.32924154712054726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 607] Loss: 0.3292432855310365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 608] Loss: 0.3292377131899404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 609] Loss: 0.3292210675257813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 610] Loss: 0.32923882902324647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 611] Loss: 0.3292304800899785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 612] Loss: 0.3292189931380261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 613] Loss: 0.32922346165650873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 614] Loss: 0.32921754067931003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 615] Loss: 0.3292248441667904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 616] Loss: 0.32924946444591136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 617] Loss: 0.32923779592567715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 618] Loss: 0.32923274806677755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 619] Loss: 0.3292467446773454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 620] Loss: 0.32926743798270103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 621] Loss: 0.32928063954493675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 622] Loss: 0.329271077312084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 623] Loss: 0.32928105259064944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 624] Loss: 0.32927380744541196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 625] Loss: 0.32925532286953246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 626] Loss: 0.329256215354952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 627] Loss: 0.32923865252832585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 628] Loss: 0.3292285212558677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 629] Loss: 0.32922611286159387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 630] Loss: 0.3292273647199765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 631] Loss: 0.32922496769712456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 632] Loss: 0.32921166000079577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 633] Loss: 0.32922903891337774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 634] Loss: 0.32921620460672957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 635] Loss: 0.32921729748004697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 636] Loss: 0.3292134910548816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 637] Loss: 0.3292458673314381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 638] Loss: 0.3292250371517674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 639] Loss: 0.32922461830774535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 640] Loss: 0.32921498540646643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 641] Loss: 0.32923232543842107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 642] Loss: 0.3292236383048289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 643] Loss: 0.3292536737033431\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 644] Loss: 0.32926682222590364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 645] Loss: 0.32931484619919843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 646] Loss: 0.32929686109839595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 647] Loss: 0.3292813392367801\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 648] Loss: 0.3292767626895886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 649] Loss: 0.32926456754262295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 650] Loss: 0.32926359130139204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 651] Loss: 0.32924564897392145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 652] Loss: 0.32922157801645496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 653] Loss: 0.3292529234311232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 654] Loss: 0.3292324371135115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 655] Loss: 0.32923537951854415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 656] Loss: 0.32922458125568016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 657] Loss: 0.32926108065044607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 658] Loss: 0.32926101960922605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 659] Loss: 0.32929781539308844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 660] Loss: 0.3292882404109435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 661] Loss: 0.3292831586304586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 662] Loss: 0.32926923893190824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 663] Loss: 0.32927667296009433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 664] Loss: 0.32935818416016643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 665] Loss: 0.32935324338272787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 666] Loss: 0.329347640408146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 667] Loss: 0.32933641531685354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 668] Loss: 0.32932357289912156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 669] Loss: 0.3293182279748485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 670] Loss: 0.32931820815225643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 671] Loss: 0.3293153502139919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 672] Loss: 0.32933360071927464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 673] Loss: 0.3293498666855335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 674] Loss: 0.329346144558025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 675] Loss: 0.32932873153864106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 676] Loss: 0.3293190256074936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 677] Loss: 0.3293015362324435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 678] Loss: 0.3292973509304637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 679] Loss: 0.32928168286508813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 680] Loss: 0.3293045809247686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 681] Loss: 0.32930137345156957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 682] Loss: 0.32929693008917615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 683] Loss: 0.32929027857613763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 684] Loss: 0.32928330422770435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 685] Loss: 0.32926814366651375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 686] Loss: 0.32928053348889624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 687] Loss: 0.32925839819217556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 688] Loss: 0.3292596095361007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 689] Loss: 0.32925542250969\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 690] Loss: 0.32925817860308076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 691] Loss: 0.3292440067540831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 692] Loss: 0.3292374689110972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 693] Loss: 0.3292177463555321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 694] Loss: 0.329207022549585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 695] Loss: 0.3292084986381438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 696] Loss: 0.32924175376194664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 697] Loss: 0.32924924197598754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 698] Loss: 0.3292639650509391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 699] Loss: 0.32927734084401605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 700] Loss: 0.3292613841165992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 701] Loss: 0.3292728080081067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 702] Loss: 0.3292539744276295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 703] Loss: 0.32922652875641106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 704] Loss: 0.3292325647441077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 705] Loss: 0.32924310856060224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 706] Loss: 0.3292347075096952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 707] Loss: 0.3292186665779292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 708] Loss: 0.32925224458260455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 709] Loss: 0.3292728642113921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 710] Loss: 0.32929032945082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 711] Loss: 0.32930283031945307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 712] Loss: 0.3292804550072883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 713] Loss: 0.32926960693856777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 714] Loss: 0.32926316846922754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 715] Loss: 0.329270428768844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 716] Loss: 0.3292706212572331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 717] Loss: 0.3292563467454615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 718] Loss: 0.32923016397337196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 719] Loss: 0.3292324144838947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 720] Loss: 0.329219891455698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 721] Loss: 0.32920873658506866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 722] Loss: 0.32921243907599873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 723] Loss: 0.3291890149245463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 724] Loss: 0.3291733909185335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 725] Loss: 0.32917242619274706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 726] Loss: 0.329170971704848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 727] Loss: 0.3291530511719199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 728] Loss: 0.3291562587621489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 729] Loss: 0.32914604832039485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 730] Loss: 0.329138374117124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 731] Loss: 0.3291358765540995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 732] Loss: 0.3291319276613204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 733] Loss: 0.32913127873090514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 734] Loss: 0.3291191272912374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 735] Loss: 0.3291160662225193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 736] Loss: 0.32910641074222374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 737] Loss: 0.3290934460364583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 738] Loss: 0.32908743396021756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 739] Loss: 0.32908323550376906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 740] Loss: 0.3290711456119361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 741] Loss: 0.3290741718687875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 742] Loss: 0.3290741883335919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 743] Loss: 0.3290840491557637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 744] Loss: 0.3290822910943473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 745] Loss: 0.32910937997024753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 746] Loss: 0.3290908065685928\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 747] Loss: 0.3290757471236932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 748] Loss: 0.32905542034058627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 749] Loss: 0.3290384935873593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 750] Loss: 0.3290533097245271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 751] Loss: 0.3290444438656171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 752] Loss: 0.32904820509978766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 753] Loss: 0.3290714327167798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 754] Loss: 0.32905580780163174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 755] Loss: 0.32905717830415054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 756] Loss: 0.32903721330409946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 757] Loss: 0.32902568188532744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 758] Loss: 0.3290509442807077\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 759] Loss: 0.3290394605059906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 760] Loss: 0.32902800741442667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 761] Loss: 0.3290256677905426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 762] Loss: 0.3290246818181537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 763] Loss: 0.3290405756093207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 764] Loss: 0.32905573463620813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 765] Loss: 0.32906022256906375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 766] Loss: 0.3290630475747749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 767] Loss: 0.3290435447267642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 768] Loss: 0.3290409610914019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 769] Loss: 0.3290364842896397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 770] Loss: 0.32904614929645776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 771] Loss: 0.32903783609442006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 772] Loss: 0.32902523271837764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 773] Loss: 0.32901366975066326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 774] Loss: 0.3290240659548294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 775] Loss: 0.32900172045294496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 776] Loss: 0.3289996714380326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 777] Loss: 0.32900454509388977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 778] Loss: 0.3289901528002267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 779] Loss: 0.3290004763242833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 780] Loss: 0.3289868129068939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 781] Loss: 0.32897360793643016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 782] Loss: 0.32896790863091446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 783] Loss: 0.3289608895316239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 784] Loss: 0.32897052429559837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 785] Loss: 0.32895598727565817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 786] Loss: 0.32894741708050046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 787] Loss: 0.3289480838438411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 788] Loss: 0.32894821249137196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 789] Loss: 0.32895459617286404\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 790] Loss: 0.3289634293155998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 791] Loss: 0.32895566135132054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 792] Loss: 0.3289529798837069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 793] Loss: 0.3289553420207004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 794] Loss: 0.3289649500630564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 795] Loss: 0.32896248952253465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 796] Loss: 0.3289534401103334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 797] Loss: 0.3289595217140078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 798] Loss: 0.3289701731887313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 799] Loss: 0.32896098489914904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 800] Loss: 0.3289421613293317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 801] Loss: 0.3289261579684914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 802] Loss: 0.3289290470562335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 803] Loss: 0.3289297214835713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 804] Loss: 0.3289104780702729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 805] Loss: 0.3289537370003533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 806] Loss: 0.3289555471590912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 807] Loss: 0.32894690401691246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 808] Loss: 0.328973775391815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 809] Loss: 0.3289655573697136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 810] Loss: 0.3289733329001128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 811] Loss: 0.32896557980759283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 812] Loss: 0.32899204336279786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 813] Loss: 0.3289927436848544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 814] Loss: 0.32900380678503105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 815] Loss: 0.32899534768939875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 816] Loss: 0.3289899564537057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 817] Loss: 0.3289741968919522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 818] Loss: 0.3289617791311512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 819] Loss: 0.3289461941806459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 820] Loss: 0.3289554273071866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 821] Loss: 0.3289375164119094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 822] Loss: 0.3289290597736986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 823] Loss: 0.32892194272082936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 824] Loss: 0.3289217969013994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 825] Loss: 0.3289212855493165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 826] Loss: 0.3289035754857886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 827] Loss: 0.3289225679601841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 828] Loss: 0.32892853446792747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 829] Loss: 0.32891340870980185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 830] Loss: 0.3288969670810993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 831] Loss: 0.32888212979466463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 832] Loss: 0.3288834087469982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 833] Loss: 0.32889154659287595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 834] Loss: 0.32892584579903233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 835] Loss: 0.3289254812224415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 836] Loss: 0.3289342563651843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 837] Loss: 0.32892814211210886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 838] Loss: 0.3289240049425536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 839] Loss: 0.32893875928427224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 840] Loss: 0.32893332817368737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 841] Loss: 0.3289145923421156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 842] Loss: 0.32890446902703996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 843] Loss: 0.32889648285641154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 844] Loss: 0.3288938877031829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 845] Loss: 0.3288860958749825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 846] Loss: 0.32887058394166896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 847] Loss: 0.32890890841901804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 848] Loss: 0.3288907640421735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 849] Loss: 0.3288721580855242\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 850] Loss: 0.328871611299878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 851] Loss: 0.3288682970813317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 852] Loss: 0.3288522348348622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 853] Loss: 0.3288866584293886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 854] Loss: 0.3288788492556361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 855] Loss: 0.32887521813430376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 856] Loss: 0.3288785868397274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 857] Loss: 0.32887545421070696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 858] Loss: 0.3289130780794465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 859] Loss: 0.328939145455926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 860] Loss: 0.32893948508655524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 861] Loss: 0.3289317295093556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 862] Loss: 0.32892570897174384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 863] Loss: 0.32893960283561186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 864] Loss: 0.32893594656767344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 865] Loss: 0.328924272576004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 866] Loss: 0.32890903644261876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 867] Loss: 0.3289030656771323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 868] Loss: 0.3289093801522987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 869] Loss: 0.32889561544529194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 870] Loss: 0.3288808163349729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 871] Loss: 0.3288741379007501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 872] Loss: 0.32887934097826094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 873] Loss: 0.3288814878372304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 874] Loss: 0.328878993392849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 875] Loss: 0.3288600772621113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 876] Loss: 0.32884823546675396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 877] Loss: 0.32885467768226523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 878] Loss: 0.3288613590872258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 879] Loss: 0.32884147237487976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 880] Loss: 0.32883125767428745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 881] Loss: 0.32882627269588005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 882] Loss: 0.3288365973969132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 883] Loss: 0.3288367364175846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 884] Loss: 0.3288260121886181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 885] Loss: 0.3288165663577578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 886] Loss: 0.3288065606914973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 887] Loss: 0.3287956160992097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 888] Loss: 0.3287845170767978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 889] Loss: 0.3287837765230907\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8931\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 890] Loss: 0.3287749811960396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 891] Loss: 0.3287818881933367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 892] Loss: 0.3288152789718461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 893] Loss: 0.32882412736915484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 894] Loss: 0.3288191720618104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 895] Loss: 0.3288075292355725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 896] Loss: 0.32880372616865267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 897] Loss: 0.32881125412487866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 898] Loss: 0.3288072759394863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 899] Loss: 0.3287899764283753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 900] Loss: 0.3287883066133788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 901] Loss: 0.32879134215871064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 902] Loss: 0.32880950779083484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 903] Loss: 0.3288145087571049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 904] Loss: 0.32881876768566626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 905] Loss: 0.3288069721815502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 906] Loss: 0.3287966595885982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 907] Loss: 0.3287873464904903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 908] Loss: 0.3288029342880496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 909] Loss: 0.3287895834896648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 910] Loss: 0.32878880126704096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 911] Loss: 0.32879107791308704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 912] Loss: 0.32880138140914594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 913] Loss: 0.32883416591125114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 914] Loss: 0.32886102836539166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 915] Loss: 0.3288408277631252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 916] Loss: 0.3288705449655288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 917] Loss: 0.32885816592808037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 918] Loss: 0.3288444180259595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 919] Loss: 0.3288412583427595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 920] Loss: 0.32882349591134524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 921] Loss: 0.32881096114420616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 922] Loss: 0.328802698937991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 923] Loss: 0.328806785847841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 924] Loss: 0.32880755339880346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 925] Loss: 0.3288048124651166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 926] Loss: 0.32879857735165646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 927] Loss: 0.3287826172978757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 928] Loss: 0.3287977692064139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 929] Loss: 0.32877709857583004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 930] Loss: 0.32879662301851814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 931] Loss: 0.32880413003963394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 932] Loss: 0.32878395633365404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 933] Loss: 0.3287752357484614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 934] Loss: 0.3287750853245498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 935] Loss: 0.32876854410830886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 936] Loss: 0.328779894450335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 937] Loss: 0.32877048896619854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 938] Loss: 0.32877678090278406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 939] Loss: 0.3287800763706038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 940] Loss: 0.3287606160861976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 941] Loss: 0.32875842178802706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 942] Loss: 0.32875915618138335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 943] Loss: 0.3287650108605642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 944] Loss: 0.32876049268199087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 945] Loss: 0.32876718252623544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 946] Loss: 0.32875851517625027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 947] Loss: 0.32874519267376134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 948] Loss: 0.3287370932965583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 949] Loss: 0.32874045526751394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 950] Loss: 0.32872845027785214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 951] Loss: 0.32871934471500136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 952] Loss: 0.32871205147285576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 953] Loss: 0.3287800848345467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 954] Loss: 0.32878252937133545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 955] Loss: 0.3287752471495712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 956] Loss: 0.32875507703650303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 957] Loss: 0.3287814667884458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 958] Loss: 0.32877715342346914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 959] Loss: 0.32876284869408284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 960] Loss: 0.32875407837992177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 961] Loss: 0.32875071858663507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 962] Loss: 0.32873729897576714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 963] Loss: 0.3287597100736556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 964] Loss: 0.328744453117399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 965] Loss: 0.3287362288704408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 966] Loss: 0.3287246900113259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 967] Loss: 0.32872165016980287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 968] Loss: 0.3287102048672588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 969] Loss: 0.32869913985164667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 970] Loss: 0.3286899951777742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 971] Loss: 0.3286933179759941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 972] Loss: 0.32871224210569466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 973] Loss: 0.32871017312572265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 974] Loss: 0.32869604826176224\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 975] Loss: 0.32868386870009414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 976] Loss: 0.3286737793942307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 977] Loss: 0.3286648298552591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 978] Loss: 0.3286649195507298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 979] Loss: 0.32867148707980737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 980] Loss: 0.3286820268152568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 981] Loss: 0.32869002762222177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 982] Loss: 0.3286811953752474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 983] Loss: 0.32867446955686885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 984] Loss: 0.32868201533063746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 985] Loss: 0.32866677597976696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 986] Loss: 0.3286582375445331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 987] Loss: 0.3286657144593477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 988] Loss: 0.32868387383351355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 989] Loss: 0.3286674576607432\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 990] Loss: 0.32866462890883635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 991] Loss: 0.32864935993945965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 992] Loss: 0.3286332554686796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 993] Loss: 0.3286177013508337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 994] Loss: 0.32860566146328013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 995] Loss: 0.328603638466335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 996] Loss: 0.32860482860215057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 997] Loss: 0.3286070650281955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 998] Loss: 0.32859310140022513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 999] Loss: 0.32858224240588785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1000] Loss: 0.32861023216326474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1001] Loss: 0.3285996629744603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1002] Loss: 0.32859658284880916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1003] Loss: 0.32860199990587624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1004] Loss: 0.32859321499400357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1005] Loss: 0.3285869372499405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1006] Loss: 0.32859520653887286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1007] Loss: 0.32858386647434773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1008] Loss: 0.3285811142041692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1009] Loss: 0.3285717957961253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1010] Loss: 0.32857370552990095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1011] Loss: 0.3285673428164039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1012] Loss: 0.32854994764741363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1013] Loss: 0.32853213819265364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1014] Loss: 0.32851690505687425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1015] Loss: 0.3284983058970353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1016] Loss: 0.32853137598809323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1017] Loss: 0.3285387124050982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1018] Loss: 0.32855956518946977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1019] Loss: 0.3285567172897022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1020] Loss: 0.3285430055844611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1021] Loss: 0.32853250773952236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1022] Loss: 0.3285689335724031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1023] Loss: 0.3285597805522231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1024] Loss: 0.328547923408097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1025] Loss: 0.3285393651569814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1026] Loss: 0.3285257375716035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1027] Loss: 0.32851960513127904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1028] Loss: 0.32851616873403583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1029] Loss: 0.32853054761165423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1030] Loss: 0.32853688458056246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1031] Loss: 0.32852632151263567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1032] Loss: 0.32850874037974037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1033] Loss: 0.3285155191907786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1034] Loss: 0.32854424052355685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1035] Loss: 0.32853166979138687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1036] Loss: 0.3285124039850767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1037] Loss: 0.32851655698891197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1038] Loss: 0.328497814527867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1039] Loss: 0.32851751363415643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1040] Loss: 0.32852135171201646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1041] Loss: 0.3285154816547771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1042] Loss: 0.328510115027742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1043] Loss: 0.3285136357826883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1044] Loss: 0.3285261644676233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1045] Loss: 0.328520458355588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1046] Loss: 0.32851990218543486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1047] Loss: 0.3285234022370988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1048] Loss: 0.3285274968382117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1049] Loss: 0.3285499435941125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1050] Loss: 0.3285524689895255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1051] Loss: 0.3285471896540442\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1052] Loss: 0.3285667264732746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1053] Loss: 0.3285511995330955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1054] Loss: 0.3285679634858471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1055] Loss: 0.3285726273052182\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1056] Loss: 0.32858601814075705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1057] Loss: 0.3285834486975359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1058] Loss: 0.32857523416345674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1059] Loss: 0.32856493807801157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1060] Loss: 0.3285611720962657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1061] Loss: 0.32854870716824347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1062] Loss: 0.3285532863521258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1063] Loss: 0.32856720959283525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1064] Loss: 0.3285757420965472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1065] Loss: 0.32856958783352974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1066] Loss: 0.32856006454881376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1067] Loss: 0.32856145701088174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1068] Loss: 0.32855423126633854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1069] Loss: 0.3285483623303946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1070] Loss: 0.3285560119488265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1071] Loss: 0.32854545039123534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1072] Loss: 0.3285600992342055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1073] Loss: 0.3285515952261396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1074] Loss: 0.3285471608394913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1075] Loss: 0.32852921785980815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1076] Loss: 0.3285308165851531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1077] Loss: 0.32852266303897415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1078] Loss: 0.3285221709573007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1079] Loss: 0.32850456705421277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1080] Loss: 0.3285091941588689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1081] Loss: 0.3285213636354214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1082] Loss: 0.32850190917198646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1083] Loss: 0.3285043686546517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1084] Loss: 0.32848647787799745\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1085] Loss: 0.3284840466266247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1086] Loss: 0.32848697691105233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1087] Loss: 0.32849247170132184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1088] Loss: 0.328498261139342\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1089] Loss: 0.3284961763265627\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1090] Loss: 0.3284870773650137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1091] Loss: 0.3284702771411979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1092] Loss: 0.328457941941877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1093] Loss: 0.3284664382310193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1094] Loss: 0.3284718892930878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1095] Loss: 0.3284869715716657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1096] Loss: 0.3285028275990129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1097] Loss: 0.32851993619854725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1098] Loss: 0.3285159941431448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1099] Loss: 0.32851499156562963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1100] Loss: 0.3285137298990983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1101] Loss: 0.32854406397645025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1102] Loss: 0.3285338395305335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1103] Loss: 0.3285500804308124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1104] Loss: 0.32856038490177913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1105] Loss: 0.328569181519144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1106] Loss: 0.32857884831017575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1107] Loss: 0.3285718520178399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1108] Loss: 0.32862769698774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1109] Loss: 0.32862936966723877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1110] Loss: 0.3286300094608363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1111] Loss: 0.328617009224972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1112] Loss: 0.3286213231941591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1113] Loss: 0.32864070111404436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1114] Loss: 0.3286382703406298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1115] Loss: 0.32862843407635645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1116] Loss: 0.32860893208042735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1117] Loss: 0.3286227657069107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1118] Loss: 0.3286079074866065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1119] Loss: 0.3286015967382592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1120] Loss: 0.328626771946234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1121] Loss: 0.3286453092344749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1122] Loss: 0.3286357762059932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1123] Loss: 0.32864242532015137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1124] Loss: 0.3286632703514991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1125] Loss: 0.3286507919257064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1126] Loss: 0.3286347940236757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1127] Loss: 0.3286295984944595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1128] Loss: 0.3286395758724979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1129] Loss: 0.3286486424242621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1130] Loss: 0.32865493057498624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1131] Loss: 0.328652833488205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1132] Loss: 0.3286651807879213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1133] Loss: 0.32865588316652106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1134] Loss: 0.32865656507270385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1135] Loss: 0.32867636845623405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1136] Loss: 0.3286706254502287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1137] Loss: 0.3286959235135866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1138] Loss: 0.32871406065424286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1139] Loss: 0.32872692150822436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1140] Loss: 0.32872354731927983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1141] Loss: 0.32871082421777237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1142] Loss: 0.32872268647363495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1143] Loss: 0.3287315007188622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1144] Loss: 0.3287468801691132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1145] Loss: 0.328770495047036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1146] Loss: 0.32878876985703726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1147] Loss: 0.32878708693905107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1148] Loss: 0.3287881589352579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1149] Loss: 0.32877716634478005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1150] Loss: 0.3287592867113825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1151] Loss: 0.3287798661648917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1152] Loss: 0.3287992533125048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1153] Loss: 0.3288016010461182\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1154] Loss: 0.32880158474618837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1155] Loss: 0.32878904709295276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1156] Loss: 0.32877074404343437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1157] Loss: 0.32875570982211677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1158] Loss: 0.32877259475090054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1159] Loss: 0.3287695184504953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1160] Loss: 0.32876984522240216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1161] Loss: 0.32878836833150415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1162] Loss: 0.3287786170903297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1163] Loss: 0.3287950435046703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1164] Loss: 0.3287808867229924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1165] Loss: 0.3287647615299502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1166] Loss: 0.32875533592865847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1167] Loss: 0.32873971741824265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1168] Loss: 0.32875124405133693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1169] Loss: 0.32874592654735424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1170] Loss: 0.3287340829351751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1171] Loss: 0.3287463017994477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1172] Loss: 0.3287465205161555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1173] Loss: 0.3287503569122172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1174] Loss: 0.3287422287208416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1175] Loss: 0.32872465474137036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1176] Loss: 0.32871631310414884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1177] Loss: 0.32872645029750286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1178] Loss: 0.32873298743395957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1179] Loss: 0.3287291642583519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1180] Loss: 0.32872704549585197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1181] Loss: 0.32872118235773595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1182] Loss: 0.3287053315266733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1183] Loss: 0.328698225468487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1184] Loss: 0.32869004056292334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1185] Loss: 0.3286877536410537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1186] Loss: 0.32867819746468235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1187] Loss: 0.3286747692020661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1188] Loss: 0.32868374189429256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1189] Loss: 0.32869372980725464\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1190] Loss: 0.3287139189048392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1191] Loss: 0.32871573925912057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1192] Loss: 0.32870878894079425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1193] Loss: 0.32871172186357295\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1194] Loss: 0.3287202269350179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1195] Loss: 0.3287072012339299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1196] Loss: 0.32870208793514816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1197] Loss: 0.3286839302403715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1198] Loss: 0.32868996563890923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1199] Loss: 0.3286809753561591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1200] Loss: 0.3286673442072471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1201] Loss: 0.3286622629666621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1202] Loss: 0.32868526230297584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1203] Loss: 0.32866991693742004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1204] Loss: 0.3286909793582873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1205] Loss: 0.32870967252686345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1206] Loss: 0.32869854449856795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1207] Loss: 0.32868015961476366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1208] Loss: 0.3286726203827689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1209] Loss: 0.32868844269363084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1210] Loss: 0.32868086637889243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1211] Loss: 0.3286704630721336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1212] Loss: 0.3286574327918141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1213] Loss: 0.32864149754559313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1214] Loss: 0.32863769768941953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1215] Loss: 0.3286589377896259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1216] Loss: 0.3286613285529009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1217] Loss: 0.3286702587828443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1218] Loss: 0.32866257223851825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1219] Loss: 0.32868291906160174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1220] Loss: 0.32868046476360385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1221] Loss: 0.3286708643644079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1222] Loss: 0.32867488144437185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1223] Loss: 0.3286607381204466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1224] Loss: 0.32865818128286506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1225] Loss: 0.3286599408224345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1226] Loss: 0.32864343056052703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1227] Loss: 0.3286506218668411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1228] Loss: 0.3286465024213782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1229] Loss: 0.32864527522842313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1230] Loss: 0.3286389371027866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1231] Loss: 0.32863653988632013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1232] Loss: 0.32863989044945197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1233] Loss: 0.3286606979886167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1234] Loss: 0.32866519974246033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1235] Loss: 0.32866223114231924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1236] Loss: 0.3286510211601675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1237] Loss: 0.32863777093718705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1238] Loss: 0.32865442684221413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1239] Loss: 0.32866634127034094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1240] Loss: 0.3286759070722008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1241] Loss: 0.32866929769498154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1242] Loss: 0.328650783882997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1243] Loss: 0.3286456325350587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1244] Loss: 0.3286263260672956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1245] Loss: 0.3286226040410542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1246] Loss: 0.3286149897872261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1247] Loss: 0.3286135415443537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1248] Loss: 0.32858897101347956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1249] Loss: 0.32859282956666147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1250] Loss: 0.3285807700820144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1251] Loss: 0.3285698106971908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1252] Loss: 0.3285770280494224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1253] Loss: 0.3285655638012641\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1254] Loss: 0.3285751487180758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1255] Loss: 0.32857026181579907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1256] Loss: 0.3285635231235501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1257] Loss: 0.3285577006051369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1258] Loss: 0.3285721978219393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1259] Loss: 0.32855660565889033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1260] Loss: 0.3285565251965971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1261] Loss: 0.32855640030097294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1262] Loss: 0.3285371789422686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1263] Loss: 0.3285353163898881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1264] Loss: 0.32852734853856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1265] Loss: 0.3285281767258642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1266] Loss: 0.32854721183212965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1267] Loss: 0.3285241946311267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1268] Loss: 0.32852066748804437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1269] Loss: 0.328500131456931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1270] Loss: 0.32850523280840704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1271] Loss: 0.32849537888009667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1272] Loss: 0.32855857837365815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1273] Loss: 0.3285540568993855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1274] Loss: 0.3285436243957831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1275] Loss: 0.32852903061495414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1276] Loss: 0.3285168627650967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1277] Loss: 0.32849847109710123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1278] Loss: 0.3284846437053757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1279] Loss: 0.32846842858305053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1280] Loss: 0.3284608659612368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1281] Loss: 0.32845107452311645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1282] Loss: 0.3284378607249456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1283] Loss: 0.3284332279961261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1284] Loss: 0.3284293627796811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1285] Loss: 0.3284377841780452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1286] Loss: 0.3284222012459806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1287] Loss: 0.3284457203828873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1288] Loss: 0.3284351161698855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1289] Loss: 0.3284404373485735\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1290] Loss: 0.3284290530801997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1291] Loss: 0.3284284656615353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1292] Loss: 0.3284261268259925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1293] Loss: 0.3284447041926889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1294] Loss: 0.32843718927618637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1295] Loss: 0.32842375043758787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1296] Loss: 0.3284119483974933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1297] Loss: 0.3284145124555201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1298] Loss: 0.3284116625546629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1299] Loss: 0.3283914109153181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1300] Loss: 0.3283785930354214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1301] Loss: 0.32837220614526497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1302] Loss: 0.3283665663838769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1303] Loss: 0.32835345811792166\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1304] Loss: 0.32835369627522626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1305] Loss: 0.32837359252527093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1306] Loss: 0.32836634465788656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1307] Loss: 0.32835415298875176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1308] Loss: 0.3283649136549008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1309] Loss: 0.32838471755058035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1310] Loss: 0.32836669405939545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1311] Loss: 0.3283589344237729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1312] Loss: 0.3283486130363454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1313] Loss: 0.3283560585117835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1314] Loss: 0.32834807177928205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1315] Loss: 0.32836341685239173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1316] Loss: 0.32835697215695797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1317] Loss: 0.3283589796550631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1318] Loss: 0.32835649641082665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1319] Loss: 0.32835597787045767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1320] Loss: 0.32839505636244587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1321] Loss: 0.3284148282487311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1322] Loss: 0.3284085199549593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1323] Loss: 0.32843563753380606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1324] Loss: 0.32841826974904015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1325] Loss: 0.3284102893162144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1326] Loss: 0.3284198629300539\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1327] Loss: 0.32845018006042787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1328] Loss: 0.3284622404203525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1329] Loss: 0.3284424286092532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1330] Loss: 0.32845029271512455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1331] Loss: 0.3284384382068652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1332] Loss: 0.32842813145716937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1333] Loss: 0.3284281688030476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1334] Loss: 0.32842350416917554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1335] Loss: 0.328506713240679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1336] Loss: 0.32851450328775117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1337] Loss: 0.3284969129843788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1338] Loss: 0.3284751760509945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1339] Loss: 0.3284984732575916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1340] Loss: 0.32850554212134453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1341] Loss: 0.32850691836645063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1342] Loss: 0.32849879138504806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1343] Loss: 0.3284827932010453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1344] Loss: 0.32847266115491386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1345] Loss: 0.32847767538218486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1346] Loss: 0.32847503312398957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1347] Loss: 0.3284732460234024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1348] Loss: 0.32846313356983325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1349] Loss: 0.3284740387370169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1350] Loss: 0.3284690666136393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1351] Loss: 0.3284781956465253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1352] Loss: 0.32847162782494504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1353] Loss: 0.32847221329218523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1354] Loss: 0.32846321581213606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1355] Loss: 0.32847661084329505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1356] Loss: 0.3284680411196721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1357] Loss: 0.3284451104001166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1358] Loss: 0.3284646877141531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1359] Loss: 0.32844973864081534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1360] Loss: 0.328437935426388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1361] Loss: 0.3284156701181189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1362] Loss: 0.32839716072437164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1363] Loss: 0.32842925263101724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1364] Loss: 0.32841797726542643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1365] Loss: 0.3284067472121521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1366] Loss: 0.32838529638118213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1367] Loss: 0.3283673039729661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1368] Loss: 0.32835921289768283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1369] Loss: 0.3283621122940449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1370] Loss: 0.32835720633296045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1371] Loss: 0.32834324832919154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1372] Loss: 0.32836511180609224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1373] Loss: 0.3283579260119636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1374] Loss: 0.3283969036788767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1375] Loss: 0.32838961000178857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1376] Loss: 0.32837105346589046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1377] Loss: 0.3283598521768885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1378] Loss: 0.3283499999913015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1379] Loss: 0.32833403345325113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1380] Loss: 0.3283916130842702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1381] Loss: 0.3283699874655526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1382] Loss: 0.32835481168576375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1383] Loss: 0.3283601931495271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1384] Loss: 0.32836087286146093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1385] Loss: 0.3283630806654148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1386] Loss: 0.32835289380811444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1387] Loss: 0.32835219404493055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1388] Loss: 0.32834261880113796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1389] Loss: 0.328354231529433\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.9016\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1390] Loss: 0.32834370123799533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1391] Loss: 0.32832484897197617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1392] Loss: 0.3283156253676073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1393] Loss: 0.32833448220865646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1394] Loss: 0.3283306989076907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1395] Loss: 0.328323859198997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1396] Loss: 0.32832493831556364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1397] Loss: 0.32833294131326707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1398] Loss: 0.3283145129636858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1399] Loss: 0.32832176431938226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1400] Loss: 0.3283106669725822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1401] Loss: 0.32831991248775366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1402] Loss: 0.3283576649938121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1403] Loss: 0.32835351824672937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1404] Loss: 0.3283355064933333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1405] Loss: 0.3283229030820074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1406] Loss: 0.3283245101348913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1407] Loss: 0.32833016660291414\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1408] Loss: 0.3283181029472483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1409] Loss: 0.3283099464231877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1410] Loss: 0.328297845958943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1411] Loss: 0.3282901546073732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1412] Loss: 0.3282845658759299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1413] Loss: 0.32828253934547696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1414] Loss: 0.3282915073622358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1415] Loss: 0.32827065715819015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1416] Loss: 0.328262995101169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1417] Loss: 0.3282575564713827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1418] Loss: 0.328262620316196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1419] Loss: 0.3282477392429359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1420] Loss: 0.3282444664000752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1421] Loss: 0.3282401488645756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1422] Loss: 0.3282420845322079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1423] Loss: 0.32823784383909704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1424] Loss: 0.32827150820725665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1425] Loss: 0.32825196107101756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1426] Loss: 0.3282655432120465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1427] Loss: 0.32828112813097793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1428] Loss: 0.32828249829173506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1429] Loss: 0.3282712185409711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1430] Loss: 0.32825073381845327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1431] Loss: 0.32825382185630464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1432] Loss: 0.3282683743870283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1433] Loss: 0.3282553932161412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1434] Loss: 0.3282543933413541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1435] Loss: 0.3282389264025088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1436] Loss: 0.3282349363333734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1437] Loss: 0.32822865790244443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1438] Loss: 0.32821808161181315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1439] Loss: 0.328213281394508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1440] Loss: 0.3282253631931652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1441] Loss: 0.32820366928675127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1442] Loss: 0.32821882118009116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1443] Loss: 0.3282358054099969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1444] Loss: 0.32823513930227194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1445] Loss: 0.3282456847108649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1446] Loss: 0.3282777343835959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1447] Loss: 0.3282725959850856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1448] Loss: 0.32829564069876466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1449] Loss: 0.32827983272767014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1450] Loss: 0.32828382684339485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1451] Loss: 0.3283285477658612\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1452] Loss: 0.3283116098402859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1453] Loss: 0.32831690692703275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1454] Loss: 0.3283095730843943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1455] Loss: 0.32831275811586524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1456] Loss: 0.32830637404964724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1457] Loss: 0.32831313976145693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1458] Loss: 0.32831371092305994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1459] Loss: 0.3283137804962779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1460] Loss: 0.32831317960531065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1461] Loss: 0.32830271288660434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1462] Loss: 0.3282900163601864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1463] Loss: 0.32827878424881496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1464] Loss: 0.32826485441660563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1465] Loss: 0.328265289461243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1466] Loss: 0.3282522447494102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1467] Loss: 0.32825380041526603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1468] Loss: 0.32825709589971946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1469] Loss: 0.3282868631567006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1470] Loss: 0.3282984696290441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1471] Loss: 0.32831778051076643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1472] Loss: 0.32831254485084954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1473] Loss: 0.3283036084033128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1474] Loss: 0.3283039235661573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1475] Loss: 0.3283178437610951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1476] Loss: 0.3283259161449986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1477] Loss: 0.328330984050472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1478] Loss: 0.32832807171244144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1479] Loss: 0.3283161391450881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1480] Loss: 0.3283017072991383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1481] Loss: 0.3283217922078499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1482] Loss: 0.32831187793421057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1483] Loss: 0.32831016572202065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1484] Loss: 0.3283149662044934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1485] Loss: 0.3283224623007692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1486] Loss: 0.3283375506234061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1487] Loss: 0.3283282372537762\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1488] Loss: 0.32832487978127806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1489] Loss: 0.3283248462130297\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1490] Loss: 0.32831408986395194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1491] Loss: 0.3283189282126099\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1492] Loss: 0.3283127730141638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1493] Loss: 0.32830515567349666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1494] Loss: 0.3282988151514181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1495] Loss: 0.3283002187162586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1496] Loss: 0.32831479311352907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1497] Loss: 0.328320857955716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1498] Loss: 0.3283513688606737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1499] Loss: 0.32834439419773226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1500] Loss: 0.3283521237835475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1501] Loss: 0.32835031715655844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1502] Loss: 0.32833933960780454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1503] Loss: 0.3283281688687072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1504] Loss: 0.32831093207600087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1505] Loss: 0.32833441048583867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1506] Loss: 0.3283264234611913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1507] Loss: 0.32833226095901896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1508] Loss: 0.328325818175679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1509] Loss: 0.32832154200620073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1510] Loss: 0.32833636729329707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1511] Loss: 0.328351755489658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1512] Loss: 0.3283530645329913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1513] Loss: 0.32833511083454325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1514] Loss: 0.3283186584042544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1515] Loss: 0.32830129382185963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1516] Loss: 0.3282858669303624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1517] Loss: 0.32827539251130156\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1518] Loss: 0.32826136225879815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1519] Loss: 0.3282864756149304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1520] Loss: 0.3282669375834432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1521] Loss: 0.32825749879427835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1522] Loss: 0.3282624087116289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1523] Loss: 0.3282616460632229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 25, Batch 1524] Loss: 0.3282630796285002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 0] Loss: 0.32829942920337857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1] Loss: 0.3283035894845075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 2] Loss: 0.3283080518795931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 3] Loss: 0.32828787115178315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 4] Loss: 0.32829796161234015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 5] Loss: 0.328303229062025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 6] Loss: 0.3283244588931829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 7] Loss: 0.32831999135566964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 8] Loss: 0.32832329070606003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 9] Loss: 0.32833189290708864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 10] Loss: 0.3283416773877048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 11] Loss: 0.3283299061630841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 12] Loss: 0.32833802763703024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 13] Loss: 0.3283407941296955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 14] Loss: 0.32833876738281914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 15] Loss: 0.32833185610699395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 16] Loss: 0.3283203672292631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 17] Loss: 0.32831030395222033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 18] Loss: 0.3283133723767144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 19] Loss: 0.3283145625803571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 20] Loss: 0.3283105719723974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 21] Loss: 0.32829722913649456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 22] Loss: 0.32830499347249004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 23] Loss: 0.32830667749787174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 24] Loss: 0.3283135593943956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 25] Loss: 0.3283347194595897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 26] Loss: 0.32832238219939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 27] Loss: 0.3283412944007792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 28] Loss: 0.3283283374872568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 29] Loss: 0.32832323058497376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 30] Loss: 0.3283072622275633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 31] Loss: 0.3283043666929694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 32] Loss: 0.32831166710840787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 33] Loss: 0.3283041840322496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 34] Loss: 0.3282971812515038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 35] Loss: 0.32828971790579387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 36] Loss: 0.32829556908129026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 37] Loss: 0.32829533939193767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 38] Loss: 0.3282941797856639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 39] Loss: 0.32830239530719746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 40] Loss: 0.32829492238293434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 41] Loss: 0.3282826073557022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 42] Loss: 0.32829215459809735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 43] Loss: 0.32830264652019137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 44] Loss: 0.328282581424915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 45] Loss: 0.3282898079300979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 46] Loss: 0.32827930066523897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 47] Loss: 0.3282722800992385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 48] Loss: 0.3282703175934897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 49] Loss: 0.3282571810737489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 50] Loss: 0.3282538190161563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 51] Loss: 0.3282495578107789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 52] Loss: 0.32824283572712787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 53] Loss: 0.328258439499812\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 54] Loss: 0.3282787986129725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 55] Loss: 0.32828923985036323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 56] Loss: 0.32831310516830337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 57] Loss: 0.32831357460197347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 58] Loss: 0.32830193546172737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 59] Loss: 0.32833717390809214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 60] Loss: 0.32833282774335915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 61] Loss: 0.3283268996079877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 62] Loss: 0.32831618244198635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 63] Loss: 0.328300577466344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 64] Loss: 0.32828038143191635\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 65] Loss: 0.3282944610609087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 66] Loss: 0.3282970387334935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 67] Loss: 0.3282917448540341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 68] Loss: 0.3282999704010455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 69] Loss: 0.32830754875907425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 70] Loss: 0.32829075977522837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 71] Loss: 0.3282916322016817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 72] Loss: 0.32832399341994795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 73] Loss: 0.32831342803607305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 74] Loss: 0.32830798904690645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 75] Loss: 0.3282889893511096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 76] Loss: 0.3282816664537127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 77] Loss: 0.328296508982056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 78] Loss: 0.32827388376373706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 79] Loss: 0.32826932563697353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 80] Loss: 0.3282695178947236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 81] Loss: 0.32825964710363886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 82] Loss: 0.3282541698373599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 83] Loss: 0.3282615358975434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 84] Loss: 0.32826421549100554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 85] Loss: 0.3282845594087986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 86] Loss: 0.32826693415570035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 87] Loss: 0.32827343172976614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 88] Loss: 0.32826968380492877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 89] Loss: 0.3282887088931088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 90] Loss: 0.32827920317086373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 91] Loss: 0.3282801421755271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 92] Loss: 0.3282753950718315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 93] Loss: 0.3282910018126648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 94] Loss: 0.3282996714618618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 95] Loss: 0.32830252300007623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 96] Loss: 0.3282982912488332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 97] Loss: 0.32831438559930465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 98] Loss: 0.3283116870792716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 99] Loss: 0.32830287774277667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 100] Loss: 0.32828766313160096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 101] Loss: 0.32828082400997627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 102] Loss: 0.32827223976599784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 103] Loss: 0.32828746981475526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 104] Loss: 0.32829093767319184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 105] Loss: 0.3282983766596409\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 106] Loss: 0.3282942496650036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 107] Loss: 0.3283059874818765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 108] Loss: 0.32829689343889623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 109] Loss: 0.32832166544621116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 110] Loss: 0.32832069204111053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 111] Loss: 0.3283276245139359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 112] Loss: 0.328338063512445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 113] Loss: 0.3283349976156439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 114] Loss: 0.32832233842499337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 115] Loss: 0.3283481351491507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 116] Loss: 0.32835133194729327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 117] Loss: 0.32838456361876495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 118] Loss: 0.3283697689340361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 119] Loss: 0.3283595187541024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 120] Loss: 0.3283700722913036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 121] Loss: 0.32836602362892375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 122] Loss: 0.32838312972505856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 123] Loss: 0.32837914344195496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 124] Loss: 0.3284011500753737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 125] Loss: 0.32841373771289606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 126] Loss: 0.3284024535040122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 127] Loss: 0.32841909334781044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 128] Loss: 0.32842379710246544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 129] Loss: 0.32841783937490915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 130] Loss: 0.3284284053263064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 131] Loss: 0.328427584890283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 132] Loss: 0.32841593264082247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 133] Loss: 0.3284044596843396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 134] Loss: 0.32840419766748935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 135] Loss: 0.3283977496526487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 136] Loss: 0.32841904230299473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 137] Loss: 0.32841219986972137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 138] Loss: 0.3284324678982425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 139] Loss: 0.3284244354900886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 140] Loss: 0.32841292992819954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 141] Loss: 0.3283951686358677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 142] Loss: 0.3283948162855965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 143] Loss: 0.3283991150821056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 144] Loss: 0.3283998966904317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 145] Loss: 0.3283932271431109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 146] Loss: 0.3283946966279697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 147] Loss: 0.32838771234475117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 148] Loss: 0.3284131752075834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 149] Loss: 0.3284100864083423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 150] Loss: 0.3283976931330544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 151] Loss: 0.3284165703301124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 152] Loss: 0.32840558695198396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 153] Loss: 0.3284005606701689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 154] Loss: 0.32839386666282805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 155] Loss: 0.3283962201627075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 156] Loss: 0.3284027426087665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 157] Loss: 0.32838902994651453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 158] Loss: 0.32839179903336585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 159] Loss: 0.328401929497712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 160] Loss: 0.3283967825203941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 161] Loss: 0.32839400078114744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 162] Loss: 0.3284091693531764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 163] Loss: 0.3283958483461968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 164] Loss: 0.32841727694348577\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 165] Loss: 0.32841103483931877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 166] Loss: 0.3284065078698098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 167] Loss: 0.3284155392942308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 168] Loss: 0.32842026765224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 169] Loss: 0.3284065773752489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 170] Loss: 0.3284105013290775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 171] Loss: 0.32841768431190493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 172] Loss: 0.3284604661196271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 173] Loss: 0.3284509029184446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 174] Loss: 0.32843600550330115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 175] Loss: 0.32843949549454776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 176] Loss: 0.3284500089182251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 177] Loss: 0.32846632135331644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 178] Loss: 0.3284745007034938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 179] Loss: 0.32847313326741223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 180] Loss: 0.3284694094291563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 181] Loss: 0.32846526830398215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 182] Loss: 0.32847429073486134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 183] Loss: 0.32846500975525433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 184] Loss: 0.32845725180350416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 185] Loss: 0.3284663332504187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 186] Loss: 0.32846371141198705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 187] Loss: 0.3284909992233081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 188] Loss: 0.32848440150954566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 189] Loss: 0.3284914287779233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 190] Loss: 0.3284917521997704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 191] Loss: 0.32848708525613984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 192] Loss: 0.3284802941829287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 193] Loss: 0.3285031568043837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 194] Loss: 0.3284932976138712\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 195] Loss: 0.32848997604510194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 196] Loss: 0.3284844376393937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 197] Loss: 0.32851063062617997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 198] Loss: 0.32850972592881256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 199] Loss: 0.32852885608454674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 200] Loss: 0.32853289368995864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 201] Loss: 0.32852817254200406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 202] Loss: 0.3285342843067067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 203] Loss: 0.32852462591915244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 204] Loss: 0.3285105342049429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 205] Loss: 0.32850711937724963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 206] Loss: 0.3285062147057341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 207] Loss: 0.3285141834523318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 208] Loss: 0.32851098508923116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 209] Loss: 0.3284906736323865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 210] Loss: 0.32850838699161744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 211] Loss: 0.3284967259375907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 212] Loss: 0.32850484092220883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 213] Loss: 0.3285071566221067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 214] Loss: 0.32853767307208576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 215] Loss: 0.3285306573925827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 216] Loss: 0.32851830385831554\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 217] Loss: 0.3285107092912092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 218] Loss: 0.328502499462352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 219] Loss: 0.3285279065049182\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 220] Loss: 0.3285233347327698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 221] Loss: 0.32852265843774614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 222] Loss: 0.32853926721851395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 223] Loss: 0.3285381367535206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 224] Loss: 0.3285230936653027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 225] Loss: 0.32854939793822757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 226] Loss: 0.3285354052269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 227] Loss: 0.3285517124265822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 228] Loss: 0.32853743668353563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 229] Loss: 0.32853884224967095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 230] Loss: 0.3285370562202473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 231] Loss: 0.328553419922305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 232] Loss: 0.3285396713206929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 233] Loss: 0.3285465245039581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 234] Loss: 0.32856870678467326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 235] Loss: 0.32855662384983303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 236] Loss: 0.32855143921006214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 237] Loss: 0.32853587827392733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 238] Loss: 0.3285251114108193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 239] Loss: 0.32852570174086493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 240] Loss: 0.32851133359432677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 241] Loss: 0.32851259852733317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 242] Loss: 0.3285104107849702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 243] Loss: 0.3285027363169771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 244] Loss: 0.3285106320876673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 245] Loss: 0.3285028866188761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 246] Loss: 0.32849080106162765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 247] Loss: 0.3285009856589511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 248] Loss: 0.328522116025479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 249] Loss: 0.3285128488715788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 250] Loss: 0.3284970738603211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 251] Loss: 0.32849890752557187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 252] Loss: 0.328495622536995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 253] Loss: 0.32847885263264515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 254] Loss: 0.3284777149209463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 255] Loss: 0.32848493346388924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 256] Loss: 0.32849569910508664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 257] Loss: 0.32849457733080123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 258] Loss: 0.3285288538982722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 259] Loss: 0.3285443570352622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 260] Loss: 0.32852678521219847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 261] Loss: 0.3285479828971548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 262] Loss: 0.32855886546701296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 263] Loss: 0.32854121169766015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 264] Loss: 0.3285255645015791\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 265] Loss: 0.3285293084837311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 266] Loss: 0.32852198748836675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 267] Loss: 0.3285069069067838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 268] Loss: 0.328497235127241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 269] Loss: 0.3284790383644742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 270] Loss: 0.3284842227487849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 271] Loss: 0.3284672341452929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 272] Loss: 0.328465275897972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 273] Loss: 0.32847101150120284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 274] Loss: 0.3284724105842225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 275] Loss: 0.328458018215537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 276] Loss: 0.32845434052858186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 277] Loss: 0.3284440296544324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 278] Loss: 0.32843903867685587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 279] Loss: 0.3284318311229355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 280] Loss: 0.3284403918340453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 281] Loss: 0.32842578038065307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 282] Loss: 0.3284374353691914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 283] Loss: 0.3284347060925824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 284] Loss: 0.3284365258749298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 285] Loss: 0.3284344874820122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 286] Loss: 0.32841886139869236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 287] Loss: 0.3284245883592612\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 288] Loss: 0.3284373302912178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 289] Loss: 0.3284445986220141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 290] Loss: 0.3284437646946435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 291] Loss: 0.32843013978930435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 292] Loss: 0.32842077931076513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 293] Loss: 0.32844009884911585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 294] Loss: 0.32842222934203164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 295] Loss: 0.3284381571339683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 296] Loss: 0.3284437587401521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 297] Loss: 0.32844193129880944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 298] Loss: 0.32843623030482555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 299] Loss: 0.32843023766625934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 300] Loss: 0.32842827772229155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 301] Loss: 0.3284154970629833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 302] Loss: 0.3284043665724868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 303] Loss: 0.3284176682857526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 304] Loss: 0.3284176354591391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 305] Loss: 0.3284260755714368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 306] Loss: 0.3284095844117891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 307] Loss: 0.32841834190596486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 308] Loss: 0.32843384269881076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 309] Loss: 0.3284282205335291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 310] Loss: 0.3284180004641412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 311] Loss: 0.32843432516096077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 312] Loss: 0.32843374689723115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 313] Loss: 0.3284174707956487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 314] Loss: 0.3284065654107398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 315] Loss: 0.32840510454508237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 316] Loss: 0.3283932712863214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 317] Loss: 0.328373929077536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 318] Loss: 0.3283906213111348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 319] Loss: 0.32839477022709646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 320] Loss: 0.32841774428747217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 321] Loss: 0.3284028095333977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 322] Loss: 0.3284133874725678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 323] Loss: 0.3283983079891186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 324] Loss: 0.32839289637262326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 325] Loss: 0.3283762573153346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 326] Loss: 0.3283875088182382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 327] Loss: 0.32839358662243057\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 328] Loss: 0.32841659838253734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 329] Loss: 0.3284291569388673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 330] Loss: 0.32842597209255314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 331] Loss: 0.3284441769317484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 332] Loss: 0.3284434479900009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 333] Loss: 0.32847000362897666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 334] Loss: 0.32846066972365173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 335] Loss: 0.3284440766637991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 336] Loss: 0.328444821939618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 337] Loss: 0.32844659868658505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 338] Loss: 0.3284379246465675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 339] Loss: 0.3284225957841677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 340] Loss: 0.32842325462013655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 341] Loss: 0.3284196947537583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 342] Loss: 0.328414082675691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 343] Loss: 0.32840376605750593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 344] Loss: 0.3284206809284174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 345] Loss: 0.32842927982280395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 346] Loss: 0.3284170693142183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 347] Loss: 0.3284142661801575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 348] Loss: 0.3284176004110407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 349] Loss: 0.32840831475214227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 350] Loss: 0.32839402259208605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 351] Loss: 0.32838485576875565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 352] Loss: 0.32838886644617044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 353] Loss: 0.32839482982163304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 354] Loss: 0.3284239321491329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 355] Loss: 0.32842926792982713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 356] Loss: 0.32842029820778446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 357] Loss: 0.3284189617337917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 358] Loss: 0.328409781178181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 359] Loss: 0.3283948428479962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 360] Loss: 0.32837667127718617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 361] Loss: 0.3283753206282291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 362] Loss: 0.32838187921771156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 363] Loss: 0.32837429420401654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 364] Loss: 0.3283666857418822\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8947\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 365] Loss: 0.3283670311977839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 366] Loss: 0.32837202344191124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 367] Loss: 0.32835874092768874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 368] Loss: 0.32835812326986086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 369] Loss: 0.3283397357488126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 370] Loss: 0.3283727935180225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 371] Loss: 0.3283757913492117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 372] Loss: 0.32839406785361974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 373] Loss: 0.32838021708728865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 374] Loss: 0.32837133678512453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 375] Loss: 0.3283755424619713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 376] Loss: 0.32836962546989973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 377] Loss: 0.32837404612148446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 378] Loss: 0.32836737426383195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 379] Loss: 0.3283923070641448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 380] Loss: 0.3283907383146566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 381] Loss: 0.3283772169560505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 382] Loss: 0.32837606519328505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 383] Loss: 0.3283767712593673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 384] Loss: 0.3283726317956077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 385] Loss: 0.3283655681261081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 386] Loss: 0.3283718279279561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 387] Loss: 0.3283618189409336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 388] Loss: 0.3283613841891949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 389] Loss: 0.3283661655444423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 390] Loss: 0.32835484413120375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 391] Loss: 0.32835492245872755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 392] Loss: 0.3283685400672748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 393] Loss: 0.32838926119018236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 394] Loss: 0.3283856574715326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 395] Loss: 0.32838783561407964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 396] Loss: 0.32838766629116145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 397] Loss: 0.3284048140848966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 398] Loss: 0.3283941988357537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 399] Loss: 0.32844097996992233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 400] Loss: 0.3284500034135818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 401] Loss: 0.32844701213718885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 402] Loss: 0.3284534021654822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 403] Loss: 0.3284552717985239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 404] Loss: 0.32843709300955026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 405] Loss: 0.32843363285476695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 406] Loss: 0.32843142916367773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 407] Loss: 0.3284477831813112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 408] Loss: 0.3284386915461077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 409] Loss: 0.32843532262601843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 410] Loss: 0.32844157411131236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 411] Loss: 0.32844275533971823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 412] Loss: 0.3284511233335477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 413] Loss: 0.3284361796690285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 414] Loss: 0.3284317093784342\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 415] Loss: 0.328423667408549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 416] Loss: 0.32842356877212797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 417] Loss: 0.32842340464768544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 418] Loss: 0.32841054772899536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 419] Loss: 0.3284098974506407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 420] Loss: 0.3284309457165326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 421] Loss: 0.32841576454467164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 422] Loss: 0.32842116339233146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 423] Loss: 0.3284182732262819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 424] Loss: 0.3284150742815828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 425] Loss: 0.3284168950276076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 426] Loss: 0.32843104625289493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 427] Loss: 0.32842021292389517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 428] Loss: 0.32841773359192317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 429] Loss: 0.32842636399238995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 430] Loss: 0.3284181083576267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 431] Loss: 0.3284298376844523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 432] Loss: 0.3284633170637922\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 433] Loss: 0.3284642639133541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 434] Loss: 0.32845996431049473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 435] Loss: 0.32844288435368757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 436] Loss: 0.32844636845168895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 437] Loss: 0.32843862757815884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 438] Loss: 0.328437458701206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 439] Loss: 0.3284279330670111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 440] Loss: 0.32841709883360526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 441] Loss: 0.3284272434705744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 442] Loss: 0.3284143481737179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 443] Loss: 0.32842210266279626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 444] Loss: 0.3284268998386589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 445] Loss: 0.3284178942735632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 446] Loss: 0.328411886676265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 447] Loss: 0.3284196914585807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 448] Loss: 0.3284244252279622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 449] Loss: 0.32842466734298886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 450] Loss: 0.3284126597302797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 451] Loss: 0.32841500000533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 452] Loss: 0.32842199285587914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 453] Loss: 0.3284236583912005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 454] Loss: 0.32841818681360274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 455] Loss: 0.3284413785478235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 456] Loss: 0.32843852063226553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 457] Loss: 0.3284231802784128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 458] Loss: 0.3284117694286739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 459] Loss: 0.3283950873218942\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 460] Loss: 0.32839317235764376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 461] Loss: 0.32838104466526263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 462] Loss: 0.32839239389523134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 463] Loss: 0.3283809189490237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 464] Loss: 0.328376338143733\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 465] Loss: 0.3283788558653136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 466] Loss: 0.32836335900146646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 467] Loss: 0.32836646004375364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 468] Loss: 0.3283715776080355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 469] Loss: 0.32838064899912334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 470] Loss: 0.3283709014433661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 471] Loss: 0.32835959423321953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 472] Loss: 0.32835325215022876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 473] Loss: 0.3283510387311848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 474] Loss: 0.32834548864772456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 475] Loss: 0.328345007459364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 476] Loss: 0.3283348831783583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 477] Loss: 0.3283238200994406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 478] Loss: 0.32833264881823654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 479] Loss: 0.32833417018318894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 480] Loss: 0.3283560828806225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 481] Loss: 0.32834484075739684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 482] Loss: 0.32834526953097565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 483] Loss: 0.32834517123880225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 484] Loss: 0.3283443890602661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 485] Loss: 0.3283452637447871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 486] Loss: 0.3283346942894934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 487] Loss: 0.3283424007729617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 488] Loss: 0.328327537708903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 489] Loss: 0.32834754060564425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 490] Loss: 0.3283417168190396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 491] Loss: 0.3283330054127666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 492] Loss: 0.3283249757892593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 493] Loss: 0.3283318470000633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 494] Loss: 0.3283300490964413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 495] Loss: 0.32833775874933835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 496] Loss: 0.3283272029710249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 497] Loss: 0.3283242408805312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 498] Loss: 0.32831814997285586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 499] Loss: 0.32829869073944495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 500] Loss: 0.3282985612162944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 501] Loss: 0.3283009070199424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 502] Loss: 0.3282962082758332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 503] Loss: 0.3282823879679327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 504] Loss: 0.3282771573748699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 505] Loss: 0.3282609512714465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 506] Loss: 0.3282467045299819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 507] Loss: 0.3282403109516958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 508] Loss: 0.328248436276446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 509] Loss: 0.3282567428776466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 510] Loss: 0.3282426796544832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 511] Loss: 0.3282319542857813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 512] Loss: 0.32821155595840007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 513] Loss: 0.3281943920751413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 514] Loss: 0.3282048291004742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 515] Loss: 0.3281912451123141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 516] Loss: 0.32818128106311595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 517] Loss: 0.32819480204054147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 518] Loss: 0.32821009833017767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 519] Loss: 0.3282111769769131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 520] Loss: 0.328199467856583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 521] Loss: 0.3281904284059871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 522] Loss: 0.3281955809525325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 523] Loss: 0.32821435502213814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 524] Loss: 0.3282301028143916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 525] Loss: 0.3282302632574964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 526] Loss: 0.32823927064256403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 527] Loss: 0.3282812897633031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 528] Loss: 0.32827075125006333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 529] Loss: 0.32828449184197334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 530] Loss: 0.3282990321026083\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 531] Loss: 0.3282931379374136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 532] Loss: 0.3282874362458513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 533] Loss: 0.32828035798480365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 534] Loss: 0.3282630651963406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 535] Loss: 0.32828468448497483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 536] Loss: 0.32827654422697294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 537] Loss: 0.3282995197222738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 538] Loss: 0.32829805815495977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 539] Loss: 0.3282978915306557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 540] Loss: 0.3282867068792398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 541] Loss: 0.328282951945786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 542] Loss: 0.32829275322153306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 543] Loss: 0.3283059357598521\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 544] Loss: 0.3283119959434761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 545] Loss: 0.3283113014424413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 546] Loss: 0.32832070090202004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 547] Loss: 0.32830951072012793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 548] Loss: 0.32829939469038044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 549] Loss: 0.3282932791807813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 550] Loss: 0.3283017165095175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 551] Loss: 0.3283099538363228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 552] Loss: 0.32829965551061796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 553] Loss: 0.3282829477239939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 554] Loss: 0.32830784299122395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 555] Loss: 0.32829720098719817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 556] Loss: 0.32831256388791247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 557] Loss: 0.32831413446576513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 558] Loss: 0.3283210688834284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 559] Loss: 0.32830925393167426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 560] Loss: 0.3282951628964492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 561] Loss: 0.32828456733580724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 562] Loss: 0.3282918282098609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 563] Loss: 0.3282941526393204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 564] Loss: 0.32828878485004015\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 565] Loss: 0.32830659436842097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 566] Loss: 0.32828694614611614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 567] Loss: 0.32827184827304545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 568] Loss: 0.3282606022771385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 569] Loss: 0.3282672009889507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 570] Loss: 0.3282648439432014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 571] Loss: 0.3282599081685823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 572] Loss: 0.3283092133496157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 573] Loss: 0.32830386962761837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 574] Loss: 0.3282921490534588\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 575] Loss: 0.3282819717881463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 576] Loss: 0.32826724506063054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 577] Loss: 0.3282625231522333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 578] Loss: 0.3282537615087391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 579] Loss: 0.32824660634974456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 580] Loss: 0.3282394487500915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 581] Loss: 0.32824197200499355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 582] Loss: 0.32825040110671894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 583] Loss: 0.3282411353860592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 584] Loss: 0.32823577544158744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 585] Loss: 0.32822939981606464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 586] Loss: 0.32821566866316765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 587] Loss: 0.32820156066462797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 588] Loss: 0.3281972989876096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 589] Loss: 0.32819276890555327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 590] Loss: 0.32819423065682823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 591] Loss: 0.3281880282535729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 592] Loss: 0.3281805435891257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 593] Loss: 0.32817513104265844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 594] Loss: 0.32817304099258915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 595] Loss: 0.32816469167121903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 596] Loss: 0.3281640390838573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 597] Loss: 0.3281527051178891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 598] Loss: 0.3281580107553817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 599] Loss: 0.32815580836615427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 600] Loss: 0.3281481573716108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 601] Loss: 0.32814537880014333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 602] Loss: 0.32812898718800454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 603] Loss: 0.32813010254382957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 604] Loss: 0.3281358375374585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 605] Loss: 0.3281376013543164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 606] Loss: 0.3281460545967568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 607] Loss: 0.3281699022498225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 608] Loss: 0.32816917156048114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 609] Loss: 0.32816167443220345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 610] Loss: 0.32817851823108113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 611] Loss: 0.3281627838285543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 612] Loss: 0.3281572146905295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 613] Loss: 0.3281880114344326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 614] Loss: 0.3281869633555567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 615] Loss: 0.3281727292801632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 616] Loss: 0.3281771766043387\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 617] Loss: 0.3281818415960754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 618] Loss: 0.32819201364139167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 619] Loss: 0.328216645619514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 620] Loss: 0.3282194273055173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 621] Loss: 0.32823666786707795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 622] Loss: 0.3282392267115637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 623] Loss: 0.3282410805775396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 624] Loss: 0.32822660541475857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 625] Loss: 0.3282506321767022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 626] Loss: 0.32824173236763865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 627] Loss: 0.32822168448984956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 628] Loss: 0.328212202612574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 629] Loss: 0.3282171713215227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 630] Loss: 0.3281961517526878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 631] Loss: 0.3281877755171776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 632] Loss: 0.3282014259184136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 633] Loss: 0.3282089886758898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 634] Loss: 0.3282154195188267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 635] Loss: 0.3282288859708426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 636] Loss: 0.32826567069539664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 637] Loss: 0.3282638271093201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 638] Loss: 0.32825147514153685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 639] Loss: 0.3283012091780966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 640] Loss: 0.32830758634952684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 641] Loss: 0.3283054825985745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 642] Loss: 0.3283074311257655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 643] Loss: 0.3282961443492115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 644] Loss: 0.32830155082107193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 645] Loss: 0.32830311291592434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 646] Loss: 0.3282897931094328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 647] Loss: 0.32829562987841726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 648] Loss: 0.3282933113784577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 649] Loss: 0.3282871987969935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 650] Loss: 0.3282742782997228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 651] Loss: 0.3283033182725798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 652] Loss: 0.3283219590577785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 653] Loss: 0.32833396155383154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 654] Loss: 0.32832429414816916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 655] Loss: 0.3283047894736751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 656] Loss: 0.32831923511205185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 657] Loss: 0.3283157172308818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 658] Loss: 0.32830811916355035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 659] Loss: 0.3283187456744789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 660] Loss: 0.32834663970250266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 661] Loss: 0.32833556086546145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 662] Loss: 0.328361226586882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 663] Loss: 0.32834642529087044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 664] Loss: 0.32835866038327755\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 665] Loss: 0.32834508682121977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 666] Loss: 0.32832739294283264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 667] Loss: 0.3283318138944813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 668] Loss: 0.32833624797233135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 669] Loss: 0.328334697747798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 670] Loss: 0.3283433238332774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 671] Loss: 0.32832963923396574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 672] Loss: 0.32833110072092464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 673] Loss: 0.32833086421471147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 674] Loss: 0.32832896335192696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 675] Loss: 0.32831937192356747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 676] Loss: 0.32831337524688575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 677] Loss: 0.3283191292362905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 678] Loss: 0.32830511980954513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 679] Loss: 0.3283094601364172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 680] Loss: 0.3282966018770659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 681] Loss: 0.3282989682639699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 682] Loss: 0.3283066896065927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 683] Loss: 0.3283066081474715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 684] Loss: 0.32831252938786515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 685] Loss: 0.32830557729621296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 686] Loss: 0.3283042170049026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 687] Loss: 0.3283148866885149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 688] Loss: 0.32830682031191066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 689] Loss: 0.3283015059376323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 690] Loss: 0.32828656718225946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 691] Loss: 0.32827552350710815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 692] Loss: 0.3282576028897724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 693] Loss: 0.3282861889342978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 694] Loss: 0.32829482123525616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 695] Loss: 0.32832424751488093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 696] Loss: 0.3283172600385615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 697] Loss: 0.32831330521170704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 698] Loss: 0.32831723443329747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 699] Loss: 0.32832733314522666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 700] Loss: 0.3283265571671417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 701] Loss: 0.3283226108930496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 702] Loss: 0.3283437152239288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 703] Loss: 0.3283473977033344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 704] Loss: 0.32834719020238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 705] Loss: 0.32833960582247973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 706] Loss: 0.3283272729641325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 707] Loss: 0.3283224439157543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 708] Loss: 0.32833624228859026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 709] Loss: 0.32832147701522435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 710] Loss: 0.3283189354810955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 711] Loss: 0.3283294897963272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 712] Loss: 0.32836693719209537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 713] Loss: 0.32837504414393304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 714] Loss: 0.32837360161372064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 715] Loss: 0.3283640191068919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 716] Loss: 0.32836206797038403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 717] Loss: 0.32837671580329547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 718] Loss: 0.32837301458046436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 719] Loss: 0.3283691480572647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 720] Loss: 0.32837199503662395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 721] Loss: 0.32836517229274975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 722] Loss: 0.3283609083766789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 723] Loss: 0.32836548630705376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 724] Loss: 0.3283608742078175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 725] Loss: 0.3283717465336074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 726] Loss: 0.3283713640292829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 727] Loss: 0.3283630001666211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 728] Loss: 0.32836774883665504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 729] Loss: 0.3283692940762543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 730] Loss: 0.32836567948709444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 731] Loss: 0.3283659208774325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 732] Loss: 0.328363772342911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 733] Loss: 0.3283702501404947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 734] Loss: 0.3283664387086389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 735] Loss: 0.3283499836869223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 736] Loss: 0.32835388621980094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 737] Loss: 0.32835612821936966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 738] Loss: 0.3283650251317024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 739] Loss: 0.3283757427031867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 740] Loss: 0.3283638377479555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 741] Loss: 0.32836086324208147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 742] Loss: 0.32834587435403195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 743] Loss: 0.3283404833289669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 744] Loss: 0.32833672875601805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 745] Loss: 0.3283449587920624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 746] Loss: 0.3283393971775242\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 747] Loss: 0.3283285306487153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 748] Loss: 0.32832469419796034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 749] Loss: 0.3283382017763152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 750] Loss: 0.3283354242237927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 751] Loss: 0.32835309648458555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 752] Loss: 0.32835555254749654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 753] Loss: 0.32836245665360436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 754] Loss: 0.32836091672396106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 755] Loss: 0.3283482630042204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 756] Loss: 0.3283397616182198\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 757] Loss: 0.3283470154660406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 758] Loss: 0.32833036654502423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 759] Loss: 0.328313459407914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 760] Loss: 0.3283266454508511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 761] Loss: 0.32831444481483263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 762] Loss: 0.32831092821462876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 763] Loss: 0.32832219007880764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 764] Loss: 0.3283120284534404\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 765] Loss: 0.3283000252126595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 766] Loss: 0.32828638427681356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 767] Loss: 0.3282943037681215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 768] Loss: 0.32829776791373444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 769] Loss: 0.3282996979511382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 770] Loss: 0.3282827096171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 771] Loss: 0.328281096069516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 772] Loss: 0.3282677657345565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 773] Loss: 0.328274721360897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 774] Loss: 0.3282722499601178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 775] Loss: 0.32825684403273153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 776] Loss: 0.328246991496866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 777] Loss: 0.3282329706126511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 778] Loss: 0.32822286266075823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 779] Loss: 0.3282212601031415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 780] Loss: 0.32823462258548486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 781] Loss: 0.3282282746518195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 782] Loss: 0.32822931687145784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 783] Loss: 0.32823490774508113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 784] Loss: 0.32824303290052737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 785] Loss: 0.3282675922962352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 786] Loss: 0.3282835474070768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 787] Loss: 0.3282861648220727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 788] Loss: 0.328274704389452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 789] Loss: 0.32827372476300465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 790] Loss: 0.32827492883001946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 791] Loss: 0.32828162199358063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 792] Loss: 0.3282948282393902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 793] Loss: 0.32829209555450073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 794] Loss: 0.32829175311126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 795] Loss: 0.3282912751230031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 796] Loss: 0.32828787519941777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 797] Loss: 0.3282931121656557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 798] Loss: 0.32827980301259496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 799] Loss: 0.32828123715515484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 800] Loss: 0.3282743887619547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 801] Loss: 0.3282623733463909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 802] Loss: 0.3282614476984304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 803] Loss: 0.3282589855990609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 804] Loss: 0.3282428565250149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 805] Loss: 0.3282373370837481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 806] Loss: 0.3282429538560686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 807] Loss: 0.32823318479782265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 808] Loss: 0.3282358038711005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 809] Loss: 0.32824207083961987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 810] Loss: 0.3282482657943174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 811] Loss: 0.3282559731546206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 812] Loss: 0.3282408154700557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 813] Loss: 0.328242824404801\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 814] Loss: 0.3282458554800005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 815] Loss: 0.32822786106432816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 816] Loss: 0.32820980064117705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 817] Loss: 0.3282003076559889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 818] Loss: 0.32819951992621815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 819] Loss: 0.32819049762618646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 820] Loss: 0.32820287728232106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 821] Loss: 0.328215230253168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 822] Loss: 0.3282205860363541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 823] Loss: 0.32820949371329194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 824] Loss: 0.328217036881938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 825] Loss: 0.3282049966263824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 826] Loss: 0.3281884114615738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 827] Loss: 0.3281746912906647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 828] Loss: 0.32817726113449247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 829] Loss: 0.32816750016838736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 830] Loss: 0.328162228553823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 831] Loss: 0.3281456884704955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 832] Loss: 0.32815555352644854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 833] Loss: 0.32815457617327054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 834] Loss: 0.32815285411002254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 835] Loss: 0.32816142767488427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 836] Loss: 0.32815592023745066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 837] Loss: 0.32814659543236346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 838] Loss: 0.3281502815043077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 839] Loss: 0.32815555128421825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 840] Loss: 0.3281458738074532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 841] Loss: 0.32813314342406336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 842] Loss: 0.32812676888290543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 843] Loss: 0.32813841309241226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 844] Loss: 0.3281244284553614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 845] Loss: 0.3281221428767799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 846] Loss: 0.32812582095687204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 847] Loss: 0.328118373309539\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 848] Loss: 0.32812703676879185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 849] Loss: 0.3281178025702761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 850] Loss: 0.3281071307912156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 851] Loss: 0.3281089237727803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 852] Loss: 0.3281067404689911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 853] Loss: 0.3281357595797145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 854] Loss: 0.32815591718782905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 855] Loss: 0.32814594080732107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 856] Loss: 0.32818922672425055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 857] Loss: 0.3281862403862359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 858] Loss: 0.3281902098989976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 859] Loss: 0.3281802470272481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 860] Loss: 0.32817569081549447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 861] Loss: 0.3281856731316132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 862] Loss: 0.3281745968490654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 863] Loss: 0.32818993519089723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 864] Loss: 0.3282126116971884\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8951\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 865] Loss: 0.32819623828884603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 866] Loss: 0.3282072094122974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 867] Loss: 0.32820249377022365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 868] Loss: 0.3282023554339589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 869] Loss: 0.32820695970586017\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 870] Loss: 0.32819096589124175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 871] Loss: 0.32819859691741565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 872] Loss: 0.32819400300803725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 873] Loss: 0.3281871902837676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 874] Loss: 0.32818581159731375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 875] Loss: 0.32816541628932455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 876] Loss: 0.3281593971188595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 877] Loss: 0.3281495673153201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 878] Loss: 0.32817426231727437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 879] Loss: 0.3281680488525982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 880] Loss: 0.32815011145735506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 881] Loss: 0.3281485299973346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 882] Loss: 0.3281631593949868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 883] Loss: 0.3281805687646593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 884] Loss: 0.3281717925501613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 885] Loss: 0.32817919758504316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 886] Loss: 0.32817733997505877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 887] Loss: 0.3281675785074323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 888] Loss: 0.3281540130966605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 889] Loss: 0.3281453590493617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 890] Loss: 0.3281615874723696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 891] Loss: 0.3281759972903818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 892] Loss: 0.32816769781996763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 893] Loss: 0.3281643434866465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 894] Loss: 0.32816866015761936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 895] Loss: 0.3281726183043812\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 896] Loss: 0.3281755255929736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 897] Loss: 0.32817199778648726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 898] Loss: 0.32816793210902134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 899] Loss: 0.3281555059451872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 900] Loss: 0.32814882365761905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 901] Loss: 0.3281544554235738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 902] Loss: 0.3281499209080256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 903] Loss: 0.32814712724892475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 904] Loss: 0.32813751948912456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 905] Loss: 0.3281287590958829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 906] Loss: 0.32811774719043135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 907] Loss: 0.32810456971563745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 908] Loss: 0.3280885071460023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 909] Loss: 0.3280785302956437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 910] Loss: 0.32807209204585436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 911] Loss: 0.3280795606248827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 912] Loss: 0.32808380206335475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 913] Loss: 0.32808180210087934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 914] Loss: 0.3281059850222989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 915] Loss: 0.3280952431727981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 916] Loss: 0.32809581348022643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 917] Loss: 0.32810785895985917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 918] Loss: 0.328102050954013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 919] Loss: 0.32809607669252666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 920] Loss: 0.32808480545702223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 921] Loss: 0.32808840830681163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 922] Loss: 0.32809373711361794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 923] Loss: 0.32808898620572424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 924] Loss: 0.3280754580629344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 925] Loss: 0.3280834245875936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 926] Loss: 0.32810210899838366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 927] Loss: 0.3280921774043455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 928] Loss: 0.3280905050947538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 929] Loss: 0.3280845998903024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 930] Loss: 0.328102192417717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 931] Loss: 0.32809960028004015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 932] Loss: 0.3280979510654052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 933] Loss: 0.3281033570404274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 934] Loss: 0.3281139297504844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 935] Loss: 0.3281168471819441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 936] Loss: 0.32811070156999605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 937] Loss: 0.32812824249594424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 938] Loss: 0.3281387366677389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 939] Loss: 0.3281478000720753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 940] Loss: 0.3281426141691056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 941] Loss: 0.32813584280940655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 942] Loss: 0.3281346301674868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 943] Loss: 0.3281436285863403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 944] Loss: 0.3281459955300472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 945] Loss: 0.32813667916609013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 946] Loss: 0.32812799606715215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 947] Loss: 0.3281354263155894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 948] Loss: 0.3281258604670479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 949] Loss: 0.3281419560003885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 950] Loss: 0.32815278193118663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 951] Loss: 0.3281560953377024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 952] Loss: 0.3281513070614809\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 953] Loss: 0.3281426763004692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 954] Loss: 0.3281272044062565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 955] Loss: 0.32811847358267815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 956] Loss: 0.32813617604098577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 957] Loss: 0.32813125176788965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 958] Loss: 0.32813019389330317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 959] Loss: 0.3281227242614625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 960] Loss: 0.3281123387836237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 961] Loss: 0.3280954850015913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 962] Loss: 0.32809213000758264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 963] Loss: 0.3281062050016286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 964] Loss: 0.3281202132064481\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 965] Loss: 0.328118582560113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 966] Loss: 0.3281318959844531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 967] Loss: 0.3281147927301829\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 968] Loss: 0.32811452855066603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 969] Loss: 0.3281016754734561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 970] Loss: 0.3280938912775944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 971] Loss: 0.3280931228467827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 972] Loss: 0.32807718747186787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 973] Loss: 0.32807140559903913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 974] Loss: 0.32807017598061244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 975] Loss: 0.32808085726252384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 976] Loss: 0.32808064329587594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 977] Loss: 0.3280844956269092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 978] Loss: 0.3280696568819798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 979] Loss: 0.3280745972615795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 980] Loss: 0.3280690042647736\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 981] Loss: 0.3280668077453193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 982] Loss: 0.32805966937374037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 983] Loss: 0.3280820697476301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 984] Loss: 0.32807682115162945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 985] Loss: 0.3280600983540312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 986] Loss: 0.3280689926849177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 987] Loss: 0.32805712087620253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 988] Loss: 0.32805059211052856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 989] Loss: 0.32806021746409775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 990] Loss: 0.3280495013134235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 991] Loss: 0.32803529581518576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 992] Loss: 0.3280212697988421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 993] Loss: 0.328025825582406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 994] Loss: 0.3280128712847391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 995] Loss: 0.3280221105288665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 996] Loss: 0.3280283704038091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 997] Loss: 0.3280160567141839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 998] Loss: 0.32800348004762164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 999] Loss: 0.3280172548057715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1000] Loss: 0.32801565075407413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1001] Loss: 0.3280452607966021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1002] Loss: 0.3280327853249408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1003] Loss: 0.3280319696385027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1004] Loss: 0.3280306556116693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1005] Loss: 0.3280127872267629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1006] Loss: 0.32799699533752763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1007] Loss: 0.32800050785557233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1008] Loss: 0.3279967349905187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1009] Loss: 0.32798573285381427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1010] Loss: 0.32798023572641666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1011] Loss: 0.3280170916959606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1012] Loss: 0.3280022263284458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1013] Loss: 0.3280295025491653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1014] Loss: 0.32803607535660545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1015] Loss: 0.32803809402184003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1016] Loss: 0.32802310364071374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1017] Loss: 0.32802545217446394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1018] Loss: 0.3280209529012488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1019] Loss: 0.3280272184668206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1020] Loss: 0.32802180081075105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1021] Loss: 0.32803344699176334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1022] Loss: 0.3280385359473783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1023] Loss: 0.32805002163362923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1024] Loss: 0.3280607725317872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1025] Loss: 0.32805920749998346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1026] Loss: 0.32804548183463195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1027] Loss: 0.3280487836235271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1028] Loss: 0.32805690087081235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1029] Loss: 0.32804661434002724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1030] Loss: 0.3280465094174362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1031] Loss: 0.32803910807696784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1032] Loss: 0.32803802737693205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1033] Loss: 0.3280294700278183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1034] Loss: 0.32800920353167157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1035] Loss: 0.32800168887695885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1036] Loss: 0.3280066050389591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1037] Loss: 0.3279993879499639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1038] Loss: 0.3279914538566148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1039] Loss: 0.3279988181967105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1040] Loss: 0.3280101570886768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1041] Loss: 0.3280046331351898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1042] Loss: 0.32799676570955516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1043] Loss: 0.32799367145519737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1044] Loss: 0.3279918825082414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1045] Loss: 0.3279868631491519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1046] Loss: 0.327971890029349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1047] Loss: 0.327960925329075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1048] Loss: 0.32796372940122437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1049] Loss: 0.32798239409588176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1050] Loss: 0.3279936591339601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1051] Loss: 0.32798643712212755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1052] Loss: 0.3279861342432957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1053] Loss: 0.32796950711569794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1054] Loss: 0.327968462372162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1055] Loss: 0.3279707809280584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1056] Loss: 0.3280087835555609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1057] Loss: 0.3280160291585783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1058] Loss: 0.3280224979146662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1059] Loss: 0.3280099232753327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1060] Loss: 0.3280119071607493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1061] Loss: 0.32802509974283417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1062] Loss: 0.3280202577798769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1063] Loss: 0.3280244127845334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1064] Loss: 0.3280063213836396\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1065] Loss: 0.32801958804992737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1066] Loss: 0.3280021984532889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1067] Loss: 0.32799210337275503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1068] Loss: 0.32798826816016285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1069] Loss: 0.32798138705987845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1070] Loss: 0.32797124971364794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1071] Loss: 0.3279701265301916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1072] Loss: 0.3279547739406793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1073] Loss: 0.32795460246787256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1074] Loss: 0.32796818145550116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1075] Loss: 0.32797544805756484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1076] Loss: 0.32797792609974713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1077] Loss: 0.3279797133125038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1078] Loss: 0.327977593804504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1079] Loss: 0.32797552014790404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1080] Loss: 0.3279626908851735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1081] Loss: 0.32795127157300535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1082] Loss: 0.32795970537989627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1083] Loss: 0.3279652480733554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1084] Loss: 0.32796369635489186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1085] Loss: 0.3279503855208229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1086] Loss: 0.3279549054051272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1087] Loss: 0.3279571002230496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1088] Loss: 0.3279539664338671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1089] Loss: 0.3279412301295938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1090] Loss: 0.3279451257385979\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1091] Loss: 0.32794086746396617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1092] Loss: 0.32793943108166584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1093] Loss: 0.32793478444524926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1094] Loss: 0.32793969113248406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1095] Loss: 0.32793641603711426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1096] Loss: 0.327952666300199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1097] Loss: 0.32794454507568005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1098] Loss: 0.3279335403961283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1099] Loss: 0.32791476799504204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1100] Loss: 0.32791284938970605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1101] Loss: 0.3279153026876067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1102] Loss: 0.32790044851510086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1103] Loss: 0.327896409938437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1104] Loss: 0.32789178441733063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1105] Loss: 0.3278947500219472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1106] Loss: 0.32790237760229984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1107] Loss: 0.32791549686957244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1108] Loss: 0.3279189664218718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1109] Loss: 0.32793236202557496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1110] Loss: 0.32792255520206043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1111] Loss: 0.32790794276972873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1112] Loss: 0.32792397979171184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1113] Loss: 0.32791792913507195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1114] Loss: 0.3279191482647506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1115] Loss: 0.32792806687632653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1116] Loss: 0.32791497501671946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1117] Loss: 0.32792182301925615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1118] Loss: 0.32791542353491365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1119] Loss: 0.3279138168464398\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1120] Loss: 0.32790119677134516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1121] Loss: 0.32789428600918125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1122] Loss: 0.32789974193972315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1123] Loss: 0.3279041553870393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1124] Loss: 0.3279028163444079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1125] Loss: 0.32789096815438695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1126] Loss: 0.3278860359716999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1127] Loss: 0.3278864584428238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1128] Loss: 0.3278881303702814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1129] Loss: 0.3278723553032104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1130] Loss: 0.3278986255098502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1131] Loss: 0.3278878088254881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1132] Loss: 0.3278772683637037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1133] Loss: 0.3279166665473455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1134] Loss: 0.3279028772589507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1135] Loss: 0.3278983834463031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1136] Loss: 0.3278959051847982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1137] Loss: 0.3279071949111347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1138] Loss: 0.32790806211550216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1139] Loss: 0.3279074330146557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1140] Loss: 0.3279136003528415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1141] Loss: 0.32790858971439246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1142] Loss: 0.3279113570226886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1143] Loss: 0.3279000945092162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1144] Loss: 0.3278956627401822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1145] Loss: 0.3278814125467153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1146] Loss: 0.32789178498391663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1147] Loss: 0.3278832409282627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1148] Loss: 0.3278739925871775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1149] Loss: 0.327878247797276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1150] Loss: 0.32786593842298734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1151] Loss: 0.3278584274420348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1152] Loss: 0.3278615964883523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1153] Loss: 0.3278468044902806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1154] Loss: 0.32784411721536494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1155] Loss: 0.3278553602628081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1156] Loss: 0.3278383588720595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1157] Loss: 0.3278393457752662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1158] Loss: 0.3278556084750014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1159] Loss: 0.3278428266488895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1160] Loss: 0.32785138720451623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1161] Loss: 0.32783691960938804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1162] Loss: 0.3278474439392103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1163] Loss: 0.3278446381850814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1164] Loss: 0.3278423832046622\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1165] Loss: 0.3278314018836011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1166] Loss: 0.3278257680149951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1167] Loss: 0.32783698474875106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1168] Loss: 0.3278498000731765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1169] Loss: 0.32786451185674126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1170] Loss: 0.3278581337116114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1171] Loss: 0.3278481098975178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1172] Loss: 0.3278377116757961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1173] Loss: 0.3278281991110847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1174] Loss: 0.32783259638584106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1175] Loss: 0.3278202831758816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1176] Loss: 0.3278138175527765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1177] Loss: 0.32782060713325983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1178] Loss: 0.3278088492842821\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1179] Loss: 0.3278123046178143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1180] Loss: 0.32781047974033417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1181] Loss: 0.32783037265256143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1182] Loss: 0.3278128604253534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1183] Loss: 0.32781069686071085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1184] Loss: 0.32781673427308944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1185] Loss: 0.327807722880608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1186] Loss: 0.32782250736904256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1187] Loss: 0.3278101681411594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1188] Loss: 0.3278027232207415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1189] Loss: 0.3278039355523264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1190] Loss: 0.32779009972979606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1191] Loss: 0.32778990908162375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1192] Loss: 0.3277748863621432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1193] Loss: 0.32780607299138304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1194] Loss: 0.32780957193564886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1195] Loss: 0.32781652958671115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1196] Loss: 0.32780160867060404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1197] Loss: 0.327808943482217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1198] Loss: 0.32782143768572725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1199] Loss: 0.32780698543144055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1200] Loss: 0.3277977368661552\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1201] Loss: 0.3277958503262217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1202] Loss: 0.3277825184544299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1203] Loss: 0.32776978489965564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1204] Loss: 0.327757787984139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1205] Loss: 0.327754768119204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1206] Loss: 0.32776835902860757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1207] Loss: 0.3277916639751109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1208] Loss: 0.32779238189747034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1209] Loss: 0.32777904136522185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1210] Loss: 0.32777101236305783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1211] Loss: 0.32776561043445385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1212] Loss: 0.3277715894935736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1213] Loss: 0.32776912307905665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1214] Loss: 0.3277769260272594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1215] Loss: 0.3277789024803281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1216] Loss: 0.32779657752029573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1217] Loss: 0.3277987061725842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1218] Loss: 0.32779056255600286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1219] Loss: 0.3277764319247179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1220] Loss: 0.3277862061431505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1221] Loss: 0.32777712191743213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1222] Loss: 0.3277699795859268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1223] Loss: 0.32777702976509354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1224] Loss: 0.3277790433030295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1225] Loss: 0.3277798608856556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1226] Loss: 0.3277844068531295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1227] Loss: 0.32777285229245506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1228] Loss: 0.3277634304751313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1229] Loss: 0.32776491235154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1230] Loss: 0.3277785658158284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1231] Loss: 0.3277654306155965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1232] Loss: 0.32775611301159496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1233] Loss: 0.3277450506938687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1234] Loss: 0.32774511172653464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1235] Loss: 0.32775312346425906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1236] Loss: 0.32775536903470626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1237] Loss: 0.32774087456702966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1238] Loss: 0.3277500572679918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1239] Loss: 0.32775843557711193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1240] Loss: 0.3277844887445955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1241] Loss: 0.3277867124590357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1242] Loss: 0.3277762597629459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1243] Loss: 0.32777624895140106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1244] Loss: 0.3277826589334169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1245] Loss: 0.32777071745786873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1246] Loss: 0.3277803010915161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1247] Loss: 0.3277798241433261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1248] Loss: 0.3277746261093251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1249] Loss: 0.3277708669487954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1250] Loss: 0.3277803068810832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1251] Loss: 0.3277744213985671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1252] Loss: 0.3277725868830426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1253] Loss: 0.3277668722169766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1254] Loss: 0.32775147310683633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1255] Loss: 0.32773297334830265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1256] Loss: 0.32773298485661906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1257] Loss: 0.32775354543439134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1258] Loss: 0.3277436125505868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1259] Loss: 0.32774548733602415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1260] Loss: 0.32773336446774876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1261] Loss: 0.32773471120906783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1262] Loss: 0.32774927811073357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1263] Loss: 0.32774376848957154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1264] Loss: 0.3277402653968126\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1265] Loss: 0.32772334972729444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1266] Loss: 0.3277131783242095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1267] Loss: 0.3277147731951382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1268] Loss: 0.32771816677529064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1269] Loss: 0.327710157402827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1270] Loss: 0.3277079300764857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1271] Loss: 0.3276942633069844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1272] Loss: 0.3277056713229785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1273] Loss: 0.32769387448667037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1274] Loss: 0.32769030899759644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1275] Loss: 0.32769710586885104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1276] Loss: 0.3277039037799241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1277] Loss: 0.3276924338106826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1278] Loss: 0.3277220557696941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1279] Loss: 0.32771605555645855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1280] Loss: 0.3277048702069356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1281] Loss: 0.3276908484072148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1282] Loss: 0.32772057922599246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1283] Loss: 0.3277173537648313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1284] Loss: 0.3277190991107248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1285] Loss: 0.3277297874237171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1286] Loss: 0.3277374754141658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1287] Loss: 0.32774010697114686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1288] Loss: 0.32774176989529535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1289] Loss: 0.3277361043707308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1290] Loss: 0.32774419830914076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1291] Loss: 0.3277586439450322\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1292] Loss: 0.327770507820262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1293] Loss: 0.32776787612448405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1294] Loss: 0.32778311375119323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1295] Loss: 0.3277742682460679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1296] Loss: 0.3277642106586541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1297] Loss: 0.3277691111249093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1298] Loss: 0.3277643423383117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1299] Loss: 0.32775963842643846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1300] Loss: 0.32776773129251985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1301] Loss: 0.327765915833727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1302] Loss: 0.327770362943126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1303] Loss: 0.32778443786534867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1304] Loss: 0.327772878925843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1305] Loss: 0.32781275217066325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1306] Loss: 0.32781911161189153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1307] Loss: 0.3278205008002497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1308] Loss: 0.32784331789368537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1309] Loss: 0.32783070056297137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1310] Loss: 0.32781942408279857\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1311] Loss: 0.32781940157355605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1312] Loss: 0.3278342778725664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1313] Loss: 0.3278424485761616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1314] Loss: 0.32785715360942047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1315] Loss: 0.3278554784848244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1316] Loss: 0.3278806133845709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1317] Loss: 0.3279163913098844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1318] Loss: 0.32792445344056154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1319] Loss: 0.3279203634107446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1320] Loss: 0.32790474452589413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1321] Loss: 0.3278989863255927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1322] Loss: 0.327891586769422\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1323] Loss: 0.3278858463934447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1324] Loss: 0.327911516508087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1325] Loss: 0.32790253125542473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1326] Loss: 0.32789623496311204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1327] Loss: 0.3278911293655131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1328] Loss: 0.32788353790321123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1329] Loss: 0.32787824359845974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1330] Loss: 0.327863611576938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1331] Loss: 0.32785281185942733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1332] Loss: 0.3278724861010193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1333] Loss: 0.3278629257804233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1334] Loss: 0.3278537191127047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1335] Loss: 0.3278614320705215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1336] Loss: 0.32786454279250277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1337] Loss: 0.3278552773941763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1338] Loss: 0.32784171656483696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1339] Loss: 0.3278451495241514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1340] Loss: 0.3278360830068624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1341] Loss: 0.327850282085452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1342] Loss: 0.32785577884145317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1343] Loss: 0.32784084070824787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1344] Loss: 0.32785156968405865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1345] Loss: 0.32784746931143666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1346] Loss: 0.3278570203016352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1347] Loss: 0.3278775630445661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1348] Loss: 0.32787134319275213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1349] Loss: 0.32788292191222823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1350] Loss: 0.32789101230065076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1351] Loss: 0.3278852217503617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1352] Loss: 0.3279189181064972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1353] Loss: 0.32791269095437425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1354] Loss: 0.3279049247122959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1355] Loss: 0.32789919059425354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1356] Loss: 0.32792607790447625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1357] Loss: 0.32791658841656496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1358] Loss: 0.32790498667848056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1359] Loss: 0.3278982596104445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1360] Loss: 0.32789447276031447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1361] Loss: 0.32790469958376683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1362] Loss: 0.32789656642762194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1363] Loss: 0.32788822116479277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1364] Loss: 0.3278832320187607\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8913\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1365] Loss: 0.3278706692117461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1366] Loss: 0.3278702179251713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1367] Loss: 0.3278704929593407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1368] Loss: 0.32786137894101286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1369] Loss: 0.3278773197512936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1370] Loss: 0.3278693234259651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1371] Loss: 0.32785690099456544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1372] Loss: 0.3278632477038997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1373] Loss: 0.32786271133935535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1374] Loss: 0.32784880471850547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1375] Loss: 0.3278528448488955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1376] Loss: 0.3278492618644974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1377] Loss: 0.3278415821811111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1378] Loss: 0.3278309471693208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1379] Loss: 0.32782649776166356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1380] Loss: 0.3278129919217984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1381] Loss: 0.32782234863505844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1382] Loss: 0.32782210184391153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1383] Loss: 0.3278181021568364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1384] Loss: 0.3278158316718653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1385] Loss: 0.32782990772613885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1386] Loss: 0.32781473009482026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1387] Loss: 0.3277979433865057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1388] Loss: 0.32780320759500353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1389] Loss: 0.32780936822955087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1390] Loss: 0.32780117944285675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1391] Loss: 0.32780152291734116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1392] Loss: 0.32778902213899025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1393] Loss: 0.32778857241079196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1394] Loss: 0.32778060235630513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1395] Loss: 0.3277782129303536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1396] Loss: 0.3277803502771192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1397] Loss: 0.32778790300217836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1398] Loss: 0.32778552699561253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1399] Loss: 0.3277671355234467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1400] Loss: 0.32775899559657296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1401] Loss: 0.3277483154648648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1402] Loss: 0.3277500235854196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1403] Loss: 0.32774082107090974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1404] Loss: 0.3277392399685338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1405] Loss: 0.3277452692109034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1406] Loss: 0.327759218720561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1407] Loss: 0.3277460983329408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1408] Loss: 0.32775902524479233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1409] Loss: 0.3277668669818349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1410] Loss: 0.3277678579155801\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1411] Loss: 0.3277800196943401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1412] Loss: 0.32777589346988484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1413] Loss: 0.3277665059965345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1414] Loss: 0.3277612370344824\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1415] Loss: 0.32775611460425325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1416] Loss: 0.3277485919109295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1417] Loss: 0.3277530050413175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1418] Loss: 0.32774590957541183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1419] Loss: 0.3277622670025617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1420] Loss: 0.32775818927409317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1421] Loss: 0.32774334378299025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1422] Loss: 0.3277382430091733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1423] Loss: 0.3277241759468796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1424] Loss: 0.32774017331996763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1425] Loss: 0.32773151375683585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1426] Loss: 0.3277329363319055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1427] Loss: 0.3277415415969498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1428] Loss: 0.3277444096484767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1429] Loss: 0.32775041204669025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1430] Loss: 0.3277452652684636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1431] Loss: 0.3277432141114392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1432] Loss: 0.3277342167450508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1433] Loss: 0.3277470662028278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1434] Loss: 0.32777949531793166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1435] Loss: 0.3277749953158289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1436] Loss: 0.32778105197203833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1437] Loss: 0.3277719543604463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1438] Loss: 0.3277753947501443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1439] Loss: 0.32777612727562816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1440] Loss: 0.3277676979258584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1441] Loss: 0.3277622918977426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1442] Loss: 0.3277945179702543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1443] Loss: 0.32778790182847944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1444] Loss: 0.32779272177879587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1445] Loss: 0.32779289168752607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1446] Loss: 0.3278022663362807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1447] Loss: 0.3277980045248111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1448] Loss: 0.32780121207665736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1449] Loss: 0.3278087865751094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1450] Loss: 0.3278108695862645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1451] Loss: 0.32780739441469703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1452] Loss: 0.32781497832760254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1453] Loss: 0.32780545324722177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1454] Loss: 0.32778977259983216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1455] Loss: 0.32777344285954546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1456] Loss: 0.3277750175232565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1457] Loss: 0.3277912711662268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1458] Loss: 0.32778391735854273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1459] Loss: 0.32777149513402215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1460] Loss: 0.32775360602556014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1461] Loss: 0.3277507976537165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1462] Loss: 0.32775250022284924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1463] Loss: 0.3277439526409501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1464] Loss: 0.32773995621126367\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1465] Loss: 0.32775012502777556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1466] Loss: 0.3277386659454865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1467] Loss: 0.32772197798469643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1468] Loss: 0.32775425157633703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1469] Loss: 0.32777387087115223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1470] Loss: 0.3277722351489664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1471] Loss: 0.3277652229196796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1472] Loss: 0.3277625924530729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1473] Loss: 0.327789881871875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1474] Loss: 0.32780406440743326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1475] Loss: 0.32780960779504476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1476] Loss: 0.32781031439212527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1477] Loss: 0.3278041843310903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1478] Loss: 0.3278632926479814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1479] Loss: 0.327898829906572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1480] Loss: 0.3278864503733087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1481] Loss: 0.3278959117164122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1482] Loss: 0.32788834491272856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1483] Loss: 0.32788129660113174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1484] Loss: 0.32786997599957335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1485] Loss: 0.32786503283064417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1486] Loss: 0.3278620743018759\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1487] Loss: 0.32785804264677204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1488] Loss: 0.3278604543702102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1489] Loss: 0.32785406473486195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1490] Loss: 0.3278526410451644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1491] Loss: 0.3278378171730039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1492] Loss: 0.3278312914714148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1493] Loss: 0.3278354770802734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1494] Loss: 0.32786544648739774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1495] Loss: 0.32788587524160373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1496] Loss: 0.32790547862779845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1497] Loss: 0.32790208290670547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1498] Loss: 0.3279074434310448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1499] Loss: 0.3279215781173971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1500] Loss: 0.32793214780107527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1501] Loss: 0.3279276027412698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1502] Loss: 0.3279363765683573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1503] Loss: 0.32794103583861034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1504] Loss: 0.32795150736202655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1505] Loss: 0.3279591238372626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1506] Loss: 0.32794628855284297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1507] Loss: 0.32795348705221494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1508] Loss: 0.32794814227821795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1509] Loss: 0.32795855937763924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1510] Loss: 0.32794882055558133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1511] Loss: 0.32793786230537075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1512] Loss: 0.3279783713676939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1513] Loss: 0.3279787349473373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1514] Loss: 0.3279993789694941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1515] Loss: 0.3280108460710275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1516] Loss: 0.3280166119511734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1517] Loss: 0.3280112758060187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1518] Loss: 0.32800531272653993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1519] Loss: 0.32800704580975615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1520] Loss: 0.3280239377053068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1521] Loss: 0.3280242272176114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1522] Loss: 0.3280225623106027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1523] Loss: 0.3280333221318039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 26, Batch 1524] Loss: 0.3280200910319225\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 0] Loss: 0.32802033925506335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1] Loss: 0.3280240967928407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 2] Loss: 0.3280387126350616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 3] Loss: 0.3280488670509963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 4] Loss: 0.328049551717572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 5] Loss: 0.3280520817598164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 6] Loss: 0.3280569758320434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 7] Loss: 0.3280472656396336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 8] Loss: 0.3280353283115838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 9] Loss: 0.32803152803312935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 10] Loss: 0.3280447101915593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 11] Loss: 0.3280384998717667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 12] Loss: 0.32804863671097534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 13] Loss: 0.32803487866384684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 14] Loss: 0.32802649492869423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 15] Loss: 0.32802117652543183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 16] Loss: 0.3280100987660121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 17] Loss: 0.32800517056874035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 18] Loss: 0.3280142094310527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 19] Loss: 0.3280057885889255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 20] Loss: 0.3280001042190843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 21] Loss: 0.32799742924131625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 22] Loss: 0.3279908779351581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 23] Loss: 0.3280118543235882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 24] Loss: 0.3280091190448438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 25] Loss: 0.32803010791423126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 26] Loss: 0.3280335201925339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 27] Loss: 0.32804073813879664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 28] Loss: 0.32802524420490325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 29] Loss: 0.32801445740988905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 30] Loss: 0.32802847180635414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 31] Loss: 0.32801860948882205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 32] Loss: 0.32800621673762975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 33] Loss: 0.3280105513391277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 34] Loss: 0.328021083008856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 35] Loss: 0.3280350992362371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 36] Loss: 0.3280468418234223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 37] Loss: 0.32804334014128184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 38] Loss: 0.328041511424178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 39] Loss: 0.32803856129930153\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 40] Loss: 0.32803169947203015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 41] Loss: 0.328019820698468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 42] Loss: 0.3280194823271279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 43] Loss: 0.32801085734399493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 44] Loss: 0.3279975478139702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 45] Loss: 0.32798463420544055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 46] Loss: 0.32800075158018466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 47] Loss: 0.3280023241149059\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 48] Loss: 0.32799761392738047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 49] Loss: 0.32800604337714184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 50] Loss: 0.327993780579542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 51] Loss: 0.32798034475559495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 52] Loss: 0.32798199467572514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 53] Loss: 0.3279815194853894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 54] Loss: 0.3279724899575861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 55] Loss: 0.3279818574146561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 56] Loss: 0.32800459355060474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 57] Loss: 0.32801696471414266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 58] Loss: 0.32802530164573407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 59] Loss: 0.3280162933370848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 60] Loss: 0.3280123809486995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 61] Loss: 0.3280233415562463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 62] Loss: 0.3280141625417825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 63] Loss: 0.32802908740518727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 64] Loss: 0.3280227977375205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 65] Loss: 0.3280330262353335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 66] Loss: 0.3280543818899405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 67] Loss: 0.3280547502061782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 68] Loss: 0.3280533378738054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 69] Loss: 0.32806264649442696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 70] Loss: 0.32804621929744077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 71] Loss: 0.32806677491835784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 72] Loss: 0.32805518224654845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 73] Loss: 0.3280514592032754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 74] Loss: 0.3280410378226583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 75] Loss: 0.3280355757888586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 76] Loss: 0.32802820147687767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 77] Loss: 0.3280157161986983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 78] Loss: 0.32800843183867984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 79] Loss: 0.3280307560374862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 80] Loss: 0.3280300146175755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 81] Loss: 0.3280179936071107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 82] Loss: 0.328011119128734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 83] Loss: 0.3280335018661268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 84] Loss: 0.32802429520904075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 85] Loss: 0.3280134162593553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 86] Loss: 0.32801970472133296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 87] Loss: 0.32801548372825096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 88] Loss: 0.3280297796282826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 89] Loss: 0.32801140646910204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 90] Loss: 0.32800037079315214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 91] Loss: 0.32798446199739434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 92] Loss: 0.3280137955789297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 93] Loss: 0.32800778065772246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 94] Loss: 0.32799491724696783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 95] Loss: 0.3279909395096222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 96] Loss: 0.3279835086074006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 97] Loss: 0.3279801206555221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 98] Loss: 0.32801692326849086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 99] Loss: 0.3280022458772645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 100] Loss: 0.32802559840713436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 101] Loss: 0.3280177481866691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 102] Loss: 0.3280162777096927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 103] Loss: 0.3279970235777842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 104] Loss: 0.327998067338884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 105] Loss: 0.3279837953011841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 106] Loss: 0.327978529792858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 107] Loss: 0.32797042136633336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 108] Loss: 0.32797291045745486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 109] Loss: 0.32797286136901177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 110] Loss: 0.32796746383513964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 111] Loss: 0.32796553434011916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 112] Loss: 0.32796168063000547\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 113] Loss: 0.3279512040610731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 114] Loss: 0.3279344724312152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 115] Loss: 0.3279329813582558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 116] Loss: 0.32792247606593244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 117] Loss: 0.3279328832595088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 118] Loss: 0.32793083835741077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 119] Loss: 0.32792255808602466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 120] Loss: 0.32791696895878386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 121] Loss: 0.327902179301585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 122] Loss: 0.3278889061056457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 123] Loss: 0.3278742182577879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 124] Loss: 0.3278596525779673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 125] Loss: 0.3278464699017187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 126] Loss: 0.32783868841603864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 127] Loss: 0.32783916767475524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 128] Loss: 0.3278430658704859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 129] Loss: 0.3278412667558592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 130] Loss: 0.3278310366236962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 131] Loss: 0.32783163764667755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 132] Loss: 0.3278165249208617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 133] Loss: 0.32783005917503627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 134] Loss: 0.32783077477398614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 135] Loss: 0.3278158124526508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 136] Loss: 0.3278220460711636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 137] Loss: 0.32782788385229905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 138] Loss: 0.3278329966680228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 139] Loss: 0.3278468565677407\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 140] Loss: 0.32785701708822224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 141] Loss: 0.3278684248925586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 142] Loss: 0.3278706525127051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 143] Loss: 0.32786567541637335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 144] Loss: 0.32785510339093005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 145] Loss: 0.3278496064924472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 146] Loss: 0.3278485608110432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 147] Loss: 0.32785755353465273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 148] Loss: 0.3278649312600306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 149] Loss: 0.32785354303121106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 150] Loss: 0.3278408796758419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 151] Loss: 0.3278345888124559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 152] Loss: 0.3278262702300668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 153] Loss: 0.3278357536084607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 154] Loss: 0.32782783921549447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 155] Loss: 0.3278112189454823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 156] Loss: 0.32780151538165253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 157] Loss: 0.32783691772862755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 158] Loss: 0.3278304671153946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 159] Loss: 0.32786480194014894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 160] Loss: 0.32786135478214085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 161] Loss: 0.32787539112302877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 162] Loss: 0.3278954846879012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 163] Loss: 0.3279086685923918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 164] Loss: 0.3278980063450918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 165] Loss: 0.32788760288200686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 166] Loss: 0.32788089545419125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 167] Loss: 0.32788167861210477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 168] Loss: 0.3278862582178857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 169] Loss: 0.32789225505280734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 170] Loss: 0.32788767488301956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 171] Loss: 0.3278800522715508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 172] Loss: 0.3278708559424348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 173] Loss: 0.3278859445271021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 174] Loss: 0.3278963914156917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 175] Loss: 0.3279241544682029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 176] Loss: 0.32792058021398063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 177] Loss: 0.32790153793718935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 178] Loss: 0.3279106969406515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 179] Loss: 0.3279133886711278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 180] Loss: 0.3279273627515723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 181] Loss: 0.3279336010164706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 182] Loss: 0.3279238791649402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 183] Loss: 0.32791226732163337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 184] Loss: 0.32792557613870493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 185] Loss: 0.32791003920487116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 186] Loss: 0.3279227509433681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 187] Loss: 0.3279098399686853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 188] Loss: 0.3279142262444692\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 189] Loss: 0.32794736946274633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 190] Loss: 0.32794628046392543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 191] Loss: 0.3279457071062552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 192] Loss: 0.32794055565673574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 193] Loss: 0.3279473400177845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 194] Loss: 0.3279458378388033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 195] Loss: 0.32796887706174255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 196] Loss: 0.3279690661405212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 197] Loss: 0.3279617135150919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 198] Loss: 0.32795349418699854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 199] Loss: 0.3279396423252206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 200] Loss: 0.32793448512154616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 201] Loss: 0.32793913637347677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 202] Loss: 0.32794653599206913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 203] Loss: 0.3279360734900299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 204] Loss: 0.32793563864327363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 205] Loss: 0.3279337777902676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 206] Loss: 0.32796673057097825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 207] Loss: 0.3279822150593623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 208] Loss: 0.3279800136393096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 209] Loss: 0.3279719997311257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 210] Loss: 0.32796424509999816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 211] Loss: 0.32794939833469194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 212] Loss: 0.3279374304822019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 213] Loss: 0.3279397807688598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 214] Loss: 0.3279294288934782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 215] Loss: 0.3279176550326153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 216] Loss: 0.3279031534268404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 217] Loss: 0.32790637915261805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 218] Loss: 0.32790653303279926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 219] Loss: 0.32789275370622206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 220] Loss: 0.32789940162459746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 221] Loss: 0.32790222876028646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 222] Loss: 0.3278973854809873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 223] Loss: 0.32789463675834263\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 224] Loss: 0.32788143279064996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 225] Loss: 0.32789039596394487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 226] Loss: 0.3278983791420092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 227] Loss: 0.3278832357946598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 228] Loss: 0.3278702412614522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 229] Loss: 0.32786301949788604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 230] Loss: 0.3278650371730614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 231] Loss: 0.32785535885353906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 232] Loss: 0.3278753671408766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 233] Loss: 0.3278833209156646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 234] Loss: 0.3279071411167362\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 235] Loss: 0.32789833135483665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 236] Loss: 0.3278974887892922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 237] Loss: 0.32788296592331284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 238] Loss: 0.32788362392224374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 239] Loss: 0.327874916915555\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 240] Loss: 0.327863353505298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 241] Loss: 0.3278604109518106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 242] Loss: 0.32787908984134057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 243] Loss: 0.3278630437879881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 244] Loss: 0.3278599048690993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 245] Loss: 0.3278542740403478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 246] Loss: 0.3278386806339014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 247] Loss: 0.3278292737087366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 248] Loss: 0.32783727000944324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 249] Loss: 0.32782961918453857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 250] Loss: 0.32784522187481396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 251] Loss: 0.3278443373208097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 252] Loss: 0.3278422775821961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 253] Loss: 0.32784917436779776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 254] Loss: 0.3278460658939352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 255] Loss: 0.3278427986630016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 256] Loss: 0.32786451592572274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 257] Loss: 0.32785237635028075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 258] Loss: 0.3278653117786957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 259] Loss: 0.32785658812528035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 260] Loss: 0.32786580573140467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 261] Loss: 0.3278611135343541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 262] Loss: 0.32786781654256475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 263] Loss: 0.32786666953949617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 264] Loss: 0.32785223277867037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 265] Loss: 0.3278697038351078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 266] Loss: 0.3278504865351917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 267] Loss: 0.32784252578348155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 268] Loss: 0.3278500123762044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 269] Loss: 0.3278659747927944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 270] Loss: 0.327875415765269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 271] Loss: 0.3278628116414461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 272] Loss: 0.3278707228515291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 273] Loss: 0.3278701456921433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 274] Loss: 0.32785860816821394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 275] Loss: 0.3278652512210247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 276] Loss: 0.3278579469188451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 277] Loss: 0.3278579298831149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 278] Loss: 0.3278650983561444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 279] Loss: 0.3278630145251631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 280] Loss: 0.3278617126036994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 281] Loss: 0.32786534201019535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 282] Loss: 0.3278778820355326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 283] Loss: 0.3278683799435329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 284] Loss: 0.3278587728591856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 285] Loss: 0.32784687845506905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 286] Loss: 0.3278500484637802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 287] Loss: 0.3278471695430165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 288] Loss: 0.32783953367736923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 289] Loss: 0.32783659175002694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 290] Loss: 0.3278924642252628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 291] Loss: 0.32789964746481765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 292] Loss: 0.32789031382324435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 293] Loss: 0.3278855390372828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 294] Loss: 0.3278756598267183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 295] Loss: 0.32787822076438594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 296] Loss: 0.3279016344997014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 297] Loss: 0.327888001789069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 298] Loss: 0.3278970402076014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 299] Loss: 0.3279120918449156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 300] Loss: 0.3279312492916733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 301] Loss: 0.3279335362437771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 302] Loss: 0.3279331101066168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 303] Loss: 0.327928864196249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 304] Loss: 0.3279306051041379\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 305] Loss: 0.32793991950099355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 306] Loss: 0.3279543470315148\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 307] Loss: 0.32794715420204473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 308] Loss: 0.32792669757631354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 309] Loss: 0.32793526677837254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 310] Loss: 0.32796050513460606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 311] Loss: 0.32798821515221654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 312] Loss: 0.3280165742606875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 313] Loss: 0.3279993145384766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 314] Loss: 0.32799912343010074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 315] Loss: 0.3280169029310424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 316] Loss: 0.3280210871314145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 317] Loss: 0.3280477167471286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 318] Loss: 0.328052293380566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 319] Loss: 0.32806057828580615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 320] Loss: 0.32808939643677604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 321] Loss: 0.32808046769782534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 322] Loss: 0.3280732900093287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 323] Loss: 0.32805938402712204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 324] Loss: 0.328074880159614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 325] Loss: 0.32806590676685643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 326] Loss: 0.3280569607303865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 327] Loss: 0.3280447776197523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 328] Loss: 0.32803645194699016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 329] Loss: 0.32804465399773286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 330] Loss: 0.32804486675246886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 331] Loss: 0.32807025047178706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 332] Loss: 0.3280606409909329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 333] Loss: 0.3280799574038993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 334] Loss: 0.3280835386526078\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 335] Loss: 0.32809167959607305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 336] Loss: 0.3281273956895499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 337] Loss: 0.32812919907668553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 338] Loss: 0.32811600027552673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 339] Loss: 0.3281062051565883\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8912000000000001\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 340] Loss: 0.3281024890596913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 341] Loss: 0.328113360081294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 342] Loss: 0.3281398919749344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 343] Loss: 0.32813438903159153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 344] Loss: 0.32814404227487726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 345] Loss: 0.328127460504782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 346] Loss: 0.32811478769238633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 347] Loss: 0.3281033549474449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 348] Loss: 0.32809670392625906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 349] Loss: 0.3281625095110175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 350] Loss: 0.3281536641774509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 351] Loss: 0.3281519776324467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 352] Loss: 0.32815673202347095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 353] Loss: 0.3281569704881068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 354] Loss: 0.32815437990294954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 355] Loss: 0.32814484498236607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 356] Loss: 0.3281457474762314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 357] Loss: 0.32813624196000307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 358] Loss: 0.3281465618350603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 359] Loss: 0.32814132146308567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 360] Loss: 0.3281590275103897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 361] Loss: 0.32815813042232655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 362] Loss: 0.328166513603587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 363] Loss: 0.32816038872382985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 364] Loss: 0.32815403512847324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 365] Loss: 0.32815496474108125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 366] Loss: 0.32816908057527133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 367] Loss: 0.32819012062115843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 368] Loss: 0.3281898244147004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 369] Loss: 0.328201060707685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 370] Loss: 0.32820324481956936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 371] Loss: 0.3281987491324169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 372] Loss: 0.328188530787421\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 373] Loss: 0.3281860797161676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 374] Loss: 0.3281776646616032\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 375] Loss: 0.32819859243917365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 376] Loss: 0.32819685345937344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 377] Loss: 0.3281890028365333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 378] Loss: 0.3281840231354424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 379] Loss: 0.32820538959824014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 380] Loss: 0.32820696674825867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 381] Loss: 0.32819756916453396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 382] Loss: 0.32820321035632166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 383] Loss: 0.32819412638150214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 384] Loss: 0.32818691777593495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 385] Loss: 0.3281810234162246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 386] Loss: 0.32819692971404524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 387] Loss: 0.3282174850231449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 388] Loss: 0.328237702186215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 389] Loss: 0.32822636496683466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 390] Loss: 0.32824846145353076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 391] Loss: 0.32823467902831416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 392] Loss: 0.32823494725989666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 393] Loss: 0.32824455854072215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 394] Loss: 0.32823587532320025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 395] Loss: 0.32821994229263346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 396] Loss: 0.32822556844569334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 397] Loss: 0.32823278224327673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 398] Loss: 0.32823718976525756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 399] Loss: 0.3282389681112212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 400] Loss: 0.3282361201098292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 401] Loss: 0.3282519992556263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 402] Loss: 0.32827210749137337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 403] Loss: 0.3282765901806622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 404] Loss: 0.32826405062639713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 405] Loss: 0.3282626315519838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 406] Loss: 0.32828412640890575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 407] Loss: 0.32828337503622695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 408] Loss: 0.3282804912987078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 409] Loss: 0.32826782715570374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 410] Loss: 0.32825544535919227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 411] Loss: 0.32824706795534575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 412] Loss: 0.32827049953690746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 413] Loss: 0.3282586564134199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 414] Loss: 0.3282601449662557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 415] Loss: 0.32826997458560037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 416] Loss: 0.32827659033057166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 417] Loss: 0.3282834954052017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 418] Loss: 0.32827898304282715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 419] Loss: 0.3282936768557543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 420] Loss: 0.32828381579095417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 421] Loss: 0.3282854477603449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 422] Loss: 0.32828363259016724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 423] Loss: 0.3282957853780189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 424] Loss: 0.32829825780636845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 425] Loss: 0.3283093884162224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 426] Loss: 0.3282936259753746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 427] Loss: 0.3283008073355177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 428] Loss: 0.3282931102438002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 429] Loss: 0.32829184756393465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 430] Loss: 0.3282914989046876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 431] Loss: 0.3282740200443949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 432] Loss: 0.328291322803872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 433] Loss: 0.32829880025053204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 434] Loss: 0.3283037282828848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 435] Loss: 0.3283088543635388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 436] Loss: 0.3283046924202065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 437] Loss: 0.328292915378413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 438] Loss: 0.32829991068831593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 439] Loss: 0.32832163701419187\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 440] Loss: 0.32833676816081464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 441] Loss: 0.3283258181957381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 442] Loss: 0.3283062500556666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 443] Loss: 0.3282975969106338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 444] Loss: 0.32829248831490965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 445] Loss: 0.3282759183417383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 446] Loss: 0.3282650922323952\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 447] Loss: 0.328254039254391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 448] Loss: 0.32824410839492596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 449] Loss: 0.3282587374323118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 450] Loss: 0.3282699251110054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 451] Loss: 0.3282527169434714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 452] Loss: 0.32825811430727647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 453] Loss: 0.3282657324193897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 454] Loss: 0.32825314882614937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 455] Loss: 0.32824519152196996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 456] Loss: 0.3282450159780441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 457] Loss: 0.32825948208800615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 458] Loss: 0.32825097626254046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 459] Loss: 0.32824601304628187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 460] Loss: 0.3282418904650337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 461] Loss: 0.3282663251874665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 462] Loss: 0.32827938048390626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 463] Loss: 0.3282891338060884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 464] Loss: 0.328282222061306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 465] Loss: 0.3282791074746425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 466] Loss: 0.32827515906514443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 467] Loss: 0.32827850149695403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 468] Loss: 0.32827244398945477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 469] Loss: 0.3282885796513733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 470] Loss: 0.3282837205194357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 471] Loss: 0.32829588073646765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 472] Loss: 0.32829960953610293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 473] Loss: 0.32830288148663334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 474] Loss: 0.3282977775735385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 475] Loss: 0.32829281297941637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 476] Loss: 0.3282810338822035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 477] Loss: 0.3282994953841069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 478] Loss: 0.32829603609047775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 479] Loss: 0.32829609810647836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 480] Loss: 0.32830435504656924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 481] Loss: 0.32829129202990537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 482] Loss: 0.32827745967890054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 483] Loss: 0.3282641645277706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 484] Loss: 0.3282532345257922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 485] Loss: 0.32825447419313486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 486] Loss: 0.3282531004442444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 487] Loss: 0.3282396760446912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 488] Loss: 0.32823939127471524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 489] Loss: 0.3282612399268504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 490] Loss: 0.3282592080378226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 491] Loss: 0.32827520067718324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 492] Loss: 0.32827592210682266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 493] Loss: 0.3282741685720018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 494] Loss: 0.3282581896768665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 495] Loss: 0.3282827498020559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 496] Loss: 0.32828417460862835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 497] Loss: 0.3282940271042706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 498] Loss: 0.3282951379408029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 499] Loss: 0.3282909871633488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 500] Loss: 0.3282826194482714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 501] Loss: 0.32827063783210897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 502] Loss: 0.3282712232314514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 503] Loss: 0.32826685969797703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 504] Loss: 0.32826672369862575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 505] Loss: 0.3282737830983639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 506] Loss: 0.3282652366389585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 507] Loss: 0.3282567276176366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 508] Loss: 0.32825321553531606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 509] Loss: 0.3282417055209288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 510] Loss: 0.32825066570982875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 511] Loss: 0.3282810443073196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 512] Loss: 0.3282788524183247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 513] Loss: 0.32828487064924955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 514] Loss: 0.3282911386885204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 515] Loss: 0.328280254552999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 516] Loss: 0.328285445815912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 517] Loss: 0.3282910609327069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 518] Loss: 0.32828049691610234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 519] Loss: 0.32828030477159087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 520] Loss: 0.32826383664166187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 521] Loss: 0.32826095347526446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 522] Loss: 0.3282688462431011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 523] Loss: 0.328261060597158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 524] Loss: 0.32825509018899013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 525] Loss: 0.32826166329210843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 526] Loss: 0.32825380692489914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 527] Loss: 0.328257095869932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 528] Loss: 0.32825361638215794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 529] Loss: 0.32824273894524153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 530] Loss: 0.3282542564706536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 531] Loss: 0.3282543192020549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 532] Loss: 0.32826218458161815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 533] Loss: 0.328253363067299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 534] Loss: 0.32824838575304516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 535] Loss: 0.32824543251440863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 536] Loss: 0.3282384617377061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 537] Loss: 0.32826059106335215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 538] Loss: 0.32826177023908243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 539] Loss: 0.3282556836049018\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 540] Loss: 0.32825135099547553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 541] Loss: 0.3282391275445858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 542] Loss: 0.32823388825096916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 543] Loss: 0.32823213118710065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 544] Loss: 0.32822863079291537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 545] Loss: 0.3282394388505666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 546] Loss: 0.3282235500353695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 547] Loss: 0.32821075388745485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 548] Loss: 0.3281995397440247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 549] Loss: 0.32818858908881837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 550] Loss: 0.32819275496857236\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 551] Loss: 0.3281818051995221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 552] Loss: 0.32820022207213156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 553] Loss: 0.3282082043049272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 554] Loss: 0.3282127199634025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 555] Loss: 0.328201584199549\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 556] Loss: 0.3281964443562847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 557] Loss: 0.3281934489260159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 558] Loss: 0.3282132053949328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 559] Loss: 0.3282265865857527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 560] Loss: 0.32822480031237566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 561] Loss: 0.328241990905755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 562] Loss: 0.32822729407676626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 563] Loss: 0.32821221003790835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 564] Loss: 0.32820511125229573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 565] Loss: 0.3282011559529474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 566] Loss: 0.32820131661166213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 567] Loss: 0.32819410394753934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 568] Loss: 0.32821492369235505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 569] Loss: 0.3282280789130877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 570] Loss: 0.3282207184552069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 571] Loss: 0.3282195669916029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 572] Loss: 0.3282074591355582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 573] Loss: 0.328202984923116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 574] Loss: 0.3282135209608573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 575] Loss: 0.32822132979032104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 576] Loss: 0.3282253654119655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 577] Loss: 0.3282243330380261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 578] Loss: 0.32821506550344787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 579] Loss: 0.32820630249250937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 580] Loss: 0.32819932113047684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 581] Loss: 0.32819219590423493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 582] Loss: 0.3282166809455248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 583] Loss: 0.32821243184632953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 584] Loss: 0.3282042606498872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 585] Loss: 0.32819530607376296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 586] Loss: 0.3281964599208613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 587] Loss: 0.3282007056197706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 588] Loss: 0.32821828942174136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 589] Loss: 0.3282061817126045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 590] Loss: 0.32819919236949535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 591] Loss: 0.3281889160628885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 592] Loss: 0.3281928046987705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 593] Loss: 0.32819043358901334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 594] Loss: 0.3281845650069385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 595] Loss: 0.3281817724994925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 596] Loss: 0.3281771918953706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 597] Loss: 0.32818133093001883\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 598] Loss: 0.3281875387090345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 599] Loss: 0.3281738565587862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 600] Loss: 0.32817365877196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 601] Loss: 0.32816147549585106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 602] Loss: 0.32815613861558096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 603] Loss: 0.32814515932418553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 604] Loss: 0.32815366996770207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 605] Loss: 0.3281598215440228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 606] Loss: 0.3281857865394811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 607] Loss: 0.328186455262035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 608] Loss: 0.3282121149340546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 609] Loss: 0.32822636568165015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 610] Loss: 0.3282278072811052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 611] Loss: 0.3282289097965134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 612] Loss: 0.32822683234551253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 613] Loss: 0.3282186251456942\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 614] Loss: 0.3282144398566089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 615] Loss: 0.3282026150887349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 616] Loss: 0.32820007800267853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 617] Loss: 0.32818607989636783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 618] Loss: 0.32818532838988945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 619] Loss: 0.3281774637453046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 620] Loss: 0.32817399060998703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 621] Loss: 0.3281615474636619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 622] Loss: 0.3281647465751404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 623] Loss: 0.3281688194799655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 624] Loss: 0.3281707119762389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 625] Loss: 0.32815448830738736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 626] Loss: 0.32814817308128147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 627] Loss: 0.3281776528193993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 628] Loss: 0.3281658717839391\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 629] Loss: 0.3281605175694846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 630] Loss: 0.32816588688984216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 631] Loss: 0.32815445706429147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 632] Loss: 0.3281643430296693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 633] Loss: 0.328162090236001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 634] Loss: 0.32816275505320747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 635] Loss: 0.32819458264490076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 636] Loss: 0.32818922790943483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 637] Loss: 0.328186118987873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 638] Loss: 0.32819022356015115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 639] Loss: 0.32820029283381646\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 640] Loss: 0.32820416406111524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 641] Loss: 0.3281948891460846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 642] Loss: 0.3282013206409276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 643] Loss: 0.32818682920058423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 644] Loss: 0.32817572264051453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 645] Loss: 0.32816545855613466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 646] Loss: 0.32816641236952526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 647] Loss: 0.32817678130699224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 648] Loss: 0.3281875510240847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 649] Loss: 0.32822212565770564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 650] Loss: 0.3282163640269903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 651] Loss: 0.32821806448287927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 652] Loss: 0.32824847812292224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 653] Loss: 0.32824562961546516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 654] Loss: 0.3282347715483185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 655] Loss: 0.3282458590280054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 656] Loss: 0.32825458439383476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 657] Loss: 0.328242654722707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 658] Loss: 0.3282362706360171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 659] Loss: 0.3282264831038095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 660] Loss: 0.32821503058323753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 661] Loss: 0.3282200847384527\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 662] Loss: 0.3282228039896993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 663] Loss: 0.3282338626424655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 664] Loss: 0.3282305274007998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 665] Loss: 0.3282135417797597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 666] Loss: 0.3282396609364762\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 667] Loss: 0.32822576567622824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 668] Loss: 0.32821243884091783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 669] Loss: 0.32820902952248343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 670] Loss: 0.3282083899403153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 671] Loss: 0.3282102005033351\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 672] Loss: 0.32820643436659497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 673] Loss: 0.3282070809340059\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 674] Loss: 0.32820231461365995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 675] Loss: 0.32819590467711796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 676] Loss: 0.32818619377772223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 677] Loss: 0.3282061854271016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 678] Loss: 0.32820250723730926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 679] Loss: 0.3282175816959115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 680] Loss: 0.32821026434470774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 681] Loss: 0.3282119532208606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 682] Loss: 0.3282118673326069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 683] Loss: 0.32820299826098676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 684] Loss: 0.3281886427419917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 685] Loss: 0.32819618500038983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 686] Loss: 0.32820610641941406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 687] Loss: 0.3282045258154341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 688] Loss: 0.328200252232601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 689] Loss: 0.32824007287290546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 690] Loss: 0.32823680221850454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 691] Loss: 0.32823355559568235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 692] Loss: 0.32822309921852394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 693] Loss: 0.32821264261545424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 694] Loss: 0.32821596068293735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 695] Loss: 0.3282057426254306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 696] Loss: 0.3282047417244709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 697] Loss: 0.32819359723894687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 698] Loss: 0.32821087168107704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 699] Loss: 0.32820174003004665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 700] Loss: 0.3282058086644778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 701] Loss: 0.32821128171986336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 702] Loss: 0.3282153968101255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 703] Loss: 0.3282004595385737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 704] Loss: 0.32820291137612484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 705] Loss: 0.32819902378076066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 706] Loss: 0.32819484945977595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 707] Loss: 0.3282005989478334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 708] Loss: 0.3281860044388839\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 709] Loss: 0.3281901117450903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 710] Loss: 0.3282008312040881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 711] Loss: 0.32819689813496644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 712] Loss: 0.3282169728014527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 713] Loss: 0.3282082029423494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 714] Loss: 0.32820006424808446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 715] Loss: 0.3281966205009908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 716] Loss: 0.3281927298152407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 717] Loss: 0.3281814587020087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 718] Loss: 0.32817301104351987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 719] Loss: 0.32816952091251683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 720] Loss: 0.32816602135831285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 721] Loss: 0.3281685006841134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 722] Loss: 0.3281640965130094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 723] Loss: 0.3281508130008987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 724] Loss: 0.32817105153151543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 725] Loss: 0.3281638067812097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 726] Loss: 0.32815153297983946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 727] Loss: 0.32815099412872833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 728] Loss: 0.32815055538266485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 729] Loss: 0.32814273169703223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 730] Loss: 0.3281396690980448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 731] Loss: 0.3281314322313012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 732] Loss: 0.32816326738221835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 733] Loss: 0.32816711916062963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 734] Loss: 0.3281681684034544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 735] Loss: 0.3281587563038715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 736] Loss: 0.3281443358174561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 737] Loss: 0.32813739438980194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 738] Loss: 0.3281273660152604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 739] Loss: 0.3281393486447\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 740] Loss: 0.32814246179425616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 741] Loss: 0.3281366376968728\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 742] Loss: 0.3281479789496223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 743] Loss: 0.3281598291290238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 744] Loss: 0.32815095746960415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 745] Loss: 0.3281475737598024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 746] Loss: 0.32814320608451664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 747] Loss: 0.32815633229627894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 748] Loss: 0.32814438242455013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 749] Loss: 0.32813123508300435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 750] Loss: 0.32813034507669947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 751] Loss: 0.3281351386863098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 752] Loss: 0.3281347044194566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 753] Loss: 0.3281444213400453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 754] Loss: 0.32813750479415404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 755] Loss: 0.32815711374063683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 756] Loss: 0.3281529364050701\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 757] Loss: 0.328141891300045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 758] Loss: 0.32815861636670407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 759] Loss: 0.3281498463736896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 760] Loss: 0.3281645645660165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 761] Loss: 0.3281523607740153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 762] Loss: 0.328153873165283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 763] Loss: 0.32815239739840857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 764] Loss: 0.3281769169814668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 765] Loss: 0.32818076769395443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 766] Loss: 0.32818113813056754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 767] Loss: 0.3281640565386356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 768] Loss: 0.32816956930155616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 769] Loss: 0.3281650953229976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 770] Loss: 0.3281494245291618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 771] Loss: 0.3281358428000259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 772] Loss: 0.3281723802896649\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 773] Loss: 0.32817079623472106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 774] Loss: 0.328154493483695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 775] Loss: 0.32814339291118033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 776] Loss: 0.3281527251518771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 777] Loss: 0.32814680969655724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 778] Loss: 0.3281556132486196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 779] Loss: 0.3281476162915397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 780] Loss: 0.32813708955979376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 781] Loss: 0.32813667495630566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 782] Loss: 0.3281356194036147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 783] Loss: 0.3281426629426818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 784] Loss: 0.32813697698392164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 785] Loss: 0.32812725424268335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 786] Loss: 0.328133557453904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 787] Loss: 0.32813848228933756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 788] Loss: 0.3281376600653341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 789] Loss: 0.3281236959116316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 790] Loss: 0.328111944067747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 791] Loss: 0.3281095479427544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 792] Loss: 0.3281043486903298\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 793] Loss: 0.3280967189297454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 794] Loss: 0.3280878691155737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 795] Loss: 0.3280710608013259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 796] Loss: 0.32806792118975686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 797] Loss: 0.3280561604037458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 798] Loss: 0.32804794204047455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 799] Loss: 0.328055769372988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 800] Loss: 0.3280629965612117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 801] Loss: 0.3280599912417682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 802] Loss: 0.32807195476850576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 803] Loss: 0.3280701838009063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 804] Loss: 0.32806364409442085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 805] Loss: 0.3280827756656915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 806] Loss: 0.32807263742349796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 807] Loss: 0.32808465289174615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 808] Loss: 0.3280794775210246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 809] Loss: 0.3280909282151345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 810] Loss: 0.3280791678940222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 811] Loss: 0.3280721578160045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 812] Loss: 0.3280732576859732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 813] Loss: 0.32807488895562353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 814] Loss: 0.32809022274044813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 815] Loss: 0.328086059898548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 816] Loss: 0.32811919765573727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 817] Loss: 0.3281390600925055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 818] Loss: 0.32813395235504283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 819] Loss: 0.32812197330764775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 820] Loss: 0.32811359469911977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 821] Loss: 0.3281207251461121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 822] Loss: 0.3281224566774317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 823] Loss: 0.3281120733362629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 824] Loss: 0.3281145476255123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 825] Loss: 0.32809865068706334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 826] Loss: 0.32809707793957393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 827] Loss: 0.32808820117698567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 828] Loss: 0.32810703083411796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 829] Loss: 0.32810943098248174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 830] Loss: 0.32811057527672927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 831] Loss: 0.3281012477015523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 832] Loss: 0.3280991579390546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 833] Loss: 0.3281013526262994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 834] Loss: 0.3281028367864919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 835] Loss: 0.3280899860144388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 836] Loss: 0.32810061269631646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 837] Loss: 0.32810815670837845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 838] Loss: 0.3281115860891613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 839] Loss: 0.32813670787323324\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8989\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 840] Loss: 0.32815433465793575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 841] Loss: 0.32816939523349964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 842] Loss: 0.3281695052679399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 843] Loss: 0.3281584899792992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 844] Loss: 0.32814731753316007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 845] Loss: 0.3281391635374693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 846] Loss: 0.3281473576403927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 847] Loss: 0.3281465257032494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 848] Loss: 0.3281385230331882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 849] Loss: 0.32814023369147965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 850] Loss: 0.32814113492984426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 851] Loss: 0.3281475573820097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 852] Loss: 0.3281659016262896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 853] Loss: 0.32816135662350393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 854] Loss: 0.32815481728103796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 855] Loss: 0.3281688137752419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 856] Loss: 0.32817895415704446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 857] Loss: 0.32817453509550776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 858] Loss: 0.32816005454427427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 859] Loss: 0.3281734386068076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 860] Loss: 0.3281678839716293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 861] Loss: 0.32816472896214655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 862] Loss: 0.3281770573857312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 863] Loss: 0.3281846655151741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 864] Loss: 0.32817037211609107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 865] Loss: 0.3281602901935718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 866] Loss: 0.32815884192949474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 867] Loss: 0.32816551174667524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 868] Loss: 0.3281718420724326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 869] Loss: 0.32816754185543373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 870] Loss: 0.32816046455900705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 871] Loss: 0.3281564097495294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 872] Loss: 0.32816468445337377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 873] Loss: 0.32815599204203527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 874] Loss: 0.3281644624585354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 875] Loss: 0.3281871589153662\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 876] Loss: 0.3281935420697972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 877] Loss: 0.3281891169530162\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 878] Loss: 0.3281986228426568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 879] Loss: 0.3281832625638174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 880] Loss: 0.3281752627023783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 881] Loss: 0.3281734926837095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 882] Loss: 0.328173830979077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 883] Loss: 0.328179432737741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 884] Loss: 0.3281819505956636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 885] Loss: 0.32816923283444516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 886] Loss: 0.3281652427350618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 887] Loss: 0.3281756124211141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 888] Loss: 0.3281831013475338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 889] Loss: 0.3281841519298073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 890] Loss: 0.3281718653782129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 891] Loss: 0.32817064191497936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 892] Loss: 0.32816503930621904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 893] Loss: 0.3281643172233205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 894] Loss: 0.32817288120135707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 895] Loss: 0.3281662209318108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 896] Loss: 0.32816804259231214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 897] Loss: 0.3281828496352179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 898] Loss: 0.328179622148492\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 899] Loss: 0.32819184016083713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 900] Loss: 0.3282027946621088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 901] Loss: 0.32821509880977245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 902] Loss: 0.32821469511486595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 903] Loss: 0.3282070296446608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 904] Loss: 0.32819201666427505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 905] Loss: 0.3281963286305213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 906] Loss: 0.32822531872547767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 907] Loss: 0.328214953363491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 908] Loss: 0.32819916352414286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 909] Loss: 0.3282077520212209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 910] Loss: 0.3282002772781944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 911] Loss: 0.3281857704470057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 912] Loss: 0.3281775640607343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 913] Loss: 0.3281610180461111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 914] Loss: 0.3281480499821402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 915] Loss: 0.32815316901212244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 916] Loss: 0.3281651926345452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 917] Loss: 0.3281545781613913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 918] Loss: 0.3281476814723456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 919] Loss: 0.3281543797599625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 920] Loss: 0.3281790233712843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 921] Loss: 0.3281930322114079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 922] Loss: 0.32819259158449565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 923] Loss: 0.3281788122260092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 924] Loss: 0.32817967594323144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 925] Loss: 0.32816575741565207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 926] Loss: 0.3281629619035402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 927] Loss: 0.3281606672247201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 928] Loss: 0.32815914414117636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 929] Loss: 0.3281638960633402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 930] Loss: 0.32823790810206954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 931] Loss: 0.3282661681708842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 932] Loss: 0.32827142327392617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 933] Loss: 0.32827440881618997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 934] Loss: 0.3282687052481397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 935] Loss: 0.3282605474822326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 936] Loss: 0.3282554142155622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 937] Loss: 0.32825028669639195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 938] Loss: 0.32824323266006267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 939] Loss: 0.3282415010776673\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 940] Loss: 0.32825579727177595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 941] Loss: 0.32824930278707665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 942] Loss: 0.3282561799335516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 943] Loss: 0.3282498176525381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 944] Loss: 0.32825834830518824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 945] Loss: 0.3282676067938145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 946] Loss: 0.32825380252177205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 947] Loss: 0.3282513402128093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 948] Loss: 0.32824590015623295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 949] Loss: 0.3282594252640943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 950] Loss: 0.3282524634754759\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 951] Loss: 0.32827768561840165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 952] Loss: 0.3282747099225322\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 953] Loss: 0.3282691269288501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 954] Loss: 0.32826466108436053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 955] Loss: 0.32825063395864235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 956] Loss: 0.3282688737423552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 957] Loss: 0.3282622303745013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 958] Loss: 0.32826073251115223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 959] Loss: 0.32827080485618926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 960] Loss: 0.3282595851676828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 961] Loss: 0.32824762376611594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 962] Loss: 0.3282617163596255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 963] Loss: 0.3282548349205028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 964] Loss: 0.32825885624505086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 965] Loss: 0.32826114767999826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 966] Loss: 0.32829602762298843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 967] Loss: 0.32829030541712645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 968] Loss: 0.3282928590912971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 969] Loss: 0.32830464075332105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 970] Loss: 0.3283227082058129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 971] Loss: 0.32831884238447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 972] Loss: 0.32831502336361623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 973] Loss: 0.3282992925707353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 974] Loss: 0.32829037295111146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 975] Loss: 0.3282741015186438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 976] Loss: 0.328268328256481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 977] Loss: 0.3282918738802745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 978] Loss: 0.3282790778937149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 979] Loss: 0.32827776733786873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 980] Loss: 0.32826908760934964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 981] Loss: 0.32825679120729784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 982] Loss: 0.3282492617105066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 983] Loss: 0.32825282287669855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 984] Loss: 0.32824438158004926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 985] Loss: 0.3282394745067394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 986] Loss: 0.3282476306438799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 987] Loss: 0.32828252289284826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 988] Loss: 0.32829065187429096\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 989] Loss: 0.3283068203187643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 990] Loss: 0.3282935307735318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 991] Loss: 0.3283029924645602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 992] Loss: 0.3283195429482735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 993] Loss: 0.32832882942465696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 994] Loss: 0.3283135529177436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 995] Loss: 0.32832292167382543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 996] Loss: 0.3283199165427069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 997] Loss: 0.3283230657438478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 998] Loss: 0.32833157732989304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 999] Loss: 0.3283171269469562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1000] Loss: 0.32833290509872914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1001] Loss: 0.3283184596393192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1002] Loss: 0.3283222245732513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1003] Loss: 0.32831560844231017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1004] Loss: 0.32831005592011925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1005] Loss: 0.32830029107470793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1006] Loss: 0.32832449337902525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1007] Loss: 0.328352611023312\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1008] Loss: 0.32835623451250945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1009] Loss: 0.32834498554057306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1010] Loss: 0.3283393574432419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1011] Loss: 0.32832947530697276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1012] Loss: 0.32833945097414075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1013] Loss: 0.32834338996167683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1014] Loss: 0.32834179964151206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1015] Loss: 0.3283468124134986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1016] Loss: 0.3283478980765645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1017] Loss: 0.3283650634858815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1018] Loss: 0.32835649406480766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1019] Loss: 0.3283543711706933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1020] Loss: 0.32837058841433237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1021] Loss: 0.3283710005472195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1022] Loss: 0.3283831950387676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1023] Loss: 0.32837803269943383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1024] Loss: 0.32837138744395833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1025] Loss: 0.32835316241967666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1026] Loss: 0.32834271656353964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1027] Loss: 0.32834302648383884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1028] Loss: 0.3283580840159943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1029] Loss: 0.32834554842844926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1030] Loss: 0.3283395656564934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1031] Loss: 0.3283335822708036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1032] Loss: 0.3283341472560122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1033] Loss: 0.32833227110247143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1034] Loss: 0.32834298011859153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1035] Loss: 0.3283339670541628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1036] Loss: 0.32834052254904444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1037] Loss: 0.3283568189514089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1038] Loss: 0.32836998705818715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1039] Loss: 0.3283705652237694\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1040] Loss: 0.3283705944705863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1041] Loss: 0.32836693454220245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1042] Loss: 0.3283622293609704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1043] Loss: 0.32835870435106496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1044] Loss: 0.32835446375979177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1045] Loss: 0.3283683873305485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1046] Loss: 0.3283576590323463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1047] Loss: 0.328350383610541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1048] Loss: 0.3283459473723657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1049] Loss: 0.3283670909178426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1050] Loss: 0.32836313949930446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1051] Loss: 0.32835166334566357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1052] Loss: 0.328342657823289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1053] Loss: 0.3283495043657265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1054] Loss: 0.3283330741240118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1055] Loss: 0.3283414181371344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1056] Loss: 0.3283289023843556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1057] Loss: 0.32833184315334485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1058] Loss: 0.3283215130255981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1059] Loss: 0.32832657848582336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1060] Loss: 0.328327543550853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1061] Loss: 0.32832844665911837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1062] Loss: 0.3283157382984875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1063] Loss: 0.32831924331413875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1064] Loss: 0.3283161151913288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1065] Loss: 0.3283287840458603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1066] Loss: 0.32833057004091765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1067] Loss: 0.3283493526705238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1068] Loss: 0.32834893886401306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1069] Loss: 0.3283420999351746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1070] Loss: 0.32833542205337596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1071] Loss: 0.3283356929284631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1072] Loss: 0.32837492081314956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1073] Loss: 0.32837530574203866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1074] Loss: 0.3283646467505517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1075] Loss: 0.3283487782081198\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1076] Loss: 0.32835301520108306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1077] Loss: 0.328365274634143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1078] Loss: 0.3283713997000318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1079] Loss: 0.3283606846587756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1080] Loss: 0.3283804016805134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1081] Loss: 0.3283657679864597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1082] Loss: 0.3283555119433243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1083] Loss: 0.32834495816523895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1084] Loss: 0.3283378321703284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1085] Loss: 0.328345835092964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1086] Loss: 0.32834523257098636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1087] Loss: 0.32838097004143224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1088] Loss: 0.32836743314729794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1089] Loss: 0.3283486623218002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1090] Loss: 0.32835656243260225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1091] Loss: 0.32834733183276626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1092] Loss: 0.3283505208766469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1093] Loss: 0.328356016477258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1094] Loss: 0.32834655451889505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1095] Loss: 0.32836008752889234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1096] Loss: 0.3283547381702516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1097] Loss: 0.3283630163635546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1098] Loss: 0.3283697245738487\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1099] Loss: 0.32835993951391806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1100] Loss: 0.3283493803376426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1101] Loss: 0.3283533027102392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1102] Loss: 0.3283602471287436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1103] Loss: 0.32834892899882673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1104] Loss: 0.32835186916799775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1105] Loss: 0.32834737636152234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1106] Loss: 0.3283399787728493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1107] Loss: 0.3283364948036349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1108] Loss: 0.32833879047999787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1109] Loss: 0.32832692818100245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1110] Loss: 0.3283188016159821\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1111] Loss: 0.32831945445180033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1112] Loss: 0.3283196655296203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1113] Loss: 0.3283098739246836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1114] Loss: 0.32829928687341187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1115] Loss: 0.32829387022111817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1116] Loss: 0.32828033309001137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1117] Loss: 0.32828077792088206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1118] Loss: 0.3282733568598034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1119] Loss: 0.32827296469804085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1120] Loss: 0.328292245863204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1121] Loss: 0.3282832274479054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1122] Loss: 0.32828803241149895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1123] Loss: 0.3282926322884881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1124] Loss: 0.32829665304373684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1125] Loss: 0.3283003581725929\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1126] Loss: 0.3282964600244845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1127] Loss: 0.3282903427018394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1128] Loss: 0.328277177273884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1129] Loss: 0.3282688661074208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1130] Loss: 0.32826386427020526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1131] Loss: 0.3282534873841567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1132] Loss: 0.32824221503089146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1133] Loss: 0.328251638435299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1134] Loss: 0.3282571810966479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1135] Loss: 0.3282505596013547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1136] Loss: 0.32825804330773917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1137] Loss: 0.32826270677854197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1138] Loss: 0.32826689654812874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1139] Loss: 0.32824826730388357\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1140] Loss: 0.3282475589959627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1141] Loss: 0.32824672668141347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1142] Loss: 0.32824994545754227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1143] Loss: 0.3282568822559241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1144] Loss: 0.3282485043851755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1145] Loss: 0.32824450422632206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1146] Loss: 0.32823579193748137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1147] Loss: 0.32823039712535046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1148] Loss: 0.32824072018990363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1149] Loss: 0.3282500418380131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1150] Loss: 0.32825407932895795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1151] Loss: 0.3282564250080737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1152] Loss: 0.32824629985503306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1153] Loss: 0.3282381229560248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1154] Loss: 0.32822964234444185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1155] Loss: 0.3282243235418082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1156] Loss: 0.3282118124640816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1157] Loss: 0.32821166061693646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1158] Loss: 0.32820650483925856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1159] Loss: 0.3282128743417334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1160] Loss: 0.32822351168457475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1161] Loss: 0.3282246268212474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1162] Loss: 0.3282518316703776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1163] Loss: 0.328250045818472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1164] Loss: 0.3282459506414056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1165] Loss: 0.32823978601660114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1166] Loss: 0.32825554094387815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1167] Loss: 0.3282555412589551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1168] Loss: 0.3282487859030477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1169] Loss: 0.32825002343569837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1170] Loss: 0.32823523743610017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1171] Loss: 0.3282375493001656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1172] Loss: 0.328249771132847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1173] Loss: 0.32826744394781937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1174] Loss: 0.3282665290022578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1175] Loss: 0.3282718411974147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1176] Loss: 0.32826869801136316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1177] Loss: 0.32828943886730827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1178] Loss: 0.32827815971283053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1179] Loss: 0.3282860807102831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1180] Loss: 0.3282847291085586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1181] Loss: 0.3282897101514377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1182] Loss: 0.3282768459614939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1183] Loss: 0.3282650547229335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1184] Loss: 0.3282678076278674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1185] Loss: 0.3282580715757199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1186] Loss: 0.32826165319313705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1187] Loss: 0.32826635363748163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1188] Loss: 0.32825873001031414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1189] Loss: 0.32825014655621143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1190] Loss: 0.32824943143903285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1191] Loss: 0.32824275888142307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1192] Loss: 0.3282492720634034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1193] Loss: 0.32824049570627645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1194] Loss: 0.328247038251909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1195] Loss: 0.32824194964923165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1196] Loss: 0.3282338099898241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1197] Loss: 0.32822787244561924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1198] Loss: 0.32822532923498626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1199] Loss: 0.32821855578306286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1200] Loss: 0.3282329548209974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1201] Loss: 0.32823137251159773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1202] Loss: 0.32823406558500884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1203] Loss: 0.32825125968776186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1204] Loss: 0.3282436088327998\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1205] Loss: 0.32824106201014314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1206] Loss: 0.3282279790805772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1207] Loss: 0.32821579579890103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1208] Loss: 0.3282081316661814\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1209] Loss: 0.328209017332086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1210] Loss: 0.3281944463009194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1211] Loss: 0.3282028953438749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1212] Loss: 0.3282165903134947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1213] Loss: 0.32821941353200557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1214] Loss: 0.3282108598306209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1215] Loss: 0.3282011078661289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1216] Loss: 0.32819139439593636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1217] Loss: 0.3281879382646192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1218] Loss: 0.32819452065522725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1219] Loss: 0.3281892772723706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1220] Loss: 0.3281825552624949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1221] Loss: 0.32817189702666794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1222] Loss: 0.3281639837021779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1223] Loss: 0.32816424894133944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1224] Loss: 0.32817529464634904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1225] Loss: 0.32817153665748716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1226] Loss: 0.32817829615941246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1227] Loss: 0.32818259100843244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1228] Loss: 0.328188001332417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1229] Loss: 0.32817524651409025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1230] Loss: 0.3282136374932787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1231] Loss: 0.32820926464483946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1232] Loss: 0.328195732358267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1233] Loss: 0.3281921849341286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1234] Loss: 0.32820197884562186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1235] Loss: 0.3281894631803459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1236] Loss: 0.3281873557393039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1237] Loss: 0.3281981796679847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1238] Loss: 0.3282008577608749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1239] Loss: 0.3281970102516102\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1240] Loss: 0.32819355354484103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1241] Loss: 0.32819103591041504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1242] Loss: 0.32819295540107046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1243] Loss: 0.3281886692595346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1244] Loss: 0.32817810855240187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1245] Loss: 0.32817230764667066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1246] Loss: 0.32816032701802833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1247] Loss: 0.3281553254878033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1248] Loss: 0.32817241524808977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1249] Loss: 0.3281848280081019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1250] Loss: 0.328178287694956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1251] Loss: 0.328176529877476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1252] Loss: 0.32818460102719016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1253] Loss: 0.32818952085702396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1254] Loss: 0.32818562151458225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1255] Loss: 0.32817429900325995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1256] Loss: 0.3281724788476924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1257] Loss: 0.328169083452254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1258] Loss: 0.3281675654853288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1259] Loss: 0.32819357150626594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1260] Loss: 0.3282104889428296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1261] Loss: 0.3282135370174661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1262] Loss: 0.32820567679369733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1263] Loss: 0.32821533464759395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1264] Loss: 0.32824644105469475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1265] Loss: 0.32824578418593564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1266] Loss: 0.32823783692036385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1267] Loss: 0.32823095834232274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1268] Loss: 0.32822735603843356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1269] Loss: 0.32822495780402244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1270] Loss: 0.32821050221641385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1271] Loss: 0.32823069301227525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1272] Loss: 0.3282520107368458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1273] Loss: 0.3282443360556251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1274] Loss: 0.32825360847060475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1275] Loss: 0.32824494086529726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1276] Loss: 0.3282490312808209\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1277] Loss: 0.32824215386331534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1278] Loss: 0.32823632011333337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1279] Loss: 0.3282409569043586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1280] Loss: 0.3282374232431805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1281] Loss: 0.32822603721734495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1282] Loss: 0.32823023469828927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1283] Loss: 0.32821845745691414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1284] Loss: 0.3282115909223912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1285] Loss: 0.3282241171857744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1286] Loss: 0.3282182359082623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1287] Loss: 0.3282125400868511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1288] Loss: 0.32821527768560893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1289] Loss: 0.3282021535344961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1290] Loss: 0.32821400089230396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1291] Loss: 0.3282141866061424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1292] Loss: 0.3282050404151905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1293] Loss: 0.32820285226725326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1294] Loss: 0.32820930365764395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1295] Loss: 0.32819433092415473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1296] Loss: 0.3281992152996516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1297] Loss: 0.32819034920691487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1298] Loss: 0.3281794381196274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1299] Loss: 0.32821461766758014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1300] Loss: 0.3282128669694651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1301] Loss: 0.3281970019442118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1302] Loss: 0.32821202256950105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1303] Loss: 0.32820537355572077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1304] Loss: 0.32823352879974077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1305] Loss: 0.3282267618932501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1306] Loss: 0.3282295787361989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1307] Loss: 0.32824678812590125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1308] Loss: 0.3282442321011889\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1309] Loss: 0.3282575038208208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1310] Loss: 0.32825469722999895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1311] Loss: 0.3282577714723769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1312] Loss: 0.32825291156898667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1313] Loss: 0.3282521283587599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1314] Loss: 0.3282498812160765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1315] Loss: 0.32824294092898854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1316] Loss: 0.32824174788463906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1317] Loss: 0.32823792768226745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1318] Loss: 0.3282375936049202\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1319] Loss: 0.3282357868926262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1320] Loss: 0.328245431706478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1321] Loss: 0.3282449041770371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1322] Loss: 0.3282509613425339\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1323] Loss: 0.3282472867471631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1324] Loss: 0.32824321611405416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1325] Loss: 0.3282488497967943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1326] Loss: 0.328284405218567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1327] Loss: 0.3282892764890896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1328] Loss: 0.3282863097594446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1329] Loss: 0.3282829418592982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1330] Loss: 0.32827830550627474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1331] Loss: 0.3283022436296557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1332] Loss: 0.3283001847068642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1333] Loss: 0.32829899979757715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1334] Loss: 0.32829862673589977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1335] Loss: 0.32829981066096686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1336] Loss: 0.3282877764980323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1337] Loss: 0.328280832936934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1338] Loss: 0.32827617161818173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1339] Loss: 0.3282708650699917\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.898\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1340] Loss: 0.328265350996681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1341] Loss: 0.32826039232757315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1342] Loss: 0.3282633112453349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1343] Loss: 0.32828897773338783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1344] Loss: 0.3282796585860821\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1345] Loss: 0.32827168470892015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1346] Loss: 0.3282631389035361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1347] Loss: 0.32826212801421817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1348] Loss: 0.32825520189428825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1349] Loss: 0.32825010571567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1350] Loss: 0.32824517265246966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1351] Loss: 0.32823879496758007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1352] Loss: 0.32824188753100597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1353] Loss: 0.3282553787819986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1354] Loss: 0.32824972789888585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1355] Loss: 0.3282624687418876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1356] Loss: 0.32825183617813053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1357] Loss: 0.32824912235077414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1358] Loss: 0.3282478687004186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1359] Loss: 0.3282538984006772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1360] Loss: 0.328286313433559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1361] Loss: 0.3282809094012244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1362] Loss: 0.3282899761463217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1363] Loss: 0.3282966036302666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1364] Loss: 0.32828968674016873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1365] Loss: 0.3282853174022926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1366] Loss: 0.3282830018684589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1367] Loss: 0.328279242234886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1368] Loss: 0.3282677222311445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1369] Loss: 0.328260120567522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1370] Loss: 0.3282691831201408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1371] Loss: 0.32830826468622964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1372] Loss: 0.32831468602385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1373] Loss: 0.3283236389339461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1374] Loss: 0.3283225054711868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1375] Loss: 0.3283508106222741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1376] Loss: 0.32834594681004053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1377] Loss: 0.3283434904267877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1378] Loss: 0.3283440718579024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1379] Loss: 0.32834645849214805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1380] Loss: 0.3283416190904568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1381] Loss: 0.32836093924043086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1382] Loss: 0.3283647690433041\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1383] Loss: 0.32835671366577596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1384] Loss: 0.3283550586972806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1385] Loss: 0.32835502663535804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1386] Loss: 0.32835618392856303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1387] Loss: 0.32834572503526277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1388] Loss: 0.32834255747593843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1389] Loss: 0.3283493464480292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1390] Loss: 0.3283716571192229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1391] Loss: 0.32838158982739885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1392] Loss: 0.32839035867525257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1393] Loss: 0.32839880186801657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1394] Loss: 0.32839761831333125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1395] Loss: 0.3283992450050265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1396] Loss: 0.3284281068392063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1397] Loss: 0.3284338520984355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1398] Loss: 0.32842523025986853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1399] Loss: 0.32845383151320373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1400] Loss: 0.32845188506028783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1401] Loss: 0.32844908461251765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1402] Loss: 0.3284657982711827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1403] Loss: 0.32845986692280776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1404] Loss: 0.3284489939998389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1405] Loss: 0.3284372486270081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1406] Loss: 0.3284361836749076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1407] Loss: 0.328437996998768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1408] Loss: 0.3284271424199964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1409] Loss: 0.32841892493578856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1410] Loss: 0.32841522743519186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1411] Loss: 0.32841300592888695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1412] Loss: 0.3284129386023266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1413] Loss: 0.32840685514729173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1414] Loss: 0.3283973095440399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1415] Loss: 0.32838762222361334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1416] Loss: 0.32838135922582146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1417] Loss: 0.3283794900238828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1418] Loss: 0.32838558144031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1419] Loss: 0.3283729787992181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1420] Loss: 0.32840173954616614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1421] Loss: 0.3283932937091572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1422] Loss: 0.328388869277464\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1423] Loss: 0.32838882236296524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1424] Loss: 0.32839010049467277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1425] Loss: 0.32838957978789796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1426] Loss: 0.3283784971140071\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1427] Loss: 0.3283758456949349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1428] Loss: 0.32840070502577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1429] Loss: 0.3283948635517106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1430] Loss: 0.32839469791353365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1431] Loss: 0.32839476919036403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1432] Loss: 0.32839781736348733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1433] Loss: 0.32840858084623953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1434] Loss: 0.3284325637655778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1435] Loss: 0.3284687155884505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1436] Loss: 0.3284746965450919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1437] Loss: 0.3284687986943483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1438] Loss: 0.32845845938885004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1439] Loss: 0.3284608719048546\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1440] Loss: 0.3284554356011393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1441] Loss: 0.32844574908973695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1442] Loss: 0.3284373110374041\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1443] Loss: 0.328432475194136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1444] Loss: 0.32843581426586343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1445] Loss: 0.3284300591922129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1446] Loss: 0.3284632248327721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1447] Loss: 0.3284575162672526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1448] Loss: 0.32845114101042117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1449] Loss: 0.3284742199907971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1450] Loss: 0.3284721692104587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1451] Loss: 0.32846398722557796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1452] Loss: 0.3284600382368926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1453] Loss: 0.3284575321322313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1454] Loss: 0.32845387384859903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1455] Loss: 0.32845571653315686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1456] Loss: 0.3284487093961225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1457] Loss: 0.32845463201484415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1458] Loss: 0.3284451958965414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1459] Loss: 0.32845011956027426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1460] Loss: 0.3284411861033473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1461] Loss: 0.3284351602280026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1462] Loss: 0.32842737516287024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1463] Loss: 0.3284435661736355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1464] Loss: 0.3284281065154666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1465] Loss: 0.32843906804246403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1466] Loss: 0.32844502725781016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1467] Loss: 0.3284624920944446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1468] Loss: 0.3284484473890717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1469] Loss: 0.32845392764157866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1470] Loss: 0.32845309980474974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1471] Loss: 0.32845126306350714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1472] Loss: 0.32843554290054755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1473] Loss: 0.32842656593748976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1474] Loss: 0.3284157586145356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1475] Loss: 0.32843088679725674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1476] Loss: 0.3284477381390033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1477] Loss: 0.328439604319118\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1478] Loss: 0.32844340425253526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1479] Loss: 0.3284347643212512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1480] Loss: 0.32843181830724477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1481] Loss: 0.32843839585842527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1482] Loss: 0.3284291402977158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1483] Loss: 0.3284256787669152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1484] Loss: 0.3284337056329544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1485] Loss: 0.3284263808174359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1486] Loss: 0.3284149325995164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1487] Loss: 0.3284219681822657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1488] Loss: 0.32843258656657304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1489] Loss: 0.3284252530647935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1490] Loss: 0.32841633725751523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1491] Loss: 0.32840670293455504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1492] Loss: 0.32841190006580734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1493] Loss: 0.32840834331328345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1494] Loss: 0.3284060121139968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1495] Loss: 0.32839482120848074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1496] Loss: 0.3283909875615156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1497] Loss: 0.3283891850665949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1498] Loss: 0.3283873403550319\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1499] Loss: 0.3283968306870232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1500] Loss: 0.32838396550686605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1501] Loss: 0.3283811680276899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1502] Loss: 0.3283851723479227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1503] Loss: 0.3283759365866637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1504] Loss: 0.3283716231078732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1505] Loss: 0.32839316023420917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1506] Loss: 0.3283863110575706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1507] Loss: 0.328387668846822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1508] Loss: 0.3283896610115263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1509] Loss: 0.3283956560213925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1510] Loss: 0.3284051984464309\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1511] Loss: 0.3284104549988452\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1512] Loss: 0.3284105100331189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1513] Loss: 0.32841020212821836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1514] Loss: 0.3283986597640664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1515] Loss: 0.328398348677288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1516] Loss: 0.3283892633863295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1517] Loss: 0.3283822586674918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1518] Loss: 0.32838377587318623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1519] Loss: 0.32838512854786955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1520] Loss: 0.32839264254331424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1521] Loss: 0.32840707891635124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1522] Loss: 0.3283917666506947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1523] Loss: 0.32838597408869247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 27, Batch 1524] Loss: 0.32838807103926854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 0] Loss: 0.32840667110753446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1] Loss: 0.32841898488680193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 2] Loss: 0.3284165426580091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 3] Loss: 0.3284167066050759\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 4] Loss: 0.3284274210127189\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 5] Loss: 0.32842941582967594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 6] Loss: 0.32842852267117534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 7] Loss: 0.32847100901250986\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 8] Loss: 0.3284852398440796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 9] Loss: 0.3284876559683913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 10] Loss: 0.328482399817317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 11] Loss: 0.32848783707920354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 12] Loss: 0.3284813859532232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 13] Loss: 0.3284835781730138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 14] Loss: 0.3284759109776281\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 15] Loss: 0.32846367033429275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 16] Loss: 0.3284655783122028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 17] Loss: 0.32845337897722476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 18] Loss: 0.32846919181559747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 19] Loss: 0.32846620838529694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 20] Loss: 0.3284602826692694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 21] Loss: 0.3284607476974495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 22] Loss: 0.32845978445344604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 23] Loss: 0.3284790163590906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 24] Loss: 0.3284810352524953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 25] Loss: 0.32850480100516577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 26] Loss: 0.3284978196133031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 27] Loss: 0.3284962337457098\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 28] Loss: 0.3284936423745361\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 29] Loss: 0.3284942353924577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 30] Loss: 0.32848318858572756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 31] Loss: 0.32848932001854825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 32] Loss: 0.328486791252327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 33] Loss: 0.3284700754546773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 34] Loss: 0.3284735267197005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 35] Loss: 0.32845868797986466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 36] Loss: 0.3284561461879869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 37] Loss: 0.3284515431643305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 38] Loss: 0.3284527700211702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 39] Loss: 0.3284482655418665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 40] Loss: 0.3284466426380864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 41] Loss: 0.32845379276986336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 42] Loss: 0.32844581687421953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 43] Loss: 0.32843959176911314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 44] Loss: 0.32846373270213597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 45] Loss: 0.32845720674549195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 46] Loss: 0.32846120402863355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 47] Loss: 0.32848016061403085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 48] Loss: 0.32847342162397397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 49] Loss: 0.32846722280163504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 50] Loss: 0.32846602369022093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 51] Loss: 0.3284546153714779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 52] Loss: 0.328451612503649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 53] Loss: 0.32845107996534856\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 54] Loss: 0.3284470430910765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 55] Loss: 0.32843069441831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 56] Loss: 0.3284481959535632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 57] Loss: 0.3284354693185264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 58] Loss: 0.32844039922244705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 59] Loss: 0.32842836869639835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 60] Loss: 0.3284470247031983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 61] Loss: 0.3284641434601833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 62] Loss: 0.32844999761051374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 63] Loss: 0.32844664151871455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 64] Loss: 0.3284483140361592\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 65] Loss: 0.3284385877200501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 66] Loss: 0.32846194089833375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 67] Loss: 0.3284713705041\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 68] Loss: 0.3284743377296329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 69] Loss: 0.3284684273104718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 70] Loss: 0.32846292425978396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 71] Loss: 0.3284580611613844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 72] Loss: 0.32844667414822476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 73] Loss: 0.3284641436168126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 74] Loss: 0.32846443435537825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 75] Loss: 0.3284639986477383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 76] Loss: 0.32845748805537633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 77] Loss: 0.3284502569503705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 78] Loss: 0.32845085764052867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 79] Loss: 0.32845972796524336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 80] Loss: 0.3284485328987176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 81] Loss: 0.32845720040841747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 82] Loss: 0.3284555562014628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 83] Loss: 0.3284482191200467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 84] Loss: 0.328465026719843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 85] Loss: 0.32847292677474355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 86] Loss: 0.3284827735514565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 87] Loss: 0.3284754230939352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 88] Loss: 0.32847284227040163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 89] Loss: 0.328463528911411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 90] Loss: 0.3284565245630968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 91] Loss: 0.3284557659547769\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 92] Loss: 0.3284486908681001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 93] Loss: 0.32844376579584816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 94] Loss: 0.3284492394915765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 95] Loss: 0.3284433897482865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 96] Loss: 0.32844660761152394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 97] Loss: 0.3284385393601915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 98] Loss: 0.3284325119381392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 99] Loss: 0.3284579297881994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 100] Loss: 0.3284450059030826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 101] Loss: 0.32844291413395654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 102] Loss: 0.32844445417401386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 103] Loss: 0.3284573950878233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 104] Loss: 0.32845527619014775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 105] Loss: 0.32846005900738967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 106] Loss: 0.32844906787724526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 107] Loss: 0.32845162871921185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 108] Loss: 0.32844610496591137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 109] Loss: 0.32845215429544006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 110] Loss: 0.3284511837470104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 111] Loss: 0.3284725673732909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 112] Loss: 0.3284547511225828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 113] Loss: 0.3284570981625278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 114] Loss: 0.32846916979924573\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 115] Loss: 0.32846689836981136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 116] Loss: 0.3284600312405498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 117] Loss: 0.3284628007918223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 118] Loss: 0.328455364314089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 119] Loss: 0.32845360213960406\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 120] Loss: 0.32846060437015023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 121] Loss: 0.3284528281648207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 122] Loss: 0.3284533539993089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 123] Loss: 0.3284577745903255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 124] Loss: 0.3284717745837365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 125] Loss: 0.3284551667278494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 126] Loss: 0.3284532693632166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 127] Loss: 0.3284779060080166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 128] Loss: 0.3284821951523001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 129] Loss: 0.32847604489353716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 130] Loss: 0.3284622595714133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 131] Loss: 0.32844802623504027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 132] Loss: 0.32844762160790353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 133] Loss: 0.3284442479991671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 134] Loss: 0.32846044105943334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 135] Loss: 0.3284649410070935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 136] Loss: 0.3284653150056266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 137] Loss: 0.328473394351012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 138] Loss: 0.32848713582212274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 139] Loss: 0.32848057995315494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 140] Loss: 0.3284868015973457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 141] Loss: 0.3284971433054526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 142] Loss: 0.32850246194783767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 143] Loss: 0.3285035439648068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 144] Loss: 0.32849732343891186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 145] Loss: 0.32850719532193245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 146] Loss: 0.32849981402903533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 147] Loss: 0.328490346049374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 148] Loss: 0.3284978719051246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 149] Loss: 0.32848749609790606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 150] Loss: 0.32848183680544474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 151] Loss: 0.3284851247068695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 152] Loss: 0.3284739267749051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 153] Loss: 0.3284583407945025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 154] Loss: 0.32846416864465816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 155] Loss: 0.3284609967669992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 156] Loss: 0.3284481805625381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 157] Loss: 0.32844088366837043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 158] Loss: 0.3284384445494466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 159] Loss: 0.32843600235541043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 160] Loss: 0.32847359349725214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 161] Loss: 0.328471539056609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 162] Loss: 0.32847665992026814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 163] Loss: 0.3284631127093915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 164] Loss: 0.32846129047962175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 165] Loss: 0.3284543444689488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 166] Loss: 0.3284533055665613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 167] Loss: 0.3284640248386579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 168] Loss: 0.32846504272111404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 169] Loss: 0.32847879348415754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 170] Loss: 0.3284736060217479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 171] Loss: 0.3284702628277912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 172] Loss: 0.3284738523349542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 173] Loss: 0.32846020265132136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 174] Loss: 0.32847365505799264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 175] Loss: 0.32846938454266683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 176] Loss: 0.3284675030330276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 177] Loss: 0.3284659913828344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 178] Loss: 0.32845360078592617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 179] Loss: 0.32845149041176563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 180] Loss: 0.3284433612847495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 181] Loss: 0.328448850355156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 182] Loss: 0.3284561941339751\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 183] Loss: 0.3284484738322397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 184] Loss: 0.32846234522796947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 185] Loss: 0.32844906118936895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 186] Loss: 0.3284430199559311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 187] Loss: 0.3284460530814467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 188] Loss: 0.3284473436092076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 189] Loss: 0.3284756806690049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 190] Loss: 0.32846766633498425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 191] Loss: 0.32847792906760365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 192] Loss: 0.3284805833074077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 193] Loss: 0.32848682779103816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 194] Loss: 0.32847867877372394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 195] Loss: 0.3284724839953456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 196] Loss: 0.3284636391344811\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 197] Loss: 0.32846828484898344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 198] Loss: 0.32845769011026477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 199] Loss: 0.3284558125909643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 200] Loss: 0.3284808456737279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 201] Loss: 0.3284934151687059\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 202] Loss: 0.3285040626970871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 203] Loss: 0.32849551845714764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 204] Loss: 0.328508311704825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 205] Loss: 0.3285211172986123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 206] Loss: 0.328541832597735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 207] Loss: 0.3285363816202178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 208] Loss: 0.32855520338483996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 209] Loss: 0.3285563406825727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 210] Loss: 0.32856140642258524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 211] Loss: 0.3285483324398993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 212] Loss: 0.3285473409367966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 213] Loss: 0.32853368147581563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 214] Loss: 0.3285372540581358\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 215] Loss: 0.3285270625767017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 216] Loss: 0.32852911317332456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 217] Loss: 0.32854398808777535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 218] Loss: 0.3285315792495991\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 219] Loss: 0.3285433883446616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 220] Loss: 0.3285399226932789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 221] Loss: 0.3285410205877724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 222] Loss: 0.3285265876905715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 223] Loss: 0.32853416309548866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 224] Loss: 0.32852559782587787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 225] Loss: 0.32852705255591125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 226] Loss: 0.3285305897594949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 227] Loss: 0.32853185367079935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 228] Loss: 0.32854212773631614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 229] Loss: 0.3285468088005885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 230] Loss: 0.3285382568606136\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 231] Loss: 0.3285471810717814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 232] Loss: 0.32853905368030284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 233] Loss: 0.3285361211059378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 234] Loss: 0.3285333334127135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 235] Loss: 0.32853780504746677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 236] Loss: 0.3285227948803635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 237] Loss: 0.3285148583517523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 238] Loss: 0.32851651283305144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 239] Loss: 0.3285277571573506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 240] Loss: 0.32851685533866787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 241] Loss: 0.3285207575802972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 242] Loss: 0.3285111600484879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 243] Loss: 0.3285373089374461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 244] Loss: 0.3285505062960667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 245] Loss: 0.32859471313183314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 246] Loss: 0.32861265632029923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 247] Loss: 0.3286014375788334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 248] Loss: 0.3285992340583106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 249] Loss: 0.32859965657500734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 250] Loss: 0.3285866962002881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 251] Loss: 0.32859069150154024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 252] Loss: 0.3286018593845101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 253] Loss: 0.3286112929908075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 254] Loss: 0.3286102174883981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 255] Loss: 0.3286427596050218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 256] Loss: 0.32863380208662646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 257] Loss: 0.3286683980502782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 258] Loss: 0.32867084034520144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 259] Loss: 0.32866341125599885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 260] Loss: 0.3286753114600695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 261] Loss: 0.3286826362428675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 262] Loss: 0.32869046350355097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 263] Loss: 0.3286892733688634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 264] Loss: 0.32870536645868614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 265] Loss: 0.3286943037606467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 266] Loss: 0.32868766770331537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 267] Loss: 0.32869148917679447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 268] Loss: 0.3286842966319028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 269] Loss: 0.3286794086699503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 270] Loss: 0.3286818095106758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 271] Loss: 0.3286945720937344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 272] Loss: 0.3286972824212789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 273] Loss: 0.32872339833938957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 274] Loss: 0.32871951794566523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 275] Loss: 0.3287341049374834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 276] Loss: 0.328755646273911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 277] Loss: 0.3287409442657214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 278] Loss: 0.32874770657666497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 279] Loss: 0.3287437286077884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 280] Loss: 0.32874860168200665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 281] Loss: 0.3287464741363444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 282] Loss: 0.32874890663428796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 283] Loss: 0.32874598028566204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 284] Loss: 0.3287443022323266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 285] Loss: 0.32874925225236284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 286] Loss: 0.32877121151743166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 287] Loss: 0.32876528750004347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 288] Loss: 0.32876205708388245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 289] Loss: 0.3287669827286888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 290] Loss: 0.3287615313910777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 291] Loss: 0.3287645684028631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 292] Loss: 0.32876250592403794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 293] Loss: 0.3287761040168732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 294] Loss: 0.32876359128900284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 295] Loss: 0.32875118156522887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 296] Loss: 0.32876485142227924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 297] Loss: 0.3287708621810331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 298] Loss: 0.32876649590199025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 299] Loss: 0.3287628315887685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 300] Loss: 0.32875746555699115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 301] Loss: 0.3287662625322749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 302] Loss: 0.32877234129325417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 303] Loss: 0.32877156290538717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 304] Loss: 0.3287593279471639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 305] Loss: 0.32875944668299123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 306] Loss: 0.32876798205396346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 307] Loss: 0.32876271328241086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 308] Loss: 0.3287724644405338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 309] Loss: 0.3287803898626027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 310] Loss: 0.3287677155121213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 311] Loss: 0.3287798383806145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 312] Loss: 0.32877123910483247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 313] Loss: 0.32876227313280104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 314] Loss: 0.3287531342973571\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8895\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 315] Loss: 0.3287478757401721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 316] Loss: 0.3287615064473527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 317] Loss: 0.32875568836167707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 318] Loss: 0.32876038490881876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 319] Loss: 0.3287546105438345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 320] Loss: 0.3287594412051143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 321] Loss: 0.3287766874717582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 322] Loss: 0.32876884090666153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 323] Loss: 0.32876359225932406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 324] Loss: 0.32876145672082563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 325] Loss: 0.3287581033171057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 326] Loss: 0.3287748114337614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 327] Loss: 0.3287712765244551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 328] Loss: 0.32876934262176283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 329] Loss: 0.3287710391230554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 330] Loss: 0.3287746165810483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 331] Loss: 0.328770361441476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 332] Loss: 0.3287685321587693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 333] Loss: 0.32876606374954226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 334] Loss: 0.3287669486994454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 335] Loss: 0.3287650878807507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 336] Loss: 0.32876242005412576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 337] Loss: 0.32875390778867625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 338] Loss: 0.32874811142992827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 339] Loss: 0.328763264267472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 340] Loss: 0.3287506413420626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 341] Loss: 0.32875361791952806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 342] Loss: 0.3287500506270823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 343] Loss: 0.3287376175559469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 344] Loss: 0.32873429734033494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 345] Loss: 0.32872984284272494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 346] Loss: 0.32873925592802633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 347] Loss: 0.32874663721089625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 348] Loss: 0.32874655013986775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 349] Loss: 0.328745875101513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 350] Loss: 0.32876321278116954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 351] Loss: 0.3287707576189332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 352] Loss: 0.3287683099320149\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 353] Loss: 0.3287816766302946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 354] Loss: 0.32879583647471705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 355] Loss: 0.32881363272899566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 356] Loss: 0.32881343628637993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 357] Loss: 0.32881503516937444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 358] Loss: 0.3288123614674735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 359] Loss: 0.32883257947573924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 360] Loss: 0.32883638829658307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 361] Loss: 0.3288327063462273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 362] Loss: 0.3288395764711675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 363] Loss: 0.3288392125583289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 364] Loss: 0.3288366701365823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 365] Loss: 0.32885146312788993\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 366] Loss: 0.3288422007227126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 367] Loss: 0.3288387597578862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 368] Loss: 0.32883799644314565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 369] Loss: 0.3288360863896835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 370] Loss: 0.3288319795171924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 371] Loss: 0.3288325650982347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 372] Loss: 0.32883984436071656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 373] Loss: 0.3288276785790031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 374] Loss: 0.3288326713192988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 375] Loss: 0.3288287569996809\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 376] Loss: 0.32881687011211197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 377] Loss: 0.3288225943756238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 378] Loss: 0.3288235208477363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 379] Loss: 0.3288263379910011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 380] Loss: 0.32882387998970086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 381] Loss: 0.32883615064026306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 382] Loss: 0.3288237962336872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 383] Loss: 0.32885183410621815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 384] Loss: 0.32884641124762515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 385] Loss: 0.3288494478763039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 386] Loss: 0.32884328711336985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 387] Loss: 0.3288382203687653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 388] Loss: 0.32882511852073865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 389] Loss: 0.3288350064182822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 390] Loss: 0.32883836168089753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 391] Loss: 0.3288309734353543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 392] Loss: 0.3288379629212052\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 393] Loss: 0.32885485561502886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 394] Loss: 0.3288494916215715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 395] Loss: 0.3288489871381963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 396] Loss: 0.32883958788953216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 397] Loss: 0.32883859005778565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 398] Loss: 0.32882871503518246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 399] Loss: 0.3288355164529471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 400] Loss: 0.3288250866042401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 401] Loss: 0.32881237586564493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 402] Loss: 0.32881233434230817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 403] Loss: 0.32880769405634175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 404] Loss: 0.3288254342999729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 405] Loss: 0.32883350642935905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 406] Loss: 0.32882839602103336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 407] Loss: 0.328838468496171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 408] Loss: 0.32883324132891123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 409] Loss: 0.32884830259718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 410] Loss: 0.32884117861769463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 411] Loss: 0.3288334548044725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 412] Loss: 0.32882548917304466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 413] Loss: 0.3288244725184992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 414] Loss: 0.328851760830153\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 415] Loss: 0.3288593348531246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 416] Loss: 0.3288775671516323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 417] Loss: 0.3288700162443552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 418] Loss: 0.32887551815782584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 419] Loss: 0.32886296388345887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 420] Loss: 0.32886854207485194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 421] Loss: 0.3288625314644669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 422] Loss: 0.3288543216532804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 423] Loss: 0.32884690925589677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 424] Loss: 0.3288363884239663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 425] Loss: 0.32884192646848953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 426] Loss: 0.3288342093435767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 427] Loss: 0.32886053011527405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 428] Loss: 0.3288567466143975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 429] Loss: 0.3288569694397846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 430] Loss: 0.3288677990143868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 431] Loss: 0.3288648960443884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 432] Loss: 0.32886545832489217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 433] Loss: 0.328876413170113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 434] Loss: 0.3288809906474022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 435] Loss: 0.32888445821021417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 436] Loss: 0.32887399648096877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 437] Loss: 0.32886730446914997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 438] Loss: 0.32885703601419314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 439] Loss: 0.32885758520652214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 440] Loss: 0.3288452051063259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 441] Loss: 0.3288314107948015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 442] Loss: 0.3288375286073517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 443] Loss: 0.32884066487184166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 444] Loss: 0.32883571155996355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 445] Loss: 0.32883732240712177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 446] Loss: 0.32882437164968387\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 447] Loss: 0.3288101644448792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 448] Loss: 0.328819884517628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 449] Loss: 0.3288302996669188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 450] Loss: 0.328831855651819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 451] Loss: 0.3288274776711655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 452] Loss: 0.32882425181161967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 453] Loss: 0.32882764876330706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 454] Loss: 0.3288261599604925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 455] Loss: 0.32883180436369736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 456] Loss: 0.32883146862206974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 457] Loss: 0.32883737194296636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 458] Loss: 0.32883354955467486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 459] Loss: 0.3288315709121495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 460] Loss: 0.32882698867913185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 461] Loss: 0.32882456738314114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 462] Loss: 0.3288193780170546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 463] Loss: 0.32881849753758546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 464] Loss: 0.32881007094891823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 465] Loss: 0.3288032763684812\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 466] Loss: 0.3287982463083826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 467] Loss: 0.32879958711276425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 468] Loss: 0.32879819587908965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 469] Loss: 0.32880666757976396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 470] Loss: 0.3287948385951079\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 471] Loss: 0.3287988963632977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 472] Loss: 0.3287885449125104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 473] Loss: 0.3287993224840121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 474] Loss: 0.32881460171513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 475] Loss: 0.3288079412852222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 476] Loss: 0.32880538788382224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 477] Loss: 0.3287961709875686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 478] Loss: 0.32879091651411246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 479] Loss: 0.3287873306782763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 480] Loss: 0.32879208637859353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 481] Loss: 0.3287804021324318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 482] Loss: 0.3287867237938901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 483] Loss: 0.32878665790120987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 484] Loss: 0.32878201946257446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 485] Loss: 0.3287867914898749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 486] Loss: 0.32879081252645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 487] Loss: 0.3287954083021901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 488] Loss: 0.3288072596952411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 489] Loss: 0.328811145097546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 490] Loss: 0.3288082963626177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 491] Loss: 0.328811246849747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 492] Loss: 0.3288168691019773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 493] Loss: 0.32881637486722476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 494] Loss: 0.32882467414316763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 495] Loss: 0.3288296370710025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 496] Loss: 0.32882588508827176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 497] Loss: 0.3288216292173238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 498] Loss: 0.32882583779441465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 499] Loss: 0.32882828122237506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 500] Loss: 0.3288221057879482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 501] Loss: 0.3288318861482532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 502] Loss: 0.3288227965507743\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 503] Loss: 0.32881669074883707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 504] Loss: 0.32882419923925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 505] Loss: 0.3288192675434288\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 506] Loss: 0.3288121441327097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 507] Loss: 0.3288004746544805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 508] Loss: 0.3287935023427058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 509] Loss: 0.32878483549767185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 510] Loss: 0.32878198774635786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 511] Loss: 0.3287803850937308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 512] Loss: 0.3287790018617154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 513] Loss: 0.3287895310841134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 514] Loss: 0.32878174182064523\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 515] Loss: 0.3287835492755698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 516] Loss: 0.3287994631607396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 517] Loss: 0.328792343397818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 518] Loss: 0.3287994230272144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 519] Loss: 0.32879720055215106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 520] Loss: 0.32879877794069184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 521] Loss: 0.3288170419594329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 522] Loss: 0.3288211482354665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 523] Loss: 0.32882648411097826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 524] Loss: 0.3288316348169938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 525] Loss: 0.32883820272042563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 526] Loss: 0.32883806897695317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 527] Loss: 0.32882978654183986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 528] Loss: 0.32883274401132073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 529] Loss: 0.3288292172861962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 530] Loss: 0.3288238533301645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 531] Loss: 0.3288246658529289\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 532] Loss: 0.3288212985468629\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 533] Loss: 0.3288074157961359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 534] Loss: 0.3287986360868917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 535] Loss: 0.32882063643955944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 536] Loss: 0.328815379328212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 537] Loss: 0.32881331257156404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 538] Loss: 0.3288188208819411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 539] Loss: 0.32883397852260005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 540] Loss: 0.32882077528243464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 541] Loss: 0.32882957006684305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 542] Loss: 0.32884665446821865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 543] Loss: 0.32885232561695116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 544] Loss: 0.32884832598983527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 545] Loss: 0.32884687035203836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 546] Loss: 0.328838946106369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 547] Loss: 0.3288270413476072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 548] Loss: 0.3288364430569024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 549] Loss: 0.3288284024201156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 550] Loss: 0.32882983677647537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 551] Loss: 0.32882459993908114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 552] Loss: 0.3288328967028481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 553] Loss: 0.32882786643344397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 554] Loss: 0.32883127393548994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 555] Loss: 0.32883575244012014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 556] Loss: 0.3288394745223557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 557] Loss: 0.32886174977755517\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 558] Loss: 0.3288501527624356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 559] Loss: 0.3288419034569925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 560] Loss: 0.3288569801195092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 561] Loss: 0.3288544463547303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 562] Loss: 0.32884601166938526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 563] Loss: 0.32884147204063374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 564] Loss: 0.3288398611709523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 565] Loss: 0.32883762901115565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 566] Loss: 0.32882284109815035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 567] Loss: 0.32882867127861226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 568] Loss: 0.3288360625772951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 569] Loss: 0.32883009690591974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 570] Loss: 0.328820227870323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 571] Loss: 0.32882414194275844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 572] Loss: 0.328809948005551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 573] Loss: 0.3288271503167479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 574] Loss: 0.3288168680202649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 575] Loss: 0.32880620713447634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 576] Loss: 0.3288062947636608\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 577] Loss: 0.32879292223036327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 578] Loss: 0.32878913925319025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 579] Loss: 0.32879063511835543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 580] Loss: 0.3287762656833409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 581] Loss: 0.32877920597140625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 582] Loss: 0.3287735294451369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 583] Loss: 0.32876878245729885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 584] Loss: 0.32876539401325694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 585] Loss: 0.3287767082224497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 586] Loss: 0.3287664323493961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 587] Loss: 0.32876475216055684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 588] Loss: 0.328762141611814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 589] Loss: 0.3287480844530095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 590] Loss: 0.3287477850285281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 591] Loss: 0.3287602386777633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 592] Loss: 0.32875992694126493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 593] Loss: 0.3287578547682844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 594] Loss: 0.3287433941090459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 595] Loss: 0.32872961783662447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 596] Loss: 0.32874116290739497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 597] Loss: 0.3287422290148874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 598] Loss: 0.32875662238242714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 599] Loss: 0.32875885810789757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 600] Loss: 0.32875306953796485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 601] Loss: 0.3287497986445184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 602] Loss: 0.32875349188983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 603] Loss: 0.3287429290406097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 604] Loss: 0.32874516012849786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 605] Loss: 0.3287439454459636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 606] Loss: 0.3287431809026619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 607] Loss: 0.32873936191538167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 608] Loss: 0.32873456163855286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 609] Loss: 0.3287206686567818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 610] Loss: 0.3287129163720254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 611] Loss: 0.32869919602013853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 612] Loss: 0.3286998687476024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 613] Loss: 0.32869998260605626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 614] Loss: 0.3286941588038827\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 615] Loss: 0.32868136486383476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 616] Loss: 0.3286686520016718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 617] Loss: 0.32866844510046767\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 618] Loss: 0.32866218454442536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 619] Loss: 0.3286543735063078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 620] Loss: 0.3286428900667584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 621] Loss: 0.32864148096630313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 622] Loss: 0.32865456053898623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 623] Loss: 0.3286533345617384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 624] Loss: 0.3286565933759338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 625] Loss: 0.328664491256872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 626] Loss: 0.3286504615822844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 627] Loss: 0.3286733762923049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 628] Loss: 0.3286814674462819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 629] Loss: 0.328677167699162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 630] Loss: 0.3286809294319796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 631] Loss: 0.3286676057678652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 632] Loss: 0.32866991152066827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 633] Loss: 0.32866528759311353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 634] Loss: 0.328662061944535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 635] Loss: 0.3286605462470606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 636] Loss: 0.3286517470516401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 637] Loss: 0.32864899113556656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 638] Loss: 0.3286534486943761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 639] Loss: 0.3286609899372941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 640] Loss: 0.32865401951851053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 641] Loss: 0.32864791127302523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 642] Loss: 0.32865384810161724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 643] Loss: 0.32864945104522425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 644] Loss: 0.32866406242068824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 645] Loss: 0.3286603587331263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 646] Loss: 0.328667342281009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 647] Loss: 0.32867227348290445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 648] Loss: 0.32867033793996786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 649] Loss: 0.3286772181199025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 650] Loss: 0.3286741739749677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 651] Loss: 0.32866607655324664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 652] Loss: 0.32866683267935504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 653] Loss: 0.3286874392201197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 654] Loss: 0.32868206975173353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 655] Loss: 0.32867896376113376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 656] Loss: 0.3286623959777025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 657] Loss: 0.32866417911212725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 658] Loss: 0.3286553953541537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 659] Loss: 0.3286481042613275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 660] Loss: 0.32866396270182446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 661] Loss: 0.3286675548191195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 662] Loss: 0.3286573053720374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 663] Loss: 0.3286517284448571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 664] Loss: 0.3286491162642449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 665] Loss: 0.32864676839177415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 666] Loss: 0.3286421728687355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 667] Loss: 0.3286524019105324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 668] Loss: 0.3286525669734954\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 669] Loss: 0.3286406612141295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 670] Loss: 0.32864612382349384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 671] Loss: 0.32865267047584107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 672] Loss: 0.3286688584306545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 673] Loss: 0.3286585320263474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 674] Loss: 0.32866141190723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 675] Loss: 0.32865848224155053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 676] Loss: 0.3286574064852408\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 677] Loss: 0.3286498844345163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 678] Loss: 0.32865426149015914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 679] Loss: 0.3286397003815887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 680] Loss: 0.3286572694410944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 681] Loss: 0.3286474875347956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 682] Loss: 0.3286461234496293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 683] Loss: 0.3286598733425285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 684] Loss: 0.3286532956792749\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 685] Loss: 0.3286460914636724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 686] Loss: 0.3286407146532717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 687] Loss: 0.32864010784457703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 688] Loss: 0.32863601941111115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 689] Loss: 0.32862489059887723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 690] Loss: 0.32861171435925035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 691] Loss: 0.32860682056793916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 692] Loss: 0.32859486711808633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 693] Loss: 0.32858771910659235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 694] Loss: 0.32861720769153197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 695] Loss: 0.3286274815337172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 696] Loss: 0.3286263702835442\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 697] Loss: 0.3286118719730411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 698] Loss: 0.32859710784426704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 699] Loss: 0.3285866736813516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 700] Loss: 0.3285872173910088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 701] Loss: 0.3285962732374659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 702] Loss: 0.3286029183535755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 703] Loss: 0.32860017102617617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 704] Loss: 0.3285958069663688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 705] Loss: 0.32858767813003065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 706] Loss: 0.3286130506896101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 707] Loss: 0.3286109691191503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 708] Loss: 0.3286099539589574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 709] Loss: 0.3286056806185806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 710] Loss: 0.32863546336532323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 711] Loss: 0.32866305544020513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 712] Loss: 0.32867742487031787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 713] Loss: 0.3286671916389417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 714] Loss: 0.32867139645816623\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 715] Loss: 0.3286638543318547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 716] Loss: 0.32866087996744875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 717] Loss: 0.3286528142174524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 718] Loss: 0.3286371217979774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 719] Loss: 0.32863817767375386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 720] Loss: 0.32863746834776986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 721] Loss: 0.3286417557279682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 722] Loss: 0.32862851994128794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 723] Loss: 0.3286262747641776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 724] Loss: 0.328642152287033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 725] Loss: 0.32865332059269275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 726] Loss: 0.3286507889594798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 727] Loss: 0.3286481638282504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 728] Loss: 0.3286516917643651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 729] Loss: 0.3286720047093995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 730] Loss: 0.3286616006892949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 731] Loss: 0.3286735979280076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 732] Loss: 0.32870424690154143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 733] Loss: 0.328693970616145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 734] Loss: 0.3287081098266917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 735] Loss: 0.32869205247137573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 736] Loss: 0.3287028403696179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 737] Loss: 0.32870229667847817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 738] Loss: 0.3287276785600353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 739] Loss: 0.3287220045620791\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 740] Loss: 0.3287179847759388\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 741] Loss: 0.3287290851260338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 742] Loss: 0.3287199081022642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 743] Loss: 0.32871335207373026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 744] Loss: 0.32870999717079963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 745] Loss: 0.32870083499131686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 746] Loss: 0.32870676347261213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 747] Loss: 0.3287021456664113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 748] Loss: 0.3287057438869049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 749] Loss: 0.32870285856022585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 750] Loss: 0.3287062582326173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 751] Loss: 0.32870346747014106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 752] Loss: 0.32871586696093313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 753] Loss: 0.3287133141687302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 754] Loss: 0.3287007652241675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 755] Loss: 0.3287001187052159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 756] Loss: 0.32869489901926435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 757] Loss: 0.32870103843984344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 758] Loss: 0.32869675529738324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 759] Loss: 0.32869178338134075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 760] Loss: 0.3287005790551858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 761] Loss: 0.3287129876973553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 762] Loss: 0.3287029941111063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 763] Loss: 0.3286938034069825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 764] Loss: 0.3286848053439067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 765] Loss: 0.3286786592301308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 766] Loss: 0.32869727472868693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 767] Loss: 0.3287012425813808\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 768] Loss: 0.3286908625940251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 769] Loss: 0.3286898608302115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 770] Loss: 0.32868612455732704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 771] Loss: 0.328685283974868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 772] Loss: 0.32867184044358644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 773] Loss: 0.3286660459323115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 774] Loss: 0.32865708888273026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 775] Loss: 0.3286507343937652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 776] Loss: 0.3286411785307268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 777] Loss: 0.32863575728868394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 778] Loss: 0.32863088620447795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 779] Loss: 0.32861955249501273\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 780] Loss: 0.3286092437781633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 781] Loss: 0.32860753117120245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 782] Loss: 0.32861103802412683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 783] Loss: 0.3286038929621936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 784] Loss: 0.32859904020929115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 785] Loss: 0.32860443190593247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 786] Loss: 0.3286180797064447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 787] Loss: 0.3286142361983334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 788] Loss: 0.3286192660968385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 789] Loss: 0.3286233514543765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 790] Loss: 0.3286166791464882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 791] Loss: 0.3286214203023389\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 792] Loss: 0.32863151272161045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 793] Loss: 0.3286537793697789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 794] Loss: 0.3286518560994532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 795] Loss: 0.3286393513382818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 796] Loss: 0.3286381693734321\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 797] Loss: 0.32863819946435563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 798] Loss: 0.32862847505102266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 799] Loss: 0.32862465151087533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 800] Loss: 0.32863908296264066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 801] Loss: 0.32864701013038417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 802] Loss: 0.3286365601049574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 803] Loss: 0.3286262728679505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 804] Loss: 0.32861481595686903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 805] Loss: 0.32861837943025196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 806] Loss: 0.3286132243535187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 807] Loss: 0.3286061083940586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 808] Loss: 0.328595300532785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 809] Loss: 0.3285905040839923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 810] Loss: 0.32860514346140235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 811] Loss: 0.32860907131845063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 812] Loss: 0.32859977016661945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 813] Loss: 0.32859797131359575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 814] Loss: 0.3286039702598452\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.897\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 815] Loss: 0.3286005755684706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 816] Loss: 0.3286176348257177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 817] Loss: 0.32861615793501825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 818] Loss: 0.32860593866737114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 819] Loss: 0.3286078843314486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 820] Loss: 0.3286065077822424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 821] Loss: 0.32859449306289096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 822] Loss: 0.3285910959755863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 823] Loss: 0.3285862371998487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 824] Loss: 0.328605490732718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 825] Loss: 0.3285973242256562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 826] Loss: 0.32859318184200487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 827] Loss: 0.3285965278336267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 828] Loss: 0.32860642909182103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 829] Loss: 0.3286075228363866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 830] Loss: 0.3286162731435254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 831] Loss: 0.3286075224434202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 832] Loss: 0.32861384244077607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 833] Loss: 0.32861165108974466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 834] Loss: 0.32861650536394227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 835] Loss: 0.32860936103616256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 836] Loss: 0.3285995750928005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 837] Loss: 0.32859873702242154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 838] Loss: 0.3286036330931439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 839] Loss: 0.3285886183108658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 840] Loss: 0.32858605501269117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 841] Loss: 0.328597156678851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 842] Loss: 0.3286064381221551\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 843] Loss: 0.3286123459833152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 844] Loss: 0.32860189487389296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 845] Loss: 0.3286100644963097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 846] Loss: 0.32859775751738785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 847] Loss: 0.32858519059774866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 848] Loss: 0.3285929261122417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 849] Loss: 0.32858081828760033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 850] Loss: 0.3285791725615589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 851] Loss: 0.3285738221378746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 852] Loss: 0.32858240591506654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 853] Loss: 0.3285750377483583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 854] Loss: 0.3285782893840543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 855] Loss: 0.32857499704991033\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 856] Loss: 0.32856456441967374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 857] Loss: 0.3285700944578988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 858] Loss: 0.32856174859512655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 859] Loss: 0.3285526369142937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 860] Loss: 0.3285597236008295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 861] Loss: 0.3285650982176199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 862] Loss: 0.3285529476126092\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 863] Loss: 0.328562346855364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 864] Loss: 0.32858352753536396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 865] Loss: 0.3285834495235802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 866] Loss: 0.3285916627947908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 867] Loss: 0.32858857753843435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 868] Loss: 0.3285767044888365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 869] Loss: 0.3285807665276058\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 870] Loss: 0.3285823743174797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 871] Loss: 0.32857509287791203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 872] Loss: 0.3285898338516566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 873] Loss: 0.3285874898936955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 874] Loss: 0.3285785021657644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 875] Loss: 0.32858827016041303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 876] Loss: 0.32858148179304864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 877] Loss: 0.328577856484306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 878] Loss: 0.3285622141457771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 879] Loss: 0.3285580207638949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 880] Loss: 0.328551445071852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 881] Loss: 0.3285399247168366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 882] Loss: 0.32853831550864715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 883] Loss: 0.3285345361294638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 884] Loss: 0.32853127917787944\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 885] Loss: 0.328534515857853\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 886] Loss: 0.32852367679948863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 887] Loss: 0.32852729795616475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 888] Loss: 0.32852627455062466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 889] Loss: 0.32852757104753066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 890] Loss: 0.3285319163288734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 891] Loss: 0.3285296739331251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 892] Loss: 0.328530530842639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 893] Loss: 0.32853233821998057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 894] Loss: 0.3285237982473553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 895] Loss: 0.3285115618288915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 896] Loss: 0.3285078266742858\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 897] Loss: 0.32851401066439534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 898] Loss: 0.32852971331498715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 899] Loss: 0.3285349987094445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 900] Loss: 0.3285257300113234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 901] Loss: 0.32852933236759146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 902] Loss: 0.32852555435650665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 903] Loss: 0.32851717700446476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 904] Loss: 0.32852479999099576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 905] Loss: 0.3285177594016447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 906] Loss: 0.32852427194433825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 907] Loss: 0.3285168974908956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 908] Loss: 0.3285204049038622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 909] Loss: 0.32850925198901965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 910] Loss: 0.32850490398855825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 911] Loss: 0.3285032750154217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 912] Loss: 0.3285072547483325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 913] Loss: 0.32849516367096276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 914] Loss: 0.3285076406017701\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 915] Loss: 0.3285060188032591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 916] Loss: 0.3285101767394984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 917] Loss: 0.32850892876042276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 918] Loss: 0.3285014196591971\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 919] Loss: 0.32852058323679717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 920] Loss: 0.32851820617696714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 921] Loss: 0.3285196096285336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 922] Loss: 0.3285131232758491\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 923] Loss: 0.3285031481850582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 924] Loss: 0.3285004520224132\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 925] Loss: 0.3284909320989895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 926] Loss: 0.32848509235921464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 927] Loss: 0.3285006577084356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 928] Loss: 0.3284897966448438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 929] Loss: 0.3284823176827218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 930] Loss: 0.3284795937013435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 931] Loss: 0.3284769382261072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 932] Loss: 0.3284932414046302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 933] Loss: 0.32849905880111996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 934] Loss: 0.3285037771424621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 935] Loss: 0.3285081066401338\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 936] Loss: 0.3285046004394594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 937] Loss: 0.3284964812252581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 938] Loss: 0.32848948613192774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 939] Loss: 0.3284918221323601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 940] Loss: 0.32849039836515487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 941] Loss: 0.3284809206832775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 942] Loss: 0.32849555253399665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 943] Loss: 0.3284914325559932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 944] Loss: 0.3284949221494985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 945] Loss: 0.32848833664541593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 946] Loss: 0.3284864106563428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 947] Loss: 0.32848817832769145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 948] Loss: 0.32848310934244807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 949] Loss: 0.328505316784593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 950] Loss: 0.328502466130518\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 951] Loss: 0.32848923178845085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 952] Loss: 0.3284981843089697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 953] Loss: 0.32848796387132306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 954] Loss: 0.32847621896480345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 955] Loss: 0.3284720950679648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 956] Loss: 0.3284758471608407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 957] Loss: 0.32846879142689217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 958] Loss: 0.3284722809012156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 959] Loss: 0.3284598705179844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 960] Loss: 0.3284663994737441\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 961] Loss: 0.3284649572009427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 962] Loss: 0.32845962023367964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 963] Loss: 0.32845575186162596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 964] Loss: 0.32844588290492155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 965] Loss: 0.3284358186285131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 966] Loss: 0.32842647646994194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 967] Loss: 0.32842614500360484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 968] Loss: 0.32841869649362865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 969] Loss: 0.3284456186183739\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 970] Loss: 0.3284568876679111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 971] Loss: 0.3284667297793962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 972] Loss: 0.32847050676044764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 973] Loss: 0.3284831817651765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 974] Loss: 0.3284828994432272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 975] Loss: 0.3284731519158004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 976] Loss: 0.3284689983667652\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 977] Loss: 0.32845962638669635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 978] Loss: 0.3284497488753343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 979] Loss: 0.3284460426491009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 980] Loss: 0.3284360610605641\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 981] Loss: 0.3284311240534838\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 982] Loss: 0.32844325834387567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 983] Loss: 0.3284372558598219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 984] Loss: 0.3284317213030878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 985] Loss: 0.32842013745208865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 986] Loss: 0.32841627429654885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 987] Loss: 0.32840911380409327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 988] Loss: 0.32840239477286914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 989] Loss: 0.32840556833268847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 990] Loss: 0.32840832796306596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 991] Loss: 0.32840021632730465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 992] Loss: 0.3284103168471819\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 993] Loss: 0.3283978303694622\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 994] Loss: 0.32839149170933474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 995] Loss: 0.328379706886007\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 996] Loss: 0.3283757224765935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 997] Loss: 0.3283642336205752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 998] Loss: 0.3283612623857756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 999] Loss: 0.32835098361353027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1000] Loss: 0.32834666440560106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1001] Loss: 0.32833645081095875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1002] Loss: 0.3283293116031851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1003] Loss: 0.3283322531803327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1004] Loss: 0.3283213239112378\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1005] Loss: 0.32832957452513556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1006] Loss: 0.32832835811144595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1007] Loss: 0.32834337281548304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1008] Loss: 0.32834795779449916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1009] Loss: 0.3283418442170173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1010] Loss: 0.3283634329703349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1011] Loss: 0.32835910063202334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1012] Loss: 0.3283663287216711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1013] Loss: 0.3283701489578317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1014] Loss: 0.3283712550770128\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1015] Loss: 0.3283750458776369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1016] Loss: 0.3283728641657053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1017] Loss: 0.32836829644853077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1018] Loss: 0.3283654666454808\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1019] Loss: 0.328360333527995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1020] Loss: 0.3283481255778783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1021] Loss: 0.3283558902253013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1022] Loss: 0.3283537519704828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1023] Loss: 0.32835010886133703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1024] Loss: 0.3283808843900392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1025] Loss: 0.32837735395175227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1026] Loss: 0.3283678766418842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1027] Loss: 0.32835765128648464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1028] Loss: 0.3283690952037059\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1029] Loss: 0.32835956846228204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1030] Loss: 0.3283585696384865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1031] Loss: 0.32835396679821566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1032] Loss: 0.3283408728392818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1033] Loss: 0.32834709144414126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1034] Loss: 0.32835622783171925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1035] Loss: 0.32836774756847603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1036] Loss: 0.3283637238397479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1037] Loss: 0.32835799111044567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1038] Loss: 0.32834864896559296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1039] Loss: 0.3283483953638617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1040] Loss: 0.3283481547513695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1041] Loss: 0.3283619046179633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1042] Loss: 0.3283557111744336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1043] Loss: 0.3283563437155402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1044] Loss: 0.32834596838941094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1045] Loss: 0.32834520386932803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1046] Loss: 0.3283438629946265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1047] Loss: 0.328344629891129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1048] Loss: 0.32834402261982726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1049] Loss: 0.32835124663121756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1050] Loss: 0.3283378856558295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1051] Loss: 0.32833246377566244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1052] Loss: 0.3283379528484639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1053] Loss: 0.32833169259224526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1054] Loss: 0.3283231773711001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1055] Loss: 0.32832079571195966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1056] Loss: 0.32831748920752063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1057] Loss: 0.32831907396924453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1058] Loss: 0.32831605624841587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1059] Loss: 0.32831619566701914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1060] Loss: 0.3283156003232254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1061] Loss: 0.3283377357959925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1062] Loss: 0.3283491095365688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1063] Loss: 0.32834136597490776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1064] Loss: 0.32836241320648546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1065] Loss: 0.3283541575862957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1066] Loss: 0.32835874047154007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1067] Loss: 0.32837493305651116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1068] Loss: 0.3283789649559021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1069] Loss: 0.3283800001879094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1070] Loss: 0.32837014510775564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1071] Loss: 0.32835858484178543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1072] Loss: 0.3283608241624402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1073] Loss: 0.3283724900410981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1074] Loss: 0.3283826161434906\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1075] Loss: 0.32839253705880556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1076] Loss: 0.32839569430685916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1077] Loss: 0.3283973371330444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1078] Loss: 0.32841773166628013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1079] Loss: 0.32840455591400813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1080] Loss: 0.32841277289226695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1081] Loss: 0.3284077980913885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1082] Loss: 0.32840108899525816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1083] Loss: 0.3283954830943791\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1084] Loss: 0.3283951554930758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1085] Loss: 0.32839157096131577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1086] Loss: 0.32839428509207064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1087] Loss: 0.3283855943818532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1088] Loss: 0.3283933028112186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1089] Loss: 0.328403781199654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1090] Loss: 0.32840839582151715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1091] Loss: 0.32841874181228375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1092] Loss: 0.3284204197365807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1093] Loss: 0.328422996719515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1094] Loss: 0.32841061741025057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1095] Loss: 0.32841249936388667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1096] Loss: 0.3284034503516453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1097] Loss: 0.328408902761024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1098] Loss: 0.3284016928433393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1099] Loss: 0.3283874675842466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1100] Loss: 0.3283860443236122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1101] Loss: 0.3283863705802857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1102] Loss: 0.32839039771751577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1103] Loss: 0.32837782334813015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1104] Loss: 0.3283678268070572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1105] Loss: 0.32836282097695485\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1106] Loss: 0.3283579902845589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1107] Loss: 0.32834902761496193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1108] Loss: 0.32835408477414724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1109] Loss: 0.3283648069007028\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1110] Loss: 0.3283698832686221\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1111] Loss: 0.3283631044176104\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1112] Loss: 0.32838113565052923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1113] Loss: 0.32838978387590034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1114] Loss: 0.3283918342745804\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1115] Loss: 0.3283919266671981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1116] Loss: 0.3283806153658423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1117] Loss: 0.3283817512965163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1118] Loss: 0.3283872161297675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1119] Loss: 0.3283828476773479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1120] Loss: 0.32839266483057405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1121] Loss: 0.32838547205742097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1122] Loss: 0.328381425402759\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1123] Loss: 0.328380014684566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1124] Loss: 0.3283837002208953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1125] Loss: 0.3283705907776984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1126] Loss: 0.32836102323168603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1127] Loss: 0.32835401813551235\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1128] Loss: 0.328355323066597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1129] Loss: 0.3283485321545469\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1130] Loss: 0.32834996828259905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1131] Loss: 0.3283569616779864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1132] Loss: 0.3283532263876886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1133] Loss: 0.3283493659803397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1134] Loss: 0.32835072126082926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1135] Loss: 0.3283370267591105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1136] Loss: 0.3283258303953418\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1137] Loss: 0.32832800480115903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1138] Loss: 0.3283226918947627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1139] Loss: 0.32831147065481736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1140] Loss: 0.3283132786548239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1141] Loss: 0.3283126768942122\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1142] Loss: 0.3283075202041269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1143] Loss: 0.32831282691909575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1144] Loss: 0.32830666022276656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1145] Loss: 0.3283015323873665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1146] Loss: 0.3282993629221783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1147] Loss: 0.32831183532959707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1148] Loss: 0.3283127570139512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1149] Loss: 0.3283239412198384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1150] Loss: 0.3283187867637558\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1151] Loss: 0.32831362874177056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1152] Loss: 0.32831284720707427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1153] Loss: 0.3283218298194425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1154] Loss: 0.3283347573327727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1155] Loss: 0.3283340041655476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1156] Loss: 0.32835109652255934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1157] Loss: 0.32834977359426554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1158] Loss: 0.32834917879106934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1159] Loss: 0.3283485572361165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1160] Loss: 0.32834704984839236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1161] Loss: 0.3283512889880775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1162] Loss: 0.32834195163565133\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1163] Loss: 0.3283500482524647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1164] Loss: 0.32835260260122295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1165] Loss: 0.328345331852375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1166] Loss: 0.3283541124932295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1167] Loss: 0.32835577746384603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1168] Loss: 0.32834860524202497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1169] Loss: 0.3283433418613166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1170] Loss: 0.32833130065833577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1171] Loss: 0.32833952078620965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1172] Loss: 0.32833514849158707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1173] Loss: 0.3283218264307473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1174] Loss: 0.32832240487897335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1175] Loss: 0.3283118534322855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1176] Loss: 0.3283257859756933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1177] Loss: 0.3283204086042653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1178] Loss: 0.32831488614746257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1179] Loss: 0.32830597345552065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1180] Loss: 0.3283104819248604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1181] Loss: 0.3283065686359617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1182] Loss: 0.328299750688494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1183] Loss: 0.32831285853798575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1184] Loss: 0.3283107891613977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1185] Loss: 0.32830692217335095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1186] Loss: 0.32830330745400893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1187] Loss: 0.3283042099337845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1188] Loss: 0.3283048269719753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1189] Loss: 0.328309697563968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1190] Loss: 0.32831483288015223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1191] Loss: 0.3283222956826763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1192] Loss: 0.32831214229328326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1193] Loss: 0.3283105175797567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1194] Loss: 0.32831264052280645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1195] Loss: 0.3283236315458009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1196] Loss: 0.3283119112407024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1197] Loss: 0.32831740991791575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1198] Loss: 0.32832332991922275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1199] Loss: 0.3283116658801167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1200] Loss: 0.32831170378004115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1201] Loss: 0.3283286963651346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1202] Loss: 0.32833251058396346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1203] Loss: 0.32833557054516044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1204] Loss: 0.32835946691795903\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1205] Loss: 0.3283731535226199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1206] Loss: 0.3283764605595246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1207] Loss: 0.32836988446209825\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1208] Loss: 0.328370745727354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1209] Loss: 0.3283628140415571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1210] Loss: 0.32836206437411986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1211] Loss: 0.32835654886131843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1212] Loss: 0.3283569275523047\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1213] Loss: 0.3283567287772894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1214] Loss: 0.32835567013409866\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1215] Loss: 0.32836300469074503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1216] Loss: 0.3283485493930996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1217] Loss: 0.3283597763693589\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1218] Loss: 0.3283605455584371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1219] Loss: 0.3283806844660197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1220] Loss: 0.32837014006090137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1221] Loss: 0.32836494895825546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1222] Loss: 0.32837592031454926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1223] Loss: 0.32837378555067653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1224] Loss: 0.3283650109691694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1225] Loss: 0.32836828585379424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1226] Loss: 0.32836745772561254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1227] Loss: 0.32837984515407403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1228] Loss: 0.32837900658806213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1229] Loss: 0.32837307997527837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1230] Loss: 0.3283841462183351\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1231] Loss: 0.32838026318312113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1232] Loss: 0.32837225145837895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1233] Loss: 0.3283726441746018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1234] Loss: 0.3283749720919668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1235] Loss: 0.32839165883324145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1236] Loss: 0.3283991237474901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1237] Loss: 0.3284021437967139\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1238] Loss: 0.3284002567150376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1239] Loss: 0.32839002338447437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1240] Loss: 0.3283768200111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1241] Loss: 0.3283831310339761\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1242] Loss: 0.32837537355459945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1243] Loss: 0.32837820761222664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1244] Loss: 0.3283783373627537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1245] Loss: 0.3283678330959245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1246] Loss: 0.3283656186330653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1247] Loss: 0.3283624020955958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1248] Loss: 0.32836600206432354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1249] Loss: 0.32836163983073824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1250] Loss: 0.3283531352995103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1251] Loss: 0.3283698650099732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1252] Loss: 0.3283638789206432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1253] Loss: 0.32837818218035253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1254] Loss: 0.3283758430690847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1255] Loss: 0.32837861884639225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1256] Loss: 0.3283895592758638\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1257] Loss: 0.32839250117045343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1258] Loss: 0.32839762199944905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1259] Loss: 0.3283861528022542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1260] Loss: 0.3283732364480308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1261] Loss: 0.32836341747026093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1262] Loss: 0.32835676775725525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1263] Loss: 0.32835618056903476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1264] Loss: 0.3283504309250198\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1265] Loss: 0.3283621187041697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1266] Loss: 0.3283611593873981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1267] Loss: 0.3283759584463184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1268] Loss: 0.3283753556646881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1269] Loss: 0.32837474804432554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1270] Loss: 0.32836868162334837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1271] Loss: 0.32836144076849155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1272] Loss: 0.32835039778312364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1273] Loss: 0.3283570149355787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1274] Loss: 0.32835862258213944\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1275] Loss: 0.328346839614639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1276] Loss: 0.32834599108253376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1277] Loss: 0.3283510651572762\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1278] Loss: 0.32834853718823737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1279] Loss: 0.3283493716287545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1280] Loss: 0.32834330320029614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1281] Loss: 0.3283512737931779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1282] Loss: 0.32837934251502704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1283] Loss: 0.32838970055385747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1284] Loss: 0.3283993544755055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1285] Loss: 0.32840535642290297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1286] Loss: 0.3284073857118039\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1287] Loss: 0.32840566289616474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1288] Loss: 0.3284015757023484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1289] Loss: 0.3283915350841802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1290] Loss: 0.3283837861589955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1291] Loss: 0.3283837264224871\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1292] Loss: 0.3283806209662624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1293] Loss: 0.32838049526563134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1294] Loss: 0.32837612279130834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1295] Loss: 0.3283934979302833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1296] Loss: 0.3283986390677997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1297] Loss: 0.32839958645800477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1298] Loss: 0.3284109988434525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1299] Loss: 0.32840938472036824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1300] Loss: 0.32840245116229255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1301] Loss: 0.3284002185495433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1302] Loss: 0.3283962970264689\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1303] Loss: 0.328401443942108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1304] Loss: 0.32839262822331644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1305] Loss: 0.32838594324925796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1306] Loss: 0.32838223596053817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1307] Loss: 0.3283772463366281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1308] Loss: 0.3283774643328016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1309] Loss: 0.32838777033339817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1310] Loss: 0.32838385490600425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1311] Loss: 0.32838810918241357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1312] Loss: 0.3283912108673601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1313] Loss: 0.32839883443082757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1314] Loss: 0.3283951399414762\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8921\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1315] Loss: 0.3284140318669946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1316] Loss: 0.3284126916648305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1317] Loss: 0.3284146470896916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1318] Loss: 0.32841096353194016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1319] Loss: 0.32841733512377697\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1320] Loss: 0.32840223103289673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1321] Loss: 0.32839867556559293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1322] Loss: 0.3283893849589867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1323] Loss: 0.32840162043808335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1324] Loss: 0.32839453864068735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1325] Loss: 0.3284154294955934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1326] Loss: 0.3284191988327836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1327] Loss: 0.32841534213271306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1328] Loss: 0.3284243654670094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1329] Loss: 0.3284198224788375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1330] Loss: 0.3284286438939144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1331] Loss: 0.32842745070993434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1332] Loss: 0.32842069964365744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1333] Loss: 0.3284194990311579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1334] Loss: 0.3284083695843485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1335] Loss: 0.32842608668211054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1336] Loss: 0.32844035664464183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1337] Loss: 0.3284324606524721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1338] Loss: 0.3284461490715534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1339] Loss: 0.32845825725689054\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1340] Loss: 0.328462567966518\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1341] Loss: 0.3284667829434208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1342] Loss: 0.3284654663726304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1343] Loss: 0.3284703360122849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1344] Loss: 0.32846530928708084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1345] Loss: 0.32846754671636447\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1346] Loss: 0.32846672716973924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1347] Loss: 0.32846163126651595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1348] Loss: 0.3284578505750584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1349] Loss: 0.3284499297320303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1350] Loss: 0.328452137248519\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1351] Loss: 0.3284519298622434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1352] Loss: 0.32844104482981956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1353] Loss: 0.3284396651612332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1354] Loss: 0.328448350193717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1355] Loss: 0.3284594388882901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1356] Loss: 0.328458801873287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1357] Loss: 0.32844495256332873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1358] Loss: 0.32844995084840156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1359] Loss: 0.32844446694800206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1360] Loss: 0.3284441099265229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1361] Loss: 0.32844798405129966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1362] Loss: 0.32845055493600744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1363] Loss: 0.32844015713452834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1364] Loss: 0.3284353930196281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1365] Loss: 0.3284516660807699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1366] Loss: 0.328451814265655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1367] Loss: 0.32846296500509925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1368] Loss: 0.3284639954481349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1369] Loss: 0.3284603144577476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1370] Loss: 0.3284498953305489\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1371] Loss: 0.32844541571677177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1372] Loss: 0.3284362273580156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1373] Loss: 0.32843902412784864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1374] Loss: 0.3284314996406382\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1375] Loss: 0.32843743865478736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1376] Loss: 0.3284366560450677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1377] Loss: 0.32843890425333366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1378] Loss: 0.32844878564301094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1379] Loss: 0.32844629873331027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1380] Loss: 0.3284482430298062\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1381] Loss: 0.3284588126505018\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1382] Loss: 0.32844896674126545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1383] Loss: 0.3284388067213606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1384] Loss: 0.3284302032129072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1385] Loss: 0.3284364438426511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1386] Loss: 0.32843960004304495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1387] Loss: 0.328429525619789\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1388] Loss: 0.3284390195360831\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1389] Loss: 0.3284422448768177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1390] Loss: 0.32844691946584076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1391] Loss: 0.32844127122427297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1392] Loss: 0.3284354633436271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1393] Loss: 0.32843442403224354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1394] Loss: 0.3284303034276201\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1395] Loss: 0.32844337901481246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1396] Loss: 0.32845075996092205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1397] Loss: 0.32845678546778273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1398] Loss: 0.3284470558980744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1399] Loss: 0.3284402843886434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1400] Loss: 0.3284319670307424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1401] Loss: 0.3284229297893381\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1402] Loss: 0.32842544723318917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1403] Loss: 0.3284378784413416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1404] Loss: 0.3284271778243583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1405] Loss: 0.3284210580160111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1406] Loss: 0.32841427792038663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1407] Loss: 0.32841007674076783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1408] Loss: 0.32841283564931245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1409] Loss: 0.32840717337153985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1410] Loss: 0.32841335321504433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1411] Loss: 0.3284229795323481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1412] Loss: 0.3284232458841283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1413] Loss: 0.3284191721080596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1414] Loss: 0.3284204698778884\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1415] Loss: 0.32843491582390716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1416] Loss: 0.32844227896028827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1417] Loss: 0.32843545080311554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1418] Loss: 0.32844178680869196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1419] Loss: 0.32844601182431077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1420] Loss: 0.3284461685772745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1421] Loss: 0.32843513977490785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1422] Loss: 0.3284288246753796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1423] Loss: 0.3284218161746939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1424] Loss: 0.32842333166859405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1425] Loss: 0.3284128571254195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1426] Loss: 0.3283975872172877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1427] Loss: 0.3283957299910314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1428] Loss: 0.32839844066350005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1429] Loss: 0.32839027196839204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1430] Loss: 0.32839270621842614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1431] Loss: 0.3284033688302401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1432] Loss: 0.3283965480068406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1433] Loss: 0.3283902237276978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1434] Loss: 0.32838106668549205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1435] Loss: 0.3283962996191385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1436] Loss: 0.3283941682289307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1437] Loss: 0.32838639444213147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1438] Loss: 0.32838879638229096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1439] Loss: 0.3283859505476329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1440] Loss: 0.3283829500141997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1441] Loss: 0.3283917122048886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1442] Loss: 0.3283855393960231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1443] Loss: 0.3283963457697553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1444] Loss: 0.32839628414548583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1445] Loss: 0.32839545201847203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1446] Loss: 0.3283992483667297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1447] Loss: 0.32840945533029614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1448] Loss: 0.3284015550517428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1449] Loss: 0.32839583763943464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1450] Loss: 0.3283982823037199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1451] Loss: 0.3283998658331921\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1452] Loss: 0.32839586661292297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1453] Loss: 0.3284025679876861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1454] Loss: 0.32839421840445127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1455] Loss: 0.32839256395949945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1456] Loss: 0.3283821556328557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1457] Loss: 0.328380493020352\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1458] Loss: 0.3283721364754014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1459] Loss: 0.3283681891083255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1460] Loss: 0.328372882446894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1461] Loss: 0.3283639541317989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1462] Loss: 0.3283588332297938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1463] Loss: 0.32835639821882484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1464] Loss: 0.32836008601218664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1465] Loss: 0.3283564515628256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1466] Loss: 0.32835052447335616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1467] Loss: 0.32836423178499496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1468] Loss: 0.3283614072355423\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1469] Loss: 0.328351736406822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1470] Loss: 0.3283493833167172\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1471] Loss: 0.3283398385622714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1472] Loss: 0.3283311921104679\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1473] Loss: 0.32833676736711276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1474] Loss: 0.3283479316650476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1475] Loss: 0.32835388863044584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1476] Loss: 0.3283708742737299\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1477] Loss: 0.32836722547883995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1478] Loss: 0.3283580394245987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1479] Loss: 0.32836496239474583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1480] Loss: 0.32835918945651704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1481] Loss: 0.32834860194024074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1482] Loss: 0.32835259664897376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1483] Loss: 0.3283480047766648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1484] Loss: 0.32833438522326863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1485] Loss: 0.3283280631334422\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1486] Loss: 0.32834914667664905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1487] Loss: 0.3283443061222894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1488] Loss: 0.32834584407437684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1489] Loss: 0.3283384728517426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1490] Loss: 0.3283329189605115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1491] Loss: 0.3283349720447111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1492] Loss: 0.32834031825098087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1493] Loss: 0.3283475529639918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1494] Loss: 0.32833610861864954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1495] Loss: 0.3283353771151306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1496] Loss: 0.3283247620456228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1497] Loss: 0.32831858680300974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1498] Loss: 0.328314057205566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1499] Loss: 0.3283120244012542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1500] Loss: 0.3283253875766222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1501] Loss: 0.3283219732743006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1502] Loss: 0.3283171641472093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1503] Loss: 0.32832401662308036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1504] Loss: 0.32831788057457567\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1505] Loss: 0.32831049737339224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1506] Loss: 0.3283165896695847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1507] Loss: 0.3283170849368331\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1508] Loss: 0.3283317686137985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1509] Loss: 0.3283467689700138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1510] Loss: 0.32834288772770587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1511] Loss: 0.3283514811000123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1512] Loss: 0.3283435123307848\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1513] Loss: 0.3283476086079397\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1514] Loss: 0.3283612789237249\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1515] Loss: 0.3283570492508926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1516] Loss: 0.32835805092024134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1517] Loss: 0.32834908472793334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1518] Loss: 0.3283527558278017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1519] Loss: 0.3283746406660511\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1520] Loss: 0.3283648380295075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1521] Loss: 0.3283532429334207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1522] Loss: 0.32836254588648756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1523] Loss: 0.3283654339171602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 28, Batch 1524] Loss: 0.32837000299459707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 0] Loss: 0.32837108109127183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1] Loss: 0.3283662724559668\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 2] Loss: 0.32836264704932183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 3] Loss: 0.3283515807363827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 4] Loss: 0.32833928148347896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 5] Loss: 0.3283311764083156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 6] Loss: 0.32834940927405004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 7] Loss: 0.32834821000071857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 8] Loss: 0.3283420952175055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 9] Loss: 0.3283355445110413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 10] Loss: 0.3283396364458614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 11] Loss: 0.32836969125519216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 12] Loss: 0.3283673798140303\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 13] Loss: 0.32836549551646965\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 14] Loss: 0.32836109326844515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 15] Loss: 0.3283515313566024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 16] Loss: 0.32834301897672985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 17] Loss: 0.32835831855164604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 18] Loss: 0.3283653957857972\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 19] Loss: 0.3283589041540073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 20] Loss: 0.3283556155728665\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 21] Loss: 0.3283588068892939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 22] Loss: 0.3283556474146705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 23] Loss: 0.3283540130624196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 24] Loss: 0.32834957699393014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 25] Loss: 0.3283424441399212\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 26] Loss: 0.328335742962979\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 27] Loss: 0.32832810195308226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 28] Loss: 0.32831504345109\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 29] Loss: 0.3283317370847915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 30] Loss: 0.3283336930958198\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 31] Loss: 0.3283261490393187\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 32] Loss: 0.3283318933887096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 33] Loss: 0.32833534675854564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 34] Loss: 0.32833931283193124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 35] Loss: 0.3283398030479737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 36] Loss: 0.3283407953146008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 37] Loss: 0.3283662092683225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 38] Loss: 0.3283594727386843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 39] Loss: 0.3283653001135614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 40] Loss: 0.328361878801253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 41] Loss: 0.3283704951571931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 42] Loss: 0.32835903869171984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 43] Loss: 0.328364612213826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 44] Loss: 0.32835040056845316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 45] Loss: 0.32834985921425075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 46] Loss: 0.3283485099206837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 47] Loss: 0.3283623906108254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 48] Loss: 0.32835637938349227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 49] Loss: 0.32834835410686686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 50] Loss: 0.32833662388171836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 51] Loss: 0.32832614379512737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 52] Loss: 0.32831671621832453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 53] Loss: 0.3283151432984153\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 54] Loss: 0.32830833623400013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 55] Loss: 0.3283111928838832\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 56] Loss: 0.328305979484211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 57] Loss: 0.3283040548465392\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 58] Loss: 0.32830205948541913\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 59] Loss: 0.32833177980677525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 60] Loss: 0.32833880337484006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 61] Loss: 0.32833138223382996\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 62] Loss: 0.32833590053209377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 63] Loss: 0.3283257685941267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 64] Loss: 0.3283270038220988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 65] Loss: 0.32832831109035643\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 66] Loss: 0.32833378753309367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 67] Loss: 0.3283319374870011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 68] Loss: 0.32833371897991076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 69] Loss: 0.32833328629209196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 70] Loss: 0.3283358483787465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 71] Loss: 0.3283457822471168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 72] Loss: 0.328338383213224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 73] Loss: 0.3283322446909128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 74] Loss: 0.32831852712117365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 75] Loss: 0.32831896647901776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 76] Loss: 0.32831672514289223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 77] Loss: 0.32831655207855165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 78] Loss: 0.3283133832879359\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 79] Loss: 0.3283119484934695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 80] Loss: 0.3283174715666008\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 81] Loss: 0.3283338408452263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 82] Loss: 0.32833242867933876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 83] Loss: 0.32832277692285594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 84] Loss: 0.3283296643877368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 85] Loss: 0.32832093574115095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 86] Loss: 0.3283135826758405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 87] Loss: 0.3283391493534457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 88] Loss: 0.3283451820388997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 89] Loss: 0.32833953070415156\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 90] Loss: 0.32834312227953555\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 91] Loss: 0.3283403570931997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 92] Loss: 0.3283557726710954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 93] Loss: 0.3283494373481778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 94] Loss: 0.3283369563235504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 95] Loss: 0.3283278962673257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 96] Loss: 0.32834108745853374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 97] Loss: 0.3283304702581538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 98] Loss: 0.32832510774461154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 99] Loss: 0.32832859950277954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 100] Loss: 0.32833167769254384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 101] Loss: 0.3283310036157394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 102] Loss: 0.32832446121954156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 103] Loss: 0.3283124971509517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 104] Loss: 0.3283160640579752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 105] Loss: 0.3283259121398583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 106] Loss: 0.3283215790090797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 107] Loss: 0.32830999295047314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 108] Loss: 0.32831216290335846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 109] Loss: 0.32831258070380753\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 110] Loss: 0.3283083643772646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 111] Loss: 0.3283025853871038\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 112] Loss: 0.32830349273456266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 113] Loss: 0.3283184648057757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 114] Loss: 0.3283221320309663\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 115] Loss: 0.3283225067288026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 116] Loss: 0.3283343401375268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 117] Loss: 0.32833323106074674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 118] Loss: 0.3283220033944547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 119] Loss: 0.32832978278796443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 120] Loss: 0.32831947977198894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 121] Loss: 0.3283098726567231\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 122] Loss: 0.32830986387896915\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 123] Loss: 0.32831249962228043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 124] Loss: 0.32832395043067664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 125] Loss: 0.3283215942848808\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 126] Loss: 0.328331744579593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 127] Loss: 0.3283405366127964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 128] Loss: 0.32833636512720155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 129] Loss: 0.32832979383745003\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 130] Loss: 0.32832284465883377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 131] Loss: 0.32831307762373446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 132] Loss: 0.3283239204634195\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 133] Loss: 0.32833770023845205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 134] Loss: 0.3283262023623828\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 135] Loss: 0.3283233150846504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 136] Loss: 0.32831359742355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 137] Loss: 0.3283091010519544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 138] Loss: 0.32830586307671633\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 139] Loss: 0.32829873351841043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 140] Loss: 0.3283089492922016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 141] Loss: 0.32829870646117126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 142] Loss: 0.3282897102491565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 143] Loss: 0.3282925020544907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 144] Loss: 0.3282819844912888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 145] Loss: 0.3282719156448602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 146] Loss: 0.32827347131656004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 147] Loss: 0.32826416255509266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 148] Loss: 0.32825115643118224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 149] Loss: 0.32825115819084333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 150] Loss: 0.32825604028015093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 151] Loss: 0.32825192384193785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 152] Loss: 0.3282456626361295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 153] Loss: 0.32824478973298316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 154] Loss: 0.32824245202223395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 155] Loss: 0.3282563801632731\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 156] Loss: 0.32825616064895546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 157] Loss: 0.3282448368096719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 158] Loss: 0.32824739980035605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 159] Loss: 0.3282602300466101\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 160] Loss: 0.32825523728937706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 161] Loss: 0.32826110800137775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 162] Loss: 0.3282559658483582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 163] Loss: 0.32824357827857276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 164] Loss: 0.32825377855380844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 165] Loss: 0.32824345944211064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 166] Loss: 0.32825383640929334\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 167] Loss: 0.32824976883661017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 168] Loss: 0.328252225756222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 169] Loss: 0.3282700162593911\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 170] Loss: 0.32825919377843443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 171] Loss: 0.3282620240441844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 172] Loss: 0.3282694511602088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 173] Loss: 0.32828762729721456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 174] Loss: 0.3282822326385626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 175] Loss: 0.32828677857388316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 176] Loss: 0.3282767674714006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 177] Loss: 0.32827800791828865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 178] Loss: 0.32826836231742623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 179] Loss: 0.3282711900629898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 180] Loss: 0.3282787379744188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 181] Loss: 0.32827443052393396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 182] Loss: 0.328272479261585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 183] Loss: 0.32826575865414925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 184] Loss: 0.32826670766973554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 185] Loss: 0.3282704392178758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 186] Loss: 0.3282673673673403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 187] Loss: 0.3282675016789581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 188] Loss: 0.3282618883991642\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 189] Loss: 0.3282516344638958\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 190] Loss: 0.3282491853917922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 191] Loss: 0.32824330730124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 192] Loss: 0.3282429016198295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 193] Loss: 0.3282472822519213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 194] Loss: 0.3282368907125009\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 195] Loss: 0.3282281280396377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 196] Loss: 0.328219320844561\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 197] Loss: 0.3282410480269286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 198] Loss: 0.32823504421257155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 199] Loss: 0.3282217337934552\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 200] Loss: 0.3282093856308155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 201] Loss: 0.3282222258357414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 202] Loss: 0.3282100409474843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 203] Loss: 0.32820027766668036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 204] Loss: 0.3281934201205344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 205] Loss: 0.328192557621737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 206] Loss: 0.32818576163976143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 207] Loss: 0.3281858480622271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 208] Loss: 0.3281811338617576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 209] Loss: 0.32817121793885634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 210] Loss: 0.328182386467268\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 211] Loss: 0.3281910988706675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 212] Loss: 0.32819739196069886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 213] Loss: 0.3282145199179649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 214] Loss: 0.32822257648106307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 215] Loss: 0.3282206455823954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 216] Loss: 0.3282215878348559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 217] Loss: 0.32822211941217166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 218] Loss: 0.3282188673490521\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 219] Loss: 0.32822154091389444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 220] Loss: 0.3282138270416373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 221] Loss: 0.3282083716624271\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 222] Loss: 0.3282143074524967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 223] Loss: 0.3282011337242785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 224] Loss: 0.32819009004934324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 225] Loss: 0.3281899369144676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 226] Loss: 0.3281754476710886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 227] Loss: 0.32817946116121427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 228] Loss: 0.328182088937943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 229] Loss: 0.328179322839444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 230] Loss: 0.3281747739927796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 231] Loss: 0.32817611100894395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 232] Loss: 0.3281682917265772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 233] Loss: 0.3281782328822037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 234] Loss: 0.3281729256347205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 235] Loss: 0.3282365377662997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 236] Loss: 0.32823125408006115\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 237] Loss: 0.32822844711457744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 238] Loss: 0.3282537826978806\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 239] Loss: 0.32824761771442773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 240] Loss: 0.3282448267810647\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 241] Loss: 0.3282563519000006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 242] Loss: 0.3282624811783568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 243] Loss: 0.32827410702754556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 244] Loss: 0.3282794680564878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 245] Loss: 0.3282703287457121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 246] Loss: 0.328262282582768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 247] Loss: 0.32826986258405394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 248] Loss: 0.3282644746877685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 249] Loss: 0.3282563009807653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 250] Loss: 0.32826379565000446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 251] Loss: 0.328254668823896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 252] Loss: 0.3282480047278624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 253] Loss: 0.32824003449048067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 254] Loss: 0.3282462187956802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 255] Loss: 0.32824204145496616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 256] Loss: 0.328240534635872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 257] Loss: 0.3282411760026951\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 258] Loss: 0.32824200051542823\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 259] Loss: 0.3282575571642546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 260] Loss: 0.3282519990822738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 261] Loss: 0.3282580943940601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 262] Loss: 0.3282643837371256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 263] Loss: 0.3282654498442869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 264] Loss: 0.3282613948957304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 265] Loss: 0.3282677782810724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 266] Loss: 0.32826288828151146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 267] Loss: 0.3282537284225029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 268] Loss: 0.328249366303425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 269] Loss: 0.32824782946426606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 270] Loss: 0.3282418493062651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 271] Loss: 0.3282431716717316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 272] Loss: 0.3282420053935544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 273] Loss: 0.3282341706380386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 274] Loss: 0.3282251544760814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 275] Loss: 0.32821712107496015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 276] Loss: 0.32822039285409543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 277] Loss: 0.32822448819813854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 278] Loss: 0.3282191560672026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 279] Loss: 0.3282243616779027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 280] Loss: 0.32823007045937175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 281] Loss: 0.32823053797884905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 282] Loss: 0.3282249717397152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 283] Loss: 0.3282228640773068\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 284] Loss: 0.32821970425875197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 285] Loss: 0.3282068178837119\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 286] Loss: 0.3281999372811357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 287] Loss: 0.3282038798476115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 288] Loss: 0.32820745126351164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 289] Loss: 0.3281990795909286\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8914\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 290] Loss: 0.32821417957767257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 291] Loss: 0.3282075573608918\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 292] Loss: 0.32819562773076794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 293] Loss: 0.3281962855756614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 294] Loss: 0.3282062615357989\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 295] Loss: 0.3281963893975046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 296] Loss: 0.32821431304671494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 297] Loss: 0.3282129022317129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 298] Loss: 0.3282067866727081\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 299] Loss: 0.3282030429634553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 300] Loss: 0.3282250498199274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 301] Loss: 0.3282289974022598\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 302] Loss: 0.32826896416996737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 303] Loss: 0.328270416823948\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 304] Loss: 0.3282702836299276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 305] Loss: 0.32826673762559044\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 306] Loss: 0.328259686155531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 307] Loss: 0.328279963666888\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 308] Loss: 0.3282731164726236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 309] Loss: 0.3282665268829849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 310] Loss: 0.32826991755316426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 311] Loss: 0.32828260289939964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 312] Loss: 0.3282924023867579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 313] Loss: 0.328291915554326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 314] Loss: 0.328286664456605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 315] Loss: 0.3282822615064864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 316] Loss: 0.32829968300650786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 317] Loss: 0.3282945347772671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 318] Loss: 0.32828836317854904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 319] Loss: 0.32828030359393945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 320] Loss: 0.32827622522557326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 321] Loss: 0.3282762055285206\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 322] Loss: 0.3282678536211958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 323] Loss: 0.32826216139001163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 324] Loss: 0.3282557433657128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 325] Loss: 0.3282519823134654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 326] Loss: 0.3282466398964544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 327] Loss: 0.32824286836609373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 328] Loss: 0.328250343050461\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 329] Loss: 0.3282633997165957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 330] Loss: 0.32827859345216676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 331] Loss: 0.32827637087902256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 332] Loss: 0.3282636865963571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 333] Loss: 0.32826463877989737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 334] Loss: 0.3282682254462752\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 335] Loss: 0.3282732639178241\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 336] Loss: 0.3282845159071427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 337] Loss: 0.3282902941494879\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 338] Loss: 0.32828791325327655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 339] Loss: 0.328288667633031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 340] Loss: 0.328288666461402\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 341] Loss: 0.3283026528966028\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 342] Loss: 0.3283030224637778\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 343] Loss: 0.328316383812424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 344] Loss: 0.3283103218323566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 345] Loss: 0.32830483072341926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 346] Loss: 0.3283023169418891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 347] Loss: 0.3283039264348512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 348] Loss: 0.32829863857148234\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 349] Loss: 0.3282929709606023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 350] Loss: 0.32829696502299754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 351] Loss: 0.3282937886592896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 352] Loss: 0.3282899517935089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 353] Loss: 0.32827815517557973\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 354] Loss: 0.3282801656130183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 355] Loss: 0.3282762429325962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 356] Loss: 0.3282731218029578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 357] Loss: 0.3282772222696764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 358] Loss: 0.32827720257920995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 359] Loss: 0.32827615199613197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 360] Loss: 0.3282734703342849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 361] Loss: 0.3282726919918688\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 362] Loss: 0.32827674439038323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 363] Loss: 0.32827243315306376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 364] Loss: 0.3282745567199258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 365] Loss: 0.3282869904580353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 366] Loss: 0.32829247443983545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 367] Loss: 0.3282977265894075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 368] Loss: 0.32830256988432954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 369] Loss: 0.3282970344748845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 370] Loss: 0.3283141454699034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 371] Loss: 0.32830691285640373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 372] Loss: 0.32832391289621154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 373] Loss: 0.3283227668430027\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 374] Loss: 0.3283319879264565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 375] Loss: 0.32832629594749246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 376] Loss: 0.3283238720690543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 377] Loss: 0.32832446944444715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 378] Loss: 0.3283343777778703\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 379] Loss: 0.32836246608286607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 380] Loss: 0.32836667634272676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 381] Loss: 0.328354897669681\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 382] Loss: 0.32834720575892345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 383] Loss: 0.3283413942699136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 384] Loss: 0.328344481701547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 385] Loss: 0.32833802244744686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 386] Loss: 0.32833710194657545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 387] Loss: 0.32834888494427183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 388] Loss: 0.3283412073941573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 389] Loss: 0.32834360354225495\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 390] Loss: 0.3283488251424426\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 391] Loss: 0.3283483758218225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 392] Loss: 0.3283520078073483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 393] Loss: 0.3283473132195301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 394] Loss: 0.32835534387082627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 395] Loss: 0.32834619733492565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 396] Loss: 0.3283403325516036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 397] Loss: 0.32834306342593106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 398] Loss: 0.3283357296765814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 399] Loss: 0.3283303147933851\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 400] Loss: 0.3283174621626021\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 401] Loss: 0.32831607319013434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 402] Loss: 0.3283098991229677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 403] Loss: 0.32830865690748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 404] Loss: 0.32830932002775065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 405] Loss: 0.3283133187987227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 406] Loss: 0.32831038943279733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 407] Loss: 0.32831130233568734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 408] Loss: 0.3283158861664117\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 409] Loss: 0.3283077058674358\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 410] Loss: 0.3282956534717957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 411] Loss: 0.3282973432891136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 412] Loss: 0.32828962574349263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 413] Loss: 0.32828096296973186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 414] Loss: 0.328272277101356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 415] Loss: 0.32826816341902265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 416] Loss: 0.328266732444446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 417] Loss: 0.3282764340532273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 418] Loss: 0.3282886158841678\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 419] Loss: 0.32829114918861935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 420] Loss: 0.3282984258457275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 421] Loss: 0.32831751185544544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 422] Loss: 0.32832168769192466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 423] Loss: 0.3283335313299308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 424] Loss: 0.32832564653576857\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 425] Loss: 0.3283174057541866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 426] Loss: 0.32835348352597576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 427] Loss: 0.32835208445861724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 428] Loss: 0.3283412938631656\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 429] Loss: 0.3283348433762411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 430] Loss: 0.3283389671220272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 431] Loss: 0.3283313443975863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 432] Loss: 0.32832835891484186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 433] Loss: 0.3283260087257735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 434] Loss: 0.3283223140835718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 435] Loss: 0.32831106788609205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 436] Loss: 0.3283126788155983\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 437] Loss: 0.3283022278733538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 438] Loss: 0.3282982052131232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 439] Loss: 0.32829109984955923\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 440] Loss: 0.3282824804285449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 441] Loss: 0.3282750295343473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 442] Loss: 0.328282854776113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 443] Loss: 0.32829341391740546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 444] Loss: 0.3283064805138169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 445] Loss: 0.3282997092208786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 446] Loss: 0.32830122756330016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 447] Loss: 0.3283008120605481\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 448] Loss: 0.32829474754587884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 449] Loss: 0.3282819436366078\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 450] Loss: 0.3282827071882615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 451] Loss: 0.32828174443828373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 452] Loss: 0.3282809170433026\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 453] Loss: 0.3282728100979978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 454] Loss: 0.32828912010764494\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 455] Loss: 0.3282986056655722\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 456] Loss: 0.3282887748670719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 457] Loss: 0.32829278873914564\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 458] Loss: 0.32828434319252414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 459] Loss: 0.32829480291025476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 460] Loss: 0.32828466336620504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 461] Loss: 0.32827927108701754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 462] Loss: 0.3282908726457974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 463] Loss: 0.32829347021891386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 464] Loss: 0.3282884969118613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 465] Loss: 0.32829016198932476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 466] Loss: 0.3282974173537793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 467] Loss: 0.3282960695315674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 468] Loss: 0.3282833428318171\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 469] Loss: 0.3282737904324595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 470] Loss: 0.32827615196792254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 471] Loss: 0.32829219678247096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 472] Loss: 0.32828585537968846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 473] Loss: 0.32829238821554674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 474] Loss: 0.3283004344144438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 475] Loss: 0.32829832040356466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 476] Loss: 0.3283089428159236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 477] Loss: 0.32831631876314366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 478] Loss: 0.3283375902859245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 479] Loss: 0.3283358010770275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 480] Loss: 0.3283452789396866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 481] Loss: 0.32835144281576684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 482] Loss: 0.32834721188673976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 483] Loss: 0.32835349582404977\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 484] Loss: 0.3283467816638273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 485] Loss: 0.3283458567588418\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 486] Loss: 0.32836196843492826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 487] Loss: 0.32835663363138456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 488] Loss: 0.3283527406751022\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 489] Loss: 0.3283446050745868\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 490] Loss: 0.32835865322918617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 491] Loss: 0.32835999619516676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 492] Loss: 0.32837584125496755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 493] Loss: 0.3283715978634484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 494] Loss: 0.32837319425237227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 495] Loss: 0.328391822901985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 496] Loss: 0.32840039396100346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 497] Loss: 0.32839387252701824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 498] Loss: 0.32841847607693386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 499] Loss: 0.32842030750925716\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 500] Loss: 0.32842314697404323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 501] Loss: 0.328436909074627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 502] Loss: 0.32842726004700434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 503] Loss: 0.32842645657907815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 504] Loss: 0.32843474606766354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 505] Loss: 0.3284350355972074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 506] Loss: 0.3284419739070613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 507] Loss: 0.3284474952616587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 508] Loss: 0.32844781665071715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 509] Loss: 0.3284372768394237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 510] Loss: 0.3284344033298357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 511] Loss: 0.32843178405066686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 512] Loss: 0.3284362102993087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 513] Loss: 0.3284522149379353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 514] Loss: 0.3284425863560002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 515] Loss: 0.32844100861877384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 516] Loss: 0.32843553252346674\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 517] Loss: 0.328440027881675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 518] Loss: 0.3284397591515909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 519] Loss: 0.3284384481346787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 520] Loss: 0.3284324875202908\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 521] Loss: 0.32843004136969445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 522] Loss: 0.32843897090520907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 523] Loss: 0.3284417413861308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 524] Loss: 0.3284321909382002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 525] Loss: 0.3284183233578262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 526] Loss: 0.3284201141062314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 527] Loss: 0.32843194541263304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 528] Loss: 0.3284440264078684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 529] Loss: 0.3284573094668143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 530] Loss: 0.32847400282183914\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 531] Loss: 0.3284745443432619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 532] Loss: 0.3284840105861486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 533] Loss: 0.32847952626268834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 534] Loss: 0.3284726967406632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 535] Loss: 0.32847120114672945\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 536] Loss: 0.32846886829866256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 537] Loss: 0.32846912963460667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 538] Loss: 0.32847747106823055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 539] Loss: 0.32847663692186707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 540] Loss: 0.3284789332155617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 541] Loss: 0.3284847583051015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 542] Loss: 0.3284887703978228\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 543] Loss: 0.32848547584455434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 544] Loss: 0.32847885193379595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 545] Loss: 0.32848305996604077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 546] Loss: 0.32848442909335535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 547] Loss: 0.3284877819587251\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 548] Loss: 0.3284942974937473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 549] Loss: 0.3284937889212249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 550] Loss: 0.32848745992856826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 551] Loss: 0.3284770653944527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 552] Loss: 0.3284873615331088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 553] Loss: 0.32848398043455057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 554] Loss: 0.3284901722894364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 555] Loss: 0.3284894594990446\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 556] Loss: 0.3284823178940868\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 557] Loss: 0.3284791133953159\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 558] Loss: 0.3284814811388089\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 559] Loss: 0.3284762199056728\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 560] Loss: 0.32846991247528606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 561] Loss: 0.328457756915864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 562] Loss: 0.32846120878928575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 563] Loss: 0.32845631598290426\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 564] Loss: 0.3284574728237376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 565] Loss: 0.3284460687760415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 566] Loss: 0.3284390341771161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 567] Loss: 0.32843963203986726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 568] Loss: 0.32843458638060163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 569] Loss: 0.3284268735791531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 570] Loss: 0.328429632068887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 571] Loss: 0.3284299892907797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 572] Loss: 0.3284446244629114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 573] Loss: 0.3284397691709865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 574] Loss: 0.32844278034069757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 575] Loss: 0.3284358641474114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 576] Loss: 0.3284323734696279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 577] Loss: 0.3284386000893505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 578] Loss: 0.32843476795659626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 579] Loss: 0.32843212461510024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 580] Loss: 0.32846989981633484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 581] Loss: 0.3284851500427827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 582] Loss: 0.3285172994317301\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 583] Loss: 0.32851403165323745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 584] Loss: 0.32851827507376863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 585] Loss: 0.32851086818656516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 586] Loss: 0.32852099955585196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 587] Loss: 0.32851152579508724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 588] Loss: 0.32850101548638466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 589] Loss: 0.328511305126377\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 590] Loss: 0.3285139636000962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 591] Loss: 0.3285080971578053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 592] Loss: 0.3284955938365305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 593] Loss: 0.3284829689865093\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 594] Loss: 0.3284834896756802\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 595] Loss: 0.3284957477205166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 596] Loss: 0.32849296195182176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 597] Loss: 0.3284852077243114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 598] Loss: 0.3284832564370732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 599] Loss: 0.32848671084777925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 600] Loss: 0.32848009524897687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 601] Loss: 0.3284791541402253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 602] Loss: 0.3284713020989143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 603] Loss: 0.3284610630219672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 604] Loss: 0.32845826470684075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 605] Loss: 0.3284635904672488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 606] Loss: 0.3284670560791784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 607] Loss: 0.3284650833472449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 608] Loss: 0.3284584660449654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 609] Loss: 0.3284640296469954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 610] Loss: 0.3284660593465438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 611] Loss: 0.3284652229366958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 612] Loss: 0.32846194732431927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 613] Loss: 0.3284709045053822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 614] Loss: 0.32847867538091174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 615] Loss: 0.3284706672372145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 616] Loss: 0.3284682514674537\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 617] Loss: 0.3284729066949293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 618] Loss: 0.32846992025912797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 619] Loss: 0.3284672643087293\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 620] Loss: 0.32845986192316645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 621] Loss: 0.3284535472486151\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 622] Loss: 0.32844640031344924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 623] Loss: 0.32843923111566364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 624] Loss: 0.32842662444068416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 625] Loss: 0.3284293375098956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 626] Loss: 0.3284316911118614\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 627] Loss: 0.32843535885228803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 628] Loss: 0.32843196711131517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 629] Loss: 0.328430722473859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 630] Loss: 0.32842195788612344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 631] Loss: 0.3284211337802116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 632] Loss: 0.32842784464667124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 633] Loss: 0.32842504241947407\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 634] Loss: 0.32842015869410746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 635] Loss: 0.3284142088792578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 636] Loss: 0.32844962516411114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 637] Loss: 0.32844452157372367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 638] Loss: 0.32843695170558745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 639] Loss: 0.3284367483944878\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 640] Loss: 0.32843987567717636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 641] Loss: 0.32843982176607134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 642] Loss: 0.3284345582601904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 643] Loss: 0.32843778766382475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 644] Loss: 0.32844640796963237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 645] Loss: 0.3284455186021296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 646] Loss: 0.3284317057809327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 647] Loss: 0.3284333530342788\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 648] Loss: 0.3284543214352401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 649] Loss: 0.3284604731729756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 650] Loss: 0.3284764750150483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 651] Loss: 0.3284897275109411\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 652] Loss: 0.32847749823150835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 653] Loss: 0.3284925148879798\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 654] Loss: 0.3284889067205218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 655] Loss: 0.3284879508848368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 656] Loss: 0.3284883129125435\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 657] Loss: 0.32847986617227304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 658] Loss: 0.32847734160973774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 659] Loss: 0.3284676724639445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 660] Loss: 0.3284626882528669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 661] Loss: 0.3284628148994449\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 662] Loss: 0.3284507883655994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 663] Loss: 0.3284434200015154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 664] Loss: 0.32843483190067513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 665] Loss: 0.3284406707521912\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 666] Loss: 0.32842941157705574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 667] Loss: 0.3284455039972264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 668] Loss: 0.32843770586888194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 669] Loss: 0.3284249563529893\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 670] Loss: 0.32842130769629707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 671] Loss: 0.3284236845588346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 672] Loss: 0.3284335738980085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 673] Loss: 0.3284348710813366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 674] Loss: 0.3284355487192113\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 675] Loss: 0.328428624742269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 676] Loss: 0.3284191084217735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 677] Loss: 0.32841272858624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 678] Loss: 0.3284143004075626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 679] Loss: 0.3284209171918434\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 680] Loss: 0.328426269080684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 681] Loss: 0.328427871093524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 682] Loss: 0.32844685738936025\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 683] Loss: 0.32844289603176285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 684] Loss: 0.328453808777875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 685] Loss: 0.32845840575556157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 686] Loss: 0.32845841050480384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 687] Loss: 0.32845135973954737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 688] Loss: 0.3284462564181295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 689] Loss: 0.32843347672075857\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 690] Loss: 0.32843508399082955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 691] Loss: 0.3284457476474283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 692] Loss: 0.3284417478334463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 693] Loss: 0.32844696769082943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 694] Loss: 0.3284464348549596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 695] Loss: 0.3284640875769877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 696] Loss: 0.32847784429323595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 697] Loss: 0.3284749731022935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 698] Loss: 0.3284719374151345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 699] Loss: 0.32846545529585347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 700] Loss: 0.32847300113637756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 701] Loss: 0.3284655680006664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 702] Loss: 0.32845975965876184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 703] Loss: 0.32846008395970916\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 704] Loss: 0.32846007836684393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 705] Loss: 0.3284758644765664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 706] Loss: 0.32846874048373176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 707] Loss: 0.32847418906507725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 708] Loss: 0.3284720551741748\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 709] Loss: 0.32846114559051043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 710] Loss: 0.32845350732683554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 711] Loss: 0.32845290906736413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 712] Loss: 0.3284491388599691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 713] Loss: 0.3284429958259396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 714] Loss: 0.3284490610561536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 715] Loss: 0.328438670086704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 716] Loss: 0.3284328692447713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 717] Loss: 0.3284313953822946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 718] Loss: 0.3284444014689559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 719] Loss: 0.3284368364788995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 720] Loss: 0.32843028181298023\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 721] Loss: 0.3284328410490574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 722] Loss: 0.32842926634789726\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 723] Loss: 0.3284250512804701\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 724] Loss: 0.3284254062628902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 725] Loss: 0.3284224985510725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 726] Loss: 0.32842132539115126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 727] Loss: 0.3284246293972611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 728] Loss: 0.32842769865614696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 729] Loss: 0.3284255330979324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 730] Loss: 0.3284166669984738\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 731] Loss: 0.3284124276823005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 732] Loss: 0.3284062667746082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 733] Loss: 0.32841491671275735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 734] Loss: 0.32841978346023143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 735] Loss: 0.32842080489270037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 736] Loss: 0.3284410410166718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 737] Loss: 0.328483994069262\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 738] Loss: 0.3284908936981873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 739] Loss: 0.3284911051847569\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 740] Loss: 0.3284939036116115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 741] Loss: 0.3284999285541255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 742] Loss: 0.328513404990641\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 743] Loss: 0.32850507114820693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 744] Loss: 0.32850129420979296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 745] Loss: 0.3284918035071525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 746] Loss: 0.32850791061002677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 747] Loss: 0.32850660983259833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 748] Loss: 0.32850951217595264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 749] Loss: 0.32850689810799644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 750] Loss: 0.32850405051044895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 751] Loss: 0.3285105260626503\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 752] Loss: 0.3285109330847992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 753] Loss: 0.32850987575268004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 754] Loss: 0.32851278923103006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 755] Loss: 0.32849993830286817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 756] Loss: 0.3284875089478682\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 757] Loss: 0.3285042959102001\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 758] Loss: 0.3285036965676649\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 759] Loss: 0.32849224000448196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 760] Loss: 0.32849087807646615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 761] Loss: 0.3284866390254591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 762] Loss: 0.32849157342845337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 763] Loss: 0.3284936827714413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 764] Loss: 0.3284996521046666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 765] Loss: 0.3284917590122729\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 766] Loss: 0.32850023290247155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 767] Loss: 0.32850085388035194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 768] Loss: 0.32848784240903345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 769] Loss: 0.3284776959290884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 770] Loss: 0.3284792975012222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 771] Loss: 0.32848318877007787\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 772] Loss: 0.32847534825660935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 773] Loss: 0.3284775675318051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 774] Loss: 0.32846981942723974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 775] Loss: 0.3284628712966673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 776] Loss: 0.32845110576125786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 777] Loss: 0.32847154705617243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 778] Loss: 0.3284640490385658\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 779] Loss: 0.3284717671614167\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 780] Loss: 0.3284719482467873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 781] Loss: 0.328472334212417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 782] Loss: 0.328471058569939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 783] Loss: 0.32847576428786396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 784] Loss: 0.3284688244208323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 785] Loss: 0.32847103045522347\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 786] Loss: 0.3284950475569733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 787] Loss: 0.3284944873041055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 788] Loss: 0.32850445274316836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 789] Loss: 0.32851446530108586\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8971\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 790] Loss: 0.3285155650640646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 791] Loss: 0.32850964935268323\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 792] Loss: 0.3284998821252646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 793] Loss: 0.3285013859541618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 794] Loss: 0.3284980227592782\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 795] Loss: 0.3284981750697057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 796] Loss: 0.3284985147419783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 797] Loss: 0.3284967676713479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 798] Loss: 0.32850143638180884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 799] Loss: 0.32850428221940176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 800] Loss: 0.3285029268718016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 801] Loss: 0.3284965046571603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 802] Loss: 0.3285093572252833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 803] Loss: 0.3285020346130978\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 804] Loss: 0.32849385708062295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 805] Loss: 0.32849483063706675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 806] Loss: 0.3284900211008261\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 807] Loss: 0.3284927093428487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 808] Loss: 0.32848752904178496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 809] Loss: 0.3284908932853626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 810] Loss: 0.3284912115480204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 811] Loss: 0.32848705471588474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 812] Loss: 0.32847822069987886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 813] Loss: 0.3284695822749546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 814] Loss: 0.32846327539457415\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 815] Loss: 0.32848068518885326\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 816] Loss: 0.3285037398456227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 817] Loss: 0.32849143521489943\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 818] Loss: 0.3284896580989626\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 819] Loss: 0.3284866273064384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 820] Loss: 0.3284878345634342\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 821] Loss: 0.3284980418435448\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 822] Loss: 0.3285081941760239\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 823] Loss: 0.3285069996075015\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 824] Loss: 0.3284968599060274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 825] Loss: 0.32848473882561796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 826] Loss: 0.3284931169937718\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 827] Loss: 0.3284875754750185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 828] Loss: 0.32849039601008184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 829] Loss: 0.3284812399896111\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 830] Loss: 0.3284786142389746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 831] Loss: 0.3284721124286174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 832] Loss: 0.32847690019980436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 833] Loss: 0.3284680835295292\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 834] Loss: 0.328461075902609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 835] Loss: 0.32848279586394263\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 836] Loss: 0.32848080589567524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 837] Loss: 0.3284746038521496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 838] Loss: 0.32848945174087835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 839] Loss: 0.32848107709215507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 840] Loss: 0.3284845078947781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 841] Loss: 0.32848860264844526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 842] Loss: 0.3284787252238936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 843] Loss: 0.3284962330036043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 844] Loss: 0.32848511712639406\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 845] Loss: 0.32847589202383687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 846] Loss: 0.32846995695221304\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 847] Loss: 0.32847568297945373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 848] Loss: 0.3284732686183488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 849] Loss: 0.3284958249176433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 850] Loss: 0.32850071253704577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 851] Loss: 0.3284998105843266\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 852] Loss: 0.32851111968085\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 853] Loss: 0.3285046445419684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 854] Loss: 0.32850750554000757\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 855] Loss: 0.32851050272366805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 856] Loss: 0.328508382735158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 857] Loss: 0.3285135446414611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 858] Loss: 0.32851256809456175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 859] Loss: 0.32851504379551544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 860] Loss: 0.32852077556296444\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 861] Loss: 0.3285168914497216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 862] Loss: 0.3285187822440368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 863] Loss: 0.32851869860879057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 864] Loss: 0.32853427793937556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 865] Loss: 0.3285280962045867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 866] Loss: 0.32852291935899497\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 867] Loss: 0.3285324170156732\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 868] Loss: 0.32854249039400285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 869] Loss: 0.32854188043023874\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 870] Loss: 0.3285432286558419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 871] Loss: 0.3285604722304269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 872] Loss: 0.328579872877815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 873] Loss: 0.32858485719932917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 874] Loss: 0.3285882630799747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 875] Loss: 0.3285864010292439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 876] Loss: 0.32857805862229517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 877] Loss: 0.3285673772710618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 878] Loss: 0.32856190789192175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 879] Loss: 0.32855338188825867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 880] Loss: 0.32854896904004505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 881] Loss: 0.3285437842859696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 882] Loss: 0.32853828519699046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 883] Loss: 0.328530351671715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 884] Loss: 0.3285385867803824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 885] Loss: 0.3285409647133948\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 886] Loss: 0.32854323752318515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 887] Loss: 0.32853261041173243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 888] Loss: 0.3285343500702305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 889] Loss: 0.32854702740983754\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 890] Loss: 0.32854249023578386\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 891] Loss: 0.3285428600659575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 892] Loss: 0.32854651443615884\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 893] Loss: 0.3285568645795116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 894] Loss: 0.3285674551536466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 895] Loss: 0.3285724647866553\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 896] Loss: 0.3285725419257741\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 897] Loss: 0.32856977658115394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 898] Loss: 0.32856515658284063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 899] Loss: 0.32856143421933226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 900] Loss: 0.32856244394131207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 901] Loss: 0.32856626134538164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 902] Loss: 0.328561346886097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 903] Loss: 0.32857427963425495\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 904] Loss: 0.32856608331192905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 905] Loss: 0.3285845953520165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 906] Loss: 0.32857399026280526\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 907] Loss: 0.3285613130841134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 908] Loss: 0.32855827902356644\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 909] Loss: 0.3285589369319796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 910] Loss: 0.32856215060552835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 911] Loss: 0.32857764723847815\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 912] Loss: 0.3285846758192852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 913] Loss: 0.32857908726846224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 914] Loss: 0.32856932004119105\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 915] Loss: 0.328571565084277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 916] Loss: 0.3285928513461329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 917] Loss: 0.32859221298817876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 918] Loss: 0.3285870332494958\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 919] Loss: 0.3285862543076376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 920] Loss: 0.3285758235947061\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 921] Loss: 0.32856725263693004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 922] Loss: 0.32856822952742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 923] Loss: 0.3285616531335595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 924] Loss: 0.32855412320417826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 925] Loss: 0.3285693234700862\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 926] Loss: 0.3285605082284959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 927] Loss: 0.3285729199457147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 928] Loss: 0.32861395974655383\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 929] Loss: 0.32861343822642536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 930] Loss: 0.32861170457448724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 931] Loss: 0.3286139691904538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 932] Loss: 0.32860418758407756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 933] Loss: 0.3285973420056533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 934] Loss: 0.32859481866967216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 935] Loss: 0.3285894524030882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 936] Loss: 0.3285878511066192\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 937] Loss: 0.3285860603202509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 938] Loss: 0.328581700906842\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 939] Loss: 0.32857268537927725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 940] Loss: 0.32857534404498684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 941] Loss: 0.3285760472811659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 942] Loss: 0.32857336927985964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 943] Loss: 0.3285844789355393\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 944] Loss: 0.3285962950330892\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 945] Loss: 0.32860953507418267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 946] Loss: 0.32860649332745145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 947] Loss: 0.3286123506441208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 948] Loss: 0.3286229042509981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 949] Loss: 0.32862447448488885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 950] Loss: 0.3286145978031556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 951] Loss: 0.3286089685842924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 952] Loss: 0.3286132634720226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 953] Loss: 0.3286151758019385\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 954] Loss: 0.32860614284010453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 955] Loss: 0.32860623105961795\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 956] Loss: 0.32862772221215814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 957] Loss: 0.3286150461173872\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 958] Loss: 0.32862884183069224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 959] Loss: 0.32862639631548946\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 960] Loss: 0.32862061451339314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 961] Loss: 0.3286149762873129\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 962] Loss: 0.32861066584442356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 963] Loss: 0.3286096528550935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 964] Loss: 0.32860986705875744\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 965] Loss: 0.32861174142357746\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 966] Loss: 0.32859981621843265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 967] Loss: 0.3285956352710581\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 968] Loss: 0.32859124402727075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 969] Loss: 0.32859026098029\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 970] Loss: 0.32859051357384733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 971] Loss: 0.3285817653996639\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 972] Loss: 0.32858466805319747\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 973] Loss: 0.3285861888605606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 974] Loss: 0.32861081833311606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 975] Loss: 0.32861068193112314\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 976] Loss: 0.32862667211475577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 977] Loss: 0.3286257002252472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 978] Loss: 0.3286189278717651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 979] Loss: 0.32860816933425196\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 980] Loss: 0.3286033895212145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 981] Loss: 0.32859403672893533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 982] Loss: 0.32860024925072007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 983] Loss: 0.3285980554329715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 984] Loss: 0.32860513175655315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 985] Loss: 0.328599550295982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 986] Loss: 0.3285954558492706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 987] Loss: 0.3285844318489473\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 988] Loss: 0.32858169563062173\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 989] Loss: 0.32858647472574615\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 990] Loss: 0.32858255912505596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 991] Loss: 0.32858546614690975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 992] Loss: 0.328597855262964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 993] Loss: 0.32859459273970826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 994] Loss: 0.32860041630584036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 995] Loss: 0.3285996981776431\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 996] Loss: 0.3285943127582311\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 997] Loss: 0.32860967400334673\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 998] Loss: 0.32861224041962017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 999] Loss: 0.3286154156030546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1000] Loss: 0.3286146934616282\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1001] Loss: 0.32861836196881317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1002] Loss: 0.3286157415397974\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1003] Loss: 0.3286185741492698\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1004] Loss: 0.32860966691916066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1005] Loss: 0.3286019027303348\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1006] Loss: 0.3285968268544576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1007] Loss: 0.3285959142484455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1008] Loss: 0.32859368982309617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1009] Loss: 0.32858172661403034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1010] Loss: 0.328577555254502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1011] Loss: 0.3285691110929432\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1012] Loss: 0.3285610138164169\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1013] Loss: 0.32856564274624067\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1014] Loss: 0.32857531375798615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1015] Loss: 0.3285701087353066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1016] Loss: 0.3285799672770046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1017] Loss: 0.32857242032599654\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1018] Loss: 0.3285687257533792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1019] Loss: 0.3285594575830114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1020] Loss: 0.3285549007258794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1021] Loss: 0.32856219653023155\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1022] Loss: 0.3285557740253186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1023] Loss: 0.32856104377229295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1024] Loss: 0.32856170926844935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1025] Loss: 0.32857345846399394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1026] Loss: 0.32857382330116736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1027] Loss: 0.32857720018954784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1028] Loss: 0.3285849368613046\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1029] Loss: 0.3285872993751294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1030] Loss: 0.32858848440311894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1031] Loss: 0.3285904318969931\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1032] Loss: 0.328579566673457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1033] Loss: 0.32858512044821175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1034] Loss: 0.32858042052389863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1035] Loss: 0.32857828815826207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1036] Loss: 0.3285825485917899\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1037] Loss: 0.32857951706922284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1038] Loss: 0.3285688750173962\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1039] Loss: 0.32856488189940436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1040] Loss: 0.32857312790008114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1041] Loss: 0.3285829313948833\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1042] Loss: 0.328580742194084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1043] Loss: 0.3285743354230084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1044] Loss: 0.32857337808570963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1045] Loss: 0.3285682974720959\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1046] Loss: 0.3285727091342616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1047] Loss: 0.3285813240168623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1048] Loss: 0.32860370580404785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1049] Loss: 0.3286083468001125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1050] Loss: 0.3286023792655191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1051] Loss: 0.3286114855033648\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1052] Loss: 0.3286176772435069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1053] Loss: 0.3286101227705202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1054] Loss: 0.3286119764243781\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1055] Loss: 0.3286165577220651\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1056] Loss: 0.32863407491653834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1057] Loss: 0.32863366581346587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1058] Loss: 0.3286361508885922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1059] Loss: 0.3286307505591341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1060] Loss: 0.328624676289183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1061] Loss: 0.3286298776925934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1062] Loss: 0.3286348973338646\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1063] Loss: 0.3286284483726513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1064] Loss: 0.32862401623346704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1065] Loss: 0.3286230197224479\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1066] Loss: 0.3286305436300144\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1067] Loss: 0.3286228640590306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1068] Loss: 0.3286153865362458\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1069] Loss: 0.328625989746696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1070] Loss: 0.3286157332114513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1071] Loss: 0.3286105444185216\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1072] Loss: 0.3286297854810152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1073] Loss: 0.32863184783345634\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1074] Loss: 0.3286428801896866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1075] Loss: 0.32863747631507667\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1076] Loss: 0.3286473540435905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1077] Loss: 0.328644748635064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1078] Loss: 0.3286448784537504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1079] Loss: 0.3286431750412852\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1080] Loss: 0.3286380641242677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1081] Loss: 0.3286267920540377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1082] Loss: 0.3286269147319653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1083] Loss: 0.3286286721611281\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1084] Loss: 0.32862620295359474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1085] Loss: 0.3286287836496493\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1086] Loss: 0.3286279061962123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1087] Loss: 0.32862308240358257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1088] Loss: 0.3286182957027967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1089] Loss: 0.32861241584221856\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1090] Loss: 0.32860433876174777\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1091] Loss: 0.32859339482005573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1092] Loss: 0.32859076441357316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1093] Loss: 0.3285875096427565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1094] Loss: 0.32858126974401236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1095] Loss: 0.32858472665952937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1096] Loss: 0.32858200615643207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1097] Loss: 0.32857180444057804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1098] Loss: 0.32857613973449695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1099] Loss: 0.3285916544396534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1100] Loss: 0.3285868060288356\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1101] Loss: 0.3285956430938445\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1102] Loss: 0.32858914600192574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1103] Loss: 0.3285810935972997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1104] Loss: 0.3285815618952024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1105] Loss: 0.32858327309498037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1106] Loss: 0.32858372768115307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1107] Loss: 0.32857907103581824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1108] Loss: 0.3285757277207709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1109] Loss: 0.3285726859986628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1110] Loss: 0.32856508164676085\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1111] Loss: 0.32856550005137203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1112] Loss: 0.3285622854374559\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1113] Loss: 0.32854937897874836\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1114] Loss: 0.32854718822971846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1115] Loss: 0.32853675981886166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1116] Loss: 0.3285378152421363\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1117] Loss: 0.32853721559798527\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1118] Loss: 0.3285465245152676\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1119] Loss: 0.32856111990888504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1120] Loss: 0.3285512373193437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1121] Loss: 0.32854883179150696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1122] Loss: 0.32855387756870486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1123] Loss: 0.32854460266447666\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1124] Loss: 0.32853473220945617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1125] Loss: 0.3285414444184822\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1126] Loss: 0.32854388616038577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1127] Loss: 0.3285395086120259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1128] Loss: 0.3285394513150846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1129] Loss: 0.32853536740216605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1130] Loss: 0.32853538035700186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1131] Loss: 0.3285411640270305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1132] Loss: 0.3285405864467459\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1133] Loss: 0.3285574326581887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1134] Loss: 0.32855408765384964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1135] Loss: 0.3285582911444141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1136] Loss: 0.328559594732562\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1137] Loss: 0.3285578321760287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1138] Loss: 0.3285491549018576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1139] Loss: 0.3285581266795515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1140] Loss: 0.328569317891168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1141] Loss: 0.3285677760859188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1142] Loss: 0.32856602834373344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1143] Loss: 0.32856237257670873\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1144] Loss: 0.32857462235301627\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1145] Loss: 0.32857071926006826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1146] Loss: 0.3285688995315572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1147] Loss: 0.3285577462748595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1148] Loss: 0.3285511105521102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1149] Loss: 0.3285432189125037\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1150] Loss: 0.32854286750345124\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1151] Loss: 0.32854170891392953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1152] Loss: 0.32854442744129664\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1153] Loss: 0.32853850598923223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1154] Loss: 0.3285367966541528\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1155] Loss: 0.32852872114143933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1156] Loss: 0.3285340093991995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1157] Loss: 0.3285359159968568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1158] Loss: 0.32853918787488606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1159] Loss: 0.32854403230898166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1160] Loss: 0.3285394299852087\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1161] Loss: 0.3285471863190905\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1162] Loss: 0.328544521793211\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1163] Loss: 0.32855610872299773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1164] Loss: 0.3285516644483375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1165] Loss: 0.3285548917463619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1166] Loss: 0.3285628066636961\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1167] Loss: 0.3285641896241986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1168] Loss: 0.32857052646059237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1169] Loss: 0.32856005287178286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1170] Loss: 0.3285644239475483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1171] Loss: 0.32855355568390215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1172] Loss: 0.328551784990142\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1173] Loss: 0.32855964028456164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1174] Loss: 0.3285537618570404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1175] Loss: 0.3285723808846522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1176] Loss: 0.32856798146157207\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1177] Loss: 0.32857736502384094\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1178] Loss: 0.3285691491265401\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1179] Loss: 0.3285653851970333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1180] Loss: 0.32855618837703143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1181] Loss: 0.3285525044176425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1182] Loss: 0.3285411337277443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1183] Loss: 0.32853951946434024\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1184] Loss: 0.32853588774835496\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1185] Loss: 0.3285269827554191\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1186] Loss: 0.3285404177733694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1187] Loss: 0.3285376212394513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1188] Loss: 0.3285494544144927\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1189] Loss: 0.3285415887746759\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1190] Loss: 0.32854762232664925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1191] Loss: 0.3285481337876127\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1192] Loss: 0.3285453682917956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1193] Loss: 0.3285414650601796\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1194] Loss: 0.32853533785547645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1195] Loss: 0.3285283284769793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1196] Loss: 0.32853213930735237\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1197] Loss: 0.3285383803977941\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1198] Loss: 0.3285421510394417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1199] Loss: 0.3285481467549396\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1200] Loss: 0.3285453947643017\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1201] Loss: 0.32853655420486183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1202] Loss: 0.3285315092459199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1203] Loss: 0.3285217777504468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1204] Loss: 0.32854016597840635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1205] Loss: 0.3285411940858501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1206] Loss: 0.3285388055465881\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1207] Loss: 0.3285312017441267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1208] Loss: 0.32853986355999226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1209] Loss: 0.3285324634672468\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1210] Loss: 0.32852183400421214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1211] Loss: 0.32853072244088427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1212] Loss: 0.32852204515238687\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1213] Loss: 0.32852076111622863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1214] Loss: 0.32852724066803907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1215] Loss: 0.328530749221775\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1216] Loss: 0.3285344460902161\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1217] Loss: 0.3285304462076704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1218] Loss: 0.328538791001442\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1219] Loss: 0.3285343935067164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1220] Loss: 0.3285304187376779\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1221] Loss: 0.32853409977237324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1222] Loss: 0.3285285066232525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1223] Loss: 0.3285338398485932\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1224] Loss: 0.3285436570003369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1225] Loss: 0.32855191700639935\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1226] Loss: 0.3285460734869168\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1227] Loss: 0.32853536709211184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1228] Loss: 0.3285284460400982\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1229] Loss: 0.32853246779054596\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1230] Loss: 0.32853232764131707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1231] Loss: 0.3285332378849902\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1232] Loss: 0.3285311570515373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1233] Loss: 0.32853622803198257\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1234] Loss: 0.32854587070578917\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1235] Loss: 0.3285380446069\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1236] Loss: 0.32853373155721843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1237] Loss: 0.32852365753018936\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1238] Loss: 0.32851750638916005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1239] Loss: 0.3285124972658573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1240] Loss: 0.32852110546365804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1241] Loss: 0.32851582620258624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1242] Loss: 0.3285193966009095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1243] Loss: 0.3285208375143246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1244] Loss: 0.3285486478761548\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1245] Loss: 0.3285501671323285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1246] Loss: 0.3285460411818967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1247] Loss: 0.32853458759062715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1248] Loss: 0.32852310725896106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1249] Loss: 0.3285190639956208\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1250] Loss: 0.32850869822757256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1251] Loss: 0.3285014435817887\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1252] Loss: 0.32849941049564413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1253] Loss: 0.32849596929857156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1254] Loss: 0.32850542066101956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1255] Loss: 0.3285047781553341\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1256] Loss: 0.32853741457138413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1257] Loss: 0.3285372383952783\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1258] Loss: 0.3285445234886967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1259] Loss: 0.32854915557016146\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1260] Loss: 0.32855376811937986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1261] Loss: 0.3285498076761954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1262] Loss: 0.32854764208638226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1263] Loss: 0.3285368029116967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1264] Loss: 0.32853308920837315\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1265] Loss: 0.3285365906648439\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1266] Loss: 0.3285296738609859\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1267] Loss: 0.3285477063210475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1268] Loss: 0.3285452391998585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1269] Loss: 0.32854571842661995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1270] Loss: 0.32853488169148504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1271] Loss: 0.3285351408431891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1272] Loss: 0.3285338481293013\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1273] Loss: 0.32853140096120026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1274] Loss: 0.3285334986971053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1275] Loss: 0.32852513430834374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1276] Loss: 0.3285342822343004\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1277] Loss: 0.3285391271156516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1278] Loss: 0.32853517898501733\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1279] Loss: 0.32852710422906606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1280] Loss: 0.3285187348438591\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1281] Loss: 0.3285262126655244\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1282] Loss: 0.32853177452350185\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1283] Loss: 0.3285403454430188\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1284] Loss: 0.3285444489023371\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1285] Loss: 0.32854526640660126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1286] Loss: 0.32853585710587924\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1287] Loss: 0.3285398984436981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1288] Loss: 0.3285358602358349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1289] Loss: 0.3285318799638007\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.8996999999999999\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1290] Loss: 0.3285337255322601\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1291] Loss: 0.32852250769079894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1292] Loss: 0.3285244950126719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1293] Loss: 0.32852365659901045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1294] Loss: 0.3285161720646072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1295] Loss: 0.3285200284823376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1296] Loss: 0.3285157350622485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1297] Loss: 0.32852240706894675\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1298] Loss: 0.32851561166135546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1299] Loss: 0.3285075654702194\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1300] Loss: 0.3284978897643482\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1301] Loss: 0.328503233222176\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1302] Loss: 0.3284934340528677\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1303] Loss: 0.32849207748442405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1304] Loss: 0.3285116863263256\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1305] Loss: 0.32850408255633073\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1306] Loss: 0.3284924114545091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1307] Loss: 0.3284905345090428\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1308] Loss: 0.3284798139593366\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1309] Loss: 0.3284671240385575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1310] Loss: 0.32847742452569006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1311] Loss: 0.32847991532223586\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1312] Loss: 0.3284752971503737\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1313] Loss: 0.32847119841692574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1314] Loss: 0.3285181269344057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1315] Loss: 0.3285311871315506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1316] Loss: 0.3285332157975063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1317] Loss: 0.3285354209981894\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1318] Loss: 0.32852440327867427\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1319] Loss: 0.3285280034432112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1320] Loss: 0.32855221793566186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1321] Loss: 0.32854480786584966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1322] Loss: 0.3285411438853824\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1323] Loss: 0.3285544480286516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1324] Loss: 0.3285497996456876\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1325] Loss: 0.3285395437292255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1326] Loss: 0.32854104939474577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1327] Loss: 0.328529590486238\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1328] Loss: 0.3285281350387791\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1329] Loss: 0.3285270758481992\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1330] Loss: 0.3285139833030429\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1331] Loss: 0.3285176429247164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1332] Loss: 0.328513191139471\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1333] Loss: 0.3285218886567498\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1334] Loss: 0.3285217154435593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1335] Loss: 0.32851564217899937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1336] Loss: 0.3285119797653399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1337] Loss: 0.3285105413697669\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1338] Loss: 0.3285055694132531\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1339] Loss: 0.32850103409867804\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1340] Loss: 0.3285297469864177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1341] Loss: 0.3285209124346357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1342] Loss: 0.3285222371562269\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1343] Loss: 0.3285307716464349\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1344] Loss: 0.32854628367039834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1345] Loss: 0.3285439454012416\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1346] Loss: 0.32854419459296724\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1347] Loss: 0.32854622450830995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1348] Loss: 0.32854917947008466\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1349] Loss: 0.32855355472956765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1350] Loss: 0.32855970805999246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1351] Loss: 0.32855912449810026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1352] Loss: 0.32855164024910327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1353] Loss: 0.32856092575516765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1354] Loss: 0.32856972490161246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1355] Loss: 0.3285624460061012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1356] Loss: 0.32855725831074467\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1357] Loss: 0.3285513800748572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1358] Loss: 0.3285609244395178\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1359] Loss: 0.32857386160251506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1360] Loss: 0.3285726503497938\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1361] Loss: 0.32856310392613436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1362] Loss: 0.32856501267689464\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1363] Loss: 0.32855926451460166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1364] Loss: 0.32855580177037486\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1365] Loss: 0.32855493681136166\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1366] Loss: 0.3285501885125259\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1367] Loss: 0.32855021499311476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1368] Loss: 0.32854510770934353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1369] Loss: 0.3285428802765419\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1370] Loss: 0.32854986018045845\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1371] Loss: 0.3285642180210939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1372] Loss: 0.3285584532871875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1373] Loss: 0.3285618292941065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1374] Loss: 0.3285519637026472\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1375] Loss: 0.3285437704410572\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1376] Loss: 0.32854149317098685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1377] Loss: 0.3285394092142455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1378] Loss: 0.3285462057344345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1379] Loss: 0.3285364368507276\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1380] Loss: 0.3285280074245141\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1381] Loss: 0.328533264966949\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1382] Loss: 0.32852617403977585\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1383] Loss: 0.32852407948239365\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1384] Loss: 0.3285179791048631\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1385] Loss: 0.32851185011099715\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1386] Loss: 0.3285136032940909\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1387] Loss: 0.32850282758686655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1388] Loss: 0.32849686712485876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1389] Loss: 0.3285098617461297\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1390] Loss: 0.32850352634158286\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1391] Loss: 0.3284980574669817\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1392] Loss: 0.3285004140018919\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1393] Loss: 0.3285061207378984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1394] Loss: 0.3284996236565708\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1395] Loss: 0.3285057825047377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1396] Loss: 0.32850729177582516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1397] Loss: 0.3285127805570279\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1398] Loss: 0.32851530003892404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1399] Loss: 0.32850975284726297\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1400] Loss: 0.3285038669861582\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1401] Loss: 0.3284938872815981\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1402] Loss: 0.3284879367387138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1403] Loss: 0.3284816531629502\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1404] Loss: 0.3284867116457568\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1405] Loss: 0.32850813779875704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1406] Loss: 0.3285105441192226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1407] Loss: 0.3285144768297016\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1408] Loss: 0.32851424055625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1409] Loss: 0.32851446012493507\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1410] Loss: 0.32853665442087876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1411] Loss: 0.32853787394619705\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1412] Loss: 0.3285389316397672\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1413] Loss: 0.3285359780141431\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1414] Loss: 0.3285523231552488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1415] Loss: 0.3285435574866412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1416] Loss: 0.32854095054039106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1417] Loss: 0.3285289224145784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1418] Loss: 0.32852478578625605\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1419] Loss: 0.3285378082653779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1420] Loss: 0.32853085243338165\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1421] Loss: 0.3285269370824577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1422] Loss: 0.3285246872662219\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1423] Loss: 0.32853709257652947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1424] Loss: 0.3285267634501049\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1425] Loss: 0.32853176908184123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1426] Loss: 0.3285309257667065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1427] Loss: 0.3285441353746113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1428] Loss: 0.32854552496926953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1429] Loss: 0.32854758918368826\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1430] Loss: 0.3285456163852719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1431] Loss: 0.3285385021507508\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1432] Loss: 0.3285330532348138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1433] Loss: 0.32854094377869264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1434] Loss: 0.3285420715018332\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1435] Loss: 0.3285455771384202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1436] Loss: 0.32854573340076343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1437] Loss: 0.3285445576535328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1438] Loss: 0.3285428782875424\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1439] Loss: 0.32855286921218313\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1440] Loss: 0.3285520953710267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1441] Loss: 0.32855228098024325\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1442] Loss: 0.32855929198945727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1443] Loss: 0.3285693038383347\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1444] Loss: 0.32855917438793536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1445] Loss: 0.3285478094857403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1446] Loss: 0.32854221930539546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1447] Loss: 0.3285335531816963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1448] Loss: 0.3285275330174953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1449] Loss: 0.3285331250219901\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1450] Loss: 0.3285257135187721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1451] Loss: 0.32853252189577514\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1452] Loss: 0.3285211025667618\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1453] Loss: 0.32851805589963584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1454] Loss: 0.32852334495683116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1455] Loss: 0.3285110566269533\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1456] Loss: 0.328511004349131\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1457] Loss: 0.3285040676647619\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1458] Loss: 0.3285074550706713\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1459] Loss: 0.3285059234798137\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1460] Loss: 0.32850359698387843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1461] Loss: 0.3285242287142628\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1462] Loss: 0.3285184468588103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1463] Loss: 0.32853905610219786\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1464] Loss: 0.3285314134068525\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1465] Loss: 0.32852326696736694\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1466] Loss: 0.3285246850677278\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1467] Loss: 0.32851711873294254\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1468] Loss: 0.3285219162139199\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1469] Loss: 0.32852743153693964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1470] Loss: 0.3285255890069135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1471] Loss: 0.32851732188259425\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1472] Loss: 0.32851755711039693\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1473] Loss: 0.328519559043035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1474] Loss: 0.3285114055312485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1475] Loss: 0.3285077183433255\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1476] Loss: 0.3285189368564246\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1477] Loss: 0.3285283113954885\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1478] Loss: 0.32852395595773454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1479] Loss: 0.3285303425669394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1480] Loss: 0.32852902917331855\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1481] Loss: 0.3285358782208843\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1482] Loss: 0.3285283621421384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1483] Loss: 0.32852807603662376\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1484] Loss: 0.3285223988929706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1485] Loss: 0.32853642689398604\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1486] Loss: 0.32853483180021864\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1487] Loss: 0.32852215458451994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1488] Loss: 0.3285231884427014\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1489] Loss: 0.3285187636665216\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1490] Loss: 0.32852122335845624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1491] Loss: 0.3285168463046645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1492] Loss: 0.3285356213498792\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1493] Loss: 0.32854956168224114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1494] Loss: 0.3285709172289671\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1495] Loss: 0.3285747769964968\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1496] Loss: 0.32856926283129684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1497] Loss: 0.32856230903511846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1498] Loss: 0.3285631868388076\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1499] Loss: 0.3285762532962048\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1500] Loss: 0.3285867412229711\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1501] Loss: 0.32859549447382636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1502] Loss: 0.3286097081740403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1503] Loss: 0.32860715819274006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1504] Loss: 0.32860214854599457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1505] Loss: 0.328609744891177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1506] Loss: 0.32860838412835575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1507] Loss: 0.3286074393615709\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1508] Loss: 0.32861403641139114\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1509] Loss: 0.3286044033135816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1510] Loss: 0.32862020142689186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1511] Loss: 0.3286301295753691\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1512] Loss: 0.32862925733050247\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1513] Loss: 0.3286258695258147\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1514] Loss: 0.3286287030143152\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1515] Loss: 0.32863637159187115\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1516] Loss: 0.32863928998594355\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1517] Loss: 0.3286292052501063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1518] Loss: 0.3286202128893125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1519] Loss: 0.3286324667873754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1520] Loss: 0.32864258557855436\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1521] Loss: 0.3286381018931055\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1522] Loss: 0.328638698643768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1523] Loss: 0.3286309349863538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 29, Batch 1524] Loss: 0.32864353459289986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 0] Loss: 0.3286312583786157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 1] Loss: 0.32863861399294886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 2] Loss: 0.3286336703822841\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 3] Loss: 0.3286295867905405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 4] Loss: 0.3286417871041413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 5] Loss: 0.3286436182336727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 6] Loss: 0.3286377196551736\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 7] Loss: 0.3286350685501763\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 8] Loss: 0.3286366872598091\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 9] Loss: 0.32863548769839546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 10] Loss: 0.32862812807859143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 11] Loss: 0.3286217489576102\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 12] Loss: 0.3286308159921499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 13] Loss: 0.32862031023734706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 14] Loss: 0.32860900201097876\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 15] Loss: 0.32861503497636807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 16] Loss: 0.3286159809383103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 17] Loss: 0.3286108848409947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 18] Loss: 0.32860904743321184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 19] Loss: 0.32861352260266175\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 20] Loss: 0.32860407315281953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 21] Loss: 0.3285965830383504\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 22] Loss: 0.3285933993981414\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 23] Loss: 0.3285852064936344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 24] Loss: 0.32860600817553615\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 25] Loss: 0.32860721170532803\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 26] Loss: 0.3286029618809534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 27] Loss: 0.32860263538819623\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 28] Loss: 0.32860122800246766\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 29] Loss: 0.3286031939858273\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 30] Loss: 0.32859594805269937\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 31] Loss: 0.3285939514638002\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 32] Loss: 0.3285995507319599\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 33] Loss: 0.3285989363939478\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 34] Loss: 0.3285945622445517\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 35] Loss: 0.32859290249226075\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 36] Loss: 0.32859020027475305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 37] Loss: 0.32860786481457227\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 38] Loss: 0.32860798849117534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 39] Loss: 0.3285975231666523\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 40] Loss: 0.32860549003865985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 41] Loss: 0.32859637358816135\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 42] Loss: 0.32860496665361616\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 43] Loss: 0.32860245244459063\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 44] Loss: 0.3286053645784006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 45] Loss: 0.32861378723575285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 46] Loss: 0.3286099026301818\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 47] Loss: 0.32860489897943984\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 48] Loss: 0.3286063894569007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 49] Loss: 0.32860374124512837\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 50] Loss: 0.32859506857705956\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 51] Loss: 0.328590494751112\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 52] Loss: 0.32859966656059253\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 53] Loss: 0.32859486400164245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 54] Loss: 0.3286105293361719\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 55] Loss: 0.3286107339800057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 56] Loss: 0.3286185415427285\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 57] Loss: 0.3286196194514602\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 58] Loss: 0.32862574227327995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 59] Loss: 0.3286184581400986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 60] Loss: 0.32861504694394683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 61] Loss: 0.32861029997202157\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 62] Loss: 0.32861164900898343\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 63] Loss: 0.3286146579375742\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 64] Loss: 0.3286075560947011\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 65] Loss: 0.32860284408841595\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 66] Loss: 0.328602065024771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 67] Loss: 0.32859818415071584\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 68] Loss: 0.32860340275089306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 69] Loss: 0.3286086710822328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 70] Loss: 0.3286081661770947\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 71] Loss: 0.3286059888095863\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 72] Loss: 0.3285943769555957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 73] Loss: 0.32860057941719056\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 74] Loss: 0.3285890010453222\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 75] Loss: 0.3285981095314243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 76] Loss: 0.3286072979760727\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 77] Loss: 0.32860949172748877\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 78] Loss: 0.32860120668016574\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 79] Loss: 0.3285957865550768\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 80] Loss: 0.32859476459312353\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 81] Loss: 0.3286002866475306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 82] Loss: 0.32860377389738793\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 83] Loss: 0.32859755088795134\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 84] Loss: 0.328588733860162\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 85] Loss: 0.32857863497501233\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 86] Loss: 0.32856874010342624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 87] Loss: 0.3285791795621377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 88] Loss: 0.32857644982070583\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 89] Loss: 0.32859615131842773\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 90] Loss: 0.32859270292578413\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 91] Loss: 0.3286002772991624\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 92] Loss: 0.32859321946317277\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 93] Loss: 0.32858359452917296\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 94] Loss: 0.3286058206316409\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 95] Loss: 0.3286039857359597\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 96] Loss: 0.3285913445954095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 97] Loss: 0.3285969190381882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 98] Loss: 0.3285979564161987\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 99] Loss: 0.3285855409260121\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 100] Loss: 0.3285822324199184\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 101] Loss: 0.32857286860539453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 102] Loss: 0.3285802950212332\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 103] Loss: 0.32858734281025725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 104] Loss: 0.32859065598138587\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 105] Loss: 0.3285815837999999\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 106] Loss: 0.3285844141303316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 107] Loss: 0.3285892373234499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 108] Loss: 0.32858516235078933\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 109] Loss: 0.3285815478355861\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 110] Loss: 0.3285757408947136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 111] Loss: 0.3285854038935966\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 112] Loss: 0.3285773369000772\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 113] Loss: 0.32857214788846695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 114] Loss: 0.3285672234298685\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 115] Loss: 0.32856266036049764\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 116] Loss: 0.32855118262306704\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 117] Loss: 0.3285501854444306\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 118] Loss: 0.3285443339688695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 119] Loss: 0.3285664029165653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 120] Loss: 0.3285606455639834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 121] Loss: 0.3285660312679891\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 122] Loss: 0.328567846940126\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 123] Loss: 0.3285672591976611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 124] Loss: 0.3285631692831252\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 125] Loss: 0.3285568762114922\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 126] Loss: 0.32854768270461865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 127] Loss: 0.32853671905721976\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 128] Loss: 0.32853238776832405\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 129] Loss: 0.3285394106263245\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 130] Loss: 0.32854508689865985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 131] Loss: 0.3285402084746114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 132] Loss: 0.32853853379197284\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 133] Loss: 0.32853228989099204\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 134] Loss: 0.32852746305430985\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 135] Loss: 0.32853466526401287\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 136] Loss: 0.32853390595485005\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 137] Loss: 0.32854070433743443\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 138] Loss: 0.3285359467293034\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 139] Loss: 0.32853986937868224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 140] Loss: 0.32853189857416576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 141] Loss: 0.3285289879536249\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 142] Loss: 0.32852432914982077\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 143] Loss: 0.3285178585533774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 144] Loss: 0.3285143099178006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 145] Loss: 0.32851913026206725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 146] Loss: 0.3285110929557483\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 147] Loss: 0.3285179761926939\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 148] Loss: 0.3285125075083953\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 149] Loss: 0.32852778579210395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 150] Loss: 0.3285198506074707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 151] Loss: 0.3285144527739515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 152] Loss: 0.3285293455405611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 153] Loss: 0.3285182576313805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 154] Loss: 0.328541668007988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 155] Loss: 0.3285453975207657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 156] Loss: 0.32853434158315636\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 157] Loss: 0.32852542297960896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 158] Loss: 0.32851821049752755\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 159] Loss: 0.3285105746678576\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 160] Loss: 0.3285120266898611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 161] Loss: 0.3285218178860844\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 162] Loss: 0.32853820290049174\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 163] Loss: 0.3285546402718197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 164] Loss: 0.32855506229171433\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 165] Loss: 0.3285454305289072\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 166] Loss: 0.3285420430863031\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 167] Loss: 0.328541762408487\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 168] Loss: 0.3285562001206218\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 169] Loss: 0.32854426061035036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 170] Loss: 0.32856071942909515\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 171] Loss: 0.32856065211335345\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 172] Loss: 0.32855734442325657\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 173] Loss: 0.32854733497134236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 174] Loss: 0.32853962418613086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 175] Loss: 0.3285299417889545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 176] Loss: 0.3285288550671594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 177] Loss: 0.3285346226175965\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 178] Loss: 0.3285294761958036\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 179] Loss: 0.3285162457229745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 180] Loss: 0.3285114858862645\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 181] Loss: 0.32849894139532637\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 182] Loss: 0.32850586364163226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 183] Loss: 0.3285000553704179\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 184] Loss: 0.3284977123882302\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 185] Loss: 0.3284963731687816\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 186] Loss: 0.3284909287445756\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 187] Loss: 0.3284944744430696\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 188] Loss: 0.3284925814963865\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 189] Loss: 0.3284889699824571\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 190] Loss: 0.32848470939276264\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 191] Loss: 0.3284812046495433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 192] Loss: 0.3284963138216354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 193] Loss: 0.32850781860552375\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 194] Loss: 0.3285058126198847\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 195] Loss: 0.3284966281757154\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 196] Loss: 0.3285068538094057\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 197] Loss: 0.3285003416130457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 198] Loss: 0.32850489356334606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 199] Loss: 0.3285102116893807\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 200] Loss: 0.32851160240145805\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 201] Loss: 0.32851140859015243\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 202] Loss: 0.32852212860915975\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 203] Loss: 0.3285391404142621\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 204] Loss: 0.32855074042870125\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 205] Loss: 0.3285407631569136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 206] Loss: 0.3285415094580898\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 207] Loss: 0.32854031450394344\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 208] Loss: 0.32853543678078617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 209] Loss: 0.32855952823170453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 210] Loss: 0.3285542132030476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 211] Loss: 0.32856755175597613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 212] Loss: 0.3285721700442412\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 213] Loss: 0.3285650398534875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 214] Loss: 0.328558003962335\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 215] Loss: 0.32856131496367336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 216] Loss: 0.3285581903969501\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 217] Loss: 0.32854935644181776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 218] Loss: 0.32856624125388106\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 219] Loss: 0.3285632612834794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 220] Loss: 0.3285580175220986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 221] Loss: 0.32857458253340904\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 222] Loss: 0.3285675374927372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 223] Loss: 0.3285749242690835\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 224] Loss: 0.3285702464858181\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 225] Loss: 0.3285652271907265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 226] Loss: 0.3285553114173653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 227] Loss: 0.3285590243460827\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 228] Loss: 0.3285652462436609\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 229] Loss: 0.32856426382598897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 230] Loss: 0.32856466721118854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 231] Loss: 0.3285573662011294\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 232] Loss: 0.32855493898563026\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 233] Loss: 0.32854984638317875\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 234] Loss: 0.3285439110340324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 235] Loss: 0.3285431006339593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 236] Loss: 0.3285389243795097\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 237] Loss: 0.3285376327451907\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 238] Loss: 0.32854326572113723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 239] Loss: 0.3285696489062821\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 240] Loss: 0.3285666808362613\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 241] Loss: 0.3285617419353258\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 242] Loss: 0.3285819227122737\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 243] Loss: 0.3285776415573699\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 244] Loss: 0.3285832158725329\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 245] Loss: 0.3285794171880512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 246] Loss: 0.3285834961087516\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 247] Loss: 0.3285799589275606\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 248] Loss: 0.32857861681693706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 249] Loss: 0.3285913852708538\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 250] Loss: 0.3285901935691193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 251] Loss: 0.32858877810534\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 252] Loss: 0.32860561955338186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 253] Loss: 0.32859542773585465\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 254] Loss: 0.32859213738941734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 255] Loss: 0.3285959030525399\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 256] Loss: 0.3285969222731128\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 257] Loss: 0.3285940705381291\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 258] Loss: 0.3286059820118369\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 259] Loss: 0.32860609320200784\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 260] Loss: 0.3286589091038707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 261] Loss: 0.3286486087730327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 262] Loss: 0.3286461836254011\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 263] Loss: 0.32864023721764485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 264] Loss: 0.32864919537240667\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "******************************************************************\n",
      "*********************** Performance Update ***********************\n",
      "******************************************************************\n",
      "\n",
      "Area Under the ROC Curve: 0.9003\n",
      "\n",
      "******************************************************************\n",
      "****************** Performance Update Complete! ******************\n",
      "******************************************************************\n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 265] Loss: 0.32864059596397593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 266] Loss: 0.3286393291467088\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 267] Loss: 0.32864577615332186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 268] Loss: 0.32863787293225594\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 269] Loss: 0.32863595197504797\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 270] Loss: 0.3286286286958579\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 271] Loss: 0.3286256929328328\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 272] Loss: 0.32861886062986395\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 273] Loss: 0.32861125093899035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 274] Loss: 0.3286012508494771\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 275] Loss: 0.3285991311159661\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 276] Loss: 0.32859989831147535\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 277] Loss: 0.32858995663874774\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 278] Loss: 0.3286113138873499\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 279] Loss: 0.32862085604084557\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 280] Loss: 0.3286116204363509\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 281] Loss: 0.328601268904336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 282] Loss: 0.32860223036917957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 283] Loss: 0.3285991188932394\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 284] Loss: 0.3285880435661655\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 285] Loss: 0.32859175507985566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 286] Loss: 0.328592398630484\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 287] Loss: 0.32858903614677193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 288] Loss: 0.32860333818217086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 289] Loss: 0.32860373249596053\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 290] Loss: 0.3286136424283849\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 291] Loss: 0.32861936068827163\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 292] Loss: 0.32861967995724156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 293] Loss: 0.3286159003412454\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 294] Loss: 0.32861323289384337\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 295] Loss: 0.3286389584076641\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 296] Loss: 0.32862560426993404\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 297] Loss: 0.328629562189438\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 298] Loss: 0.3286595098498377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 299] Loss: 0.3286642285505368\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 300] Loss: 0.32866418026172156\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 301] Loss: 0.3286592458451717\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 302] Loss: 0.3286753940622107\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 303] Loss: 0.3286714416339082\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 304] Loss: 0.3286744295727477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 305] Loss: 0.3286818266018934\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 306] Loss: 0.3286795767831103\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 307] Loss: 0.32867839212988215\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 308] Loss: 0.32867375712144725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 309] Loss: 0.3286992314453734\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 310] Loss: 0.32870324650961213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 311] Loss: 0.32869929377908547\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 312] Loss: 0.3286984010439702\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 313] Loss: 0.3287034876644611\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 314] Loss: 0.3287137673829776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 315] Loss: 0.32871730413427463\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 316] Loss: 0.32871814184536735\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 317] Loss: 0.3287093776848721\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 318] Loss: 0.32871264932966043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 319] Loss: 0.3287107053452333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 320] Loss: 0.3287030845972546\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 321] Loss: 0.32871853286935554\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 322] Loss: 0.32871231702068854\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 323] Loss: 0.3287036894480506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 324] Loss: 0.3286976006509544\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 325] Loss: 0.32870166467844275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 326] Loss: 0.3287205151278232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 327] Loss: 0.328719127742723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 328] Loss: 0.32872397681575183\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 329] Loss: 0.3287294125877994\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 330] Loss: 0.3287412719366529\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 331] Loss: 0.32874399602545695\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 332] Loss: 0.3287402443640684\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 333] Loss: 0.32873003685670177\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 334] Loss: 0.32875089521626316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 335] Loss: 0.3287407692522799\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 336] Loss: 0.3287354172208342\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 337] Loss: 0.32873703363956136\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 338] Loss: 0.32874249728906213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 339] Loss: 0.32873465918482897\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 340] Loss: 0.3287266962328545\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 341] Loss: 0.3287279883594542\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 342] Loss: 0.32874350948774955\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 343] Loss: 0.32873612934926066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 344] Loss: 0.32873246161216896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 345] Loss: 0.32873407824286305\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 346] Loss: 0.3287232624691543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 347] Loss: 0.32871895233029413\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 348] Loss: 0.3287350636855988\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 349] Loss: 0.32873449118638265\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 350] Loss: 0.3287400381515275\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 351] Loss: 0.3287472489600051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 352] Loss: 0.3287427870350437\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 353] Loss: 0.3287386400655969\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 354] Loss: 0.3287362293451659\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 355] Loss: 0.3287471002824318\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 356] Loss: 0.3287344521451745\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 357] Loss: 0.3287352125391283\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 358] Loss: 0.3287234722003316\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 359] Loss: 0.32872504311321066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 360] Loss: 0.3287274465300456\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 361] Loss: 0.3287382600302214\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 362] Loss: 0.3287281581520229\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 363] Loss: 0.3287263176481653\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 364] Loss: 0.32872128452540517\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 365] Loss: 0.328728428378123\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 366] Loss: 0.3287529823982794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 367] Loss: 0.3287578232007267\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 368] Loss: 0.3287543404308505\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 369] Loss: 0.3287438383918045\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 370] Loss: 0.3287424305417524\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 371] Loss: 0.32874067401652035\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 372] Loss: 0.3287383217779512\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 373] Loss: 0.3287327214202725\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 374] Loss: 0.32872485953617536\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 375] Loss: 0.3287187626549867\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 376] Loss: 0.32871991762883895\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 377] Loss: 0.3287294821470357\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 378] Loss: 0.3287250551267882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 379] Loss: 0.328734392361367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 380] Loss: 0.3287354666076065\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 381] Loss: 0.32873465236064964\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 382] Loss: 0.32872358263396373\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 383] Loss: 0.3287157605205066\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 384] Loss: 0.3287258239994012\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 385] Loss: 0.32871881882318776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 386] Loss: 0.32871164556548116\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 387] Loss: 0.32872506020370457\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 388] Loss: 0.32872684022562565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 389] Loss: 0.3287258816267997\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 390] Loss: 0.32872844963217707\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 391] Loss: 0.3287312407937986\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 392] Loss: 0.32872813704992226\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 393] Loss: 0.32873619195007364\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 394] Loss: 0.3287323923003145\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 395] Loss: 0.3287224816520308\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 396] Loss: 0.32871278168407475\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 397] Loss: 0.3287097009252577\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 398] Loss: 0.3287111858777926\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 399] Loss: 0.32870715863788086\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 400] Loss: 0.32870061281578006\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 401] Loss: 0.3287086405602223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 402] Loss: 0.3287110400266625\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 403] Loss: 0.32871545485640374\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 404] Loss: 0.3287050847015051\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 405] Loss: 0.32869865142794064\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 406] Loss: 0.3287060341054765\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 407] Loss: 0.32871199822190084\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 408] Loss: 0.3287074914822566\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 409] Loss: 0.32871024141221683\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 410] Loss: 0.3287034959536563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 411] Loss: 0.3286958292391272\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 412] Loss: 0.3286905587855617\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 413] Loss: 0.32868341243060506\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 414] Loss: 0.3286771356334632\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 415] Loss: 0.32867935264026776\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 416] Loss: 0.328675472967158\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 417] Loss: 0.3286719075446513\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 418] Loss: 0.3286637675163377\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 419] Loss: 0.32866059854384794\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 420] Loss: 0.32866060998402113\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 421] Loss: 0.32866873499386967\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 422] Loss: 0.32866705705427274\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 423] Loss: 0.32867396347627714\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 424] Loss: 0.3286761933446607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 425] Loss: 0.32867589674653186\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 426] Loss: 0.32866434155685925\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 427] Loss: 0.3286759148471488\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 428] Loss: 0.32867041685293896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 429] Loss: 0.3286716567164995\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 430] Loss: 0.32866559340334556\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 431] Loss: 0.3286629669807403\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 432] Loss: 0.3286748596394814\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 433] Loss: 0.328682419914573\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 434] Loss: 0.3286835073272607\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 435] Loss: 0.3286921729567205\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 436] Loss: 0.32869458234638954\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 437] Loss: 0.32868437589548455\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 438] Loss: 0.3286776659550541\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 439] Loss: 0.32868163840001785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 440] Loss: 0.32868118954942327\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 441] Loss: 0.32867636263816236\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 442] Loss: 0.32868221437067563\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 443] Loss: 0.32869103054745474\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 444] Loss: 0.32869192774276096\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 445] Loss: 0.32868043308116485\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 446] Loss: 0.32867876763081333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 447] Loss: 0.3286668041311754\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 448] Loss: 0.32869048855995164\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 449] Loss: 0.32868940099175\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 450] Loss: 0.3286778347880333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 451] Loss: 0.3286806181419522\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 452] Loss: 0.328677169055451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 453] Loss: 0.3286923434136532\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 454] Loss: 0.3287125712374758\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 455] Loss: 0.3287146604924476\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 456] Loss: 0.32872227177230834\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 457] Loss: 0.3287205765193248\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 458] Loss: 0.3287174168607639\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 459] Loss: 0.3287176974367808\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 460] Loss: 0.3287145243187307\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 461] Loss: 0.3287117236884217\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 462] Loss: 0.3287150316674213\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 463] Loss: 0.3287212270875706\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 464] Loss: 0.32873015303690883\n",
      "\n",
      "*********** Saving network weights and optimizer state *********** \n",
      "\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 465] Loss: 0.32873461149420224\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 466] Loss: 0.328731872877451\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 467] Loss: 0.32874423347244963\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 468] Loss: 0.32876239754198333\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 469] Loss: 0.3287626322455372\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 470] Loss: 0.3287521667066603\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 471] Loss: 0.32873967059225095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 472] Loss: 0.3287354309989453\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 473] Loss: 0.32873261052230957\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 474] Loss: 0.32872529084872043\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 475] Loss: 0.32871723758723354\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 476] Loss: 0.32871220560586095\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 477] Loss: 0.32871119491192785\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 478] Loss: 0.3287058199481317\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 479] Loss: 0.3287153004494336\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 480] Loss: 0.3287265095417882\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 481] Loss: 0.32872060055611074\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 482] Loss: 0.3287087377160543\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 483] Loss: 0.32871459329870384\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 484] Loss: 0.3287192809421007\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 485] Loss: 0.32873045113767324\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 486] Loss: 0.3287378020439223\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 487] Loss: 0.32872923658216197\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 488] Loss: 0.32872775738119886\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 489] Loss: 0.32874174031302866\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 490] Loss: 0.3287305596756193\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 491] Loss: 0.3287286235634575\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 492] Loss: 0.3287324850234108\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 493] Loss: 0.32873757072062143\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 494] Loss: 0.3287329032995635\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 495] Loss: 0.32873335707504225\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 496] Loss: 0.3287315486434417\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 497] Loss: 0.32872405410002686\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 498] Loss: 0.3287214868320846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 499] Loss: 0.32873051040105367\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 500] Loss: 0.3287198631432869\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 501] Loss: 0.32872028865994846\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 502] Loss: 0.32872004419725565\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 503] Loss: 0.32872124758458593\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 504] Loss: 0.32871866761048346\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 505] Loss: 0.3287137370972578\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 506] Loss: 0.328715455047295\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 507] Loss: 0.3287132481595477\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 508] Loss: 0.3287122401464138\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 509] Loss: 0.3287066580283232\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 510] Loss: 0.32871155119318723\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 511] Loss: 0.32871816168487433\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 512] Loss: 0.3287144967786202\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 513] Loss: 0.3287111633893896\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 514] Loss: 0.3287133911449779\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 515] Loss: 0.3287069568121813\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 516] Loss: 0.3287044173092019\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 517] Loss: 0.3287106578459203\n",
      "\n",
      "CUDA Memory Allocated: 0\n",
      "[Epoch 30, Batch 518] Loss: 0.3287087187796138\n",
      "\n",
      "*********** Finished Training this Epoch in 9938.20194387436 seconds ***********\n"
     ]
    }
   ],
   "source": [
    "learn_weights = True\n",
    "\n",
    "print(\"Pre-Training CUDA Memory Allocation:\", torch.cuda.max_memory_allocated())\n",
    "\n",
    "if learn_weights:\n",
    "\n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.forward(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.unsqueeze(-1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sched.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # update mini-batch count\n",
    "        mini_batch += 1\n",
    "        epoch = mini_batch // 1525\n",
    "\n",
    "        # print every mini-batch\n",
    "        print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "        print(f'[Epoch {epoch}, Batch {mini_batch % 1525}] Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "        # save and outoput every 100 mini-batch\n",
    "        if i % 100 == 0:\n",
    "            print(\"*********** Saving network weights and optimizer state *********** \\n\\n\")\n",
    "            # save the weights and optimizer\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "            \n",
    "        # eval every 500 mini-batch\n",
    "        if i % 500 == 0:\n",
    "            \n",
    "            print(\"******************************************************************\")\n",
    "            print(\"*********************** Performance Update ***********************\")\n",
    "            print(\"******************************************************************\\n\")\n",
    "            \n",
    "            net.eval()\n",
    "            \n",
    "            ground_truths = []\n",
    "            probs = []\n",
    "\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            with torch.no_grad():\n",
    "                for j, valdata in enumerate(val_loader, 0):\n",
    "                    image, label = valdata\n",
    "                    image = image.to(device)\n",
    "\n",
    "                    # save for analysis\n",
    "                    ground_truths.append(label)\n",
    "\n",
    "                    # calculate outputs by running images through the network \n",
    "                    outputs = net(image)\n",
    "                    outputs = outputs.to(\"cpu\")\n",
    "\n",
    "                    # # save for analysis\n",
    "                    probs.append(outputs)\n",
    "\n",
    "            print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "            \n",
    "            net.train()\n",
    "\n",
    "            print(\"\\n******************************************************************\")\n",
    "            print(\"****************** Performance Update Complete! ******************\")\n",
    "            print(\"******************************************************************\\n\\n\")\n",
    "\n",
    "        # save unique set of weights and optimizer for validation later\n",
    "        if mini_batch % 1525 == 0:\n",
    "\n",
    "            uPATH = f'./saved_weights3/melanoma_ResNet50_{epoch}e_{mini_batch % 1525}b.pth'\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, uPATH)\n",
    "\n",
    "    print('*********** Finished Training this Epoch in', time.time() - start_time, 'seconds ***********')\n",
    "    \n",
    "    # save the weights and optimizer\n",
    "    torch.save({'mini_batch': mini_batch,\n",
    "                'model_state_dict': net.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict(), \n",
    "                'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998de40",
   "metadata": {},
   "source": [
    "# Formally test performance on our test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f63c0",
   "metadata": {},
   "source": [
    "First, let us see what the convolutional neural network thinks of a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88b172eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  Benign Benign Benign Benign Benign Benign Benign Benign Malignant Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign Benign\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data256x256\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data256x256\", \"val.csv\"), \n",
    "                            num_samples=8281, up_sample=False, start_ind=0, transform=val_transf)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate2d, \n",
    "                         num_workers=n_workers)\n",
    "\n",
    "\n",
    "\n",
    "testiter = iter(test_loader)\n",
    "images, labels = next(testiter)\n",
    "\n",
    "# print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072622c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_weights | create_new_weights:\n",
    "    \n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9271d8",
   "metadata": {},
   "source": [
    "Fortunately, we saved weights off at different epoch/batch values. Here is the list of saved weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cc00fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['melanoma_ResNet50_10e_0b.pth',\n",
       " 'melanoma_ResNet50_2e_0b.pth',\n",
       " 'melanoma_ResNet50_3e_0b.pth',\n",
       " 'melanoma_ResNet50_4e_0b.pth',\n",
       " 'melanoma_ResNet50_5e_0b.pth',\n",
       " 'melanoma_ResNet50_1e_0b.pth',\n",
       " 'melanoma_ResNet50_6e_0b.pth',\n",
       " 'melanoma_ResNet50_7e_0b.pth',\n",
       " 'melanoma_ResNet50_8e_0b.pth',\n",
       " 'melanoma_ResNet50_9e_0b.pth',\n",
       " 'melanoma_ResNet50_11e_0b.pth',\n",
       " 'melanoma_ResNet50_12e_0b.pth',\n",
       " 'melanoma_ResNet50_13e_0b.pth',\n",
       " 'melanoma_ResNet50_14e_0b.pth',\n",
       " 'melanoma_ResNet50_15e_0b.pth',\n",
       " 'melanoma_ResNet50_16e_0b.pth',\n",
       " 'melanoma_ResNet50_17e_0b.pth',\n",
       " 'melanoma_ResNet50_18e_0b.pth',\n",
       " 'melanoma_ResNet50_19e_0b.pth',\n",
       " 'melanoma_ResNet50_20e_0b.pth',\n",
       " 'melanoma_ResNet50_21e_0b.pth',\n",
       " 'melanoma_ResNet50_22e_0b.pth',\n",
       " 'melanoma_ResNet50_23e_0b.pth',\n",
       " 'melanoma_ResNet50_24e_0b.pth',\n",
       " 'melanoma_ResNet50_25e_0b.pth',\n",
       " 'melanoma_ResNet50_26e_0b.pth',\n",
       " 'melanoma_ResNet50_27e_0b.pth',\n",
       " 'melanoma_ResNet50_28e_0b.pth',\n",
       " 'melanoma_ResNet50_29e_0b.pth',\n",
       " 'melanoma_ResNet50_30e_0b.pth']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./saved_weights3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29b2cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: melanoma_ResNet50_22e_0b.pth\n",
      "\n",
      "\t Processing Batch #0 ... Running Time 3.1229822635650635\n",
      "\t Current Testing Loss: 0.2180425524711609\n",
      "\n",
      "\t Processing Batch #10 ... Running Time 6.390270709991455\n",
      "\t Current Testing Loss: 0.2567623664032329\n",
      "\n",
      "\t Processing Batch #20 ... Running Time 9.668898820877075\n",
      "\t Current Testing Loss: 0.2600921016363871\n",
      "\n",
      "\t Processing Batch #30 ... Running Time 13.383598327636719\n",
      "\t Current Testing Loss: 0.25621281516167427\n",
      "\n",
      "\t Processing Batch #40 ... Running Time 17.582876920700073\n",
      "\t Current Testing Loss: 0.2620270426680402\n",
      "\n",
      "\t Processing Batch #50 ... Running Time 21.257492780685425\n",
      "\t Current Testing Loss: 0.265476974494317\n",
      "\n",
      "\t Processing Batch #60 ... Running Time 24.897810220718384\n",
      "\t Current Testing Loss: 0.26385827777815646\n",
      "\n",
      "\t Processing Batch #70 ... Running Time 28.20353412628174\n",
      "\t Current Testing Loss: 0.2664304323179621\n",
      "\n",
      "\t Processing Batch #80 ... Running Time 32.036911725997925\n",
      "\t Current Testing Loss: 0.2689184899683352\n",
      "\n",
      "\t Processing Batch #90 ... Running Time 35.23231863975525\n",
      "\t Current Testing Loss: 0.27059409742826945\n",
      "\n",
      "\t Processing Batch #100 ... Running Time 38.592026233673096\n",
      "\t Current Testing Loss: 0.27212308671804936\n",
      "\n",
      "\t Processing Batch #110 ... Running Time 41.87573432922363\n",
      "\t Current Testing Loss: 0.2685408131764816\n",
      "\n",
      "\t Processing Batch #120 ... Running Time 45.88936948776245\n",
      "\t Current Testing Loss: 0.265880407873264\n",
      "\n",
      "\t Processing Batch #130 ... Running Time 50.02958703041077\n",
      "\t Current Testing Loss: 0.26501983006036917\n",
      "\n",
      "\t Processing Batch #140 ... Running Time 53.52280807495117\n",
      "\t Current Testing Loss: 0.264519305728006\n",
      "\n",
      "\t Processing Batch #150 ... Running Time 56.80324983596802\n",
      "\t Current Testing Loss: 0.2646886744838677\n",
      "\n",
      "\t Processing Batch #160 ... Running Time 60.383057594299316\n",
      "\t Current Testing Loss: 0.2665218615568943\n",
      "\n",
      "\t Processing Batch #170 ... Running Time 63.39507794380188\n",
      "\t Current Testing Loss: 0.26459912154061055\n",
      "\n",
      "\t Processing Batch #180 ... Running Time 67.41509985923767\n",
      "\t Current Testing Loss: 0.2654821914697879\n",
      "\n",
      "\t Processing Batch #190 ... Running Time 70.50812697410583\n",
      "\t Current Testing Loss: 0.26778784339652634\n",
      "\n",
      "\t Processing Batch #200 ... Running Time 73.02521800994873\n",
      "\t Current Testing Loss: 0.26573336761982286\n",
      "\n",
      "\t Processing Batch #210 ... Running Time 75.09165167808533\n",
      "\t Current Testing Loss: 0.26753489002232306\n",
      "\n",
      "\t Processing Batch #220 ... Running Time 77.14963603019714\n",
      "\t Current Testing Loss: 0.26842600757854557\n",
      "\n",
      "\t Processing Batch #230 ... Running Time 79.51464939117432\n",
      "\t Current Testing Loss: 0.2696156500802412\n",
      "\n",
      "\t Processing Batch #240 ... Running Time 82.25242614746094\n",
      "\t Current Testing Loss: 0.2711893379131788\n",
      "\n",
      "\t Processing Batch #250 ... Running Time 84.91819405555725\n",
      "\t Current Testing Loss: 0.2694047052724903\n",
      "\n",
      "******* Final Testing Loss: 0.2694402459332842 *******\n",
      "\n",
      "Loading: melanoma_ResNet50_24e_0b.pth\n",
      "\n",
      "\t Processing Batch #0 ... Running Time 2.892976760864258\n",
      "\t Current Testing Loss: 0.23723313212394714\n",
      "\n",
      "\t Processing Batch #10 ... Running Time 6.571284770965576\n",
      "\t Current Testing Loss: 0.26457361470569263\n",
      "\n",
      "\t Processing Batch #20 ... Running Time 9.734061241149902\n",
      "\t Current Testing Loss: 0.26591260447388604\n",
      "\n",
      "\t Processing Batch #30 ... Running Time 13.317290782928467\n",
      "\t Current Testing Loss: 0.2602073016666597\n",
      "\n",
      "\t Processing Batch #40 ... Running Time 17.995444774627686\n",
      "\t Current Testing Loss: 0.2676812097793672\n",
      "\n",
      "\t Processing Batch #50 ... Running Time 22.128260612487793\n",
      "\t Current Testing Loss: 0.27043456394298404\n",
      "\n",
      "\t Processing Batch #60 ... Running Time 26.34553050994873\n",
      "\t Current Testing Loss: 0.2696293333514792\n",
      "\n",
      "\t Processing Batch #70 ... Running Time 29.858524084091187\n",
      "\t Current Testing Loss: 0.27243325219187936\n",
      "\n",
      "\t Processing Batch #80 ... Running Time 33.512041091918945\n",
      "\t Current Testing Loss: 0.27540455684985643\n",
      "\n",
      "\t Processing Batch #90 ... Running Time 37.58692789077759\n",
      "\t Current Testing Loss: 0.27732323372102047\n",
      "\n",
      "\t Processing Batch #100 ... Running Time 41.554845571517944\n",
      "\t Current Testing Loss: 0.27873945118177057\n",
      "\n",
      "\t Processing Batch #110 ... Running Time 45.51608228683472\n",
      "\t Current Testing Loss: 0.2752882085136465\n",
      "\n",
      "\t Processing Batch #120 ... Running Time 49.142863750457764\n",
      "\t Current Testing Loss: 0.2728371142355864\n",
      "\n",
      "\t Processing Batch #130 ... Running Time 52.76536226272583\n",
      "\t Current Testing Loss: 0.2719216339915763\n",
      "\n",
      "\t Processing Batch #140 ... Running Time 56.20824384689331\n",
      "\t Current Testing Loss: 0.27133522251396314\n",
      "\n",
      "\t Processing Batch #150 ... Running Time 59.97347950935364\n",
      "\t Current Testing Loss: 0.27115103730697504\n",
      "\n",
      "\t Processing Batch #160 ... Running Time 63.37231135368347\n",
      "\t Current Testing Loss: 0.27244300436899527\n",
      "\n",
      "\t Processing Batch #170 ... Running Time 66.88822722434998\n",
      "\t Current Testing Loss: 0.2703249146018112\n",
      "\n",
      "\t Processing Batch #180 ... Running Time 70.04388880729675\n",
      "\t Current Testing Loss: 0.2713685662212951\n",
      "\n",
      "\t Processing Batch #190 ... Running Time 72.93315529823303\n",
      "\t Current Testing Loss: 0.2737785785298073\n",
      "\n",
      "\t Processing Batch #200 ... Running Time 75.10183715820312\n",
      "\t Current Testing Loss: 0.2719987925901935\n",
      "\n",
      "\t Processing Batch #210 ... Running Time 77.9834213256836\n",
      "\t Current Testing Loss: 0.2739628155790799\n",
      "\n",
      "\t Processing Batch #220 ... Running Time 80.10719537734985\n",
      "\t Current Testing Loss: 0.27453021873715777\n",
      "\n",
      "\t Processing Batch #230 ... Running Time 82.15823674201965\n",
      "\t Current Testing Loss: 0.27584690997352845\n",
      "\n",
      "\t Processing Batch #240 ... Running Time 84.21482753753662\n",
      "\t Current Testing Loss: 0.2778994979576451\n",
      "\n",
      "\t Processing Batch #250 ... Running Time 86.52849292755127\n",
      "\t Current Testing Loss: 0.276182751197264\n",
      "\n",
      "******* Final Testing Loss: 0.2760954785185891 *******\n",
      "\n",
      "Loading: melanoma_ResNet50_26e_0b.pth\n",
      "\n",
      "\t Processing Batch #0 ... Running Time 3.661571502685547\n",
      "\t Current Testing Loss: 0.2000880241394043\n",
      "\n",
      "\t Processing Batch #10 ... Running Time 7.8908469676971436\n",
      "\t Current Testing Loss: 0.23067591000686993\n",
      "\n",
      "\t Processing Batch #20 ... Running Time 11.747536897659302\n",
      "\t Current Testing Loss: 0.22872227004596166\n",
      "\n",
      "\t Processing Batch #30 ... Running Time 15.031019449234009\n",
      "\t Current Testing Loss: 0.22616748704064277\n",
      "\n",
      "\t Processing Batch #40 ... Running Time 18.314416885375977\n",
      "\t Current Testing Loss: 0.23272003487842838\n",
      "\n",
      "\t Processing Batch #50 ... Running Time 21.766568660736084\n",
      "\t Current Testing Loss: 0.23515941757781833\n",
      "\n",
      "\t Processing Batch #60 ... Running Time 25.245728731155396\n",
      "\t Current Testing Loss: 0.2339392563358682\n",
      "\n",
      "\t Processing Batch #70 ... Running Time 30.103929042816162\n",
      "\t Current Testing Loss: 0.2361055165529251\n",
      "\n",
      "\t Processing Batch #80 ... Running Time 33.835328578948975\n",
      "\t Current Testing Loss: 0.2380107766316261\n",
      "\n",
      "\t Processing Batch #90 ... Running Time 38.41880774497986\n",
      "\t Current Testing Loss: 0.23993979664621773\n",
      "\n",
      "\t Processing Batch #100 ... Running Time 42.76935291290283\n",
      "\t Current Testing Loss: 0.24247441942443942\n",
      "\n",
      "\t Processing Batch #110 ... Running Time 47.22451853752136\n",
      "\t Current Testing Loss: 0.23958546681715562\n",
      "\n",
      "\t Processing Batch #120 ... Running Time 51.26660513877869\n",
      "\t Current Testing Loss: 0.2370989254314052\n",
      "\n",
      "\t Processing Batch #130 ... Running Time 55.351051330566406\n",
      "\t Current Testing Loss: 0.2365363605946075\n",
      "\n",
      "\t Processing Batch #140 ... Running Time 58.62885332107544\n",
      "\t Current Testing Loss: 0.236287385172455\n",
      "\n",
      "\t Processing Batch #150 ... Running Time 62.96459603309631\n",
      "\t Current Testing Loss: 0.23607423077553313\n",
      "\n",
      "\t Processing Batch #160 ... Running Time 67.9985077381134\n",
      "\t Current Testing Loss: 0.23798190334939068\n",
      "\n",
      "\t Processing Batch #170 ... Running Time 72.64149880409241\n",
      "\t Current Testing Loss: 0.23615336008587776\n",
      "\n",
      "\t Processing Batch #180 ... Running Time 75.99769330024719\n",
      "\t Current Testing Loss: 0.23693507843913295\n",
      "\n",
      "\t Processing Batch #190 ... Running Time 78.61782431602478\n",
      "\t Current Testing Loss: 0.23887017416080256\n",
      "\n",
      "\t Processing Batch #200 ... Running Time 80.93975782394409\n",
      "\t Current Testing Loss: 0.23674089302174486\n",
      "\n",
      "\t Processing Batch #210 ... Running Time 83.10050225257874\n",
      "\t Current Testing Loss: 0.23890325321122932\n",
      "\n",
      "\t Processing Batch #220 ... Running Time 85.21486735343933\n",
      "\t Current Testing Loss: 0.23949487601739788\n",
      "\n",
      "\t Processing Batch #230 ... Running Time 87.73945593833923\n",
      "\t Current Testing Loss: 0.2405423665201509\n",
      "\n",
      "\t Processing Batch #240 ... Running Time 89.91655278205872\n",
      "\t Current Testing Loss: 0.24221843097714468\n",
      "\n",
      "\t Processing Batch #250 ... Running Time 92.28411102294922\n",
      "\t Current Testing Loss: 0.2406001317192359\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Final Testing Loss: 0.24076163426444336 *******\n",
      "\n",
      "Loading: melanoma_ResNet50_28e_0b.pth\n",
      "\n",
      "\t Processing Batch #0 ... Running Time 2.9310150146484375\n",
      "\t Current Testing Loss: 0.23320090770721436\n",
      "\n",
      "\t Processing Batch #10 ... Running Time 6.884751558303833\n",
      "\t Current Testing Loss: 0.27523701705715875\n",
      "\n",
      "\t Processing Batch #20 ... Running Time 10.069297790527344\n",
      "\t Current Testing Loss: 0.27777826218377977\n",
      "\n",
      "\t Processing Batch #30 ... Running Time 13.588273763656616\n",
      "\t Current Testing Loss: 0.2741760145271978\n",
      "\n",
      "\t Processing Batch #40 ... Running Time 17.05518865585327\n",
      "\t Current Testing Loss: 0.2798778080358738\n",
      "\n",
      "\t Processing Batch #50 ... Running Time 20.772919178009033\n",
      "\t Current Testing Loss: 0.2830998558624118\n",
      "\n",
      "\t Processing Batch #60 ... Running Time 23.928083419799805\n",
      "\t Current Testing Loss: 0.2811310542900054\n",
      "\n",
      "\t Processing Batch #70 ... Running Time 27.363563299179077\n",
      "\t Current Testing Loss: 0.2841773289190212\n",
      "\n",
      "\t Processing Batch #80 ... Running Time 31.182796239852905\n",
      "\t Current Testing Loss: 0.286892377300027\n",
      "\n",
      "\t Processing Batch #90 ... Running Time 34.54928731918335\n",
      "\t Current Testing Loss: 0.29013608723551365\n",
      "\n",
      "\t Processing Batch #100 ... Running Time 38.31567096710205\n",
      "\t Current Testing Loss: 0.292416653715738\n",
      "\n",
      "\t Processing Batch #110 ... Running Time 41.7800452709198\n",
      "\t Current Testing Loss: 0.288444299418647\n",
      "\n",
      "\t Processing Batch #120 ... Running Time 45.71084475517273\n",
      "\t Current Testing Loss: 0.28549214815797885\n",
      "\n",
      "\t Processing Batch #130 ... Running Time 49.000845193862915\n",
      "\t Current Testing Loss: 0.284758321087779\n",
      "\n",
      "\t Processing Batch #140 ... Running Time 53.35075902938843\n",
      "\t Current Testing Loss: 0.28490089186539885\n",
      "\n",
      "\t Processing Batch #150 ... Running Time 56.518837690353394\n",
      "\t Current Testing Loss: 0.2848185288985044\n",
      "\n",
      "\t Processing Batch #160 ... Running Time 60.39731693267822\n",
      "\t Current Testing Loss: 0.28583338773398664\n",
      "\n",
      "\t Processing Batch #170 ... Running Time 64.0779914855957\n",
      "\t Current Testing Loss: 0.2841733158157583\n",
      "\n",
      "\t Processing Batch #180 ... Running Time 67.9859709739685\n",
      "\t Current Testing Loss: 0.285041854279476\n",
      "\n",
      "\t Processing Batch #190 ... Running Time 70.60091400146484\n",
      "\t Current Testing Loss: 0.28732996500287383\n",
      "\n",
      "\t Processing Batch #200 ... Running Time 72.75835800170898\n",
      "\t Current Testing Loss: 0.2851246911198346\n",
      "\n",
      "\t Processing Batch #210 ... Running Time 75.10872745513916\n",
      "\t Current Testing Loss: 0.286945802764305\n",
      "\n",
      "\t Processing Batch #220 ... Running Time 77.01122212409973\n",
      "\t Current Testing Loss: 0.2875735400354161\n",
      "\n",
      "\t Processing Batch #230 ... Running Time 78.9636697769165\n",
      "\t Current Testing Loss: 0.2887855581777952\n",
      "\n",
      "\t Processing Batch #240 ... Running Time 80.90851187705994\n",
      "\t Current Testing Loss: 0.2905941739740213\n",
      "\n",
      "\t Processing Batch #250 ... Running Time 83.72649478912354\n",
      "\t Current Testing Loss: 0.2886806658183436\n",
      "\n",
      "******* Final Testing Loss: 0.2886844287162582 *******\n",
      "\n",
      "Loading: melanoma_ResNet50_30e_0b.pth\n",
      "\n",
      "\t Processing Batch #0 ... Running Time 2.918994426727295\n",
      "\t Current Testing Loss: 0.22589242458343506\n",
      "\n",
      "\t Processing Batch #10 ... Running Time 6.84101939201355\n",
      "\t Current Testing Loss: 0.26820685782215814\n",
      "\n",
      "\t Processing Batch #20 ... Running Time 10.17777395248413\n",
      "\t Current Testing Loss: 0.27042110619090853\n",
      "\n",
      "\t Processing Batch #30 ... Running Time 13.311892032623291\n",
      "\t Current Testing Loss: 0.2702442638335689\n",
      "\n",
      "\t Processing Batch #40 ... Running Time 16.71304154396057\n",
      "\t Current Testing Loss: 0.27707054847624246\n",
      "\n",
      "\t Processing Batch #50 ... Running Time 20.42550253868103\n",
      "\t Current Testing Loss: 0.2798094097890106\n",
      "\n",
      "\t Processing Batch #60 ... Running Time 23.524672031402588\n",
      "\t Current Testing Loss: 0.2780109043004083\n",
      "\n",
      "\t Processing Batch #70 ... Running Time 27.184008836746216\n",
      "\t Current Testing Loss: 0.28095844975659545\n",
      "\n",
      "\t Processing Batch #80 ... Running Time 31.555945873260498\n",
      "\t Current Testing Loss: 0.28399716078499215\n",
      "\n",
      "\t Processing Batch #90 ... Running Time 35.76515007019043\n",
      "\t Current Testing Loss: 0.28597309645060653\n",
      "\n",
      "\t Processing Batch #100 ... Running Time 40.60018754005432\n",
      "\t Current Testing Loss: 0.2885549922685812\n",
      "\n",
      "\t Processing Batch #110 ... Running Time 45.263524770736694\n",
      "\t Current Testing Loss: 0.28456574557600794\n",
      "\n",
      "\t Processing Batch #120 ... Running Time 49.34451341629028\n",
      "\t Current Testing Loss: 0.2823016541309593\n",
      "\n",
      "\t Processing Batch #130 ... Running Time 52.717681884765625\n",
      "\t Current Testing Loss: 0.28111462533928966\n",
      "\n",
      "\t Processing Batch #140 ... Running Time 56.22004055976868\n",
      "\t Current Testing Loss: 0.2813320185275788\n",
      "\n",
      "\t Processing Batch #150 ... Running Time 60.03249430656433\n",
      "\t Current Testing Loss: 0.2809302673631946\n",
      "\n",
      "\t Processing Batch #160 ... Running Time 64.49974966049194\n",
      "\t Current Testing Loss: 0.28176013199809175\n",
      "\n",
      "\t Processing Batch #170 ... Running Time 68.17728328704834\n",
      "\t Current Testing Loss: 0.27985829480907376\n",
      "\n",
      "\t Processing Batch #180 ... Running Time 71.70999932289124\n",
      "\t Current Testing Loss: 0.28095359260535374\n",
      "\n",
      "\t Processing Batch #190 ... Running Time 75.47570991516113\n",
      "\t Current Testing Loss: 0.28322788456659664\n",
      "\n",
      "\t Processing Batch #200 ... Running Time 77.57203316688538\n",
      "\t Current Testing Loss: 0.2809475385282763\n",
      "\n",
      "\t Processing Batch #210 ... Running Time 79.51303052902222\n",
      "\t Current Testing Loss: 0.2829414779117322\n",
      "\n",
      "\t Processing Batch #220 ... Running Time 81.48226714134216\n",
      "\t Current Testing Loss: 0.2835612317285926\n",
      "\n",
      "\t Processing Batch #230 ... Running Time 83.76777338981628\n",
      "\t Current Testing Loss: 0.28508318528468474\n",
      "\n",
      "\t Processing Batch #240 ... Running Time 85.73212838172913\n",
      "\t Current Testing Loss: 0.287010069210005\n",
      "\n",
      "\t Processing Batch #250 ... Running Time 87.85868310928345\n",
      "\t Current Testing Loss: 0.2852297624743792\n",
      "\n",
      "******* Final Testing Loss: 0.28508788059577056 *******\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_fnames = os.listdir('./saved_weights3/')\n",
    "#weight_fnames.sort() # isnt perfectly sorted, but too lazy to add the code (not important)\n",
    "batch_sizes = []\n",
    "losses = []\n",
    "\n",
    "for fname in weight_fnames[21::2]:\n",
    "    \n",
    "    print(f'Loading: {fname}\\n')\n",
    "\n",
    "    checkpoint = torch.load(f'./saved_weights3/{fname}', map_location=device)\n",
    "    \n",
    "    # network weights load\n",
    "    net = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "    # for feature extraction\n",
    "    #for param in net.parameters():\n",
    "        #param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = net.fc.in_features\n",
    "    net.fc = nn.Sequential(\n",
    "               nn.Linear(num_ftrs, 300),\n",
    "               nn.BatchNorm1d(300),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(300, 100),\n",
    "               nn.BatchNorm1d(100),\n",
    "               nn.ReLU(),\n",
    "               nn.Dropout(p=0.3),\n",
    "               nn.Linear(100, 1),\n",
    "               nn.Sigmoid()).to(device)\n",
    "\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])  \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ground_truths = []\n",
    "    probs = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, testdata in enumerate(test_loader, 0):\n",
    "            \n",
    "            image, label = testdata\n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = net(image)\n",
    "            \n",
    "            loss = criterion(outputs, label.unsqueeze(-1).float())\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # everything saved should be on RAM\n",
    "            #outputs = outputs.to(\"cpu\")\n",
    "            #label = label.to(\"cpu\")\n",
    "            \n",
    "            # save for analysis\n",
    "            ground_truths.append(label)\n",
    "            \n",
    "            # # save for analysis\n",
    "            probs += outputs.squeeze(-1).tolist()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"\\t Processing Batch #{i} ... Running Time {time.time() - start_time}\")\n",
    "                print(f'\\t Current Testing Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "                \n",
    "    print(f'******* Final Testing Loss: {running_loss / (i+1)} *******\\n')\n",
    "\n",
    "    batch_sizes.append(checkpoint['mini_batch'])\n",
    "    losses.append(running_loss / (i+1))\n",
    "                \n",
    "    # Save ground-truths and probability results\n",
    "    res = {}\n",
    "    res[\"ground_truths\"] = ground_truths\n",
    "    res[\"probs\"] = probs\n",
    "    res[\"num_batches\"] = checkpoint['mini_batch']\n",
    "    res[\"testing_loss\"] = running_loss / (i+1)\n",
    "\n",
    "    pkl_f_name = f'./saved_results3/results_ResNet50_{checkpoint[\"mini_batch\"]}b.pkl'\n",
    "    with open(pkl_f_name, 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "\n",
    "        \n",
    "plt.plot(batch_sizes, losses, 'o')\n",
    "plt.title(\"Testing Loss Over Time\")\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Overall Testing Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f86c7e",
   "metadata": {},
   "source": [
    "## Choose the results from the best performing model (training size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d8d6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 15250] Size Area Under the ROC Curve: 0.884967608877827 \n",
      "\n",
      "[Batch 3050] Size Area Under the ROC Curve: 0.871584630901783 \n",
      "\n",
      "[Batch 6100] Size Area Under the ROC Curve: 0.8809908522051555 \n",
      "\n",
      "[Batch 9150] Size Area Under the ROC Curve: 0.883370215556102 \n",
      "\n",
      "[Batch 12200] Size Area Under the ROC Curve: 0.8864596244202131 \n",
      "\n",
      "[Batch 18300] Size Area Under the ROC Curve: 0.885618274848666 \n",
      "\n",
      "[Batch 21350] Size Area Under the ROC Curve: 0.8871136357173802 \n",
      "\n",
      "[Batch 24400] Size Area Under the ROC Curve: 0.8875150748767665 \n",
      "\n",
      "[Batch 27450] Size Area Under the ROC Curve: 0.8854351182321959 \n",
      "\n",
      "[Batch 30500] Size Area Under the ROC Curve: 0.8886633581389279 \n",
      "\n",
      "[Batch 33550] Size Area Under the ROC Curve: 0.8846991464399875 \n",
      "\n",
      "[Batch 36600] Size Area Under the ROC Curve: 0.886565838531134 \n",
      "\n",
      "[Batch 39650] Size Area Under the ROC Curve: 0.8822528765624765 \n",
      "\n",
      "[Batch 42700] Size Area Under the ROC Curve: 0.8842600723594084 \n",
      "\n",
      "[Batch 45750] Size Area Under the ROC Curve: 0.8864362071359155 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# in case pkl results were calculated in batch job\n",
    "# we may wont to visualize the test plot over time\n",
    "recalc_loss_plot = True\n",
    "\n",
    "if recalc_loss_plot:\n",
    "    \n",
    "    batch_sizes = []\n",
    "    losses = []\n",
    "    res_fnames = os.listdir('./saved_results3/')\n",
    "    \n",
    "    for fname in res_fnames:\n",
    "        with open(f'./saved_results3/{fname}', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "            batch_sizes.append(res[\"num_batches\"])\n",
    "            losses.append(res[\"testing_loss\"]) \n",
    "            \n",
    "            \n",
    "            gt = res[\"ground_truths\"]\n",
    "            probs = np.array(res[\"probs\"])\n",
    "\n",
    "            # match formats (shouldve done this before, forgot to check)\n",
    "            ground_truths = []\n",
    "            for i in range(len(gt)):\n",
    "                if gt[i].size() > torch.Size([1]):\n",
    "                    ground_truths += gt[i].squeeze(-1).tolist()\n",
    "                else:\n",
    "                    ground_truths.append(gt[i].squeeze(-1).tolist())\n",
    "\n",
    "            ground_truths = np.array(ground_truths)\n",
    "            print(f\"[Batch {res['num_batches']}] Size Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs), \"\\n\")\n",
    "            \n",
    "    \n",
    "    plt.plot(batch_sizes, losses, 'o')\n",
    "    plt.title(\"Testing Loss Over Time\")\n",
    "    plt.xlabel(\"Batch Number\")\n",
    "    plt.ylabel(\"Overall Testing Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b21dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size = 42700\n",
    "\n",
    "\n",
    "with open(f'./saved_results3/results_ResNet50_{best_batch_size}b.pkl', 'rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    \n",
    "    \n",
    "gt = res[\"ground_truths\"]\n",
    "probs = np.array(res[\"probs\"])\n",
    "\n",
    "\n",
    "# match formats (shouldve done this before, forgot to check)\n",
    "ground_truths = []\n",
    "for i in range(len(gt)):\n",
    "    if gt[i].size() > torch.Size([1]):\n",
    "        ground_truths += gt[i].squeeze(-1).tolist()\n",
    "    else:\n",
    "        ground_truths.append(gt[i].squeeze(-1).tolist())\n",
    "        \n",
    "ground_truths = np.array(ground_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc478afa",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13c8fc4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F2-Score is: 0.34536891679748827\n",
      "Max G-Mean is: 0.8033140411530464\n",
      "Max Cohen's Kappa is: 0.22652674402477935\n",
      "Area Under the ROC Curve: 0.8842600723594084 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFnCAYAAABU0WtaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABWcElEQVR4nO3dd3hT5fvH8XeSNp0pHbRsBNlDNipL9pShghQZshyUXUCZUpDxY08BcSuigoiiqICCgsgeghSQIbIEOulumnF+f1TypVBoC01Pkt6v6/peX3KSnHzyWLj7nOec+2gURVEQQgghhEvQqh1ACCGEEPlHCrsQQgjhQqSwCyGEEC5ECrsQQgjhQqSwCyGEEC5ECrsQQgjhQtzUDiCEyJ0qVapQtmxZdDodABaLhYYNGzJlyhS8vb0BiIqKYtGiRezZswc3Nzd8fHzo3bs3L7zwgm0/GRkZrFixgs2bN6PVatFqtXTo0IFhw4ah1+vv+ty8vl4IoS6NXMcuhHOoUqUKO3fupHjx4kBmwQ0PD6dixYqEh4eTmprKs88+S6dOnQgLC0Ov13P58mVGjhxJ586dGTx4MACjR48mLS2NuXPn4u/vz82bNxk/fjy+vr4sXLjwrs/N6+uFEOqSQ/FCOCm9Xk+zZs04deoUAF9//TWBgYGMGjXKNpMuU6YMc+bM4e233yY5OZmzZ8+yc+dOW5EG8Pf3Z/bs2fTo0eOuz8jN6/v168emTZts77n9cZUqVVi9ejXt27dn7ty5zJw50/a6+Ph46tSpQ1JSEufOnaNv3760b9+eLl268Oeff+b7eAlRWEhhF8JJJSQksHnzZurWrQvAgQMHaNmy5V2vq1KlCgaDgWPHjnHgwAHq1KljK9K3BAUF0ahRo7vem9fXZ0dRFLZu3UqHDh3YsWOHbfuOHTt48skn8fHxITw8nG7durF161amTZvG0KFDMZvNudq/ECIrWWMXwon069cPnU6HyWQiISGBAQMG8PLLLwOQnJxMQEBAtu8rWrQoCQkJJCcnExQUlOvPy+vrs9OiRQsAateujaIonD59mqpVq/LTTz/RsWNH/v77by5dukT37t0BqF+/PoGBgRw9epSGDRs+1GcLURhJYRfCiaxZs4bixYsTFxdHhw4d6NSpE25umX+NixcvTlRUVLbvi4mJITAwEJPJxO7du3P9ecWLF8/T67Nz+2y/bdu2bN++nbJly3LkyBEWLFjAmTNnsFgsdOrUyfa65ORkbt68+VCfK0RhJYfihXBCgYGB9OvXj/nz59u2NWzYkJ9//vmu1545c4abN29Sq1Yt6tWrx4kTJ7hx40aW1yQmJrJ06VLuPJc2N6/XarVYrVbbc/cryO3bt2fHjh3s3r2bhg0b4uvrS0hICD4+PmzZssX2v927d9O2bdu8DIkQ4j9S2IVwUgMHDuTo0aMcOHAAgC5dumCxWJgzZw4mkwmAf//9lwkTJjBs2DC8vb0pU6YMXbp0YcyYMcTExACZhXjMmDHEx8ej0WiyfEZuXh8cHMzp06cBOHr0KJcuXbpn5nr16hEbG8vGjRvp2LEjAKVKlaJ48eJs2bIFgLi4OMaMGUNqamo+jpYQhYdc7iaEk7jzcjeADz74gO+//54NGzag0WiIjY1lwYIFHDx4EDc3N/R6Pf369eP555+3vcdkMrFq1Sq+//57NBoN7u7udO3alcGDB6PV3v27fk6vj4yMZMyYMWi1Wh5//HGioqLo0KED3bp1yzbzzJkz+fLLL9mzZw8+Pj4AnD9/nmnTphEdHY1Wq2XgwIFZMgshck8KuxBCCOFC5FC8EEII4ULsWtjPnDlDmzZt+PTTT+96bs+ePfTo0YPQ0FBWrFhhzxhCCCFEoWG3wp6amsqMGTPu2cRi5syZLF++nM8//5zffvuNc+fO2SuKEEIIUWjYrbDr9XreffddQkJC7nru8uXLFClShBIlSqDVamnevDl79+61VxQhhBCi0LBbYXdzc8PT0zPb56KjowkMDLQ9Llq0KNHR0faKIoQQQhQaqnSey+5E/Duvn83uPTm9RgghBAyeuY2YhHSKFsl+ciUcV+lr5yl/9Qy/Ncjs8/D+lHZ53ocqhb1YsWK2ZhcAN27cIDg4+L7v0Wg0REcn2TtaoRYcbJAxLgCuMM7rd5zj4Ons29c6Ap1Og8VSeK/kjU8yEmDwYM6rubtRz4NwhZ9jh2Iy4b10Id7vzAOgS8TLWEuXeaBdqXK5W+nSpUlOTubKlSuYzWZ++eUXmjRpokYUIcQDOHg6ivgko9oxxD0EGDxoWPXu85uEY9KdjMS/Qyt85s3GGhxCwqfrHriogx1n7CdOnGDu3LlcvXoVNzc3tm7dSqtWrShdujRt27Zl2rRpjB07FoBOnTpRvnx5e0URQuRRTjPyWzPC+UMbF2Cq3JPZpHAKioL3kgV4L5iDxmQi7YW+pLw5G6WI/0Pt1m6FvWbNmqxZs+aezzds2JB169bZ6+OFEA/h1ow8wOCR7fMyIxQiH2g0aP+5gDWoKMmLlpHRpn2+7FZu2yqEyGL9jnPEJqYT5OfpsDNyIZyW2Yz+h+/I6PIMaDSkzPg/UqxWFP+AfPsIaSkrhMji1iF4mZELkb90f53G/+k2FHmpPx7ffAWA4lckX4s6yIxdCKdlrzPT45OMBPl50rNVxXzftxCFktmM18rl+MyfjcZoJL1HKBktWtnt46SwC+GkcloHf1Cyfi5E/tGdPYNh5BDcDx/CGhxC4oKlZHR82q6fKYVdCCck6+BCOAf9r9txP3yI9OeeJ3n2PJTAILt/phR2IZyQrIML4bh0f5/DUqIUeHmRNvhVzFWrY2rWvMA+Xwq7EE7i9jV1WQcXwgFZLHi9swqf/3uTtMGvkhIxA7TaAi3qIIVdCKdx+5q6rIML4Vh0f5/DMHIo7gf2YS1aFFO9BqplkcIuhIO7NVN39G5vQhRKVite772Nz6zpaNLSSO/6LMlzFqIULapaJCnsQji424u6zNKFcCxux47iO2UC1qAgEpe/TUbXZ9WOJIVdCEdwv2vSZaYuhIOxWtEkJ6H4FcFctz6Jy1aR0bodSg53KS0o0nlOCAdwv7ulyUxdCMeh/ecCRZ7rjN/gF0HJvDWwsVcfhynqIDN2IVRz51nuMisXwoFZrXh++B6+MyLQpKZg7NQFUlPBx0ftZHeRwi6ESuQsdyGcg/bSRQyjh6HfvQurvz9JC9/D+NzzoNGoHS1bUtiFKCC3Zug6nQaLRZFZuhDOwGjEv3M7dNevYezQieT5S7AWK652qvuSwi5EAbk1Qy/q7wnI2rkQDs1qBa0WPDxIeWM6AMYeoQ47S7+dFHYhCsDtvd3fn9KO6OgktSMJIbKjKHh+8iFeH75H/OZt4OuL8fleaqfKEzkrXogCIL3dhXB82iuXKdLzGQyvjUZ75TJuJyPVjvRApLALUUCkt7sQDkpR8Pz0YwKeehL9zl8wtm5L/G/7MT/+hNrJHogcihdCCFGo+U4ch9cH72I1+JG0ZAXpL/R1irX0e5HCLsRDul/XuFtunQEvhHA86T1C0V66mHnGe6nSasd5aHIoXoiHdL+ucbfIGfBCOA7ttX/xG9QP7d/nATA3eJzEzza4RFEHmbEL8VBuP9tdrkcXwsEpCh7rPsN3ygS0iQlYypUnZeqbaqfKd1LYhXgIcra7EM5Be/0avmNH4vHTVqw+viQtWEp6vwFqx7ILKexCPKDbZ+tytrsQjst99y78BvZFm3CTjGYtSFryFtYyZdWOZTdS2IV4QDJbF8I5mCtVQfHzI2lyBOn9Bzn1Ge+5IYVdFEq5OZM9J/FJRpmtC+GIFAWPjV9iDQzC1LI1SrFixO09Anq92skKhBR2USjdfme1ByVnugvheDRRURheG43Hj5sxV6hI/O6DoNMVmqIOUthFIZDd7FzurCaEi1EUPL7egO/EcWjj48lo3JSkJSsyi3ohI4VduLzsZucy2xbCdWgSbmIYPRyP779F8fIiafY80ge9knl3tkJICrtwSbfP0mV2LoRrU7y80f1zAdMTjUhcuhLroxXUjqQqKezCJd0+S5fZuRCuRxMTg/vB/WR0fBr0em6u+xqlaNFCO0u/nRR24XKkG5wQrk3/3SYM48PRJCYSv3MvlgqVUELkl/dbpLALlyPXlwvhmjSxsfhOHIvnNxtRPD1JmTwNS7lH1Y7lcKSwC5ck15cL4Vr033+H4bXRaGOiMdVvSNLyt7FUrKR2LIckhV0IIYTD8/juGzRJiSRHzCRtyLBCeRlbbslZBkIIIRyS29HDtj8nz55H/PbdpA0bKUU9BzJjF04hLy1gH7ajnBBCXZr4OHwnj8dzwzoS3l9DRpduKIFBWAKD1I7mFGTGLpzCrcvXckMubxPCeem3/UjAU0/iuWEdpjp1sVSuonYkpyMzduGQ7pyhS5MZIVybJuEmvlMm4LnuMxS9nuTJEaQNGwVuUqbySkZMOKQ728DKLFwI1+a5/nM8132GqXZdkpatwlKtutqRnJYUduFQbs3UZYYuhOvTJCageHqBXk/aoFdQvLxJD+0N7u5qR3NqssYuHMrtRV1m6EK4LvcdPxHQ7Am8F83N3KDTkd63vxT1fCAzdqEqWUsXonDRJCbgEzEZr7WfoLi5gaeX2pFcjhR2oSpZSxei8HD/ZTuG8OHo/r2KucZjJC5bheWxWmrHcjlS2IUqZC1diMJF99dp/EOfRXFzI2XcBFJHjwO9Xu1YLkkKu1CFrKULUUiYzeDmhqVKVVImTSWjdVvMj9VWO5VLk8IusvX12Q0sObyQM/GnqRxQlSc8+6L8Wzff9i8zdSFcmyY5CZ9pb6CNuk7ix5+DRpM5Sxd2J2fFi7t8fXYDr/40iFNxkVgUC6fiIvno34mcSPsp3z5DZupCuC7333YS0LwRXp98gO7iP2ji49SOVKjIjF3cZcnhhdlu/9trIz8OjSjgNEIIp5GcjO+MqXh9+B6KTkdK+DhSx4wHD7l3Q0GSwi7ucib+dLbbE7hcwEmEEE7DYiHg6ba4nYrEXKUqSctWYa5bX+1UhZJdC/vs2bM5duwYGo2GSZMmUavW/y5rWLt2Ld9++y1arZaaNWsyefJke0YReVA5oCqn4iLv2l41qKoKaYQQTkGnI23AYHRXr5AybgJ4eqqdqNCy2xr7gQMHuHjxIuvWrWPmzJnMmDHD9lxycjLvv/8+a9eu5fPPP+f8+fP88ccf9ooi8mh0/bHZbh9Vb0wBJxFCODL3fXvw690D0tIASB/4EilTpklRV5ndCvvevXtp06YNABUrViQxMZHk5GQA3N3dcXd3JzU1FbPZTFpaGkWKFLFXFJEH63ecY89PJamfNpYAyuOmdaN6UE1Wt/2AZyv1UDueEMIRpKZCeDhFunVEv+Nn9L/9qnYicRu7HYqPiYmhRo0atsdBQUFER0fj6+uLh4cHw4YNo02bNnh6evL0009Tvnx5e0UReXDr+vKahrYMrNqHnq0qqh1JCOFA3PbvwzAqDP4+j6VCxcy19IZPqB1L3MZuhV1RlLseazQaIPNQ/OrVq9myZQu+vr7079+f06dPU7Xq/ddwg4MN9oorgA++iyQ2MZ2QAC/en9JO7TguTX6W7U/G2A7mz4fx4zP/PHYsbjNmEOAlvd4djd0Ke7FixYiJibE9joqKomjRogCcP3+eMmXKEBgYCECDBg04ceJEjoU9OjrJXnEF8PuxqwDUqxQsY21HwcEGGV87kzG2D/cqj+FboSJJi1cQ0Llt5hgnyzjb04P8gmq3wt6kSROWL19Or169OHnyJCEhIfj6+gJQqlQpzp8/T3p6Oh4eHpw4cYLmzZvbK4q4h7vurJZsJMjPUw6/CyEypaXhs2geaf0GYC37CKZGTYjftR/c5EppR2a3/zr16tWjRo0a9OrVC41GQ0REBBs3bsRgMNC2bVsGDx7Miy++iE6no27dujRo0MBeUcQ93HlntaJFPKlXKVjlVEIIR+B26ACGUUNxO3sGTdQNkpeu/O8JKeqOTqPcuRjuwOTQWv5Zv+McWw5cIsjP09avXQ5fFgwZZ/uTMX4I6en4zJuN18plaKxWUl8JI2VSBHh7Z3mZjHHBcKhD8cKx3ToEL/3ahRC36E6dxO/l/rid+QvLI+VIWrYKU6MmascSeSSFvRC5fU09PknW04UQWSlFiqC9cYPUl14lZfI08PFRO5J4AFLYC5Hb19Tl7mpCCAC3P46AMQPzE09iLVmKuH1HUYKC1I4lHoIUdhd059nut8g90IUQNkYj3ovm4r1sMdZSpYnbcxj0einqLkAKuwu682z3W2SWLoQAcDv+B4YRQ3A7dRJLmbIkLX4L9Hq1Y4l8IoXdicnMXAiRJxkZeC+ej/eSBWgsFtL6DyYl4k0UX+nS50qksDsxmZkLIfLEasVj8yasxUuQtPgtTC1aqZ1I2IEUdicnM3MhxH1lZOB27GjmjVo8PUn8aC3WkGIoBj+1kwk7sdttW4UQQqhLd+JP/Du0wr97F3TnzwJgqVBJirqLkxm7E7q1tp7dYXghhMBkwnvZIrwXzUNjMpHWux/WYFmeKyyksDuh24u6rKULIW6nO3USw4ghuB//A0vxEiQvXk5Ga7kNc2Eihd3BZXfmu5z1LoS4F+/F83A//gfpvfqQPOP/UIr4qx1JFDAp7A4uu0PuMlMXQtxOe/0a1uIlAEieOQ/j873IaNtB5VRCLVLYHdSd6+gyOxdC3MVsxmvlMnzmzSbxgzVktOuIEhIiRb2Qk8LuoGQdXQhxP7q/TmMYFYb7kcNYQoqhyH3SxX/kJ8EBrd9xjtjE9Cz3ShdCCAAsFrxWLsdn3iw0RiPp3XuSPHseSkCg2smEg5DC7oDkXulCiHvxXPsJvjOmYg0OIXHBUjI6Pq12JOFgpLA7mNtn63KvdCEEABYLKAq4uZH+Ql+0Vy6TNmQYSqDciU3cTTrPORiZrQshbqc7fxb/rh3wXr44c4O7O6mTpkpRF/ckM3YHcftZ8DJbF0JgseD17ip8Zr+JJj0dS7nymbN2jUbtZMLBSWF3EHIWvBDiFt3f5zCMHIr7gX1Yg4JIXPEOGV2eUTuWcBJS2B2IXK8uhNBevkRAyyZo0tIwdu5G0txFKMHBascSTkQKuxBCOBBrmbKk9RuAucHjGLs9J4feRZ5JYVfR7X3g5U5tQhRSViueH76L+x9HSVr+NgApM+eqHEo4MynsKrp9XV3W1oUofLQX/8Ewehj633/DGhCA9t+rWEuWUjuWcHJS2FUm6+pCFEJWK54ff4Dv9DfQpKZg7PA0SfOXoBQrpnYy4QKksAshREFSFPz6heLx01as/v4kzX8HY49QWUsX+UYKu0pu7zAnhChENBpMTZ4CrZbkBUuxFiuudiLhYqTznEqkw5wQhYf2ymV8XwsHoxGAtCHDSPzkCynqwi5kxl7ApMOcEIWIouD56cf4RExGm5yEqX4DjL36gFbmVMJ+pLAXMOkwJ0ThoL16BcOYEeh/2Y7VrwiJy1ZhDO2tdixRCEhhL0Byn3UhCgePTRvxHTMSbVIixtZtSV64TC5jEwVGCnsBknV1IQoHaxF/0GhIWrKC9Bf6yhnvokBJYS8gcp91IVyYouCx7jNMzVtiLVESU4tWxB3+E6WIv9rJRCEkZ3AUEJmtC+GatNf+xa/P8/iNDMPnjYm27VLUhVqksBcgma0L4UIUBY8v1hLw1JN4/LyNjKdakjJtptqphJBD8fnt9hu73E5u8iKE69DcuIFh7Ag8tm3B6uNL0vwlpL84UNbShUOQwp7Pbr+c7XZyeZsQrkOTnoZ+929kNGtO0uK3sJZ9RO1IQthIYc9HcjmbEK5Lc+MG2phoLDVqYn2kHPFbdmCpXEWazQiHIz+R+UhOkBPCBSkKHhu/JPCpx/Eb1BdSUwGwVK0mRV04JJmx5zM5QU4I16GJisLwejgeP3yH4u1N2ith4Ck3bhKOLcdfN69evcrIkSPp168fAF9++SX//POPvXMJIYSqPDZtJPCpx/H44TsyGjUh7pc9pA9+VWbpwuHl+BM6ffp0unXrhqIoAJQrV4433njD7sGcza31dSGECzAa8Z79Jpq0NJJnzSXh6++xln9U7VRC5EqOhd1sNtO6dWs0/13G0bBhQ7uHckayvi6E89Neupj5Bw8Pkt75kLhf9pD2cpjM0oVTyfGn1WQykZiYaCvsZ8+exfjfPYVFVrK+LoRz0sTEYHh5AIFPPYn24j8AmGvXxfpoBXWDCfEAcjx5btiwYfTs2ZPo6Gi6dOlCfHw88+fPL4hsQghhd/rvNmEYH442JgZTg8fBalU7khAPJcfCXr16db755hvOnDmDXq+nfPnyREXd3VmtMLv9+nUhhHPQxMXiO3Ecnl9/heLhQfK0WaS9OhR0OrWjCfFQ7nso3mq1MmzYMDw8PKhZsyaVK1fGYrEwdOjQgsrnFGR9XQjn4/vGRDy//gpT/YbE7/idtKEjpKgLl3DPGfvmzZtZvnw5Fy9epFq1amg0GhRFQaPR0KxZs4LM6NDkdqxCOJG0NPDyAiDljemYa9bKvDZdCrpwIfcs7J07d6Zz584sX76cESNGZHkuKSnJ7sGchczWhXAO+i0/4PvaaJKWv42pRSusxUuQFjZc7VhC5Lsc19hHjBjBuXPniI+PByAjI4OZM2fy448/2j2cI7t1F7f4JKPM1oVwYJqb8fhOHo/nl1+g6PXoLl3EpHYoIewox8I+a9Ysdu/eTUxMDGXLluXy5csMGjQoVzufPXs2x44dQ6PRMGnSJGrVqmV77tq1a4wZMwaTyUT16tV58803H/xbqOD2u7jJbF0Ix6T/aQu+Y0ehu34NU526JC17O7PHuxAuLMfr2P/8809+/PFHqlatyldffcUHH3xAWlpajjs+cOAAFy9eZN26dcycOZMZM2ZkeX7OnDkMGjSIDRs2oNPp+Pfffx/8W9iZx9cb0DSoR2Axf9Jr1mJD2GxbUZ8/tLHM1oVwQPrvNlGkT0+0sTGkTJrKzR+2S1EXhUKOhd3d3R3IbFSjKAo1a9bkyJEjOe547969tGnTBoCKFSuSmJhIcnIykHm2/eHDh2nVqhUAERERlCxZ8oG/hD15fL0Bv1cHUfTSOXSKlTJR/xD21Rw6/LNXZupCOKL/2l9ntOtAeveexP+0i9TR48BN7nklCoccf9LLly/P2rVradCgAQMHDqRkyZK5OnkuJiaGGjVq2B4HBQURHR2Nr68vcXFx+Pr6smzZMg4fPkzdunUZM2aMrbvdvQQHG3LxlfLZW4uz3Rx29gcI/b8CDmN/qoxxISTjbAcJCTBmDFSvDmPHEly6KGxYh3SXsB/5OXZMORb26dOnk5CQgJ+fH99//z2xsbGMHDkyxx3fumnM7Y9vFW5FUbhx4wbdu3dn5MiRvPLKK+zcuZMWLVrcd5/R0QV/Nn7RkyfJ7tcN5eRJYlTIY0/BwQZVxriwkXHOf+6/bMcQPhzdv1cxNXgc9/BwomNT1I7l0uTnuGA8yC9P9z0Un5iYSGRkJB4eHmi1Wrp06cKAAQO4ceNGjjsuVqwYMTExtsdRUVEULVoUgICAAEqUKEHZsmXR6XQ0atSIs2fP5jl8QbBUrpqn7UKIgqNJSsR37Ej8Q59FG3WDlNcncXPTj3LTFlGo3fOn/6effqJTp0688cYbtG3blhMnTpCRkcHcuXMZN25cjjtu0qQJW7duBeDkyZOEhITg6+sLgJubG2XKlLHd1z0yMpLy5cvnw9fJf6mjx2a/fdSYAk4ihLidJiaGgOaN8FrzEebqNYnf+iup4ybAf+cFCVFY3fNQ/Pvvv8+mTZsICgrixIkTTJ06FaPRSNOmTdm0aVOOO65Xrx41atSgV69eaDQaIiIi2LhxIwaDgbZt2zJp0iQiIiIwGo1UqlTJdiKdozE+24NV287w9O51lIm9jKVyVVJHjcH4bA+1owlRqClFi2J6/AnSQ3uTGv4a6PVqRxLCIWiUOxfD/9OvXz/WrFlje9ypUyfmzp3LY489VmDh7qTWes5rK/cAMH9oY1U+v6DImlnBkHF+cO67fkX/6w5Spv7X90JRIJuTbmWM7U/GuGDk6xr7nWeoBwUFqVrUhRCFWHIyvq+H49+jK16rlqM79985OTlcSSNEYXTPwq4oCoqiYLVasf53f+I7HwshhL25795FYItGeH30Puaq1bj543YsFSupHUsIh3XPNfaDBw9SvXp122NFUahevbrtsrVTp04VSEC1yb3WhVCPz9RJeL/9FopWS+qosaSMmwAeHmrHEsKh3bOwnz59uiBzOCy5e5sQ6lECAjBXrkLSslWY6zVQO44QTkEu9rwPude6EAUsJQWv5UvAlHn/tdQR4cT//JsUdSHyQJon34fM1oUoOO779mAYGYbunwvg6UHay2GZ/d2lx7sQeSJ/Y3Igs3Uh7Cw1FZ//exOvd1ZlPhw2irS+A9TNJIQTy/FQfEZGBmvXrmXBggUAHDt2DKPRaPdgQgjX53ZwPwGtmuC9eiWWRytwc/M2UiJmgJeX2tGEcFo5Fvbp06dz6dIl9u/fD2S2f50wYYLdgwkhXJ82Pg7dPxdIDRtB/I7fMTd8Qu1IQji9HAv71atXmThxIp6emZd79e7dm6ioKLsHE0K4JrdDB9D8929IRruOxO85RMr0WTJLFyKf5FjYzWYz8L9OdKmpqaSnp9s3lcrW7zjHayv3EJ8kSw5C5Jv0dHymv4F/53YYJvzv5kqWR+UcFiHyU44nz7Vv357+/ftz5coVZs6cya5du+jdu3dBZFPNwdNRxCcZCTB4yBnxQuQDt8MHMYwMw+3sGSzlypP2SpjakYRwWTkW9n79+lG7dm0OHDiAXq9n0aJF1KxZsyCyqSrA4OHyN30Rwu7S0/GZNxuvlcvQWK2kvvQqKZOngY+P2smEcFk5FvaePXvSrVs3unfvTkBAQEFkEkK4CO2/V/F6722spcuStHQFpibN1I4khMvLcY19/PjxXLhwgeeee46wsDC2bNlCRkZGQWRTxa1uc0KIB2Q0or10EQDroxVIWPslcb/ukaIuRAHJsbDXr1+fKVOmsGPHDgYMGMBvv/1Gs2au+xdUus0J8eDcjh0loF1zivTuAf+dZGtq1hx8fVVOJkThkavOc4mJifz8889s2bKFy5cv06tXL3vnUpV0mxMijzIy8F40F++li9BYLKT1HwwWi9qphCiUcizsgwcP5syZM7Rp04YhQ4ZQr169gsglhHASbn8ewzAiDLeTJ7CULkPS4rcwNW+pdiwhCq0cC/uLL75Is2bN0Gpd/0Zwcu91IfLIYsHw8gDc/j5PWr+BpEybgWLwUzuVEIXaPQv7zJkzmTJlCqtXr+add9656/m1a9faNZgaZH1diFxKTs5cN9fpSF78FqSnY2rZWu1UQgjuU9h79OgBwOjRowsqi0OQ9XUh7sNkwnvpQrzeX0389t1YS5bC1KiJ2qmEELe5Z2GvWrUqABs3bmTOnDlZnhs8eDCPP/64fZMJIRyK7mQkhhFDcP/zGJaSpdBe+xdryVJqxxJC3OGehf3bb7/liy++4OzZs/Tp08e2PS0tjYSEhAIJV5BkfV2IezCZ8F6+GO+Fc9GYTKT17kfKm7NR/IqonUwIkY17FvauXbvyxBNPMG7cOEaMGGHbrtVqqVjR9Q5Vy/q6ENnziZiE93ursRQvQfKiZWS0aa92JCHEfdyzsEdFRVGsWDFmz55913NJSUn4+/vbM1eBun22LuvrQgCKAv/d0TEtbAQaYwYpb0xD8Ze20kI4unsW9rlz57Jw4UL69++PRqNBURTbcxqNhu3btxdIwIIgs3Uh/kf312kMo4eS8sabmBo3xVqmLMkLl6odSwiRS/cs7AsXLgRgx44dBRZGDTJbF+I/ZjNeK5fjM28WmowM9Dt+xtS4qdqphBB5lGPXmZ07d7Jp0yYAxo4dS7t27di2bZvdgxUUma0LAbozf+HfuS2+MyOw+geQ8MkXpEyZpnYsIcQDyLGwr1y5kmbNmrFz506sVitff/01a9asKYhsdiezdSHA/fffCGjdFPcjh0l/7nnid+0jo0MntWMJIR5Qji1lPT09CQwMZOfOnXTr1g0fHx+XaS8rs3UhwFSvAaa69Ul7dRgZT3dRO44Q4iHlWKGNRiPvvfceu3btolGjRvzzzz8kJSUVRLYCIbN1UehYLHitXI7nJx9mPvbyImHTj1LUhXARORb2GTNmcOPGDebMmYOHhwe7d+9m3LhxBZFNCJHPdOfP4t+1A77TJuO9bBFkZGQ+8d+lbUII55djYa9UqRL9+/cnLi6On376iVatWtG4ceOCyGZXt9bXhSgUrFa8Vq8goGUT3A/uJ73bc8Rv+QX0erWTCSHyWY5r7J9//jnvvvsujz32GIqiMGfOHIYPH86zzz5bEPnsRtbXRWGhSUrEr09P9Pv2YA0KIvGt1WR0de6/v0KIe8uxsG/atIkff/wRDw8PAFJTUxk4cKDTF3aQ9XVROCi+BhQ/P4ydu5E0dxFKcLDakYQQdpRjYXdzc7MVdQBvb2/c3d3tGkoI8XC0/1zAY8v3pA0ZDhoNie9+DJ6espYuRCGQY2EvXrw4M2bMsK2r7969mxIlStg9mBDiAViteH74Hr4zpqJJTcX0ZGPMdeqBl5fayYQQBSTHwj5jxgzWrFnDxo0bAahTpw79+vWzezAhRN5oL/6DYfQw9L//htXfn6SFyzDXrqt2LCFEAcuxsBuNRl555ZWCyCKEeECen3yI79RJaFJTMHboRPL8JViLFVc7lhBCBfcs7IcOHWL06NGYTCaKFi3KqlWrKFu2bEFms4v1O85x8HQU8UlGAgweOb9BCCeg/fcKit6dpPnvYOwRKmvpQhRi97yOffHixXz44Yfs37+fKVOm2O725uxuL+pyqZtwWoqC/rtvwGIBIHXMeOJ/O4Dx+V5S1IUo5O5Z2LVaLZUqVQKgUaNGxMXFFVgoewsweDB/aGO51E04Je2VyxTp+QxFBr+I1+qVmRv1ejn0LoQA7lPYNXf81n/nYyFEAVMUPD/9mICnnkS/8xeMbdphfLa72qmEEA7mnmvsCQkJ7N271/Y4MTExy+NGjRrZN5kQwkZ79QqGMSPQ/7Idq8GPxGWrMIb2lsPuQoi73LOw+/n5sXLlSttjg8Fge6zRaKSwC1GA3I4eQf/LdjJatSFp0XKsJUupHUkI4aDuWdjXrFlTkDmEEHfQXvsXxdMTJSCQjM5dubnhW0zNmsssXQhxXzne3U0IUcAUBY8v1hLQ7Al8J75m22x6qoUUdSFEjgpVYZdbtQpHp71+Db++PfEbGQYWC6YmzUBR1I4lhHAiOXaecyVyq1bhsBQFjy+/wHfyeLQJN8lo1oKkJW9hLeP8TaGEEAUrxxn71atXGTlypK0//Jdffsk///xj71z57tZsXW7VKhyR9vIlDGNGoDGZSJq3mIQNm6SoCyEeSI6Fffr06XTr1g3lv8OB5cqV44033rB7sPwms3XhcBQFzc14AKxlHyHprdXE7dxL+oDBspYuhHhgORZ2s9lM69atbQ1qGjZsmOudz549m9DQUHr16sXx48ezfc3ChQsL7G5xMlsXjkJz4wZ+/Xvj/2xnyMgAwPhMd6yPlFM3mBDC6eVY2E0mE4mJibbCfvbsWYxGY447PnDgABcvXmTdunXMnDmTGTNm3PWac+fOcfDgwQeILYSTUhT4/HMCn3ocjy3fY/XzQ5OQoHYqIYQLybGwDxs2jJ49exIZGUmXLl0YOHAg4eHhOe547969tGnTBoCKFSuSmJhIcnJyltfMmTMnV/sSwhVooqPxG9QPevdGYzSSNHseCV9/jxIcrHY0IYQLyfGs+CeffJJvvvmGM2fOoNfrKV++PB4eOd/uNCYmhho1atgeBwUFER0dja+vLwAbN27k8ccfp1Sp3HfQCg425Pq1d9LpNA+9j8JAxsdOFAXaPQV//AHNmqH58EMMFSogo20/8rNsfzLGjinHwr506dJst48aNeq+71PuuPZWURTb4fybN2+yceNGPvzwQ27cuJHbrERHJ+X6tbdbv+McUfFpBPl5PvA+CoPgYIOMT36zWkGbeWDMfcIbuJ07i+/E14iOTQEZa7uRn2X7kzEuGA/yy1OOh+J1Op3tf1arlf3795OUlPN/zGLFihETE2N7HBUVRdGiRQHYt28fcXFx9OnTh+HDhxMZGcns2bPzHD635Ix4oQb9d98Q0OxxNP/98mpq1Za0V4baCr0QQthDjjP24cOHZ3lssVgYMWJEjjtu0qQJy5cvp1evXpw8eZKQkBDbYfgOHTrQoUMHAK5cucLEiROZNGnSg+TPNTkjXhQUTWwsvhPH4vnNRhRPT9yPHiajQye1YwkhCok8d56zWCxcunQpx9fVq1ePGjVq0KtXLzQaDREREWzcuBGDwUDbtm0fKKwQjk7//XcYXhuNNiYaU4PHSVq2CkvFSmrHEkIUIjkW9ubNm9vWxiHzPu3PPvtsrnY+bty4LI+rVq1612tKly5t1zvJ3d5xTgh78lq6EN9Z01E8PEiOmEnakGGg06kdSwhRyORY2D/77DPbnzUaDb6+vvj5+dk1VH6S9XVRUIxdnkG/61eS5yzEUqmy2nGEEIVUjmfxzJ8/n1KlSlGqVClKlizpVEX9FllfF/agiY/DMPxV3A4dAMD6aAUSvvpOiroQQlU5zthLly7Nhg0bqFu3Lnq93ra9TJkydg0mhCPTb/0R37Ej0UXdALOZpAaPqx1JCCGAXBT2H3744a5tGo2G7du32yVQfpL1dZHfNDfj8Z0yAc/1n6Po9SRPmUba0JFqxxJCCJt7FvZvv/2Wrl27smPHjoLMk69kfV3kJ92JPynSuwe669cw1a6becZ7tepqxxJCiCzuuca+YcOGgsyR7+T+6yK/WcqVR/H1JWXiG9z84Wcp6kIIh5Tn69idhczWRX5w3/ET2oQEjM/2AF9f4n/dC7edayKEEI7mnoX96NGjtGjR4q7tt3q+//rrr3aMlT9kti4elCYxAZ+IyXit/QRrYCDGdh3Bx0eKuhDC4d2zsFevXp1FixYVZBYhHIL7L9sxhA9H9+9VTDVrkbRsVWZRF0IIJ3DPwq7X6/N0S1UhnJ7RiO+k1/Fa8yGKmxsp4yaQOnqczNKFEE7lnoW9Vq1aBZlDCPXp9eguX8RcvSZJy1dhfqy22omEECLP7lnYX3vttYLMIYQqNMlJ6Lf/hLHbc6DRkLjqfRSDQWbpQginJTeGFoWW+287CWjeCL+XB+C2fx8ASlCQFHUhhFOTwi4Kn+RkfMePwb97F7T/XiUlfBzmOnXVTiWEEPnCZa9jFyI77r//hmHUMHSX/sFcpSpJy9/GXKee2rGEECLfuOSM/VbXOSHupP95G9orl0gdNZb4n3+Toi6EcDkuOWOXrnPidm7Hjmae4a7VkjJ+MsZnnsNcWw69CyFck0vO2EG6zgkgJQWfya/j364FXu+vztzm6SlFXQjh0lxyxi6E2769GEaF4Xbhb8wVK2GqW1/tSEIIUSBcdsYuCqnUVHzemIh/tw7o/rlAatgI4rfvxtzgcbWTCSFEgZAZu3Ap+u0/4b16BeZHK5C0dBXmJ55UO5IQQhQoKezC+aWlobGYUXwNZHTuStLit0h/tgd4e6udTAghCpwcihdOze3QAQJaN8Vn8vjMDRoN6X1elKIuhCi0XK6wyzXshUR6Oj5vTsW/czt0589l9ne3WtVOJYQQqnO5Q/FyDbvrcztyCMPIMNzO/IXlkXIkLVuFqVETtWMJIYRDcLnCDnINuyvTREXh360jGqOR1JdeJWXyNPDxUTuWEEI4DJcs7MIFmc3g5oYSEkLytFlYqlbD1KSZ2qmEEMLhuExhX7/jHAdPRxGfZCTA4KF2HJFfjEa8F85Fv3sXN7/dAm5upA9+Re1UQgjhsFzm5Lnbi7qsr7sGt+N/ENCuOT5LFqC9cR3tlctqRxJCCIfnMjN2gACDB/OHNlY7hnhYGRl4L5qH99KFaCwW0l4cRMq0GSi+BrWTCSGEw3Opwi5cQ5G+PdH/ugNL6TIkLX4LU/OWakcSQginIYVdOJy0AS9hKVOWlGkzUQx+ascRQgin4jJr7MJ56U78SZGez6CJjQUgo1Nnkhcuk6IuhBAPwCUKu3Sbc1ImE94L5xLQvgX6X3fg8cN3aicSQgin5xKH4qXbnPPRnYzEMDIM9+N/YClRkuRFy8ho3U7tWEII4fRcYsYO0m3OmXis/5yAtk/hfvwP0l7oS/yufVLUhRAin7jEjF04F3OdelhLliL5/+aT0aa92nGEEMKlSGEX9mc247ViKaaWrTHXqoOlchXi9h4BN/nxE0KI/Ob0/7LeOnEuyM9T7SgiG7q/TmMYOQT3o0fI+P03EtZ/k/mEFHUhhLALp19jlxPnHJTZjNeyxQS0bor70SOk9wglcfUHaqcSQgiX5xLTJjlxzrFor1zG7+X+uB8+hDU4hMQFS8no+LTasYQQolBw+hm7cDyKnx/aa9dIf+554n7bL0VdCCEKkEvM2IX6dOfOor30D6ZWbVH8ihD/828oRYuqHUsIIQodmbGLh2Ox4LXqLQJaNcFvyGA08XEAUtSFEEIlMmMXD0z39zkMI4fifmAf1qAgkuYtRgkIVDuWEEIUajJjF3lnteL1zkoCWjbB/cA+jF2eIW7XATK6PKN2MiGEKPSccsaekLCB6OiFpKef5um6pTl55QWgsdqxChX9D5tRvLxIWrYKY7fn1I4jhBDiP05X2BMSNnDlyiAANBoI9rtI8+pzSEioTJEiPVRO58KsVtwOHsD8xJOg1ZK04h0Udz1KiPQPEEIIR+J0h+KjoxfeY/uiAk5SeGj/uUCR5zrj37U9bgf2A2AtVVqKuhBCOCCnK+xG4+k8bRcPwWrF8/13CGzRGP2e3WR0eBrLI+XUTiWEEOI+7Hoofvbs2Rw7dgyNRsOkSZOoVauW7bl9+/axaNEitFot5cuXZ9asWWi1Of+e4eFRFaMxMtvtIv9oL13EMHoY+t27sPr7k7TwPYzPPZ+5/iGEEMJh2W3GfuDAAS5evMi6deuYOXMmM2bMyPL81KlTWbZsGV988QUpKSn89ttvudpvcPDYe2wf89CZxf94vbca/e5dGDt0Iv63Axi795SiLoQQTsBuM/a9e/fSpk0bACpWrEhiYiLJycn4+voCsHHjRtufAwMDiY+Pz9V+ixTpwd4TN/DQrKao4TJeXtUIDh4jJ87lh2vXQOcDGg0p4ydjrt8AY9dnpaALIYQTsduMPSYmhoCAANvjoKAgoqOjbY9vFfWoqCj27NlD8+bNc73v7cfqsmbXEk5FH6RixT1S1B+WouD5yYdQpUrm/wP4+GRexiZFXQghnIrdZuyKotz1WHNHkYiNjWXIkCFMnTo1yy8B9xIcbABAp9MQEuDFsNC6+Re4sLp0CV56CX76CYoUwVAyGMN/4yzsJ1jG2O5kjO1Pxtgx2a2wFytWjJiYGNvjqKgoit7WPzw5OZmXX36ZUaNG0bRp01ztMzo6CQCLRcnyWDwARcFz7Sf4TJ2ENjkJY+u2eHz8IdF6P5BxtavgYIP87NqZjLH9yRgXjAf55cluh+KbNGnC1q1bATh58iQhISG2w+8Ac+bMoX///nk6BC/yj/7nrRjGjACNhqQlK0j8bAOUKqV2LCGEEA/JbjP2evXqUaNGDXr16oVGoyEiIoKNGzdiMBho2rQp33zzDRcvXmTDhg0AdO7cmdDQUHvFEQCKAiYT6PVktGlPyrgJpPd5EWup0monE0IIkU/seh37uHHjsjyuWvV/15qfOHHCnh8t7qC99i++Y0diLV2G5HmLQaMh9fVJascSQgiRz5yu85zII0XB44u1BDR7Ao+ft6G78HfmrF0IIYRLcrqbwKzfcY7YxHSC/DzVjuLwtDeu4zt2JB7btmD18SVp/hLSXxwol7AJoRKr1YLValU7Rr7IyMjAbJZJQn7RarVotbp82ZfTFfaDp6MAaFhVbkByP5qkRAJaNEIbG0tGs+YkLX4La9lH1I4lRKFlMqXh4+OJm5uH2lHyjZ+fl9oRXIbZbCIlJQ1394cfU6cr7ABBfp70bFVR7RgOTTH4kfbSEKyBQaT3HwS56MMvhLAPq9WCj48n3t4+akfJN+7uOjQai9oxXIZerwcgPd3y0DN3pyzsIhuKgsfXG/D45isSP1wLOh2pY8ernUoIAVitVpeaqQv7cHNzx2pNk8IuQBMVheH1cDx++A7F2xvdyUgsj9XK+Y1CCCFcjhR2Z6YoeGzaiO+EsWjj4sho1ISkJSuwln9U7WRCCJV8883X/Pjjj5QvXx6r1UJycgozZswkPj6OpUuX4unpicViwWAwMGrUaKxWK4sXLyItLQ2r1YpGAxMmTMLDI/MIg9lszvZ5d3dvlb+puBcp7E7Md9xovNZ8iOLlRfKsuaQNflXW0oVwAh//cJI9x6891D4a1ypB/07Vs32uc+fOdOnSFYBRo0Zy/fp1li1bwtChw3jkkXIArF+/ju+++5b09HQqVKjAc891BzI7hSYnJ9sK+1dfbcj2+eHDh/Luu+9z/fp1li9fRsOGDfn9999p1ao1P/20lUWLlnDixAl27NjOY489RmRkJOnp6Tz66KO2fQn7kCrgxExNm2F6ohFxv+wh7eUwKepCCAC2bNnC4sWLGDCgP40aNaJUqVLExsbZijpA/fr1OX36NGfOnKFevfq27dWrVycoKMj2OKfnb1e/fn06duyIp6cX8fHxbN78Hc89151PPvkEjUaDl5cXx48fz/8vLLKQGbsT0cTE4DN3FimTp6L4B2B8pnvmrVWloAvhVPp3qn7P2XZ+6NChA126dOXTT9fYZt4hISH8/fffPPpo5lLd4cOHqVatOmlpqezbt49y5coBcOzYMQIDAylTpgwAlStXzvb5W3frNBrTbZ/r45N51n+XLl34/vvNxMfHUbp0aTQaDa+88iru7u5cv37dbt9bZJLC7iT0323CMD4cbUwM1pIlSQ1/LbPRjDSbEULcQ+/efRg2LIwnn3ySMWPGsnTpEry9vbFarfj5+TF8+AisViuLFi1g2rQI3N3d0evdGTUq3LaPHj2ez/b5xo0b89Zby/Hyuvu66yefbMTixYsYNGgwAP369WP69Gno9Xpq1arFM888W2BjUBhplDtvnO7AoqOTeG3lHgDmD22scpqCoYmNxXfSODy//grF05OUiVNJeyUMdPnToeh2chvGgiHjbH+ONsZmswk/Py/btcquwN1dh8kk17Hnp4yMDBIT03Bzc7dte5DbtsqM3YG57/oVvyGD0cZEY6rfkKTlb2OpWEntWEIIIRyYFHYHZg0MgvR0kiNmkjZkmF1m6UIIIVyLFHYHo9/yA5ZHymGpVh1LzceIOxqJUsRf7VhCCCGchJxO7SA08XEYhr5MkRd7YRg3Cv479UGKuhBCiLyQGbsD0G/7Ed+xo9DduI6pbj2SFi2Xs92FEEI8EJmxq0iTmIBhZBhF+oaijYsleXIEN7//GUuVqmpHE0KoRLNuHW716uLm5YFbvbpo1q1TO5JwMjJjV5PZjH77T5hq1yVp2Sos1ezXsEII4fg069bh1q/P/zac+BO3fn0wA0poaK72cXuveMi8ptzPz8C6devw8fGhTJkyDBw4yPb66Oho5s+fR4kSJUhKSqJq1ar07Jm7z8ptnkOHDuLl5U1SUhJ9+/ajZs2ad73uyJHDXL16lRo1anLp0kVatGiZp8/Q6XS2NroA77yzmqtXr6LVaklLS2P8+AkEBAQ80Hc4cOAAR48eoWLFilSsWDFLB797mT59GhER0x7o8x6WUxX29TvOEZuYTpCfp9pRHpgm4Sa6c2cx12+IEhjEzW9+wFKuPLi75/xmIYRL082dk/32eXMx57KwQ9Ze8QB//vknEREReHv78Oqrr2Qp7JGRkYSEhDBq1Gi0Wi0XLlxAURRmzZqJp6cn8fHxTJ/+JnPnziEwMJBr164xatRolixZhL9/AO3atefIkcOkpaVx/fp1evR43la4z58/x6FDB5k5czYA6enpDB0axgcffMjTT3ekT5++nDx5kj59+vDtt9+SnJyMt7c3586dIzIyErPZTEZGBmazmfLlH2Xfvr0sWrSYNWs+4ebNm9y8Gc9zz/W46/vv3v0bGRkZTJ/+JgAXLlwgOTmZCxf+5rvvvsXfP4Dg4GB69+7DrFkzs3yvRYsWEhgYSLt27fnuu00EBAQSGxtLcHAwp0+fJiAggDlz5tCsWTMuXbpE7dp1aNCgAUuXLqFkyZIkJyfz4ov92b9/H5s3f0fp0mX45Zcd6HQ6vLy86N69B7NmzaRcuXKkpKQwYcLEXP93zS2nKuwHT0cB0LBqiMpJHoz7jp8whI9Ak2Ek7reDKEWLYqlUWe1YQghHcepk3rbfw+bNm4mMjASgdes2NGzY0HaXtgEDBmR5bfPmzUlIuMnMmTNQFCutWrXGaEzHy8uLsWPHce3aNc6fP49e705Y2FB+/fVXfvjhBwCeeeYZihcvQUTEVFq3bo3BYODo0aO2wn7u3Dnq1Klr+yxPT08CAvxJSkrC29ub3r37cO7cWb766ivq1KmDTqfDYPCzvf6JJ57gkUceYdGiRUycOIljx/4gNjaW0qVLk5aWhoeHJ7//vpvixYtn+U5nzpyhbt16tse3jl4sXLiAmTNn4evry0svDaZ+/Qb3/F5FiwYTGxvLpElT2L79Z86dO2fbn9FopEeP54mNjWHlypU0adKEYsWK4ePjw9atW3j99fGULFmSzp27EB4+mgoVKqDRaDh9+hQZGRlkZBipWrUqTz7ZKE//XXPLqQo7QJCfJz1bVVQ7Rp5oEhPwiZiM19pPUNzcSB3zOkqRImrHEkI4mmrV4cSf2W/Pgztn7ImJicybN4cBAwZSsWIlLly4wGefraVKlSrUqlWbFi1a0q3bM1gsFnr3foHp09/EarUCYDJlkNmgNPOEXqvVgk6XeXqWj48viqJQrFgIw4YNJzU1FZPJZPvcypWr8M47q+nR43kgsyAmJCRgMPyvm5rZbEGrzf5kYb1ej0ajtXXs02q1WCwW1qxZw0cffczPP//MX3+dvut9lStXZv/+fTRp0gSAv//+m/T0dDQazW2fpfzX7z777wW3f2drlv1rtRpbNqvVyqZN31CjRg1atWrNpk2b7srTq9cLFC1alOvXrxMSEsKcOfM4fvwY4eGjWLVqNe75fMTW6Qq7s3H/dQeG8OHorl7BXOMxEpetwvJYLbVjCSEckGX8hKxr7Le2vz7+ofa7dOkS0tONfP3117i5uREePobJk6cA8NdffzFr1kyCg4MxmTLo0KEDVatW5csv17N48SJiY2OIiJiOxWJh9eq3uXz5MmPHjuPUf0cRfH19qVnzMebPn0tMTAwDBgykyH8Tl/Lly9OoUWOmTJmEr6+BpKQkxo4dB2Qelv/44484ceIEL730Mmlpabz//rt06NAxx+8TEhLC8uXL8Pf358iRw/j7++Pn97+ZftOmzTh16hRTpkzG29sLk8lMePgYXnyxP4sWLcLHx4c2bdpRuXLlu77XrSMdRYr44+dnYOnSJSQlJREcHHzPPNWqVWfNmk84e/YsFSpUYNu2rVSqVJkPPnifAQMGMn/+PIKCgggICKBly5a88847lC1bljJlyuR7UQcn6xU/YPpWwIn6xCsK/k+3xe2PI6SOHkfq6HHgwL2iHa2/tquScbY/RxvjvPSK16xbh27e3MzD79WqY3l9fK5PnCtID9sr/qWXBvHeex/kYyLnJ73iHZj20kWsZR8BjYak5avQpKRgrlVH7VhCCCeghIbm6UQ5Ie7kNNexf/BdJLGJ6Tm/UE3Jyfi+Hk7gk3Vx++MIAJYKlaSoCyHEHWS2bj9OM2P//dhVwHHPiHffvQvD6GHoLl3EXLUais5phlYIIYQLcZoZOzjoGfHJyfhOGIv/c53RXrlMyuhxxP+0S06QE0IIoQqnKuyOyGfpQrw+eBdzlarc/HE7qZOmgoeH2rGEEE5qXeQ66r1bF6//86Deu3VZFyktZUXeyPHiB5GWBp6eoNGQOjIcxdub1LARmduEEOIBrYtcR79N/7vc7UT0n7bHoTVyd0Kd2Wxm6dIlpKWlAZnXsIeHj6FEiRK216xY8RYXL15k3rz5AOzZs4fZs2eyefMPD/0dPvjgfS5evIheryclJYUhQ4ZQtuwjd73uu+++pVSpUgBotTrq1KmT689YseItGjVqRL169QFszXfS0tKwWq1oNDBhwiQ8HnCSdatFrdGYQdu2bW2X792Pmi1k7ySFPY/c9+3BMDKMlDGvY+zVB8XgR2r4a2rHEkK4gLl7sm8pO2/v3FwX9q++2kCFChV45plnAUhIuIlGc/fBWYvFwvXr1ylevDg///wTNWrUAODjjz/K0h7Ww8ODTz9dQ3BwMO7u7rz66hCeeaYrffv2Zf/+AwwbNpxy5coBma1cU1NTba1cY2NjmTZtKhMmTGLs2DF07dqV48ePM2rUaL799lvKlCnDY489hpubG19+uZ7KlStz4cIFgoKCCAoKIjIyklmzZrN06RJ0Oh3Xr19n6NCh9/zOzz3XHYCTJ0+SnJzMrl07OXToEDqdjrp16/LUU82ZMWM6ZcqU5d9//2XSpMmMGRNOxYoVefbZ51i1aiWVKlXi9OnTNG/enKNHj9C0aVOGDx9Gp06dOHnyJM888wx+fkWyjEnr1q3Zv38fv/76K4piJTIykvT0dB599FFq167D6tVvU7p0adzdM7vc2Zscis+t1FR83phAkW4d0V66iO7qFbUTCSFczKmY7FvH3mt7ds6ePUvdupltXL/44gtWrHiLzz5be9frnn/+eTZs+JKoqCgCAwNxc3MnJSWFTZs2YbFYbO1hfX19CQoKws/Pj127dgLg62vghRdeoGnTZhw/fty2zzNnzthm0QBBQUGkpxsBKFasGL1796Fjx078/PPP1KlTh86dO//X/S1Ty5at6Ny5C2azmd69+3DjxnUASpcug6enJxaLhUOHDt/1Xe783OrVqxMUFMT69euZMGEir732OuvXr2fPnt+pVq06r746hCpVqvD777tJTU1lyJAw0tPTCAkJ4aWXXqZ27dpZ9q8oCi+80Jtu3Z7h4MGDd41JxYqVKFmyJC1atOCTTz5Bo9Hg5eXF8ePHSU9Px2KxULt2nSw9+u1JCnsuuO3fR0CrJnivXonl0Qrc/G4rqWMfrhOUEELcqVrR7FvH3mt7dqpWrcaBAwcA6NWrF6++Gsbly5f5448/mDVrJj/9tA2AMmXKEhUVxYYNX9K9e+aNVG5vDxsWNpSuXbvy8ccf0a5de154oTcmkxkAT8/MQ9xarQar9X9NaqpVq8aBA/ttj+Pi4vDy8sqSz2Ix37eF7K12rbckJiayc+evvPTSy1SrVi3L591SuXJl9u3bZ3t87NgxLl++jFabtcRpNBrbLxIWixWtVodOp8XLywurVbntuayfcfv3tVgs2Y7J7Z/xyiuvMmzYcIYMCaNKlSpERExDUayMHTsm2++d3+RQfA7c9u/Dv2t7AFLDRpAyYQrc8YMqhBD5YXzjCVnW2G95vVHuJxLPPvssy5YtZebMGWi1GhITk+jTpy+PPfaYbR37zJkzALRv355vv91kW3/Prj1srVq1+eijDylfvjzFioVw5MjdM+ZbGjVqzKlTp5g+PQIPD0+Sk5N5/b92uDExMXzwwftERp7g9dcncOzYH6xb9wV16tTF19f3nvv09vbGZDKxcuUKdDodhw4dpEqVqlle06PH8yxatIBp0yJwd3dHr3dn1Khwnn++J/Pnz8NqtRIa2ovGjZswe/YsVq9+m6tXrxIaGsqnn34CQJUqVXj//Xdt5x80a9bsnpmyG5PAwCA2bfqGfv36MX36NPR6PbVq1aJkyZJs2pQ5xhUrFsxVXU7TUnbwzG1YLErBtZNVFNBowGrFd+xI0nv1xfzEkwXz2SpxtDacrkrG2f4cbYzz0lJ2XeQ65u2dy6mYk1QrWp3XG43P9fp6QcpLS9mrV6+yevXbvPnmDDuncm7SUtZe0tLwmTsLgJRpM0GrJXnxWyqHEkIUFqE1Qh2ykAvnIWvst3E7fJCANs3wXrkM/ZbvITVV7UhCCOH0SpUqJbP1AiSFHSA9HZ8ZEZl3Yjt7htSXhxC/fTd4e6udTAghhMgTORSfnk5A+xa4nTqJ5ZFyJC1dialxU7VTCSGEEA9ECrunJxlPtcTUuCnJU6aDj4/aiYQQQogHVigLu9uxo3iu/YTkOQtBqyXlzdmZZ8ALIYTKoqPXceXKHFJTT+LtXZ3SpScQHCwn04ncK1yFPSMD70Vz8V66CI3FgvGZ7pmH3aWoCyEcQHT0Os6c+d917Kmpf9oe57a43+pz3qVLV1auXEHp0mXo2rVrvuQ7cOAA//571dauNjvSK159haawux3/A8OIMNxORWIpU5akxW/JWroQwqFcuZJ9r/grV+bmadauKLBw4QLq1atHy5atSEtLY/bsWZQsWZJr164RETGNsLAhNG7cmJs3b1K6dBnKli3L+++/R/PmzTl27A+mTp3Gr7/+wsmTkZjNFho1aswjjzyCu7s7H374AfHxcSQlJdO1azdbC1vpFS+94guM11tL8W/fErdTkaS9OIj4nXsxPdVC7VhCCJFFamr2PeHT0nLfKx5g3bov+Ouvv2jY8HEA3Nx0lCxZEi8vL86fP09UVBQZGRn06PE8o0eHs3XrFgAqVKhA7959qFOnLvv376NYseJ4eXnj7+/P9u0/U758eerWrUtCQgL+/v707NnTVtRBesVLr/gCZC1aFGvxEtxc/w3JC5ag+Oa9k48QQtibt3f2PeG9vHLfKx4gNLQX48ePZ/LkSaSnp7Nr1y58fQ0MGDCQwMAArFar7bWKonBnA1Kz2YJWq2XVqhWEhQ2lRYsWWd4zdOgwOnbsyC+//JLlBjPSK156xduPyYTXu2+T3q8/isEPY2hvjJ27wX36EQshhNpKl56QZY39f9vzdtMpjQYqVKjIoEGDmTx5IsOHj2TDhi9JTU2haNFgtm3bik6n5euvN3L58iW6dOkCwIULF3j//fc4deoU3bt3Z+/evSxduoQSJUpw6dIlbty4QbFixXjrreVoNJCWlp5ldiu94qVXfJ7ktle8LvIEhpFhuP95jNRho0iJkG5HueVo/bVdlYyz/TnaGOelV3zmWfFzSUs7iZdXdUqXHm+Xs+JfemkQ7733ge3xgQMHOHr0CK++OiRX75de8flPesXfyWTCe9kivBfNQ2Mykda7H6nh49ROJYQQeRIcHCqXt4mH4jQz9i5jNxHk55ntjF3312kMw17B/fgfWIqXIHnRMjLatFchpXNztFmOq5Jxtj9HG+O8zNidRV5m7CJ38mvG7lQnzzWsGpLtdk1qCm6Rf5Ie2pv4XfukqAshHIpWq8VsNqkdQzg4s9l01wl/D8JpDsWHBHjRs9X/TjzQnT4Fencsj1bEXLc+8bsPYKlQScWEQgiRPa1WR0pKGkCW2ZgzUxSZsecns9lESko67u5eOb84B3Yt7LNnz+bYsWNoNBomTZpErVq1bM/t2bOHRYsWodPpeOqppxg2bFjudmo247VyGT7zZmOuVYebm7eBVitFXQjh0NzdvUhPt2C1pqkdJV8EBfmSmOga38URaLXafCnqYMfCfuDAAS5evMi6des4d+4cEydO5Msvv7Q9P3PmTN5///3/mhb0pn379jleCqA78xeGkUNwP3IYS0gxUkeNhXw4bCGEEAVBq9Wh1erUjpEv9Hq9yxx9cDV2q4p79+6lTZs2AFSsWJHExESSk5MBuHz5MkWKFKFEiRJotVqaN2/O3r1777u/9ru/JKB1U9yPHCa9e0/if9tPRvuO9oovhBBCOCW7FfaYmBgCAgJsj4OCgoiOjgYgOjqawMBA23NFixa1PXcvHX/7EsXgR8JHn5G06j2UgMD7vl4IIYQojOx2KP7Oq+gU5X/t+rK7wk6Twx3WDCk3Acj5HjviYTzIpRUi72Sc7U/G2P5kjB2T3WbsxYoVIyYmxvY4KiqKokWLZvvcjRs3CA4OtlcUIYQQotCwW2Fv0qQJW7duBTJvoRcSEmLrB1y6dGmSk5O5cuUKZrOZX375hSZNmtgrihBCCFFo2LXz3IIFCzh06BAajYaIiAhOnjyJwWCgbdu2HDx4kAULFgDQrl07Bg8ebK8YQgghRKHhNC1lhRBCCJEzuQhcCCGEcCFS2IUQQggX4pCFffbs2YSGhtKrVy+OHz+e5bk9e/bQo0cPQkNDWbFihUoJnd/9xnjfvn307NmTXr16MXHiRKxWq0opndv9xviWhQsX0q9fvwJO5jruN8bXrl3jhRdeoEePHkydOlWlhK7hfuO8du1aQkNDeeGFF5g1a5ZKCZ3fmTNnaNOmDZ9++uldz+W57ikOZv/+/corr7yiKIqinD17VunRo0eW5zt27Kj8+++/isViUUJDQ5WzZ8+qEdOp5TTGbdu2Va5du6YoiqKMGDFC+fXXXws8o7PLaYxvbQ8NDVX69u1b0PFcQk5jPHLkSGXbtm2KoijKtGnTlKtXrxZ4Rldwv3FOSkpSWrZsqZhMJkVRFGXgwIHK0aNH1Yjp1FJSUpS+ffsqU6ZMUdasWXPX83mtew43Y8/vVrTibvcbY4CNGzdSvHhxAAIDA4mPj1clpzPLaYwB5syZQ3h4uBrxXML9xthqtXL48GFatWoFQEREBCVLllQtqzO73zi7u7vj7u5OamoqZrOZtLQ0ihSRNmJ5pdfreffddwkJufvW5A9S9xyusOd3K1pxt/uNMWDrNxAVFcWePXto3rx5gWd0djmN8caNG3n88ccpVaqUGvFcwv3GOC4uDl9fX5YtW0bfvn1ZuHBhth0vRc7uN84eHh4MGzaMNm3a0KpVK+rUqUP58uXViuq03Nzc8PT0zPa5B6l7DlfY7/zLpzxkK1pxt/uN8S2xsbEMGTKEqVOnZvlLLXLnfmN88+ZNNm7cyMCBA9WI5jJy+rfixo0bdO/enY8//piTJ0+yc+dONWI6vfuNc3JyMqtXr2bLli38/PPP/PHHH5w+fVqNmC7rQeqewxV2aUVrf/cbY8j8y/ryyy8zatQomjZtqkZEp3e/Md63bx9xcXH06dOH4cOHExkZyezZs9WK6rTuN8YBAQGUKFGCsmXLotPpaNSoEWfPnlUrqlO73zifP3+eMmXKEBgYiF6vp0GDBpw4cUKtqC7pQeqewxV2aUVrf/cbY8hc++3fv78cgn8I9xvjDh068MMPP7B+/XreeustatSowaRJk9SM65TuN8Zubm6UKVOGf/75B4DIyEg5RPyA7jfOpUqV4vz586Snp6MoCidOnKBcuXIqpnU9D1L3HLLznLSitb97jXHTpk1p2LAhdevWtb22c+fOhIaGqpjWOd3v5/iWK1euMHHiRNasWaNiUud1vzG+ePEiERERGI1GKlWqxLRp09BqHW4u4xTuN85ffPEFGzduRKfTUbduXV5//XW14zqdEydOMHfuXK5evYqbmxvFihWjVatWlC5d+oHqnkMWdiGEEEI8GPn1VQghhHAhUtiFEEIIFyKFXQghhHAhUtiFEEIIFyKFXQghhHAhbmoHEKIwuHLlCh06dMhyGSHApEmTqFatWrbvWb58OWaz+aH6ye/fv5+hQ4dSvXp1AIxGI9WrV2fy5Mm4u7vnaV+7du0iMjKSsLAwjhw5QnBwMGXKlGHWrFl069aNmjVrPnDO5cuXs3HjRkqXLg2AyWSiRIkSvPnmmxgMhnu+78aNG/z99980atTogT9bCFcjhV2IAhIYGKjK9eqVK1e2fa6iKISHh7N+/Xr69OmTp/089dRTPPXUU0Bmr/tOnTpRpkwZJk+enC85u3btmuWXmPnz5/P222/z2muv3fM9+/fv5/z581LYhbiNFHYhVHb+/HkiIiLQ6XQkJyczevRomjVrZnvebDYzZcoULly4gEajoVq1akRERJCRkcGbb77JxYsXsVqttG7dmkGDBt33szQaDfXr1+f8+fMA/Prrr6xYsQJPT0+8vLyYMWMGxYoVY8GCBezbtw+9Xk9ISAjz5s1j8+bN7Nmzh/bt27NlyxaOHz/OxIkTWblyJWFhYSxcuJApU6bYjkoMGDCAgQMHUqlSJaZPn47RaMRkMjFs2DAaN26c47jUrVuX9evXA3Do0CEWLFiAXq8nPT2diIgI/Pz8WLJkCYqi4O/vT58+ffI8HkK4IinsQqgsJiaGUaNG0bBhQ44ePcqMGTOyFPYzZ85w7NgxfvzxRwDWr19PUlIS69atIyQkhJkzZ2KxWOjZsyeNGzematWq9/wso9HIL7/8Qo8ePUhLS2PKlCls2LCB4sWL8+mnn7JkyRImTJjA2rVrOXToEDqdjh9++CFLr+q2bdvyySefEBYWRqNGjVi5ciUAXbp0YcuWLdStW5fY2FjOnz9PkyZNGDp0KIMGDeLJJ58kOjqa0NBQtm3bhpvbvf/5MZvNbN68mTp16gCZN86ZNm0aVatWZfPmzaxevZply5bx7LPPYjabGThwIO+9916ex0MIVySFXYgCEhcXR79+/bJsW7p0KcHBwcybN4/FixdjMpm4efNmltdUqFCBgIAAXn75ZVq2bEnHjh0xGAzs37+f69evc/DgQQAyMjK4dOnSXYXszJkzWT63ZcuWdOrUiVOnThEUFETx4sUBePzxx/niiy8oUqQIzZo1o2/fvrRt25ZOnTrZXnM/Tz/9NL169WLixIls2bKFjh074ubmxv79+0lJSWHFihVAZh/32NhYihUrluX93377LUeOHEFRFE6ePMmLL77IK6+8AmTeqnL+/PkYjUYSExOzved3bsdDCFcnhV2IAnKvNfaxY8fy9NNP06NHD86cOcOQIUOyPO/h4cFnn31GZGSkbbb9+eefo9frGTZsGB06dLjv596+xn4/t9+Oc9myZZw/f56dO3fSt29fli9fnuP7g4ODKVu2LMePH+fHH39kwoQJAOj1epYvX57lntLZuX2NfciQIZQqVco2q3/99deZPn06jRo14pdffuGDDz646/25HQ8hXJ1c7iaEymJiYihbtiwAP/zwAxkZGVme//PPP/n666+pUaMGw4cPp0aNGvzzzz/Ur1+fLVu2AGC1Wvm///u/u2b791O+fHliY2P5999/Adi7dy+1a9fm8uXLfPTRR1SoUIFBgwbRtm3bu+6xrdFoSE9Pv2ufXbp0YcOGDSQkJNjOkq9fv75tGSEuLi5Xt6iNiIjgrbfe4vr161nGyGq1smXLFtsYaTQajEaj7XMeZjyEcBUyYxdCZYMGDeKNN96gdOnSDBgwgG3btjFnzhx8fHwAKFu2LCtWrGDdunXo9XrKli1LvXr1qF27NmfPniU0NBSLxUKLFi3w9/fP9ed6enoya9YswsPD0ev1eHt7M2vWLPz8/Dh58iQ9evTAx8eHIkWKMGzYMLZt22Z7b5MmTZg+fTpmsznLPtu1a8eMGTN49dVXbdsmT57M1KlT+f7778nIyCAsLCzHbCVKlOCll17ijTfe4N133+Xll1/mlVdeoWTJkgwePJjXX3+djz76iAYNGhAeHo6npydhYWEPNR5CuAq5u5sQQgjhQuRQvBBCCOFCpLALIYQQLkQKuxBCCOFCpLALIYQQLkQKuxBCCOFCpLALIYQQLkQKuxBCCOFCpLALIYQQLuT/AcEiVxxeYb9MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************* USING F2-SCORE OPTIMAL THRESHOLD *************************\n",
      "The confusion matrix is:\n",
      " [[7536  598]\n",
      " [  59   88]] \n",
      "\n",
      "Recall / Sensitivity: 0.5986394557823129\n",
      "Precision: 0.1282798833819242\n",
      "Specificity: 0.9264814359478731\n",
      "F2-Score: 0.34536891679748827\n",
      "G-Mean: 0.7447337394050645\n",
      "Cohen's Kappa: 0.1875297268423325\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "********************** USING G-MEAN OPTIMAL THRESHOLD **************************\n",
      "The confusion matrix is:\n",
      " [[6430 1704]\n",
      " [  28  119]] \n",
      "\n",
      "Recall / Sensitivity: 0.8163265306122449\n",
      "Precision: 0.06527701590784421\n",
      "Specificity: 0.790508974674207\n",
      "F2-Score: 0.24678556615512232\n",
      "G-Mean: 0.8033140411530464\n",
      "Cohen's Kappa: 0.09094635891574943\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "********************** USING KAPPA OPTIMAL THRESHOLD ***************************\n",
      "The confusion matrix is:\n",
      " [[8052   82]\n",
      " [ 116   31]] \n",
      "\n",
      "Recall / Sensitivity: 0.21768707482993196\n",
      "Precision: 0.2743362831858407\n",
      "Specificity: 0.9899188591099091\n",
      "F2-Score: 0.2211126961483595\n",
      "G-Mean: 0.4642117412976751\n",
      "Cohen's Kappa: 0.22652674402477935\n",
      "********************************************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(ground_truths, probs)\n",
    "recall = tpr\n",
    "\n",
    "# compute other metrics using the same thresholds\n",
    "specificity = np.zeros_like(tpr)\n",
    "precision = np.zeros_like(tpr)\n",
    "fbetascores = np.zeros_like(tpr)\n",
    "CKappas = np.zeros_like(tpr)\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    preds = probs > thresholds[i]\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(ground_truths, preds).ravel()\n",
    "    \n",
    "    specificity[i] = tn / (tn + fp)\n",
    "    precision[i] = tp / (tp + fp)\n",
    "    \n",
    "    # more attention put on recall, such as when false negatives are more important to\n",
    "    # minimize, but false positives are still important.\n",
    "    fbetascores[i] = metrics.fbeta_score(ground_truths, preds, beta = 2)\n",
    "    \n",
    "    CKappas[i] = metrics.cohen_kappa_score(ground_truths, preds,)\n",
    "    \n",
    "\n",
    "\n",
    "gmeans = np.sqrt(specificity * recall)\n",
    "\n",
    "\n",
    "print(\"Max F2-Score is:\", np.nanmax(fbetascores))\n",
    "print(\"Max G-Mean is:\", np.nanmax(gmeans))\n",
    "print(\"Max Cohen's Kappa is:\", np.nanmax(CKappas))\n",
    "\n",
    "\n",
    "print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs), \"\\n\")\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot(fpr[np.nanargmax(fbetascores)], tpr[np.nanargmax(fbetascores)], 'ro')\n",
    "plt.plot(fpr[np.nanargmax(gmeans)], tpr[np.nanargmax(gmeans)], 'go')\n",
    "plt.plot(fpr[np.nanargmax(CKappas)], tpr[np.nanargmax(CKappas)], 'yo')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(['ROC Curve', 'F2-Score Optimal Coordinates', 'G-Mean Optimal Coordinates', \n",
    "            \"Kappa's Optimal Coordinates\"], loc='lower right', prop={'size': 8}, \n",
    "           frameon=True, facecolor = 'white')\n",
    "plt.show()\n",
    "\n",
    "fb_opt_thresh = thresholds[np.nanargmax(fbetascores)]\n",
    "fb_opt_preds = probs > fb_opt_thresh\n",
    "\n",
    "print('\\n********************* USING F2-SCORE OPTIMAL THRESHOLD *************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, fb_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(fbetascores)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(fbetascores)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(fbetascores)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(fbetascores)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(fbetascores)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(fbetascores)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "gm_opt_thresh = thresholds[np.nanargmax(gmeans)]\n",
    "gm_opt_preds = probs > gm_opt_thresh\n",
    "\n",
    "print('\\n********************** USING G-MEAN OPTIMAL THRESHOLD **************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, gm_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(gmeans)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(gmeans)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(gmeans)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(gmeans)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(gmeans)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(gmeans)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "\n",
    "ck_opt_thresh = thresholds[np.nanargmax(CKappas)]\n",
    "ck_opt_preds = probs > ck_opt_thresh\n",
    "\n",
    "print('\\n********************** USING KAPPA OPTIMAL THRESHOLD ***************************')\n",
    "print(\"The confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, ck_opt_preds), \"\\n\")\n",
    "print(\"Recall / Sensitivity:\",  recall[np.nanargmax(CKappas)] )\n",
    "print(\"Precision:\",  precision[np.nanargmax(CKappas)] )\n",
    "print(\"Specificity:\",  specificity[np.nanargmax(CKappas)] )\n",
    "print(\"F2-Score:\", fbetascores[np.nanargmax(CKappas)] )\n",
    "print(\"G-Mean:\", gmeans[np.nanargmax(CKappas)] )\n",
    "print(\"Cohen's Kappa:\", CKappas[np.nanargmax(CKappas)] )\n",
    "print('********************************************************************************\\n')\n",
    "\n",
    "\n",
    "accuracy_scores = []\n",
    "for thresh in thresholds:\n",
    "    accuracy_scores.append(metrics.accuracy_score(ground_truths, [m > thresh for m in probs]))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(thresholds, fbetascores, \"-r\")\n",
    "plt.plot(thresholds, gmeans, \"-g\")\n",
    "plt.plot(thresholds, CKappas, \"-y\")\n",
    "plt.title(\"F2-Score, G-Means, and Cohen's Kappa Curves\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Performance Metrics\")\n",
    "plt.legend(['F2-Score', 'G-Mean', \"Cohen's Kappa\"], loc='upper right',\n",
    "           frameon=True, facecolor = 'white')\n",
    "plt.show()    \n",
    "    \n",
    "\n",
    "plt.plot(thresholds, accuracy_scores)\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAS Pytorch CUDA",
   "language": "python",
   "name": "mas_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
