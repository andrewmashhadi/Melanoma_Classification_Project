\documentclass [MAS] {uclathes}

% \input {mymacros}                         % personal LaTeX macros

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Usually things live in separate flies.
%
% \input {prelim}                           % preliminary page info

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                      %
%                          PRELIMINARY PAGES                           %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title          {An Application of Split Attention Networks:\\
                Melanoma Detection}
\author         {Andrew Mashhadi}
\department     {Statistics}
\degreeyear     {2023}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chair          {Yingnian\ Wu}
\member         {Frederic Paik\ Schoenberg}
\member         {Michael Tsiang}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\abstract       {(Abstract temporarily omitted)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{subcaption} 
\usepackage{graphicx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin {document}

\makeintropages

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\section{Background}

In the past decade, machine learning has exploded in popularity. Machine learning methods have demonstrated endless applciations to a variety of industries including but not limited to engineering, science, finance, medicine, and technology. A large branch of machine learning that has recently taken the world by storm is \textit{deep learning}. Deep learning is made up of \textit{artificial neural networks} (ANN) and is generally trained with a form of \textit{feature learning}. 

Neural network architures have evolved and expanded since the original perceptron and ANN models. Through different areas of application, variations in neural network architecture such as \textit{deep neural networks}, \textit{convolutional neural networks}, \textit{recurrent neural networks}, and more recently \textit{transformers}, have all been proposed and adopted. It is no secret that the transformer model has quickly become a front-runner for applications in computer vision due to its successes in natural language processing. However, deep convolutional neural networks are still state-of-the-art for tasks such as image classification, object detection, semantic segmentation, and instance segmentation

Different learning methods have also been adopted. However, the type of learning method used generally depends on the model's particular objective. \textit{Supervised Learning} is one of the most common methods for classification or regression models. It is the process of using labeled datasets to train machine learning models to classify or predict outcomes appropriately. \textit{Unsupervised Learning} generally involves the analysis or clustering of unlabeled datsets. And \textit{Reinforcement Learning} is based on rewarding desired behaviors and/or punishing undesired ones.

More recently, the medical community has been opening it's doors to modern deep learning techniques. In particular, convolutional neural networks (CNNs) have often been used to develop more efficient, and accurate, diagnostic tools to analyze medical images. Due to the growth of effective image recognition models, collection of medical images for specific applciations in the healthcare community have been been growing. 


\section{Problem Statement}

Skin cancer is one of the most common types of cancer. Although melanoma only accounts for about 1\% of skin cancer, the death rate was still about 2.1 per 100,000 men and women per year based on 2016-2020 deaths \cite{SEER}. In 2023, the American Cancer Society estimates that bout 7,990 people are expected to die from a total of about 97,610 new melanoma cases in the United States alone \cite{ACS}. It is well known that early detection of melanoma will provide the best chance for successful treatment and greater chance of survival. 

Image analysis tools that automate the diagnosis of melanoma will improve dermatologist's diagnostic accuracy, and better detection of melanoma has the opportunity to positively impact millions of people. Providing an accurate machine learning model to aid dermatologist's in their evaluations of patients moles may lead to an earlier diagnoses, and could therefore provide the best chance for appropriate intervention. We want to use a new deep convolutional-neural-network architecture that uses patients skin-lesion images along with any other patient-level contextual information to determine which patients are likely to have melanoma skin cancer. In particular, the goal of this paper is to identify the presence of melanoma from images of skin lesions using the novel \textit{ResNeSt} architecture that was designed to apply channel-wise attention on different network branches.


\chapter{Dataset}

\section{ISIC 2020 Challenge Dataset}

For this paper, we used the ``ISIC 2020 Challenge Dataset''. This was the official dataset of the SIIM-ISIC Melanoma Classification Challenge hosted as a Kaggle sponsored competition in the Summer of 2020. It contains over 30,000 dermoscopic images of distinct skin lesions from approximately 2,000 patients. Each image has an associated record of metadata. The metadata includes the corresponding ``beniegn'' or ``malignant'' status, as well as the following patient-level features: 

\begin{itemize}
    \item \textit{patient\_id}: unique patient idenitfier
    \item \textit{sex}: sex of the patient 
    \item \textit{age\_approx}: approximate age of the of the patient
    \item \textit{anatom\_site\_general\_challenge}: the general location of imaged lesion
    \item \textit{diagnosis}: additional details regarding the diagnosis
\end{itemize}

We should note that all associated malignant and benign diagnoses have been confimed using histopathology, expert agreement, or longitudinal follow-up \cite{ISIC}.

The International Skin Imaging Collaboration (ISIC) was responsible for compiling the images from the Hospital Cl√≠nic de Barcelona, Medical University of Vienna, Memorial Sloan Kettering Cancer Center, Melanoma Institute Australia, University of Queensland, and the University of Athens Medical School to form this official dataset. The ISIC Archive contains the largest collection of quality-controlled dermoscopic images of skin lesions available to the public. 

The resolution of each image varied drastically throughout the dataset, with some images reaching as high as 4000x6000 pixels. The set of images consisted of over 110GB, so we hosted the data on UCLA's Hoffman2 Linux Cluster. To support the size of each image and the large number of individual images within the dataset, we used computing resources from the Hoffman2 cluster and Google Colab to tune, train, and test our models with powerful \textit{Graphical Processing Units} (GPUs). Although the GPU would occasionally change, we mostly used a single NVIDIA A100 GPU with approximately 40GB VRAM to train our larger models.

\section{Data Preparation}

Throughout training, we found it to be difficult to train our models without batch-sizes greater than or equal to 16 images. However, computational constraints limited our ability to utilize larger batch-sizes with such large lesion images. We ultimately found that the only way to train efficiently with suffcient batch-size ($B \geq 16$) was to center crop, or resize (using bilinear interpolation), each original lesion image to a fixed-sized 512x512 image. Further transformations and resizing are discussed in the methodology section.

The patient-level features within the metadata also required minor preprocessing. We created dummy variables with treatment coding (also known as \textit{one-hot encoding}) for the \textit{sex} and \textit{anatom\_site\_general\_challenge} features, while keeping \textit{age\_approx} as a continuous variable.


\section{Exploratory Data Analysis}

In this section, we provide an exploratory data analysis of both the images and the patient-level features within the metadata provided in our dataset.

\subsection{Skin Lesion Images}

The images of skin lesions are the most important part of data for our model. They will be used to train the image classification network, so we decided to investigate the data a bit more, before beginning to model. First, we investigated the proportion of ``positives'' (malignant) and ``negative'' (beniegn) images within our dataset. Table 2.1 presents the balance of malignant and beniegn skin lesions within our dataset. As we can see from the table, there is significantly large class imbalance. Only about 1.8\% of the skin lesion image are classified as malignant. 

\begin{table}[h!]
\centering
\begin{tabular}{| c | c | c |} 
\hline
& Beniegn ($-$) & Malignant ($+$) \\ 
\hline
\hline
Count & 32542 & 584\\
\hline
Proportion & 0.9824 & 0.0176\\
\hline  
\end{tabular}
\label{tab:propMel}
\caption{Proportion of Beniegn \& Malignant Skin Lesions}
\end{table}


As mentioned above, we fixed the resolution of the images in our dataset to 512x512 pixels. We visually inspected the quality of several randomly selected skin lesions images after cropping and resizing to make sure that the \textit{object of interest} (the actually skin lesion itself) was still present and easily distinguishable. In Figures 2.1-2.2 , we present 6 images from our dataset. The top 3 skin lesions were randomly selected from the images flagged as malignant, while the bottom 3 skin lesisons were randomly selected from the images marked as beniegn. Although the relative and absolute size of the skin lesions differ, they are all clearly distinguishable in the images. 

\begin{figure}[hbt!]
\hspace*{\fill}
\centering
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/mal_ex1.jpg}}\hspace{0.5em}
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/mal_ex2.jpg}}\hspace{0.5em}
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/mal_ex3.jpg}}
\hspace*{\fill}
\label{fig:mel_examples}
\vspace{-1cm}
\caption{Examples of Malignant Skin Lesions}
\end{figure}

\begin{figure}[hbt!]
\hspace*{\fill}
\centering
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/ben_ex1.jpg}}\hspace{0.5em}
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/ben_ex2.jpg}}\hspace{0.5em}
\subcaptionbox*{}{\includegraphics[height = 50mm, width=50mm]{imgs/ben_ex3.jpg}}
\hspace*{\fill}
\label{fig:ben_examples}
\vspace{-1cm}
\caption{Examples of Beniegn Skin Lesions}
\end{figure}


We also visually compared a random collection of images flagged as malignant with another random collection of images flagged as benign. The objective here was to see if our ``untrained'' eye could easily classfiy the skin lessions as malignant or beniegn. We can see from Figures 2.1-2.2 that without proper training and eductaion, it is very difficult to determine whether or not a skin lesion is considered malignant. Even with the proper training, it can still be difficult to accurately determine if melanoma is present. According to the Skin Cancer Foundation, features such as assymmetry shapes, irregular borders, uneven distribution of color, and large relative size may indicate the presence of melanoma (or other skin cancers) \cite{SCF}. Ideally, our network will pick up on these characteristics while training.

\subsection{Patient-Level Features}

In this section we explore the one-way frequency tables for the approximate ages, patient sexes, and the locations of imaged lesions. Then we explored the two-way frequency tables for each of these variables with the response variable (malignant or beniegn).

\subsubsection*{Patient Age}

We can see from the histogram of approximate ages in Figure 2.3(a) that most of the patients in this data are in their 40's, 50's, and 60's. The box-plot in Figure 2.3(b) clearly indicates that older patients are generally associated with a larger number of malignant skin lesions.

\begin{figure}[hbt!]
\hspace*{\fill}
\centering
\subcaptionbox{}{\includegraphics[height = 60mm, width=80mm]{imgs/age.png}}\hspace{0.5em}
\subcaptionbox{}{\includegraphics[height = 60mm, width=80mm]{imgs/age_2way.png}}
\hspace*{\fill}
\label{fig:age_eda}
\vspace{0cm}
\caption{Histogram and Box-Plot For Appoximate Age}
\end{figure}

\subsubsection*{Patient Sex}

We can see from the frequencies shown in Figure 2.4(a) that there are a similar number of males and females in this dataset, with just one or two thousand more males. The two-way contingency table between the response variable and patient sex is also shown in Figure 2.4(b). We can see that the malignant cases have a significantly larger proportion of males than the beniegn cases do. In fact, the $\chi^2$-test of independence reported a p-value very close to 0. Therefore, we reject the hypothesis that patient sex and the presence of melanoma are independent, and conclude that there is a relationship between the two variables.

\begin{figure}[h!tbp]
    \hspace*{\fill}
    \centering
    \subcaptionbox{}{\includegraphics[height = 60mm, width=80mm]{imgs/sex.png}}\hspace{1em}
    \subcaptionbox{}{\vspace{17mm} \footnotesize \begin{tabular}{| c || c | c |} 
        \hline
        & \textbf{Beniegn} & \textbf{Malignant} \\ 
        \hline
        \hline
        \textbf{Female} & 15761 & 220\\
        \hline
        \textbf{Male} & 16716 & 364\\
        \hline  
        \end{tabular}}
    \hspace*{\fill}
    \label{fig:sex_eda}
    \vspace{0cm}
    \caption{Frequency Plot and Two-way Contingency Table for Patient Sex}
    \end{figure}

\subsubsection*{Skin-Lesion Location}

There were 6 categories for the general skin-lesion location: oral/genital, palms/soles, head/neck, upper extremity, lower extremity, and torso. Figure 2.5(a) presents the associated frequencies within our dataset. None of the general locations have a similar number of counts, and almost half of the skin-lesions come from the torso region. We also present the two-way contingency table between the response variable and lesion location in Figure 2.5(b). While it is somewhat difficult to tell, the does appear to be some differences in the balance between beniegn and malignant cases when conditioned on the skin-lesion location. In this case, the $\chi^2$-test of independence also reported a p-value very close to 0, indicating that there is a relationship between the location of the skin-lesion and the presence of melanoma.

\begin{figure}[h!tbp]
    \hspace*{\fill}
    \centering
    \subcaptionbox{}{\includegraphics[height = 60mm, width=80mm]{imgs/site.png}}\hspace{1em}
    \subcaptionbox{}{\vspace{5mm} \footnotesize \begin{tabular}{| c || c | c |} 
        \hline
        & \textbf{Beniegn} & \textbf{Malignant} \\ 
        \hline
        \hline
        \textbf{Head/Neck} & 1781 & 74\\
        \hline
        \textbf{Lower Extremity} & 8293 & 124\\
        \hline  
        \textbf{Oral/Genital} & 120 & 4\\
        \hline
        \textbf{Palms/Soles} & 370 & 5\\
        \hline  
        \textbf{Torso} & 16588 & 257\\
        \hline
        \textbf{Upper Extremity} & 4872 & 111\\
        \hline  
        \end{tabular}}
    \hspace*{\fill}
    \label{fig:sex_eda}
    \vspace{0cm}
    \caption{Frequency Plot and Two-way Contingency Table for Lesion Location}
    \end{figure}


\chapter{Methodology}

See the methodology intro in 412 paper.

\section{Training, Validation, and Testing Sets}

We randomly split 80\% of the data into a training set and used the other random 20\% as the test set. The test set was
not used by any network during the training process. Additionally, we partitioned another 20\% of the training data into a validation set. Recall that our dataset is largely imbalanced. As shown in the Exploratory Data Analysis section, only about 2\% of the skin lesions in the dataset are flagged as malignant, while the remaining skin lesions are marked as benign. We ensured that each split of the data had a similar sample proportional of about 2\% malignant skin lesions.

Since the response variable (malignant or beniegn) in the training data is heavily imbalanced, we used randomized oversampling of the malignant observations to combat any potential bias toward a ``beniegn'' classification. By oversampling, we hoped that the networks would better detect when skin lesions were truly malignant. 

Note that using standard $k$-fold cross validation would require a model to be trained $k$ times for each set of hyper-parameters. Given the size of our data and our models, the time it would take to perform this procedure was simply infeasible. Therefore, we used the independent validation set to tune each network's hyper-parameters effectively. This method minimized overall training time, and produced optimal hyper-parameters. Once the hyper-parameters were obtained, we retrained the model on a new oversampled dataset made up from combining the training and validation sets.

We tuned each model with the area under the \textit{Receiver Operating Characteristic} (ROC-AUC) as our performance
metric. The ROC-AUC was chosen over other metrics because it summarizes how well our network separates the two response
classes over \textit{all} possible thresholds (as opposed to a single predetermined threshold). 



\section{Multi-Network Ensemble Learning}

Discuss the idea of using the two network ensemble. One MLP for meta data and the CNN for the image data. Disuss the use of the mentioned Image Augmentations and then discuss the idea of Batch Normalization, Adam Optimizer, L2 Regularization, and Dropout layers. Discuss the difference between starting the CNN weights at random values, vs starting the ResNeSt weights at the IMAGENET trained weights and finetuned for our set of data (effectively leveraging their training).

\section{Network for Contextual Features}

Give back-ground on Multi-Layer Perceptron for metadata.

\section{Network for Lesion Images}

\subsection{Image Augmentations}

Write about cropping augmentations to training data, etc.

\subsection{Convolutional Neural Network}

Write here. Discuss final implementation of Batch Normalization, Adam Optimizer, L2 Regularization, and Dropout layers.

\subsection{ResNeSt}

Write about evolution from CNN to ResNet to ResNeSt. Also use the following description of ResNeSt somewher (from pytorch website):

While image classification models have recently continued to advance, most downstream applications such as object detection and semantic segmentation still employ ResNet variants as the backbone network due to their simple and modular structure. We present a simple and modular Split-Attention block that enables attention across feature-map groups. By stacking these Split-Attention blocks ResNet-style, we obtain a new ResNet variant which we call ResNeSt. Our network preserves the overall ResNet structure to be used in downstream tasks straightforwardly without introducing additional computational costs. ResNeSt models outperform other networks with similar model complexities, and also help downstream tasks including object detection, instance segmentation and semantic segmentation.

Discuss final implementation of Batch Normalization, Adam Optimizer (different rates), L2 Regularization, and Dropout layers.

A New ResNet Variant, is modularized architecture is designed to apply the channel-wise attention on different network branchesresidual-network variant known as \textit{ResNeSt}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Results}

% use import tikzplotlib

\section{CNN + MLP Ensemble Results}

Write here. Give all plots from analysis notebook. Give table of statistics and confusion matrix.

\section{ResNeSt + MLP Ensemble Results}

Write here. Write here. Give all plots from analysis notebook. Give table of statistics and confusion matrix. Compare to regular CNN + MLP model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion and Future Work}

Write here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{bib/resnest_melanoma_detection.bib}    % bibliography references
\bibliographystyle{uclathes}


\end{document}