Job 5733224 started on:    g10
Job 5733224 started on:    Thu Jan 12 12:42:51 PST 2023
 
Device: cuda:0
Number of devices: 2
Loading the pre-trained CNN weights.
CUDA Memory Allocated: 20931072
CUDA Memory Allocated: 8802686464
[Epoch 7, Batch 23807] Loss: 0.32780981063842773

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8853999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23832] Loss: 0.4282563707003227

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23857] Loss: 0.4248064309358597

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23882] Loss: 0.4146284015212012

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23907] Loss: 0.4117777246686787

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23932] Loss: 0.4005892549804042

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23957] Loss: 0.40873721275256564

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 23982] Loss: 0.41668783766429196

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24007] Loss: 0.4231291783334159

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24032] Loss: 0.4373845279266217

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24057] Loss: 0.43155640492074754

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24082] Loss: 0.4248972772485644

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24107] Loss: 0.43812907530471334

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24132] Loss: 0.43278459076158293

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24157] Loss: 0.4320665913397855

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24182] Loss: 0.43007848667912185

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24207] Loss: 0.4288391835123598

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24232] Loss: 0.43551222116472155

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24257] Loss: 0.44242738110081453

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24282] Loss: 0.4439825801640561

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24307] Loss: 0.4500665199755135

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24332] Loss: 0.4471816366587982

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24357] Loss: 0.44689774607898103

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24382] Loss: 0.44741083720388514

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 24407] Loss: 0.45008324560230467

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24] Loss: 0.4488715111507109

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 49] Loss: 0.4478479387516159

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 74] Loss: 0.44562911072514466

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 99] Loss: 0.4449036543745117

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 124] Loss: 0.4457389564297006

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 149] Loss: 0.445867891759474

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 174] Loss: 0.4479220884410453

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 199] Loss: 0.44900873801048924

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 224] Loss: 0.45157182471010354

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 249] Loss: 0.4557539746427928

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 274] Loss: 0.45399480816572224

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 299] Loss: 0.4508648266339805

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 324] Loss: 0.4509899761230075

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 349] Loss: 0.44904098606479403

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 374] Loss: 0.44789585555697503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 399] Loss: 0.44808036990679584

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8851
Using max F1-Score threshold, the confusion matrix is:
 [[77 23]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 424] Loss: 0.4477479424487371

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 449] Loss: 0.4492271397737777

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 474] Loss: 0.4491770523634902

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 499] Loss: 0.4475195396312603

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 524] Loss: 0.4480364456438653

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 549] Loss: 0.447333210755583

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 574] Loss: 0.447302020978512

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 599] Loss: 0.44684088808623185

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 624] Loss: 0.44770845958923533

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 649] Loss: 0.44827438881107085

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 674] Loss: 0.44834313079492893

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 699] Loss: 0.4468057398511803

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 724] Loss: 0.4475756541574388

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 749] Loss: 0.44666373858615743

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 774] Loss: 0.4476236960130505

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 799] Loss: 0.4477189109221282

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 824] Loss: 0.44693328293502793

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 849] Loss: 0.44607863587671975

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 874] Loss: 0.44499472781213195

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 899] Loss: 0.4443420191034228

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 924] Loss: 0.44566849949080034

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 949] Loss: 0.44315308880428395

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 974] Loss: 0.44388259140665876

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 999] Loss: 0.444871749785926

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1024] Loss: 0.4456327023937712

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1049] Loss: 0.4446829991039455

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1074] Loss: 0.4436262990214677

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1099] Loss: 0.4432549623215132

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1124] Loss: 0.4424014360431327

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1149] Loss: 0.4432791525531009

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1174] Loss: 0.44168191702369397

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1199] Loss: 0.4454378397077289

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1224] Loss: 0.4450470447736136

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1249] Loss: 0.44350765085201016

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1274] Loss: 0.4419754978710178

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1299] Loss: 0.44178441389689693

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1324] Loss: 0.4405150711633118

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1349] Loss: 0.4411473323532339

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1374] Loss: 0.44133310609681886

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1399] Loss: 0.4413234296141714

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8845000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1424] Loss: 0.4406282894629599

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1449] Loss: 0.44238914299060633

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1474] Loss: 0.4436563999932223

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1499] Loss: 0.44382927758882496

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1524] Loss: 0.44351731707724834

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1549] Loss: 0.44342259389509825

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1574] Loss: 0.4425854349460946

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1599] Loss: 0.44336576705484537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1624] Loss: 0.44311571819916945

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1649] Loss: 0.4437074511647489

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1674] Loss: 0.4419812730485688

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1699] Loss: 0.44254902702817345

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1724] Loss: 0.4427428049702431

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1749] Loss: 0.44157617165529184

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1774] Loss: 0.43993698288796323

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1799] Loss: 0.43979567245908796

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1824] Loss: 0.44044090852276513

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1849] Loss: 0.44044692082059284

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1874] Loss: 0.43985002807767304

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1899] Loss: 0.439714222002487

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1924] Loss: 0.43930483637163775

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1949] Loss: 0.43949871146646213

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1974] Loss: 0.43886782352448156

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 1999] Loss: 0.4394082309121767

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2024] Loss: 0.4398524832584798

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2049] Loss: 0.43983410078904306

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2074] Loss: 0.43950100261606667

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2099] Loss: 0.4392205954180056

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2124] Loss: 0.4388241099831884

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2149] Loss: 0.4380565082789096

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2174] Loss: 0.4383937355120175

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2199] Loss: 0.438475271549258

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2224] Loss: 0.4385602916791898

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2249] Loss: 0.4378163408774194

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2274] Loss: 0.4382549863365661

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2299] Loss: 0.43805152800233355

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2324] Loss: 0.4378008817705139

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2349] Loss: 0.4378680137608747

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2374] Loss: 0.43763905034590794

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2399] Loss: 0.4376227025020841

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8834
Using max F1-Score threshold, the confusion matrix is:
 [[76 24]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2424] Loss: 0.4377917812303723

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2449] Loss: 0.43783336885637314

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2474] Loss: 0.437865200078282

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2499] Loss: 0.43765682605765244

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2524] Loss: 0.43751008922540446

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2549] Loss: 0.4377006712150608

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2574] Loss: 0.43723783339197825

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2599] Loss: 0.4368061337204547

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2624] Loss: 0.43705166565913706

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2649] Loss: 0.43691803421681935

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2674] Loss: 0.4361416771462112

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2699] Loss: 0.43592414314983036

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2724] Loss: 0.43767343790696567

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2749] Loss: 0.43819188137720216

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2774] Loss: 0.4384742552961854

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2799] Loss: 0.4382550228388213

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2824] Loss: 0.43839841315352074

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2849] Loss: 0.43889731075695654

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2874] Loss: 0.438998385217851

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2899] Loss: 0.43887859562896586

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2924] Loss: 0.438551993233427

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2949] Loss: 0.43807670044558245

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2974] Loss: 0.43800171167679314

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 2999] Loss: 0.43809703133236827

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3024] Loss: 0.43855528533150495

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3049] Loss: 0.4386103641312193

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3074] Loss: 0.4389917078388447

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3099] Loss: 0.43930398240852553

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3124] Loss: 0.43960732854732776

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3149] Loss: 0.43987591826100964

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3174] Loss: 0.4406996463288324

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3199] Loss: 0.4405823482415631

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3224] Loss: 0.44041880157713376

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3249] Loss: 0.4402362409953954

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3274] Loss: 0.4397623366243768

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3299] Loss: 0.4391748595150067

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3324] Loss: 0.43930682330285553

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3349] Loss: 0.43991756826635403

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3374] Loss: 0.4397490283697319

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3399] Loss: 0.43979304365327704

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8833000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3424] Loss: 0.43953407714879017

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3449] Loss: 0.4394196289929673

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3474] Loss: 0.44002421611967524

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3499] Loss: 0.4401678365437912

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3524] Loss: 0.44114853307230995

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3549] Loss: 0.44119581122959173

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3574] Loss: 0.4415023941506535

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3599] Loss: 0.4410938853218396

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3624] Loss: 0.44092367510666114

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3649] Loss: 0.4402530852856846

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3674] Loss: 0.44044934946371084

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3699] Loss: 0.4403895965269127

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3724] Loss: 0.4406130552426208

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3749] Loss: 0.4406412346136588

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3774] Loss: 0.44013490551576984

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3799] Loss: 0.43992013335050206

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3824] Loss: 0.43997044016897907

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3849] Loss: 0.4400206172604041

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3874] Loss: 0.4397480226782674

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3899] Loss: 0.4398847413753151

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3924] Loss: 0.44002535077156785

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3949] Loss: 0.4401720675272068

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3974] Loss: 0.440322965814999

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 3999] Loss: 0.44005347962250946

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4024] Loss: 0.4395227678735381

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4049] Loss: 0.4397622911318403

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4074] Loss: 0.44017700776792396

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4099] Loss: 0.4401258648470459

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4124] Loss: 0.4396080494264375

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4149] Loss: 0.4398633065919479

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4174] Loss: 0.439763190338647

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4199] Loss: 0.4396938666626827

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4224] Loss: 0.43948373325721785

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4249] Loss: 0.439404364345452

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4274] Loss: 0.4395353491731306

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4299] Loss: 0.43920390309841567

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4324] Loss: 0.43928679864372644

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4349] Loss: 0.4399034537339609

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4374] Loss: 0.4398854480561474

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4399] Loss: 0.43957785071484434

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8817
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4424] Loss: 0.4407074919520439

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4449] Loss: 0.4412364418605659

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4474] Loss: 0.4413930694624001

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4499] Loss: 0.4410921392406939

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4524] Loss: 0.4409504312054602

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4549] Loss: 0.4410960345041391

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4574] Loss: 0.44111596230616135

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4599] Loss: 0.44121778247725035

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4624] Loss: 0.4413331651709435

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4649] Loss: 0.4412866402381949

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4674] Loss: 0.4412954290968686

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4699] Loss: 0.44143634152325834

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4724] Loss: 0.44141831519757163

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4749] Loss: 0.44124052514987133

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4774] Loss: 0.4406760442368631

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4799] Loss: 0.4407311012215569

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4824] Loss: 0.440936899013128

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4849] Loss: 0.44070692776532006

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4874] Loss: 0.44088461816955804

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4899] Loss: 0.4403186167379202

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4924] Loss: 0.44089375633154493

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4949] Loss: 0.4406189085525439

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4974] Loss: 0.44059728218277266

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 4999] Loss: 0.4403942304144074

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5024] Loss: 0.44056141936811866

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5049] Loss: 0.4406790303824813

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5074] Loss: 0.4408213534760614

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5099] Loss: 0.4411376986252051

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5124] Loss: 0.44163417447666753

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5149] Loss: 0.441205221688052

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5174] Loss: 0.4413866624461843

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5199] Loss: 0.44177479438138223

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5224] Loss: 0.44108543752309304

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5249] Loss: 0.44102847036480436

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5274] Loss: 0.4411917141010418

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5299] Loss: 0.44109781817235577

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5324] Loss: 0.4417429372462074

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5349] Loss: 0.44207122918938896

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5374] Loss: 0.4418163442550354

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5399] Loss: 0.4415366066664139

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8825
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5424] Loss: 0.4413989412546074

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5449] Loss: 0.44137264381668734

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5474] Loss: 0.4416179566765529

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5499] Loss: 0.4413410862961195

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5524] Loss: 0.4411455556550229

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5549] Loss: 0.44105638307356493

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5574] Loss: 0.4412776849768245

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5599] Loss: 0.44151710379322656

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5624] Loss: 0.4417082764438081

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5649] Loss: 0.4417549845130992

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5674] Loss: 0.4415986859794632

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5699] Loss: 0.4418957934789791

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5724] Loss: 0.4418001174225984

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5749] Loss: 0.4417893494700934

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5774] Loss: 0.4415670653026308

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5799] Loss: 0.44113661293036405

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5824] Loss: 0.4407251694471854

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5849] Loss: 0.44050528891407703

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5874] Loss: 0.440634463477415

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5899] Loss: 0.44030333614675077

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5924] Loss: 0.44021037602988383

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5949] Loss: 0.44056600196862233

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5974] Loss: 0.4404673324025479

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 5999] Loss: 0.44086998851439063

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6024] Loss: 0.4405689684703942

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6049] Loss: 0.44096655059908857

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6074] Loss: 0.4406925552195957

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6099] Loss: 0.4406861282674933

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6124] Loss: 0.44050082868868456

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6149] Loss: 0.44078204041828917

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6174] Loss: 0.44066236837005074

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6199] Loss: 0.44070518501031714

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6224] Loss: 0.4406468830762582

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6249] Loss: 0.4407136048357637

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6274] Loss: 0.44056173842541174

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6299] Loss: 0.44053699785821626

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6324] Loss: 0.440714029901842

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6349] Loss: 0.4406397320113625

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6374] Loss: 0.44109701756291825

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6399] Loss: 0.4406476023484172

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8839999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[76 24]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6424] Loss: 0.4409207341539836

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6449] Loss: 0.44113697605071517

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6474] Loss: 0.44068051891642535

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6499] Loss: 0.4403754396647647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6524] Loss: 0.4400953121369361

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6549] Loss: 0.4403474651445852

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6574] Loss: 0.44033429162408594

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6599] Loss: 0.4402571205647786

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6624] Loss: 0.44057969739565245

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6649] Loss: 0.44072343722019724

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6674] Loss: 0.4408698805040563

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6699] Loss: 0.4411895599383583

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6724] Loss: 0.44081680542796264

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6749] Loss: 0.44124045106971926

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6774] Loss: 0.4413727913256391

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6799] Loss: 0.4416363988999857

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6824] Loss: 0.4418037035378334

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6849] Loss: 0.44203125971862295

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6874] Loss: 0.44184228904129724

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6899] Loss: 0.44181877016249405

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6924] Loss: 0.4422187242301049

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6949] Loss: 0.44268371002461726

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6974] Loss: 0.4425276897524591

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 6999] Loss: 0.44285103326489145

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7024] Loss: 0.44265652521873183

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7049] Loss: 0.44267974273071475

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7074] Loss: 0.44261965458972913

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7099] Loss: 0.4425276441906175

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7124] Loss: 0.44211024385130787

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7149] Loss: 0.44201019586863793

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7174] Loss: 0.44224285342708547

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7199] Loss: 0.44264484644762303

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7224] Loss: 0.44266889833362283

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7249] Loss: 0.44282444579418356

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7274] Loss: 0.4428163211167884

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7299] Loss: 0.44272005514329804

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7324] Loss: 0.4425229635745298

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7349] Loss: 0.44219062051010416

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7374] Loss: 0.4419031769105905

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7399] Loss: 0.44190453773825605

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8839999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7424] Loss: 0.4417979157876261

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7449] Loss: 0.4420625126833072

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7474] Loss: 0.44227933802481867

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7499] Loss: 0.4421520670417201

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7524] Loss: 0.4420843894263111

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7549] Loss: 0.4421270117031118

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7574] Loss: 0.4423644501509039

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7599] Loss: 0.4426267367195206

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7624] Loss: 0.4424596320773882

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7649] Loss: 0.4422083695536183

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7674] Loss: 0.4420784026325386

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7699] Loss: 0.4419887012162222

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7724] Loss: 0.441700155505834

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7749] Loss: 0.441420840069789

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7774] Loss: 0.4413752797586308

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7799] Loss: 0.44159601273722643

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7824] Loss: 0.4413834584179674

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7849] Loss: 0.4416480737214518

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7874] Loss: 0.44176970900675006

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7899] Loss: 0.4416247341948816

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7924] Loss: 0.44169967732152593

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7949] Loss: 0.44193254275252464

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7974] Loss: 0.44216667403468735

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 7999] Loss: 0.4419731872424582

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8024] Loss: 0.4416586255813188

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8049] Loss: 0.4416141982455465

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8074] Loss: 0.4415414388016306

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8099] Loss: 0.4415382588145863

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8124] Loss: 0.4414993917184011

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8149] Loss: 0.44142896795557873

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8174] Loss: 0.4415403119793099

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8199] Loss: 0.4413186772866688

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8224] Loss: 0.4411812133968059

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8249] Loss: 0.4408071594784814

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8274] Loss: 0.4406042901394908

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8299] Loss: 0.4404924701321307

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8324] Loss: 0.44060135763259567

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8349] Loss: 0.44031730027243604

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8374] Loss: 0.4404250083378319

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8399] Loss: 0.44033372469238935

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8822000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8424] Loss: 0.4402340819942378

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8449] Loss: 0.43993851705914755

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8474] Loss: 0.44010650572326376

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8499] Loss: 0.44036428550922

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8524] Loss: 0.44008355705345503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8549] Loss: 0.4399160536855081

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8574] Loss: 0.43975479327854333

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8599] Loss: 0.4397522476296793

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8624] Loss: 0.4399551930549639

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8649] Loss: 0.43976123796405664

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8674] Loss: 0.4398480682234622

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8699] Loss: 0.43984702220187594

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8724] Loss: 0.4399589498761227

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8749] Loss: 0.43999876684838185

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8774] Loss: 0.43986014679329366

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8799] Loss: 0.43994291277705144

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8824] Loss: 0.4400157166529133

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8849] Loss: 0.4398429763120339

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8874] Loss: 0.4400151276661405

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8899] Loss: 0.43990168154299253

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8924] Loss: 0.4401461615284063

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8949] Loss: 0.4402103266206702

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8974] Loss: 0.44028906068479085

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 8999] Loss: 0.4403639002375746

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9024] Loss: 0.44052925879364446

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9049] Loss: 0.44056011859411315

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9074] Loss: 0.44056890262063686

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9099] Loss: 0.4408241770366654

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9124] Loss: 0.44101053169818755

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9149] Loss: 0.44100609370670146

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9174] Loss: 0.4408646868372263

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9199] Loss: 0.4407895565769959

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9224] Loss: 0.4407079906159064

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9249] Loss: 0.4406205223892733

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9274] Loss: 0.4405361633152207

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9299] Loss: 0.44042822032050916

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9324] Loss: 0.44060721240000195

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9349] Loss: 0.44047496543019643

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9374] Loss: 0.4405793114253503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9399] Loss: 0.44069351460186823

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8836
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9424] Loss: 0.4405034628111342

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9449] Loss: 0.4405131825891662

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9474] Loss: 0.4408005586812001

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9499] Loss: 0.4406729311185413

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9524] Loss: 0.4404944792620171

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9549] Loss: 0.4404131310794045

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9574] Loss: 0.4404387089395281

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9599] Loss: 0.4407124479706907

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9624] Loss: 0.4406368936957205

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9649] Loss: 0.44052182351122826

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9674] Loss: 0.4403972341780543

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9699] Loss: 0.4401072455386929

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9724] Loss: 0.43986466594755436

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9749] Loss: 0.43997720880922475

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9774] Loss: 0.44016806820156906

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9799] Loss: 0.4401181445554373

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9824] Loss: 0.44009917393632614

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9849] Loss: 0.43991333111901765

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9874] Loss: 0.44002672015846134

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9899] Loss: 0.43980302331078175

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9924] Loss: 0.43994801025873054

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9949] Loss: 0.44001885516082306

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9974] Loss: 0.439971523121832

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 9999] Loss: 0.439697811484573

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10024] Loss: 0.439515656287665

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10049] Loss: 0.4396322903553596

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10074] Loss: 0.4396197120196707

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10099] Loss: 0.4395978838621696

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10124] Loss: 0.43981772451361967

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10149] Loss: 0.4397544199712564

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10174] Loss: 0.440001371205987

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10199] Loss: 0.43998451107910647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10224] Loss: 0.43992535478172046

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10249] Loss: 0.44001613097882813

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10274] Loss: 0.4400659197422156

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10299] Loss: 0.4399961939877971

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10324] Loss: 0.43977921483579646

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10349] Loss: 0.43955723554424586

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10374] Loss: 0.4393835504891951

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10399] Loss: 0.4393793794128131

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.883
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10424] Loss: 0.4394065929963947

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10449] Loss: 0.4393678353329962

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10474] Loss: 0.4392735196937396

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10499] Loss: 0.43940579487265374

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10524] Loss: 0.4393826520655377

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10549] Loss: 0.4395331911460058

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10574] Loss: 0.4396722384934489

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10599] Loss: 0.43959319105664674

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10624] Loss: 0.4397995876332185

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10649] Loss: 0.439802850863231

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10674] Loss: 0.4398364781150307

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10699] Loss: 0.43997584069529266

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10724] Loss: 0.4402299609277664

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10749] Loss: 0.4399722173037773

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10774] Loss: 0.43998787069150264

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10799] Loss: 0.43994003340733273

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10824] Loss: 0.44001308940341227

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10849] Loss: 0.4398780620766135

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10874] Loss: 0.4397946738051403

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10899] Loss: 0.43973363168377605

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10924] Loss: 0.43984914884655124

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10949] Loss: 0.4401433437784666

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10974] Loss: 0.4402261307862418

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 10999] Loss: 0.440171684721868

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11024] Loss: 0.4400680876168287

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11049] Loss: 0.43976542667950436

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11074] Loss: 0.439906439613921

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11099] Loss: 0.43996414898028513

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11124] Loss: 0.44014443788530044

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11149] Loss: 0.4402229817273954

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11174] Loss: 0.44025424408075353

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11199] Loss: 0.4403831393930437

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11224] Loss: 0.44028915741754787

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11249] Loss: 0.4403967004735848

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11274] Loss: 0.44016903922079104

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11299] Loss: 0.43990209162953336

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11324] Loss: 0.4399880712077836

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11349] Loss: 0.4398453945752086

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11374] Loss: 0.4398718517419553

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11399] Loss: 0.43986012819732573

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8815999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11424] Loss: 0.4396933841828982

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11449] Loss: 0.4395939145688842

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11474] Loss: 0.4400778958841087

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11499] Loss: 0.44031779547607924

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11524] Loss: 0.4405274157764572

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11549] Loss: 0.440526071294827

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11574] Loss: 0.44062557846978406

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11599] Loss: 0.44050252664907236

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11624] Loss: 0.44047328174015504

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11649] Loss: 0.4405186514214074

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11674] Loss: 0.4405418567099381

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11699] Loss: 0.44051335174591866

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11724] Loss: 0.4405062608751791

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11749] Loss: 0.4404006409129675

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11774] Loss: 0.44033539799507404

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11799] Loss: 0.44017136117802275

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11824] Loss: 0.44027961596142656

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11849] Loss: 0.44029275970803516

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11874] Loss: 0.44017214963374446

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11899] Loss: 0.44038234393647047

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11924] Loss: 0.44019610807329357

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11949] Loss: 0.4399735370675968

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11974] Loss: 0.4404083486618569

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 11999] Loss: 0.44049788303019916

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12024] Loss: 0.44051207514158447

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12049] Loss: 0.44048240462733407

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12074] Loss: 0.4405067187969644

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12099] Loss: 0.440633164324836

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12124] Loss: 0.44035823114609174

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12149] Loss: 0.44018936655368374

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12174] Loss: 0.44029384079994605

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12199] Loss: 0.44036312938523997

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12224] Loss: 0.44047565329599175

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12249] Loss: 0.44077712122364554

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12274] Loss: 0.440799600424337

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12299] Loss: 0.4406548272379412

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12324] Loss: 0.44052992182325973

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12349] Loss: 0.4405597108434597

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12374] Loss: 0.44062220602185476

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12399] Loss: 0.4404897132004321

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8826
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 5 95]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12424] Loss: 0.4404028587853492

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12449] Loss: 0.44027922918880047

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12474] Loss: 0.4402387506254735

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12499] Loss: 0.4400690605494414

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12524] Loss: 0.4399835147320062

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12549] Loss: 0.4402443557670611

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12574] Loss: 0.4402358975200945

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12599] Loss: 0.440283632353902

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12624] Loss: 0.44043584359460775

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12649] Loss: 0.44044688202114063

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12674] Loss: 0.44046463887256315

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12699] Loss: 0.4407129664038184

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12724] Loss: 0.44062315894962567

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12749] Loss: 0.44072297727169457

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12774] Loss: 0.44086925885623374

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12799] Loss: 0.44060489353542787

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12824] Loss: 0.44053070941524025

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12849] Loss: 0.44049301329532387

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12874] Loss: 0.4405617846929877

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12899] Loss: 0.4404604801834049

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12924] Loss: 0.44063613327963985

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12949] Loss: 0.4405776543957718

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12974] Loss: 0.4408816684722905

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 12999] Loss: 0.44087434988944096

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13024] Loss: 0.4410478056561703

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13049] Loss: 0.4409932689402182

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13074] Loss: 0.4411626074213342

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13099] Loss: 0.4412253626107215

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13124] Loss: 0.4411596670277546

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13149] Loss: 0.44127295075404205

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13174] Loss: 0.4412160149089122

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13199] Loss: 0.441321331747435

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13224] Loss: 0.4418482041830038

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13249] Loss: 0.44170425518401546

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13274] Loss: 0.44183140342722765

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13299] Loss: 0.4418838734143396

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13324] Loss: 0.4418382636854179

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13349] Loss: 0.4417816640789285

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13374] Loss: 0.4419125423516916

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13399] Loss: 0.44196440751191596

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8835
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13424] Loss: 0.4420101227112349

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13449] Loss: 0.4420171763560221

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13474] Loss: 0.44207170533739365

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13499] Loss: 0.4420844292347809

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13524] Loss: 0.4422700074455844

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13549] Loss: 0.442335906985503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13574] Loss: 0.44208458887752666

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13599] Loss: 0.4419548801823839

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13624] Loss: 0.44179460125793707

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13649] Loss: 0.4418828061435919

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13674] Loss: 0.4418811631209169

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13699] Loss: 0.4419502561319192

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13724] Loss: 0.4421628380045305

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13749] Loss: 0.4420328250864945

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13774] Loss: 0.44199721840053224

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13799] Loss: 0.4418313381024847

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13824] Loss: 0.44187386618439317

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13849] Loss: 0.44205581025474955

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13874] Loss: 0.44189875762401143

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13899] Loss: 0.4417698411818813

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13924] Loss: 0.44180591636928856

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13949] Loss: 0.44193688817332494

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13974] Loss: 0.44211247900941

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 13999] Loss: 0.44189833476412327

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14024] Loss: 0.441790724526589

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14049] Loss: 0.4417544204142151

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14074] Loss: 0.4418668436457886

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14099] Loss: 0.44190048412059707

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14124] Loss: 0.4420114753441006

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14149] Loss: 0.44207120302964326

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14174] Loss: 0.44210510925187124

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14199] Loss: 0.44216771807483074

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14224] Loss: 0.4420958635057165

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14249] Loss: 0.4422607390457992

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14274] Loss: 0.4425576589649739

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14299] Loss: 0.4426161108065878

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14324] Loss: 0.4426887321881036

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14349] Loss: 0.4426629305523482

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14374] Loss: 0.4426655817378171

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14399] Loss: 0.44265468260072804

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8835
Using max F1-Score threshold, the confusion matrix is:
 [[76 24]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14424] Loss: 0.442625460996366

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14449] Loss: 0.4425083932991343

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14474] Loss: 0.442439354978142

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14499] Loss: 0.44246141052909793

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14524] Loss: 0.44253352383733124

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14549] Loss: 0.4425659118763968

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14574] Loss: 0.4426153594658415

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14599] Loss: 0.44252808333182364

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14624] Loss: 0.44244743945950765

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14649] Loss: 0.4424194741013906

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14674] Loss: 0.44240402821346564

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14699] Loss: 0.44236601146400506

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14724] Loss: 0.4426733297752232

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14749] Loss: 0.442619657595203

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14774] Loss: 0.44262997698488005

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14799] Loss: 0.44270928254746866

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14824] Loss: 0.44271613059667575

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14849] Loss: 0.44283076231193386

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14874] Loss: 0.4429690421914692

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14899] Loss: 0.4428688619812376

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14924] Loss: 0.4429260841776542

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14949] Loss: 0.44294012562024976

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14974] Loss: 0.44307181075225865

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 14999] Loss: 0.44302418293943235

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15024] Loss: 0.4430491410574412

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15049] Loss: 0.44313602045137473

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15074] Loss: 0.44317220255119893

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15099] Loss: 0.44331947860802867

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15124] Loss: 0.44333786621387056

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15149] Loss: 0.4432033963791653

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15174] Loss: 0.4433029031974422

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15199] Loss: 0.4433669524758764

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15224] Loss: 0.4433660588973283

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15249] Loss: 0.4433054015839228

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15274] Loss: 0.4430811815938785

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15299] Loss: 0.44320343304211113

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15324] Loss: 0.4434184418106083

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15349] Loss: 0.44344584295378664

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15374] Loss: 0.44356578208716435

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15399] Loss: 0.44339918516507376

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8839
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15424] Loss: 0.44340600920151874

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15449] Loss: 0.44331430669408145

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15474] Loss: 0.44329780997276497

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15499] Loss: 0.44323934035874435

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15524] Loss: 0.44325413403051483

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15549] Loss: 0.44320474514492886

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15574] Loss: 0.44310652455600563

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15599] Loss: 0.4431433494808517

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15624] Loss: 0.443211771618163

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15649] Loss: 0.4432030090365659

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15674] Loss: 0.44304333989052747

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15699] Loss: 0.443052757791816

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15724] Loss: 0.44305024152986944

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15749] Loss: 0.44299523221159914

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15774] Loss: 0.4431626146665397

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15799] Loss: 0.4430239266097504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15824] Loss: 0.44293819697630255

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15849] Loss: 0.4429813836272153

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15874] Loss: 0.4429958032686729

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15899] Loss: 0.44297235502300025

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15924] Loss: 0.44302372486445196

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15949] Loss: 0.4431096749841306

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15974] Loss: 0.4428665383611482

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 15999] Loss: 0.44286421709748663

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16024] Loss: 0.443093891931447

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16049] Loss: 0.44304255647060714

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16074] Loss: 0.44311918747810386

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16099] Loss: 0.4430440663495065

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16124] Loss: 0.44311786374640916

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16149] Loss: 0.4430930047977564

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16174] Loss: 0.44304223342975857

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16199] Loss: 0.4430523356194954

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16224] Loss: 0.4431954930386671

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16249] Loss: 0.44296760767670434

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16274] Loss: 0.44308068768802744

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16299] Loss: 0.4431911645217223

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16324] Loss: 0.4431501546226249

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16349] Loss: 0.44317927600347895

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16374] Loss: 0.44334810510974265

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16399] Loss: 0.44356771900692876

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8833
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16424] Loss: 0.4435738554179737

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16449] Loss: 0.4436002792897041

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16474] Loss: 0.44370933526098943

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16499] Loss: 0.44369678222306075

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16524] Loss: 0.44357069974886343

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16549] Loss: 0.44362059681354377

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16574] Loss: 0.4436717655740264

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16599] Loss: 0.4436906477263489

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16624] Loss: 0.44363822448331747

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16649] Loss: 0.4437404000301016

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16674] Loss: 0.4436889765308672

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16699] Loss: 0.4438367832661352

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16724] Loss: 0.4437354928470394

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16749] Loss: 0.44376234433584033

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16774] Loss: 0.4437130403630547

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16799] Loss: 0.4435701632177412

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16824] Loss: 0.4437747616631895

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16849] Loss: 0.44380765499184327

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16874] Loss: 0.44398766275378904

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16899] Loss: 0.44413760761773424

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16924] Loss: 0.4440425581309503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16949] Loss: 0.44395439355269023

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16974] Loss: 0.4439146037823506

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 16999] Loss: 0.44372860256513286

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17024] Loss: 0.44377727714851944

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17049] Loss: 0.4439739419137769

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17074] Loss: 0.4439199024225069

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17099] Loss: 0.4438380772934735

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17124] Loss: 0.4437287616652019

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17149] Loss: 0.4437162145307194

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17174] Loss: 0.4438033980470608

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17199] Loss: 0.4438667347223909

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17224] Loss: 0.44396114582284696

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17249] Loss: 0.4439121836618079

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17274] Loss: 0.4438966429178826

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17299] Loss: 0.4439802689358245

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17324] Loss: 0.4439801860505739

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17349] Loss: 0.4440398860328897

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17374] Loss: 0.4440134769703689

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17399] Loss: 0.44397506409877624

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8826
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17424] Loss: 0.44390086169966025

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17449] Loss: 0.4438241314374909

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17474] Loss: 0.44397159133934544

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17499] Loss: 0.4441049094933684

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17524] Loss: 0.4442985286267396

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17549] Loss: 0.4443203237106392

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17574] Loss: 0.44430889031600984

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17599] Loss: 0.44434393881843937

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17624] Loss: 0.444280970375525

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17649] Loss: 0.4441749238766353

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17674] Loss: 0.44426893762880104

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17699] Loss: 0.44438339741128574

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17724] Loss: 0.44446195735801736

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17749] Loss: 0.44440545703434003

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17774] Loss: 0.4443758829594312

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17799] Loss: 0.44442980249550174

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17824] Loss: 0.4443708577027637

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17849] Loss: 0.44449496956166695

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17874] Loss: 0.44441728404146247

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17899] Loss: 0.44436898661031254

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17924] Loss: 0.44435710353493485

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17949] Loss: 0.444516116914775

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17974] Loss: 0.44456042395423356

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 17999] Loss: 0.44448092029249275

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18024] Loss: 0.4444101500336605

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18049] Loss: 0.4445532421914958

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18074] Loss: 0.44447423983814105

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18099] Loss: 0.4445848743992076

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18124] Loss: 0.4445598426539641

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18149] Loss: 0.4445676306289135

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18174] Loss: 0.4447009506624257

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18199] Loss: 0.44480321953230373

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18224] Loss: 0.4446793415832109

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18249] Loss: 0.44467290231176354

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18274] Loss: 0.4447050619178494

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18299] Loss: 0.44485483019554634

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18324] Loss: 0.44489658787719805

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18349] Loss: 0.44481414115762785

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18374] Loss: 0.4448907959306751

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18399] Loss: 0.4448593025243343

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8831999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18424] Loss: 0.44484999552948684

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18449] Loss: 0.44484723553716166

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18474] Loss: 0.4447041553251631

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18499] Loss: 0.4446469114035404

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18524] Loss: 0.4445490344493458

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18549] Loss: 0.4444995942021705

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18574] Loss: 0.44428306404770457

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18599] Loss: 0.4443599357189236

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18624] Loss: 0.4444046726783209

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18649] Loss: 0.44439300046934244

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18674] Loss: 0.44443405271482866

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18699] Loss: 0.4445790126272197

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18724] Loss: 0.44469677176452577

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18749] Loss: 0.44453022999251113

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18774] Loss: 0.4443670440365043

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18799] Loss: 0.4442530606170701

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18824] Loss: 0.44419118556325654

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18849] Loss: 0.44434485031191007

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18874] Loss: 0.44430223160359644

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18899] Loss: 0.44439494227160004

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18924] Loss: 0.44436208964039786

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18949] Loss: 0.4443423513030205

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18974] Loss: 0.444332967185947

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 18999] Loss: 0.4442201657913001

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19024] Loss: 0.4443675705755518

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19049] Loss: 0.4444291732870154

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19074] Loss: 0.4443487564307619

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19099] Loss: 0.44436158189344593

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19124] Loss: 0.4442591062825976

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19149] Loss: 0.4443568500366833

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19174] Loss: 0.44451508617876656

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19199] Loss: 0.4446432932651244

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19224] Loss: 0.44466708204739525

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19249] Loss: 0.4448191629717366

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19274] Loss: 0.44475754255464145

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19299] Loss: 0.4448368915761356

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19324] Loss: 0.4448511028944815

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19349] Loss: 0.4448897288208943

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19374] Loss: 0.4449497940375712

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19399] Loss: 0.44500155339950553

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8830000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19424] Loss: 0.4450756194532062

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19449] Loss: 0.4449717040549889

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19474] Loss: 0.4450539791440503

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19499] Loss: 0.44490344004940824

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19524] Loss: 0.4450020176534087

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19549] Loss: 0.4449828582226603

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19574] Loss: 0.4448870552037558

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19599] Loss: 0.4448146253848576

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19624] Loss: 0.44487962953567295

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19649] Loss: 0.444775426005361

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19674] Loss: 0.4446680721965383

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19699] Loss: 0.4446462156021419

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19724] Loss: 0.4446936498057861

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19749] Loss: 0.44477057092834116

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19774] Loss: 0.44469603127781643

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19799] Loss: 0.44466833352542634

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19824] Loss: 0.4446015219684425

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19849] Loss: 0.44455075662763993

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19874] Loss: 0.44461260665625457

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19899] Loss: 0.44455205127994807

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19924] Loss: 0.44442284291140605

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19949] Loss: 0.44438304882961555

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19974] Loss: 0.44437787065767315

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 19999] Loss: 0.4443490066392473

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20024] Loss: 0.4443608775497759

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20049] Loss: 0.4442710889730023

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20074] Loss: 0.44430022100837097

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20099] Loss: 0.44421918410200495

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20124] Loss: 0.44421780342393435

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20149] Loss: 0.444215812459825

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20174] Loss: 0.4440826548728375

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20199] Loss: 0.44399445659267556

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20224] Loss: 0.44403739368826906

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20249] Loss: 0.44409861572892223

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20274] Loss: 0.4440481482755516

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20299] Loss: 0.4440351899108705

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20324] Loss: 0.4439562204068976

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20349] Loss: 0.4440668384689422

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20374] Loss: 0.4442433422348944

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20399] Loss: 0.4442951642035371

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8825000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[75 25]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20424] Loss: 0.44429247681390605

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20449] Loss: 0.44435756350477024

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20474] Loss: 0.4444774302826658

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20499] Loss: 0.4445736576052665

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20524] Loss: 0.44456248307327473

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20549] Loss: 0.444479355662177

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20574] Loss: 0.4444644471684462

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20599] Loss: 0.4443505355188367

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20624] Loss: 0.4444695125276662

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20649] Loss: 0.44431713742563067

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20674] Loss: 0.44432122519059086

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20699] Loss: 0.44429078623717166

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20724] Loss: 0.4444351038916247

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20749] Loss: 0.44446221922387

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20774] Loss: 0.4443439879249203

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20799] Loss: 0.4442684002516377

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20824] Loss: 0.4441952803270841

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20849] Loss: 0.444215178499584

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20874] Loss: 0.4443012281653344

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20899] Loss: 0.4445327947430895

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20924] Loss: 0.44446597048872777

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20949] Loss: 0.44444458412372007

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20974] Loss: 0.44458670258612853

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 20999] Loss: 0.4445388971507021

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21024] Loss: 0.44451401342884084

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21049] Loss: 0.444500688886031

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21074] Loss: 0.44450707005914

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21099] Loss: 0.44439344602378167

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21124] Loss: 0.4443120951518659

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21149] Loss: 0.4443872940197911

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21174] Loss: 0.44444707407110384

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21199] Loss: 0.4443452703048371

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21224] Loss: 0.44427968972274423

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21249] Loss: 0.44429627787927883

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21274] Loss: 0.4442746223007225

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21299] Loss: 0.4442137293820362

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21324] Loss: 0.4445644219924238

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21349] Loss: 0.4445294467365314

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21374] Loss: 0.44448900962598326

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21399] Loss: 0.4444407240048367

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8825
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21424] Loss: 0.4445796281980156

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21449] Loss: 0.444554510668902

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21474] Loss: 0.44457472971798984

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21499] Loss: 0.44440638714648095

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21524] Loss: 0.44442338957149485

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21549] Loss: 0.4444231064963675

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21574] Loss: 0.4444515381191829

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21599] Loss: 0.44450724038827916

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21624] Loss: 0.44450995269658317

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21649] Loss: 0.444362801360747

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21674] Loss: 0.4442170663357308

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21699] Loss: 0.4442038156281263

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21724] Loss: 0.4442011352528688

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21749] Loss: 0.4442693959046736

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21774] Loss: 0.44426537282158235

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21799] Loss: 0.4442717057664537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21824] Loss: 0.44424432890205146

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21849] Loss: 0.4443329065876516

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21874] Loss: 0.4443238713451374

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21899] Loss: 0.44442293355161533

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21924] Loss: 0.44448101337143114

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21949] Loss: 0.4443880068098182

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21974] Loss: 0.44433481584843987

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 21999] Loss: 0.44423522629898027

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22024] Loss: 0.4442651291626212

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22049] Loss: 0.44420144513907583

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22074] Loss: 0.44425529227688154

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22099] Loss: 0.4442262286895098

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22124] Loss: 0.44418054753931685

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22149] Loss: 0.444170678726889

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22174] Loss: 0.4440701195829024

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22199] Loss: 0.44416364759716853

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22224] Loss: 0.44417555272309256

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22249] Loss: 0.444042515079824

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22274] Loss: 0.44393174024999027

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22299] Loss: 0.44383721174829627

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22324] Loss: 0.44393276790618275

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22349] Loss: 0.44382222064193605

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22374] Loss: 0.44395532957774336

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22399] Loss: 0.44389819075389847

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8819
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22424] Loss: 0.44407204231885555

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22449] Loss: 0.44403563279996805

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22474] Loss: 0.44411560993843086

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22499] Loss: 0.4441785772825445

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22524] Loss: 0.4441379499324082

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22549] Loss: 0.4440962245216288

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22574] Loss: 0.4441581924520189

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22599] Loss: 0.44413537750187854

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22624] Loss: 0.4441372594274603

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22649] Loss: 0.44411476100302094

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22674] Loss: 0.4441550113083092

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22699] Loss: 0.444115183695439

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22724] Loss: 0.4440333011322101

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22749] Loss: 0.4440902047094418

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22774] Loss: 0.4441222844050635

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22799] Loss: 0.44412009689881604

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22824] Loss: 0.44409662546442236

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22849] Loss: 0.443988938437223

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22874] Loss: 0.44394873125006695

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22899] Loss: 0.44391451678318267

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22924] Loss: 0.4438865373753031

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22949] Loss: 0.44382882990965816

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22974] Loss: 0.4437396330490309

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 22999] Loss: 0.4437825074852268

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23024] Loss: 0.4437904936810745

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23049] Loss: 0.4437857836385362

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23074] Loss: 0.44386205982752325

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23099] Loss: 0.44400946759514254

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23124] Loss: 0.4441594224096426

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23149] Loss: 0.44419379988301366

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23174] Loss: 0.4441843322081984

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23199] Loss: 0.444261065548362

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23224] Loss: 0.4442631324801948

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23249] Loss: 0.44427810065666323

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23274] Loss: 0.44423832152793047

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23299] Loss: 0.44434407151534744

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23324] Loss: 0.44436465544567105

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23349] Loss: 0.44432607786231043

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23374] Loss: 0.4442929124037313

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23399] Loss: 0.4442987178211848

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8804000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [ 5 95]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23424] Loss: 0.4443437554212615

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23449] Loss: 0.44432031598280863

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23474] Loss: 0.4443216199885598

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23499] Loss: 0.44441175527404164

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23524] Loss: 0.44430070703219665

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23549] Loss: 0.4442772534868901

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23574] Loss: 0.4443290086481893

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23599] Loss: 0.44417818504521916

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23624] Loss: 0.44421281805311946

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23649] Loss: 0.4443907265441439

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23674] Loss: 0.44433829642498973

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23699] Loss: 0.44431748264257465

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23724] Loss: 0.44427808034133826

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23749] Loss: 0.44420451874903283

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23774] Loss: 0.4441647601408947

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23799] Loss: 0.44416807005076187

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23824] Loss: 0.44417601161830333

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23849] Loss: 0.4442010519678789

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23874] Loss: 0.444257163082638

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23899] Loss: 0.44435240349408367

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23924] Loss: 0.44430829494853463

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23949] Loss: 0.44434655838586856

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23974] Loss: 0.44427349881326944

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 23999] Loss: 0.44435813549160535

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24024] Loss: 0.4443223272899327

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24049] Loss: 0.4444295053520398

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24074] Loss: 0.44456707552209146

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24099] Loss: 0.4444971032559656

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24124] Loss: 0.444687759045481

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24149] Loss: 0.44464409810579597

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24174] Loss: 0.44467041714781214

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24199] Loss: 0.44463585861298216

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24224] Loss: 0.44455989199712803

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24249] Loss: 0.44459344779538235

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24274] Loss: 0.44461427402205933

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24299] Loss: 0.4446122808562412

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24324] Loss: 0.444700948412782

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24349] Loss: 0.44462534286967764

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24374] Loss: 0.4445599717812041

CUDA Memory Allocated: 9090220032
[Epoch 8, Batch 24399] Loss: 0.44458631740706495

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8795000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16] Loss: 0.44445148269502743

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 41] Loss: 0.44448786691243997

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 66] Loss: 0.44445426272925703

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 91] Loss: 0.4443630509285983

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 116] Loss: 0.44437459662786755

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 141] Loss: 0.44426517271701915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 166] Loss: 0.44422767708633804

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 191] Loss: 0.44424201762250864

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 216] Loss: 0.4441748182260136

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 241] Loss: 0.44409276098074885

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 266] Loss: 0.4441921887120483

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 291] Loss: 0.44418760048084394

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 316] Loss: 0.44422327575072956

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 341] Loss: 0.4442100046879752

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 366] Loss: 0.44415312583709765

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 391] Loss: 0.444197159575682

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 416] Loss: 0.444316144698004

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 441] Loss: 0.44430513257342064

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 466] Loss: 0.4442248176974881

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 491] Loss: 0.44421553640548544

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 516] Loss: 0.44424640055470593

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 541] Loss: 0.44418099540611294

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 566] Loss: 0.4440851353454378

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 591] Loss: 0.4441472216967686

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 616] Loss: 0.44414434451233337

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 641] Loss: 0.44412203118307314

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 666] Loss: 0.44408449166023317

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 691] Loss: 0.44412329954592605

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 716] Loss: 0.4440510682755877

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 741] Loss: 0.44400502091280825

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 766] Loss: 0.4440077995662627

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 791] Loss: 0.4439276032661494

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 816] Loss: 0.4438955042702206

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 841] Loss: 0.44396220601601993

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 866] Loss: 0.44400943050379543

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 891] Loss: 0.4439622158433686

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 916] Loss: 0.443986551986001

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 941] Loss: 0.4440775942247576

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 966] Loss: 0.44409241869415794

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 991] Loss: 0.4442082676745819

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8799
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [ 5 95]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1016] Loss: 0.44429947747007636

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1041] Loss: 0.44437517879623667

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1066] Loss: 0.4442825468143065

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1091] Loss: 0.4442354423699702

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1116] Loss: 0.44427358693648783

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1141] Loss: 0.4442816573507096

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1166] Loss: 0.44429564517911313

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1191] Loss: 0.44432343991513057

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1216] Loss: 0.4443336794597317

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1241] Loss: 0.44439635713699704

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1266] Loss: 0.4443936409334577

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1291] Loss: 0.44450462183630274

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1316] Loss: 0.4444159510593757

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1341] Loss: 0.4445664730712006

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1366] Loss: 0.44446071577327617

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1391] Loss: 0.4444908591713376

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1416] Loss: 0.44449820216204655

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1441] Loss: 0.444527794191971

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1466] Loss: 0.4444463349313719

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1491] Loss: 0.444593182209865

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1516] Loss: 0.4447038923219225

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1541] Loss: 0.44469581043896245

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1566] Loss: 0.4447208895996462

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1591] Loss: 0.44477796487148613

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1616] Loss: 0.44487626437067845

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1641] Loss: 0.4448420515754373

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1666] Loss: 0.4447469107400582

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1691] Loss: 0.44475627367539844

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1716] Loss: 0.4447803399603292

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1741] Loss: 0.44478936294759175

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1766] Loss: 0.44477618936296803

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1791] Loss: 0.444865843002389

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1816] Loss: 0.44483031096430015

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1841] Loss: 0.4448844182412665

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1866] Loss: 0.4448586421512641

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1891] Loss: 0.4448105384330881

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1916] Loss: 0.4448705667617801

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1941] Loss: 0.4448500997930614

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1966] Loss: 0.4448319217561626

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 1991] Loss: 0.4448472553598049

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8811
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2016] Loss: 0.444874250821434

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2041] Loss: 0.44481582524321917

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2066] Loss: 0.44481234457800606

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2091] Loss: 0.444811674259876

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2116] Loss: 0.44482171485296795

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2141] Loss: 0.44493489993612595

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2166] Loss: 0.4448982613071556

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2191] Loss: 0.44490923028451473

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2216] Loss: 0.44480446594365886

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2241] Loss: 0.44485723869930094

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2266] Loss: 0.44486354475695883

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2291] Loss: 0.4447963307003919

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2316] Loss: 0.4447372373958846

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2341] Loss: 0.44478693308826905

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2366] Loss: 0.4448456118465197

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2391] Loss: 0.44478021522890165

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2416] Loss: 0.4446681805832064

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2441] Loss: 0.44465860285824077

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2466] Loss: 0.44461163486123423

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2491] Loss: 0.4445989650057922

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2516] Loss: 0.4445902209201547

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2541] Loss: 0.44457250739733445

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2566] Loss: 0.44456533804701487

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2591] Loss: 0.4444951750534458

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2616] Loss: 0.44442654830977196

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2641] Loss: 0.444439932344592

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2666] Loss: 0.4444578898938574

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2691] Loss: 0.44442141035478294

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2716] Loss: 0.4443919425364013

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2741] Loss: 0.44440416519441417

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2766] Loss: 0.44438546598424344

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2791] Loss: 0.44438117674118854

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2816] Loss: 0.4444031765397853

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2841] Loss: 0.4444559343468982

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2866] Loss: 0.44453968638149294

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2891] Loss: 0.44460770056481613

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2916] Loss: 0.4446133415050037

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2941] Loss: 0.4446404484204231

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2966] Loss: 0.4445669696569626

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 2991] Loss: 0.444644828720104

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8816
Using max F1-Score threshold, the confusion matrix is:
 [[61 39]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3016] Loss: 0.44459185686951647

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3041] Loss: 0.44467577016912235

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3066] Loss: 0.44468324636308865

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3091] Loss: 0.44465199580657955

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3116] Loss: 0.4446894087728895

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3141] Loss: 0.4446772852333789

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3166] Loss: 0.44472522392164554

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3191] Loss: 0.4448154255650571

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3216] Loss: 0.44485544924542636

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3241] Loss: 0.44487084244739517

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3266] Loss: 0.444990209049919

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3291] Loss: 0.44496560560055687

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3316] Loss: 0.44508765770323233

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3341] Loss: 0.4450742190130259

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3366] Loss: 0.4450046740542422

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3391] Loss: 0.44503359237039075

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3416] Loss: 0.44502491868436356

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3441] Loss: 0.445013878518934

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3466] Loss: 0.4451030626532498

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3491] Loss: 0.4450362915009985

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3516] Loss: 0.4450858514199639

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3541] Loss: 0.4450607925786154

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3566] Loss: 0.44509448130031803

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3591] Loss: 0.44504084037220565

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3616] Loss: 0.44495252001459834

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3641] Loss: 0.44496018218492145

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3666] Loss: 0.4450721060502523

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3691] Loss: 0.445081840493848

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3716] Loss: 0.4450730693824903

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3741] Loss: 0.4449911730412619

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3766] Loss: 0.445040975052054

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3791] Loss: 0.4450118019115605

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3816] Loss: 0.4449484211770128

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3841] Loss: 0.4448819879702246

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3866] Loss: 0.44478925501435945

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3891] Loss: 0.44476633766709045

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3916] Loss: 0.44479528362106463

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3941] Loss: 0.44473573199999056

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3966] Loss: 0.4447478725246942

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 3991] Loss: 0.44478339316355964

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.882
Using max F1-Score threshold, the confusion matrix is:
 [[73 27]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4016] Loss: 0.44476136419006257

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4041] Loss: 0.4446878909639862

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4066] Loss: 0.44466320317053304

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4091] Loss: 0.44466854110090037

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4116] Loss: 0.4446987630031997

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4141] Loss: 0.4446716600495056

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4166] Loss: 0.4447692433690199

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4191] Loss: 0.4448605512318053

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4216] Loss: 0.44482320510234646

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4241] Loss: 0.44487354931699247

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4266] Loss: 0.4449744805605699

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4291] Loss: 0.4449665754787988

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4316] Loss: 0.4448409675076362

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4341] Loss: 0.4448805021129777

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4366] Loss: 0.44487464997140297

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4391] Loss: 0.44489100953000016

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4416] Loss: 0.44503071312378306

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4441] Loss: 0.444987216558201

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4466] Loss: 0.4449677125925282

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4491] Loss: 0.44493377268337597

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4516] Loss: 0.4448997536765615

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4541] Loss: 0.444889653998641

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4566] Loss: 0.444894220536156

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4591] Loss: 0.44494828913525825

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4616] Loss: 0.44499269164588146

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4641] Loss: 0.445040450709349

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4666] Loss: 0.4451071457693325

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4691] Loss: 0.44505491423463284

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4716] Loss: 0.44491802825135224

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4741] Loss: 0.44504086951689215

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4766] Loss: 0.4449409940382611

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4791] Loss: 0.44497782083912696

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4816] Loss: 0.44492294944981164

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4841] Loss: 0.444909936600156

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4866] Loss: 0.4448676484717139

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4891] Loss: 0.44493876093902807

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4916] Loss: 0.4449792195971444

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4941] Loss: 0.4450915873535521

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4966] Loss: 0.44507174352621387

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 4991] Loss: 0.4450196403359271

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8814
Using max F1-Score threshold, the confusion matrix is:
 [[61 39]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5016] Loss: 0.445030777499577

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5041] Loss: 0.44501020099574373

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5066] Loss: 0.44497632177704916

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5091] Loss: 0.44504439176722466

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5116] Loss: 0.44501390983469596

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5141] Loss: 0.44508040716633096

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5166] Loss: 0.44514336486404793

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5191] Loss: 0.4451456039979665

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5216] Loss: 0.4450019283216721

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5241] Loss: 0.44494151535112175

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5266] Loss: 0.44490668969610303

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5291] Loss: 0.44493837586695434

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5316] Loss: 0.4448127164984811

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5341] Loss: 0.4447629735952536

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5366] Loss: 0.4448139343216592

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5391] Loss: 0.44499797224225257

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5416] Loss: 0.44499399989007365

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5441] Loss: 0.4449550656806151

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5466] Loss: 0.44493041106707903

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5491] Loss: 0.444925019830852

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5516] Loss: 0.4449102109990851

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5541] Loss: 0.4449216979189518

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5566] Loss: 0.44481505092848334

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5591] Loss: 0.44474465910422983

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5616] Loss: 0.44469666341593367

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5641] Loss: 0.44479349009393804

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5666] Loss: 0.444919475223676

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5691] Loss: 0.44496204418503554

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5716] Loss: 0.4449590702771775

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5741] Loss: 0.44496792871521984

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5766] Loss: 0.44499645197544585

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5791] Loss: 0.4450540524793992

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5816] Loss: 0.445000750160766

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5841] Loss: 0.4450003448575805

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5866] Loss: 0.44496561668330975

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5891] Loss: 0.4449745259497843

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5916] Loss: 0.4449691305799546

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5941] Loss: 0.4449872371326688

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5966] Loss: 0.4449805738075773

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 5991] Loss: 0.4450188056426097

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8814
Using max F1-Score threshold, the confusion matrix is:
 [[73 27]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6016] Loss: 0.44495580942328994

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6041] Loss: 0.44489680836935486

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6066] Loss: 0.4448444910316234

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6091] Loss: 0.444801577172425

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6116] Loss: 0.4449466333850466

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6141] Loss: 0.444947406849511

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6166] Loss: 0.4450361174472431

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6191] Loss: 0.4451001837177355

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6216] Loss: 0.4451568715917306

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6241] Loss: 0.4451440075115094

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6266] Loss: 0.4452959964598737

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6291] Loss: 0.44525014639396693

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6316] Loss: 0.44522111081970545

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6341] Loss: 0.4453181527146646

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6366] Loss: 0.44529874055405455

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6391] Loss: 0.44527160758789974

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6416] Loss: 0.4453153810313298

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6441] Loss: 0.4455198904084016

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6466] Loss: 0.4454634077387497

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6491] Loss: 0.44546928384207163

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6516] Loss: 0.44544583861165143

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6541] Loss: 0.44538533248219003

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6566] Loss: 0.4453443712901434

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6591] Loss: 0.4452913422342914

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6616] Loss: 0.44526019810480955

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6641] Loss: 0.44540479312811254

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6666] Loss: 0.4455240868037095

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6691] Loss: 0.4454875507023497

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6716] Loss: 0.4454541621590999

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6741] Loss: 0.44548341000765845

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6766] Loss: 0.4454859423424806

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6791] Loss: 0.44548538621139705

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6816] Loss: 0.4454794287643128

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6841] Loss: 0.4453889323120223

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6866] Loss: 0.44533193558998535

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6891] Loss: 0.4453777663668896

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6916] Loss: 0.44528886668072176

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6941] Loss: 0.4452414883545859

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6966] Loss: 0.44517110789282427

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 6991] Loss: 0.445196127309907

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8813
Using max F1-Score threshold, the confusion matrix is:
 [[73 27]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7016] Loss: 0.44519332725981486

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7041] Loss: 0.44518457777328724

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7066] Loss: 0.44519633293954497

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7091] Loss: 0.4451830574847724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7116] Loss: 0.4452486738665729

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7141] Loss: 0.4451907976272366

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7166] Loss: 0.4451537541241903

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7191] Loss: 0.4451625038424885

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7216] Loss: 0.44522546293964893

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7241] Loss: 0.44531893803601497

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7266] Loss: 0.44536507170178663

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7291] Loss: 0.445392590685822

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7316] Loss: 0.44527389234744813

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7341] Loss: 0.44520022263632114

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7366] Loss: 0.44518983252375854

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7391] Loss: 0.4452614364323496

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7416] Loss: 0.4452563238862452

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7441] Loss: 0.44520927156477225

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7466] Loss: 0.44521174535520874

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7491] Loss: 0.4451592131635744

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7516] Loss: 0.4451293681761039

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7541] Loss: 0.4450900690744065

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7566] Loss: 0.4450127163271304

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7591] Loss: 0.4450165747238159

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7616] Loss: 0.4449511835020631

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7641] Loss: 0.44489255971523284

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7666] Loss: 0.4448999008263281

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7691] Loss: 0.44482697388182024

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7716] Loss: 0.44475901404217894

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7741] Loss: 0.44481425506318534

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7766] Loss: 0.44490267781937765

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7791] Loss: 0.44488537870197015

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7816] Loss: 0.44480902113512155

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7841] Loss: 0.4447887905214138

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7866] Loss: 0.4447863216876831

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7891] Loss: 0.4448322767021208

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7916] Loss: 0.4447902430960579

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7941] Loss: 0.4448784556319717

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7966] Loss: 0.4448707862744437

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 7991] Loss: 0.44489332084191774

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8806
Using max F1-Score threshold, the confusion matrix is:
 [[61 39]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8016] Loss: 0.44488994536047416

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8041] Loss: 0.4449164654702782

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8066] Loss: 0.444945339822215

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8091] Loss: 0.44496031425526306

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8116] Loss: 0.4449713159340902

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8141] Loss: 0.4449301914836364

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8166] Loss: 0.44489807311472085

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8191] Loss: 0.4449596691609099

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8216] Loss: 0.44506514295102023

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8241] Loss: 0.4450935354635114

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8266] Loss: 0.4450918954464538

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8291] Loss: 0.4451183020982267

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8316] Loss: 0.4451919827399934

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8341] Loss: 0.4451603635390559

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8366] Loss: 0.4450541235088701

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8391] Loss: 0.44511014239474483

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8416] Loss: 0.4451132676791401

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8441] Loss: 0.44511204947863964

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8466] Loss: 0.44514948099131946

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8491] Loss: 0.4451634917846743

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8516] Loss: 0.4451186947283925

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8541] Loss: 0.44520625864131413

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8566] Loss: 0.4451742102941503

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8591] Loss: 0.4452088865303256

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8616] Loss: 0.44518806710218317

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8641] Loss: 0.4452188041469715

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8666] Loss: 0.44514707280894267

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8691] Loss: 0.44517693279690157

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8716] Loss: 0.44522963353081846

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8741] Loss: 0.4453558844101469

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8766] Loss: 0.44531573323298124

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8791] Loss: 0.4452708495687365

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8816] Loss: 0.4452370498937049

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8841] Loss: 0.4453267921107031

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8866] Loss: 0.44528418206423936

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8891] Loss: 0.4453257146674914

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8916] Loss: 0.44537573168394623

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8941] Loss: 0.44533795660153663

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8966] Loss: 0.4452437271776243

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 8991] Loss: 0.44528802193334555

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8813
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9016] Loss: 0.4453644551260291

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9041] Loss: 0.44540615930062216

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9066] Loss: 0.4453787873091594

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9091] Loss: 0.4453853249271242

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9116] Loss: 0.44539619011012815

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9141] Loss: 0.44533726338104923

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9166] Loss: 0.44537828691916437

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9191] Loss: 0.44541690869335876

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9216] Loss: 0.4454969770235546

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9241] Loss: 0.445393451391022

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9266] Loss: 0.4454197987108131

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9291] Loss: 0.44544562898138684

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9316] Loss: 0.4454507002636453

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9341] Loss: 0.4454520582434684

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9366] Loss: 0.4455064063595542

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9391] Loss: 0.4454286834472502

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9416] Loss: 0.4453837032302076

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9441] Loss: 0.44539882462268

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9466] Loss: 0.44539613401147615

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9491] Loss: 0.4454153185049604

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9516] Loss: 0.44546275605324964

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9541] Loss: 0.4454873594880798

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9566] Loss: 0.44546506355688675

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9591] Loss: 0.4454818457248597

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9616] Loss: 0.4454488683097802

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9641] Loss: 0.4454758149495896

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9666] Loss: 0.44551315839100064

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9691] Loss: 0.4455001952198764

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9716] Loss: 0.44547756768599256

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9741] Loss: 0.4454542539178116

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9766] Loss: 0.4454542345425272

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9791] Loss: 0.44544001541160305

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9816] Loss: 0.4454430117244991

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9841] Loss: 0.4454112844576409

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9866] Loss: 0.44535845496847926

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9891] Loss: 0.44541145945699295

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9916] Loss: 0.44543241911161313

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9941] Loss: 0.4454340636728329

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9966] Loss: 0.4455009111795608

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 9991] Loss: 0.4454540207171623

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8808
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10016] Loss: 0.44546463801898584

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10041] Loss: 0.44553017756784746

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10066] Loss: 0.44552631034113915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10091] Loss: 0.4455485242718207

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10116] Loss: 0.445542001977911

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10141] Loss: 0.4454994708303505

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10166] Loss: 0.44558186272777384

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10191] Loss: 0.44555707083282303

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10216] Loss: 0.4455547071174022

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10241] Loss: 0.44552581690636817

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10266] Loss: 0.44547662679497263

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10291] Loss: 0.4454124773117278

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10316] Loss: 0.4453992343712078

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10341] Loss: 0.4453663928686111

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10366] Loss: 0.44536709617364756

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10391] Loss: 0.4453756908249565

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10416] Loss: 0.44537066468707776

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10441] Loss: 0.44539834023658864

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10466] Loss: 0.44543273038187153

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10491] Loss: 0.44533559586810817

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10516] Loss: 0.4452534495224351

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10541] Loss: 0.4451908042718525

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10566] Loss: 0.44515709421232075

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10591] Loss: 0.44539505538116875

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10616] Loss: 0.44536961821920984

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10641] Loss: 0.4452878724579009

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10666] Loss: 0.44528633371425835

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10691] Loss: 0.44526918132943527

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10716] Loss: 0.4453111759134927

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10741] Loss: 0.44528853188138773

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10766] Loss: 0.44522038738984987

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10791] Loss: 0.44518811531791647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10816] Loss: 0.4452215807735394

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10841] Loss: 0.4451126051803894

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10866] Loss: 0.4450664255318806

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10891] Loss: 0.4450304042985054

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10916] Loss: 0.44503917170495433

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10941] Loss: 0.44508638556408137

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10966] Loss: 0.4451261583122288

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 10991] Loss: 0.44512473226413835

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8793000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11016] Loss: 0.44512656115081617

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11041] Loss: 0.44514866298892963

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11066] Loss: 0.4451714659732435

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11091] Loss: 0.44513950261990454

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11116] Loss: 0.445125402985531

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11141] Loss: 0.4451070316108318

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11166] Loss: 0.4450851477668843

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11191] Loss: 0.44511962645171066

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11216] Loss: 0.44514693961673796

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11241] Loss: 0.44522203956277606

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11266] Loss: 0.445286886187801

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11291] Loss: 0.4453290553015598

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11316] Loss: 0.4453606707055124

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11341] Loss: 0.44535672883288313

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11366] Loss: 0.4452998389882233

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11391] Loss: 0.44527528835329294

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11416] Loss: 0.4452163166760155

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11441] Loss: 0.4452487632268884

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11466] Loss: 0.44534672195500263

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11491] Loss: 0.4454244493598269

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11516] Loss: 0.4454655110814254

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11541] Loss: 0.4455260910206763

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11566] Loss: 0.44547352088456516

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11591] Loss: 0.4454297018281305

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11616] Loss: 0.44547090301845904

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11641] Loss: 0.4454600742509193

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11666] Loss: 0.4455200578473833

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11691] Loss: 0.44556221352248476

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11716] Loss: 0.44567101768904743

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11741] Loss: 0.44562789414582593

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11766] Loss: 0.4456033859098709

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11791] Loss: 0.44566444632327773

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11816] Loss: 0.4457427472297624

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11841] Loss: 0.44567062731161833

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11866] Loss: 0.4456123559585344

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11891] Loss: 0.4456842542183509

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11916] Loss: 0.44567338215904084

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11941] Loss: 0.4456986244672884

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11966] Loss: 0.44565940334497195

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 11991] Loss: 0.44564960453442226

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8785000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12016] Loss: 0.4455875717400541

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12041] Loss: 0.44555885705752823

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12066] Loss: 0.44552471779125796

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12091] Loss: 0.4455539919944301

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12116] Loss: 0.44555361623646667

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12141] Loss: 0.44543153259724505

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12166] Loss: 0.44541616572623993

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12191] Loss: 0.44536112902580804

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12216] Loss: 0.44548433260833653

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12241] Loss: 0.445423501431995

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12266] Loss: 0.4454049102712222

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12291] Loss: 0.4455126725486633

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12316] Loss: 0.4455461211562484

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12341] Loss: 0.44562873159631

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12366] Loss: 0.44564721331975404

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12391] Loss: 0.4456485733844796

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12416] Loss: 0.4456104465488255

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12441] Loss: 0.4456123133123306

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12466] Loss: 0.445667238816835

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12491] Loss: 0.44562226869750504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12516] Loss: 0.4456383103166705

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12541] Loss: 0.44553966903699677

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12566] Loss: 0.44563962641792826

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12591] Loss: 0.4456161536364863

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12616] Loss: 0.44556552675291133

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12641] Loss: 0.4454836164558379

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12666] Loss: 0.4455622071449476

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12691] Loss: 0.44555147765087466

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12716] Loss: 0.4454814606537362

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12741] Loss: 0.4455497386188591

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12766] Loss: 0.4455390489110275

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12791] Loss: 0.44547852272516325

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12816] Loss: 0.44540701516179726

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12841] Loss: 0.44538215927019187

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12866] Loss: 0.4453631688874177

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12891] Loss: 0.4452688700115604

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12916] Loss: 0.4452082196149435

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12941] Loss: 0.4452839987619487

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12966] Loss: 0.44532821871166545

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 12991] Loss: 0.44530795164506193

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8796
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13016] Loss: 0.44531605651378586

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13041] Loss: 0.445314252003533

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13066] Loss: 0.44529456729726336

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13091] Loss: 0.4452947224797233

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13116] Loss: 0.44525926008612704

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13141] Loss: 0.44522623930841004

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13166] Loss: 0.44513353928685995

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13191] Loss: 0.4450725599821733

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13216] Loss: 0.4449947463734768

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13241] Loss: 0.44500240622211656

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13266] Loss: 0.44501148306664223

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13291] Loss: 0.44505793718547554

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13316] Loss: 0.44500125206586344

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13341] Loss: 0.4449966044847167

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13366] Loss: 0.44499823549748874

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13391] Loss: 0.44504422684639344

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13416] Loss: 0.4449911432955919

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13441] Loss: 0.4449119986281282

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13466] Loss: 0.4449242844866419

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13491] Loss: 0.4449027007894071

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13516] Loss: 0.4449346666035261

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13541] Loss: 0.44507052199499286

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13566] Loss: 0.44508216106820037

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13591] Loss: 0.44505387083250786

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13616] Loss: 0.44498788726270183

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13641] Loss: 0.4449618151144434

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13666] Loss: 0.4449538027056705

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13691] Loss: 0.4449302317131447

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13716] Loss: 0.4449617332676518

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13741] Loss: 0.44495964449578507

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13766] Loss: 0.4449325169477032

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13791] Loss: 0.445039967837671

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13816] Loss: 0.44503025598306384

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13841] Loss: 0.44502551374173427

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13866] Loss: 0.4450538446302412

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13891] Loss: 0.4449489843762274

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13916] Loss: 0.4449227046483861

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13941] Loss: 0.4449223631920058

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13966] Loss: 0.44489097521196014

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 13991] Loss: 0.4449071472904993

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8788
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14016] Loss: 0.44488781663160915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14041] Loss: 0.44492828883408597

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14066] Loss: 0.44501609178906815

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14091] Loss: 0.4450240409761895

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14116] Loss: 0.4450586328797053

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14141] Loss: 0.4450120021705923

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14166] Loss: 0.44504440123320776

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14191] Loss: 0.44506424666536776

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14216] Loss: 0.4451222779319837

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14241] Loss: 0.4450783254787036

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14266] Loss: 0.44506316733494766

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14291] Loss: 0.4450366021629254

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14316] Loss: 0.445076478111245

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14341] Loss: 0.4450323371888231

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14366] Loss: 0.4449868848301973

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14391] Loss: 0.44496658054641813

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14416] Loss: 0.44493949961635626

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14441] Loss: 0.4449980908283659

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14466] Loss: 0.4450015480916178

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14491] Loss: 0.4450533117140373

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14516] Loss: 0.4450247564891871

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14541] Loss: 0.44505686293532043

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14566] Loss: 0.44509666018478017

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14591] Loss: 0.44511829300983874

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14616] Loss: 0.44513789084784405

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14641] Loss: 0.4451687505752649

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14666] Loss: 0.44514110783219346

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14691] Loss: 0.44519166571624935

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14716] Loss: 0.4452294017913504

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14741] Loss: 0.4452364623558268

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14766] Loss: 0.44530944635935465

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14791] Loss: 0.4453516736056286

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14816] Loss: 0.4453802874665336

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14841] Loss: 0.4453207108288828

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14866] Loss: 0.4453643846182594

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14891] Loss: 0.4453296720848695

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14916] Loss: 0.44529153758997536

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14941] Loss: 0.44529611001911595

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14966] Loss: 0.44539768314859884

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 14991] Loss: 0.44537602586659186

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8796
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15016] Loss: 0.4454797113661941

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15041] Loss: 0.4455151467981172

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15066] Loss: 0.44552568371576123

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15091] Loss: 0.44546720434185716

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15116] Loss: 0.4454838028803127

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15141] Loss: 0.4455520569792593

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15166] Loss: 0.44547600481084376

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15191] Loss: 0.4455262379053978

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15216] Loss: 0.4455200066668528

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15241] Loss: 0.4455658542175096

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15266] Loss: 0.4455867674873835

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15291] Loss: 0.44557998200315513

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15316] Loss: 0.44560633615049244

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15341] Loss: 0.44569549806457487

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15366] Loss: 0.44565965344195924

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15391] Loss: 0.4457176575369047

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15416] Loss: 0.44566564749858967

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15441] Loss: 0.4456435446119425

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15466] Loss: 0.4456409161325934

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15491] Loss: 0.4455884709774762

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15516] Loss: 0.4455972426256666

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15541] Loss: 0.44567320901787166

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15566] Loss: 0.445632187952237

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15591] Loss: 0.4456354221639679

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15616] Loss: 0.4455795592201752

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15641] Loss: 0.44572973341996147

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15666] Loss: 0.44575876384270247

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15691] Loss: 0.44576530229071987

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15716] Loss: 0.4457537266034288

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15741] Loss: 0.445691895097691

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15766] Loss: 0.44572987796887936

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15791] Loss: 0.44575838089582825

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15816] Loss: 0.4458355199079938

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15841] Loss: 0.44581523276409063

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15866] Loss: 0.44587447719031215

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15891] Loss: 0.4458119300634027

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15916] Loss: 0.44586200869992143

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15941] Loss: 0.4458289444117482

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15966] Loss: 0.44592328177409446

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 15991] Loss: 0.44594204376841295

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8799
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16016] Loss: 0.44593048676809277

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16041] Loss: 0.4460068986733693

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16066] Loss: 0.44604079456725915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16091] Loss: 0.4460106654035024

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16116] Loss: 0.44601633971116245

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16141] Loss: 0.446092966456648

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16166] Loss: 0.4461269335720078

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16191] Loss: 0.4461245304673387

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16216] Loss: 0.44615987618097996

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16241] Loss: 0.4461915837620695

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16266] Loss: 0.44624597059795384

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16291] Loss: 0.44618152390452204

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16316] Loss: 0.4461963825458169

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16341] Loss: 0.4461279203928336

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16366] Loss: 0.44620784307759

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16391] Loss: 0.44621199221796987

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16416] Loss: 0.446171581708705

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16441] Loss: 0.4461398096238382

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16466] Loss: 0.4461769426660922

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16491] Loss: 0.4461219871316332

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16516] Loss: 0.44605079863556596

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16541] Loss: 0.4460787106844775

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16566] Loss: 0.4461458460678482

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16591] Loss: 0.4461478994175941

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16616] Loss: 0.44618085147251835

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16641] Loss: 0.44618757367352774

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16666] Loss: 0.44614695638342844

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16691] Loss: 0.44615331525037766

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16716] Loss: 0.4461376197825267

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16741] Loss: 0.4461042147994333

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16766] Loss: 0.4461544727947292

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16791] Loss: 0.4461316513008119

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16816] Loss: 0.4460957227051887

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16841] Loss: 0.4461528919236866

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16866] Loss: 0.44618500648065956

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16891] Loss: 0.4461700732947473

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16916] Loss: 0.44622937878172636

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16941] Loss: 0.44623302422090133

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16966] Loss: 0.446248885421117

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 16991] Loss: 0.44619775065935663

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8802
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17016] Loss: 0.4462235079046578

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17041] Loss: 0.4461495875065576

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17066] Loss: 0.4461118144953597

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17091] Loss: 0.4460784631841516

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17116] Loss: 0.44611175708214595

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17141] Loss: 0.44611296304273684

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17166] Loss: 0.446114205248582

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17191] Loss: 0.44613202688599163

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17216] Loss: 0.4460823822060364

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17241] Loss: 0.4459925268465627

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17266] Loss: 0.4460744538899985

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17291] Loss: 0.446078949387611

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17316] Loss: 0.44610270288919995

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17341] Loss: 0.4460686459331061

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17366] Loss: 0.44604598973239584

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17391] Loss: 0.44602193645692334

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17416] Loss: 0.44600137236069703

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17441] Loss: 0.44587631919961496

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17466] Loss: 0.44586043929008407

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17491] Loss: 0.4459173538843079

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17516] Loss: 0.4459449847882148

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17541] Loss: 0.4460101337460455

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17566] Loss: 0.4459994484468822

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17591] Loss: 0.44600009276854946

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17616] Loss: 0.4459503574424822

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17641] Loss: 0.44584940920133276

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17666] Loss: 0.44580406556423147

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17691] Loss: 0.44584931022763286

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17716] Loss: 0.44592984801923663

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17741] Loss: 0.4459639998159475

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17766] Loss: 0.44603079608772633

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17791] Loss: 0.4460241541311309

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17816] Loss: 0.4460498701023337

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17841] Loss: 0.4459894721912819

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17866] Loss: 0.4459662791410834

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17891] Loss: 0.44603862783528964

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17916] Loss: 0.44603228290373825

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17941] Loss: 0.4460246801712739

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17966] Loss: 0.4459899324910621

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 17991] Loss: 0.4460466650212684

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8806
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18016] Loss: 0.4460522461085703

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18041] Loss: 0.44604201590889514

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18066] Loss: 0.44606602596640443

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18091] Loss: 0.44603981602023746

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18116] Loss: 0.4460878071861692

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18141] Loss: 0.44611076757108337

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18166] Loss: 0.44606022728107575

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18191] Loss: 0.44609219858707483

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18216] Loss: 0.446077033874421

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18241] Loss: 0.44604417246863654

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18266] Loss: 0.44598376165034476

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18291] Loss: 0.44589347187010686

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18316] Loss: 0.44580393212727076

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18341] Loss: 0.44583071028517124

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18366] Loss: 0.44585696997720703

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18391] Loss: 0.445821408383299

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18416] Loss: 0.44580875650768076

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18441] Loss: 0.44581752378073103

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18466] Loss: 0.44590951072896384

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18491] Loss: 0.445884046926948

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18516] Loss: 0.44588004625800587

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18541] Loss: 0.44589870076457

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18566] Loss: 0.4458961777492449

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18591] Loss: 0.4458737341920848

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18616] Loss: 0.445873095928677

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18641] Loss: 0.4458277710020016

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18666] Loss: 0.44583338574517944

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18691] Loss: 0.44583611252059857

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18716] Loss: 0.4458222984560297

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18741] Loss: 0.4458188106114124

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18766] Loss: 0.44577561923257525

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18791] Loss: 0.4457712663909212

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18816] Loss: 0.4457324880430893

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18841] Loss: 0.4456529489003431

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18866] Loss: 0.4456114659777803

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18891] Loss: 0.44556282059069546

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18916] Loss: 0.4456134891315451

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18941] Loss: 0.4456359331011296

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18966] Loss: 0.44561877720054494

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 18991] Loss: 0.4456127158358672

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8814
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19016] Loss: 0.44566117522671816

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19041] Loss: 0.4456544259712097

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19066] Loss: 0.4457040670055393

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19091] Loss: 0.44572371674347594

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19116] Loss: 0.4456703784364047

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19141] Loss: 0.4456726492642612

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19166] Loss: 0.4456867659420417

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19191] Loss: 0.44569553157946723

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19216] Loss: 0.44568504254985936

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19241] Loss: 0.4457806509225503

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19266] Loss: 0.4458078273590496

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19291] Loss: 0.44585990724061214

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19316] Loss: 0.4458306690591058

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19341] Loss: 0.4457869769064846

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19366] Loss: 0.4458288763946645

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19391] Loss: 0.4458980775481437

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19416] Loss: 0.4458387899838508

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19441] Loss: 0.44583196837899375

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19466] Loss: 0.4457863549300787

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19491] Loss: 0.4457853933792017

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19516] Loss: 0.44581480799197676

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19541] Loss: 0.44579295100940364

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19566] Loss: 0.44581716648121705

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19591] Loss: 0.4457804943411904

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19616] Loss: 0.4458010467459492

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19641] Loss: 0.4457410398620371

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19666] Loss: 0.445719491343705

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19691] Loss: 0.44572139939932093

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19716] Loss: 0.4456784645078101

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19741] Loss: 0.4456705805019749

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19766] Loss: 0.44570090822577735

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19791] Loss: 0.4457223255948571

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19816] Loss: 0.4456953903470822

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19841] Loss: 0.4457106669580326

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19866] Loss: 0.4457024993429608

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19891] Loss: 0.4456733354369162

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19916] Loss: 0.44571407589201456

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19941] Loss: 0.44571124126117023

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19966] Loss: 0.44574961134378605

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 19991] Loss: 0.44578104101889066

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8811
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20016] Loss: 0.44569987178539083

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20041] Loss: 0.4457471554501287

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20066] Loss: 0.4458152781982915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20091] Loss: 0.44587216493488496

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20116] Loss: 0.44588123799326407

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20141] Loss: 0.4458511762256186

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20166] Loss: 0.44584428399352416

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20191] Loss: 0.44582062985708326

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20216] Loss: 0.44583788356836296

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20241] Loss: 0.44583894169895627

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20266] Loss: 0.4458234224367307

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20291] Loss: 0.44577837327360315

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20316] Loss: 0.4456887333298606

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20341] Loss: 0.44566823739204997

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20366] Loss: 0.44563401783647394

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20391] Loss: 0.44562595676434547

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20416] Loss: 0.4456193039075002

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20441] Loss: 0.445650724951373

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20466] Loss: 0.44560230800606576

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20491] Loss: 0.44560847218650473

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20516] Loss: 0.4455894187064305

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20541] Loss: 0.4456132363487694

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20566] Loss: 0.44561192528824495

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20591] Loss: 0.4455653253082254

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20616] Loss: 0.4456035634257415

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20641] Loss: 0.44561437539298826

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20666] Loss: 0.44558225047941563

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20691] Loss: 0.44564822034517054

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20716] Loss: 0.44564112402161926

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20741] Loss: 0.44559923188392386

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20766] Loss: 0.445619705087282

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20791] Loss: 0.44566252840052223

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20816] Loss: 0.4456409028069691

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20841] Loss: 0.4457199364409934

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20866] Loss: 0.4456462001974751

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20891] Loss: 0.4456206641202824

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20916] Loss: 0.44557615830409497

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20941] Loss: 0.4456186012541111

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20966] Loss: 0.44561888866081323

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 20991] Loss: 0.44564051054295317

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8821
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [ 3 97]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21016] Loss: 0.44564191906229783

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21041] Loss: 0.44563415818980484

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21066] Loss: 0.4456702787122669

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21091] Loss: 0.44569657975847177

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21116] Loss: 0.4457644258332998

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21141] Loss: 0.4457558576167837

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21166] Loss: 0.44577319415306194

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21191] Loss: 0.44576875242994646

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21216] Loss: 0.4457305851958382

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21241] Loss: 0.4457523613498515

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21266] Loss: 0.44574879337203926

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21291] Loss: 0.4457353062994342

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21316] Loss: 0.4457169265387752

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21341] Loss: 0.44570530280549614

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21366] Loss: 0.4458044161814448

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21391] Loss: 0.44576549202230886

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21416] Loss: 0.4457930436181164

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21441] Loss: 0.44581271572127673

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21466] Loss: 0.44582585075445974

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21491] Loss: 0.4458876080924062

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21516] Loss: 0.44587891756450876

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21541] Loss: 0.44591247306226

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21566] Loss: 0.44593150439951795

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21591] Loss: 0.4458982266895944

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21616] Loss: 0.4458350695478537

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21641] Loss: 0.445845324835092

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21666] Loss: 0.4457804101625995

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21691] Loss: 0.4457273163398043

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21716] Loss: 0.44566845530323956

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21741] Loss: 0.44563284357748134

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21766] Loss: 0.44562452914133066

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21791] Loss: 0.4456101571830816

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21816] Loss: 0.44560149059922227

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21841] Loss: 0.4455602534441479

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21866] Loss: 0.44552160992141426

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21891] Loss: 0.4456150720618721

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21916] Loss: 0.44559327498245377

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21941] Loss: 0.44558800449202696

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21966] Loss: 0.445542475040282

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 21991] Loss: 0.44548943962736415

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8812
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22016] Loss: 0.4455262904346898

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22041] Loss: 0.4454697392960409

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22066] Loss: 0.4454609666587699

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22091] Loss: 0.44552747016154803

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22116] Loss: 0.44556595251465025

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22141] Loss: 0.44556292811941667

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22166] Loss: 0.4455386186567398

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22191] Loss: 0.44552846007851427

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22216] Loss: 0.44555116391414995

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22241] Loss: 0.44554466077234517

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22266] Loss: 0.44553291058738004

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22291] Loss: 0.4455506453850033

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22316] Loss: 0.44552558727639724

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22341] Loss: 0.4455793356058623

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22366] Loss: 0.4455310535018072

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22391] Loss: 0.44550016906913825

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22416] Loss: 0.4454576286418511

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22441] Loss: 0.44543317256867915

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22466] Loss: 0.4454105771931775

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22491] Loss: 0.44539877479459

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22516] Loss: 0.4454167953093168

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22541] Loss: 0.44537691814030816

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22566] Loss: 0.44536527942438403

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22591] Loss: 0.4453126126980337

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22616] Loss: 0.44531628455378813

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22641] Loss: 0.4453343494371984

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22666] Loss: 0.44536408632184193

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22691] Loss: 0.4453396915114771

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22716] Loss: 0.4452985811949542

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22741] Loss: 0.44537619312735643

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22766] Loss: 0.44541384435605946

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22791] Loss: 0.44538222954153506

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22816] Loss: 0.44542952478418024

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22841] Loss: 0.4454468558488226

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22866] Loss: 0.44543083800215044

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22891] Loss: 0.4454121359379516

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22916] Loss: 0.4454710682748266

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22941] Loss: 0.4454742401401066

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22966] Loss: 0.44538860943403524

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 22991] Loss: 0.44545264810830343

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8801
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23016] Loss: 0.44549944683396225

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23041] Loss: 0.4455959045919679

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23066] Loss: 0.44556020954485115

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23091] Loss: 0.4455609722853101

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23116] Loss: 0.44557003508329796

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23141] Loss: 0.4455672119011864

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23166] Loss: 0.4455483032071735

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23191] Loss: 0.44563092175201136

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23216] Loss: 0.44566112644876177

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23241] Loss: 0.44564494575705027

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23266] Loss: 0.4455922775357753

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23291] Loss: 0.4455688327489341

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23316] Loss: 0.4455716965959566

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23341] Loss: 0.4456260429196332

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23366] Loss: 0.44561047392053466

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23391] Loss: 0.4455654137052037

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23416] Loss: 0.4455153743792949

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23441] Loss: 0.4455159204567593

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23466] Loss: 0.4455093631089134

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23491] Loss: 0.445511197008283

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23516] Loss: 0.44548424106431805

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23541] Loss: 0.445465857799312

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23566] Loss: 0.44545384592654114

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23591] Loss: 0.44547240735562066

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23616] Loss: 0.44546334957035516

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23641] Loss: 0.4454485966100067

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23666] Loss: 0.44547710090816545

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23691] Loss: 0.4455205679196224

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23716] Loss: 0.4455602098125155

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23741] Loss: 0.44557389602340486

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23766] Loss: 0.44560339105833635

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23791] Loss: 0.44564200810086857

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23816] Loss: 0.44570295703331664

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23841] Loss: 0.44569804300237337

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23866] Loss: 0.4457305344342603

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23891] Loss: 0.4456963502696045

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23916] Loss: 0.4456409157948934

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23941] Loss: 0.44567916216577025

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23966] Loss: 0.44570427406698676

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 23991] Loss: 0.4456763058834768

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8806
Using max F1-Score threshold, the confusion matrix is:
 [[61 39]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24016] Loss: 0.4456879483501388

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24041] Loss: 0.44578079712104945

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24066] Loss: 0.4458300818192574

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24091] Loss: 0.44584431475112346

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24116] Loss: 0.4459238169867684

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24141] Loss: 0.4459106504311333

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24166] Loss: 0.4458893271942541

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24191] Loss: 0.44590677684911406

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24216] Loss: 0.44590458548206463

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24241] Loss: 0.4459731659804751

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24266] Loss: 0.445991230287102

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24291] Loss: 0.44595018826533583

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24316] Loss: 0.4459383729704811

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24341] Loss: 0.4458972394822843

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24366] Loss: 0.44596114798534386

CUDA Memory Allocated: 9090220032
[Epoch 9, Batch 24391] Loss: 0.4459158163449468

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 8] Loss: 0.44585170815312336

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 33] Loss: 0.4458404096357469

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 58] Loss: 0.4458736562307426

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 83] Loss: 0.44590942176631104

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 108] Loss: 0.44587247320823364

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 133] Loss: 0.4458354302317524

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 158] Loss: 0.44581795339049535

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 183] Loss: 0.4458223445173244

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 208] Loss: 0.445856744895682

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 233] Loss: 0.44587354387843614

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 258] Loss: 0.44588408367125637

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 283] Loss: 0.4458491862162311

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 308] Loss: 0.4458125930968574

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 333] Loss: 0.44577715130196116

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 358] Loss: 0.44581719332475517

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 383] Loss: 0.44584863781282713

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 408] Loss: 0.44587513792532985

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 433] Loss: 0.4458776833292441

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 458] Loss: 0.4458682011342073

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 483] Loss: 0.44583001457309585

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 508] Loss: 0.4458264613559373

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 533] Loss: 0.4458696186755508

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 558] Loss: 0.44589992202174356

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 583] Loss: 0.44593563705443745

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8803000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[61 39]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 608] Loss: 0.44596150485681135

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 633] Loss: 0.44596343424901885

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 658] Loss: 0.44600218777748707

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 683] Loss: 0.4460205537300322

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 708] Loss: 0.44601554856334824

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 733] Loss: 0.44606043169155074

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 758] Loss: 0.44602848112822824

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 783] Loss: 0.4460024567844217

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 808] Loss: 0.4460320880874883

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 833] Loss: 0.44603624718340434

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 858] Loss: 0.4460301674620575

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 883] Loss: 0.4459902006281894

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 908] Loss: 0.4459602728403747

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 933] Loss: 0.44599410697022596

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 958] Loss: 0.44598031322870685

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 983] Loss: 0.445995191823167

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1008] Loss: 0.44600907604798173

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1033] Loss: 0.44604128370086366

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1058] Loss: 0.4459551922549355

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1083] Loss: 0.4459078196231907

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1108] Loss: 0.4458913891003163

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1133] Loss: 0.4459045376750306

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1158] Loss: 0.44591192193199697

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1183] Loss: 0.44587689843900824

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1208] Loss: 0.44587241149477774

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1233] Loss: 0.4458650633962957

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1258] Loss: 0.44585203280644053

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1283] Loss: 0.44588750251592274

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1308] Loss: 0.4458784616251522

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1333] Loss: 0.44586455343397857

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1358] Loss: 0.44590338803172597

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1383] Loss: 0.4459673537007077

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1408] Loss: 0.4460007447217035

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1433] Loss: 0.4459852930866424

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1458] Loss: 0.4460397699465008

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1483] Loss: 0.44600232008653085

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1508] Loss: 0.44604442225823954

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1533] Loss: 0.44603684054845294

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1558] Loss: 0.4460277454082036

CUDA Memory Allocated: 9090220032
[Epoch 10, Batch 1583] Loss: 0.44604701558829035

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

