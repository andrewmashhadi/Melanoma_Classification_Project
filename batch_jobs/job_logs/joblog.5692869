Job 5692869 started on:    g6
Job 5692869 started on:    Sat Jan 7 20:32:42 PST 2023
 
Device: cuda:0
Number of devices: 2
Loading the pre-trained CNN weights.
CUDA Memory Allocated: 20931072
CUDA Memory Allocated: 8802686464
[Epoch 4, Batch 2205] Loss: 0.2046716958284378

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8318
Using max F1-Score threshold, the confusion matrix is:
 [[59 41]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2230] Loss: 0.4536540260395178

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2255] Loss: 0.44730729949386683

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2280] Loss: 0.47089755248376414

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2305] Loss: 0.45071802120471355

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2330] Loss: 0.46527630612549803

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2355] Loss: 0.4727558460185267

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2380] Loss: 0.469169358394786

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2405] Loss: 0.45970840854987277

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2430] Loss: 0.4667178880241988

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2455] Loss: 0.4700134823922498

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2480] Loss: 0.4688130312167324

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2505] Loss: 0.47323388767821645

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2530] Loss: 0.46902581712836683

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2555] Loss: 0.46873232204880977

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2580] Loss: 0.4709901666278614

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2605] Loss: 0.4683067557864133

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2630] Loss: 0.4648147913290651

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2655] Loss: 0.46596540710961076

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2680] Loss: 0.46986102970598753

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2705] Loss: 0.47004097612749435

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2730] Loss: 0.46984715727529713

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2755] Loss: 0.46947771735732763

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2780] Loss: 0.47447309871010174

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2805] Loss: 0.47449339956305486

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2830] Loss: 0.4788658052546005

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2855] Loss: 0.480939013085195

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2880] Loss: 0.48067151206771475

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2905] Loss: 0.47752755848470324

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2930] Loss: 0.4765296378647575

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2955] Loss: 0.4764017059595464

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 2980] Loss: 0.47959659988367837

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3005] Loss: 0.4820463972377792

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3030] Loss: 0.4794219473679043

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3055] Loss: 0.4807027729466715

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3080] Loss: 0.4787599443879029

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3105] Loss: 0.47620196605347237

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3130] Loss: 0.4772622116014651

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3155] Loss: 0.47953528877578827

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3180] Loss: 0.4814563228664767

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3205] Loss: 0.481711613086911

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.824
Using max F1-Score threshold, the confusion matrix is:
 [[59 41]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3230] Loss: 0.48166419999568666

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3255] Loss: 0.4807739285247083

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3280] Loss: 0.4788810552052849

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3305] Loss: 0.47621257241805176

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3330] Loss: 0.4766830326244897

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3355] Loss: 0.4748816087964977

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3380] Loss: 0.47377490803764083

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3405] Loss: 0.47234334302236397

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3430] Loss: 0.4719691330652082

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3455] Loss: 0.47383074768387873

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3480] Loss: 0.4728244061897097

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3505] Loss: 0.4739022267528514

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3530] Loss: 0.4733186181210442

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3555] Loss: 0.47265311999923426

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3580] Loss: 0.4735777248170898

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3605] Loss: 0.47495179780646574

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3630] Loss: 0.47570463077284053

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3655] Loss: 0.4744725503363768

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3680] Loss: 0.4738401036651497

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3705] Loss: 0.47383808103985064

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3730] Loss: 0.4722124326395586

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3755] Loss: 0.47084154455359906

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3780] Loss: 0.4733023304494599

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3805] Loss: 0.4725475058641324

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3830] Loss: 0.4724457277383697

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3855] Loss: 0.47269563613485416

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3880] Loss: 0.47044235611165514

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3905] Loss: 0.4690335645476714

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3930] Loss: 0.4704142264419625

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3955] Loss: 0.4702470023972198

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 3980] Loss: 0.47077971611797037

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4005] Loss: 0.4714050602875257

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4030] Loss: 0.4716075694061987

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4055] Loss: 0.4714221679155228

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4080] Loss: 0.47106107596311964

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4105] Loss: 0.47147182232432305

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4130] Loss: 0.47030293020329833

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4155] Loss: 0.47125231787688393

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4180] Loss: 0.4704370707328156

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4205] Loss: 0.47013628733870777

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8321999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[59 41]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4230] Loss: 0.471108846600845

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4255] Loss: 0.4704061888879404

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4280] Loss: 0.4704764496009287

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4305] Loss: 0.4698496859960403

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4330] Loss: 0.47045734231224456

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4355] Loss: 0.4696548864962416

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4380] Loss: 0.4701035993930418

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4405] Loss: 0.47125148455333515

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4430] Loss: 0.4718450874572173

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4455] Loss: 0.47225725416115577

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4480] Loss: 0.47156543690901126

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4505] Loss: 0.47174089369985367

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4530] Loss: 0.47112276824951965

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4555] Loss: 0.4714071694167306

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4580] Loss: 0.4708693536180338

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4605] Loss: 0.4710717530170923

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4630] Loss: 0.4711322144222095

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4655] Loss: 0.4705621003960223

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4680] Loss: 0.471539210653766

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4705] Loss: 0.4719556464997233

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4730] Loss: 0.4730240563837692

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4755] Loss: 0.4725291750717635

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4780] Loss: 0.4732027747943095

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4805] Loss: 0.4719337803261159

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4830] Loss: 0.47322364284756957

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4855] Loss: 0.4732479039995581

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4880] Loss: 0.4733024206512255

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4905] Loss: 0.4729912471031699

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4930] Loss: 0.4725708931360615

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4955] Loss: 0.47194934169914515

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 4980] Loss: 0.4720335741116738

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5005] Loss: 0.4714146421245382

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5030] Loss: 0.470926626346167

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5055] Loss: 0.47052503246663746

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5080] Loss: 0.46974823802258814

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5105] Loss: 0.4689520483695918

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5130] Loss: 0.4694210912584138

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5155] Loss: 0.4701315990555432

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5180] Loss: 0.47031104636894316

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5205] Loss: 0.4701765537564852

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8353999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5230] Loss: 0.4708782894301714

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5255] Loss: 0.47094562912243226

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5280] Loss: 0.4706923875446651

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5305] Loss: 0.470447696520749

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5330] Loss: 0.47140677385413526

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5355] Loss: 0.47155975922351034

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5380] Loss: 0.4716722641295052

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5405] Loss: 0.4719801083607474

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5430] Loss: 0.47133063842061507

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5455] Loss: 0.47036190990327653

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5480] Loss: 0.4708274823553196

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5505] Loss: 0.4718301259680919

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5530] Loss: 0.47220944411945104

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5555] Loss: 0.47192859400304993

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5580] Loss: 0.47129282413902407

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5605] Loss: 0.47151086474605886

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5630] Loss: 0.47122524786246883

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5655] Loss: 0.471391335150248

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5680] Loss: 0.4711772630278394

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5705] Loss: 0.47145950563690364

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5730] Loss: 0.47158021495323066

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5755] Loss: 0.4714810709479249

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5780] Loss: 0.47141924960240805

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5805] Loss: 0.47137066866075933

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5830] Loss: 0.4716830725236593

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5855] Loss: 0.47175329870418614

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5880] Loss: 0.4716652100302798

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5905] Loss: 0.4720974995044277

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5930] Loss: 0.472090552383019

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5955] Loss: 0.47208145967185877

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 5980] Loss: 0.4717435208706667

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6005] Loss: 0.4718262863788196

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6030] Loss: 0.47168669739852026

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6055] Loss: 0.4715379654695634

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6080] Loss: 0.47158990844736265

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6105] Loss: 0.47068871817508817

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6130] Loss: 0.4707268017538222

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6155] Loss: 0.4716936782388084

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6180] Loss: 0.4712976727187746

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6205] Loss: 0.47152681449710787

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8332999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6230] Loss: 0.47171125496458677

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6255] Loss: 0.47213693178906924

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6280] Loss: 0.4714608023859838

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6305] Loss: 0.47189423845618983

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6330] Loss: 0.4724698162024143

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6355] Loss: 0.4732630709928831

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6380] Loss: 0.4730613769368372

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6405] Loss: 0.47269539284136103

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6430] Loss: 0.4723934925501127

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6455] Loss: 0.47175236979214213

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6480] Loss: 0.4716715089871371

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6505] Loss: 0.4721203104412485

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6530] Loss: 0.47189138869363584

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6555] Loss: 0.471612041751901

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6580] Loss: 0.4715483607056038

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6605] Loss: 0.47098751865256255

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6630] Loss: 0.4709385456315335

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6655] Loss: 0.4709326984949613

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6680] Loss: 0.4710947380299656

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6705] Loss: 0.4708924595584401

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6730] Loss: 0.470296221250241

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6755] Loss: 0.4709162242330776

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6780] Loss: 0.471195710221325

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6805] Loss: 0.4709758907046442

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6830] Loss: 0.47144785554257373

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6855] Loss: 0.4717090400210172

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6880] Loss: 0.47123616744849395

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6905] Loss: 0.4710642979297073

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6930] Loss: 0.47092749172261195

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6955] Loss: 0.4703442685708319

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 6980] Loss: 0.470248344176101

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7005] Loss: 0.4700593424616065

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7030] Loss: 0.4698743818225891

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7055] Loss: 0.4694203269757965

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7080] Loss: 0.469614905484366

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7105] Loss: 0.4693536010008914

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7130] Loss: 0.46876277767577057

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7155] Loss: 0.4683978148651223

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7180] Loss: 0.46800308607457286

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7205] Loss: 0.4680446895538503

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8324
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7230] Loss: 0.4682353452834572

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7255] Loss: 0.46815437960531175

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7280] Loss: 0.468201370019953

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7305] Loss: 0.46845526849367913

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7330] Loss: 0.46881886050969923

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7355] Loss: 0.46850128421190007

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7380] Loss: 0.46821116584344513

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7405] Loss: 0.4678458468983166

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7430] Loss: 0.4679952966590357

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7455] Loss: 0.4685759380295904

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7480] Loss: 0.4682812520050055

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7505] Loss: 0.46828913392484683

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7530] Loss: 0.46826118637027425

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7555] Loss: 0.46845205051020705

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7580] Loss: 0.46875004096814554

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7605] Loss: 0.46845580788887586

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7630] Loss: 0.4681808415191352

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7655] Loss: 0.46748076579436987

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7680] Loss: 0.46723658992236083

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7705] Loss: 0.4672606135787091

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7730] Loss: 0.4674952093055428

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7755] Loss: 0.4674241933240142

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7780] Loss: 0.46702671023600145

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7805] Loss: 0.4674664517607519

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7830] Loss: 0.4674559443880507

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7855] Loss: 0.4670119162031221

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7880] Loss: 0.4670900971253965

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7905] Loss: 0.46681083410970475

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7930] Loss: 0.46691669185538204

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7955] Loss: 0.4670601166037244

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 7980] Loss: 0.4669514136321822

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8005] Loss: 0.4667167296471616

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8030] Loss: 0.4664577243157777

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8055] Loss: 0.4668618056246983

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8080] Loss: 0.46716550948640995

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8105] Loss: 0.46730722964013244

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8130] Loss: 0.4670867917834807

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8155] Loss: 0.46681028438838135

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8180] Loss: 0.4668814675029058

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8205] Loss: 0.46712904767479535

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8308000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8230] Loss: 0.46749088963709456

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8255] Loss: 0.46735673972856917

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8280] Loss: 0.4670810271342671

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8305] Loss: 0.4670711898981763

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8330] Loss: 0.4668856800281161

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8355] Loss: 0.46710641977155115

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8380] Loss: 0.46696411386956194

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8405] Loss: 0.46748662739361346

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8430] Loss: 0.46718878074529097

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8455] Loss: 0.46734603096757377

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8480] Loss: 0.4672195875837359

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8505] Loss: 0.46712182068195474

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8530] Loss: 0.46717209911513913

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8555] Loss: 0.4671712770636927

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8580] Loss: 0.466889547750265

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8605] Loss: 0.4673257262589009

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8630] Loss: 0.46691610010725165

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8655] Loss: 0.46720958629819687

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8680] Loss: 0.4673052116494495

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8705] Loss: 0.4673599197857748

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8730] Loss: 0.467090335870096

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8755] Loss: 0.46669584530850816

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8780] Loss: 0.4667126201416101

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8805] Loss: 0.46674816190819457

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8830] Loss: 0.4665196936953124

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8855] Loss: 0.4664885184543193

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8880] Loss: 0.4664927798101802

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8905] Loss: 0.46649712028220647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8930] Loss: 0.46648743540855026

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8955] Loss: 0.4661874650315238

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 8980] Loss: 0.46654237961174466

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9005] Loss: 0.4660225480109116

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9030] Loss: 0.4658676319925615

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9055] Loss: 0.46567241290108147

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9080] Loss: 0.4658109017562743

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9105] Loss: 0.46558954874467906

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9130] Loss: 0.46597116132980304

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9155] Loss: 0.46598265219681845

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9180] Loss: 0.46595279153472735

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9205] Loss: 0.465667519754592

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8289
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9230] Loss: 0.46590514364261304

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9255] Loss: 0.465489553764976

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9280] Loss: 0.46568628712917887

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9305] Loss: 0.46591228642615695

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9330] Loss: 0.46653271807603897

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9355] Loss: 0.4662823966360354

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9380] Loss: 0.46595280955274615

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9405] Loss: 0.46584541336583474

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9430] Loss: 0.46571251942752684

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9455] Loss: 0.4656104242002458

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9480] Loss: 0.4656555567696023

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9505] Loss: 0.46565372363338037

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9530] Loss: 0.4662476938297713

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9555] Loss: 0.4662353831214506

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9580] Loss: 0.4662703615153681

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9605] Loss: 0.46625088544610527

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9630] Loss: 0.4662394243912807

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9655] Loss: 0.46616714982856616

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9680] Loss: 0.4666174684719463

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9705] Loss: 0.4664115629814105

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9730] Loss: 0.4666049220633141

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9755] Loss: 0.46634104855258945

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9780] Loss: 0.4663415024132756

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9805] Loss: 0.46660455568023235

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9830] Loss: 0.4665407221334447

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9855] Loss: 0.4661682068706611

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9880] Loss: 0.46599280322431635

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9905] Loss: 0.4665243267062933

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9930] Loss: 0.4664120769093005

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9955] Loss: 0.46651801864703446

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 9980] Loss: 0.46622492039744806

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10005] Loss: 0.4665733964099225

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10030] Loss: 0.466314803596149

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10055] Loss: 0.4666659866250058

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10080] Loss: 0.46712133627164487

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10105] Loss: 0.46681667929554144

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10130] Loss: 0.466946103219521

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10155] Loss: 0.46668629276475665

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10180] Loss: 0.4666203266551948

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10205] Loss: 0.4666126107618002

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8422999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[73 27]
 [15 85]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10230] Loss: 0.46648943018369654

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10255] Loss: 0.4661539397539633

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10280] Loss: 0.4659257311265087

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10305] Loss: 0.4660514649300351

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10330] Loss: 0.4663655574078443

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10355] Loss: 0.4667404725399943

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10380] Loss: 0.4664154950358017

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10405] Loss: 0.466329838366948

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10430] Loss: 0.46629827919737893

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10455] Loss: 0.4662259048048044

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10480] Loss: 0.4660928460747749

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10505] Loss: 0.4659408609649942

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10530] Loss: 0.4661326788080829

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10555] Loss: 0.46614561281757483

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10580] Loss: 0.46590790292848555

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10605] Loss: 0.4658509438251927

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10630] Loss: 0.4657442854724448

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10655] Loss: 0.46626013993389076

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10680] Loss: 0.4662936824811653

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10705] Loss: 0.4663960257666281

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10730] Loss: 0.4663327747764542

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10755] Loss: 0.46644294176391415

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10780] Loss: 0.4662647764513412

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10805] Loss: 0.4661859096297638

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10830] Loss: 0.4659772633134182

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10855] Loss: 0.4659797734605802

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10880] Loss: 0.46649364614429845

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10905] Loss: 0.4666348238429702

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10930] Loss: 0.4664940676822022

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10955] Loss: 0.46662469385693056

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 10980] Loss: 0.46691706252399806

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11005] Loss: 0.4671101194546397

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11030] Loss: 0.4670957372585679

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11055] Loss: 0.46708688047761776

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11080] Loss: 0.467058115631028

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11105] Loss: 0.4668319824691278

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11130] Loss: 0.4668786059186504

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11155] Loss: 0.46699545523870717

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11180] Loss: 0.4671891183771256

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11205] Loss: 0.46730828348105613

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8433999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[70 30]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11230] Loss: 0.4673691047908589

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11255] Loss: 0.4669927641502017

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11280] Loss: 0.46700638837832426

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11305] Loss: 0.4670467954873957

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11330] Loss: 0.46693553680171546

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11355] Loss: 0.4670657818712992

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11380] Loss: 0.4671204334022209

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11405] Loss: 0.4671067259155085

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11430] Loss: 0.46707081621011676

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11455] Loss: 0.46706321871780165

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11480] Loss: 0.46687583770878444

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11505] Loss: 0.4669487444178646

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11530] Loss: 0.46705492784584923

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11555] Loss: 0.4669692432929164

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11580] Loss: 0.4668036600266529

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11605] Loss: 0.46698159136554906

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11630] Loss: 0.4666097380642584

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11655] Loss: 0.46658521863974733

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11680] Loss: 0.4666638963737078

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11705] Loss: 0.466743072111396

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11730] Loss: 0.46670790823126057

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11755] Loss: 0.4668624080620443

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11780] Loss: 0.4666998763523962

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11805] Loss: 0.46675770031264013

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11830] Loss: 0.46666921034850817

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11855] Loss: 0.4664920050289539

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11880] Loss: 0.46680477228644757

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11905] Loss: 0.4667368345916864

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11930] Loss: 0.46675555327316964

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11955] Loss: 0.4668803414779359

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 11980] Loss: 0.4669674272073963

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12005] Loss: 0.46710134468176007

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12030] Loss: 0.4670798368439224

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12055] Loss: 0.46703157415847046

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12080] Loss: 0.46719325493863506

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12105] Loss: 0.46709640911692724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12130] Loss: 0.4675393640785229

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12155] Loss: 0.46753389393283146

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12180] Loss: 0.46782504097049205

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12205] Loss: 0.46830975124049057

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8173
Using max F1-Score threshold, the confusion matrix is:
 [[51 49]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12230] Loss: 0.46825007536316077

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12255] Loss: 0.4683433046380808

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12280] Loss: 0.4684530134274358

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12305] Loss: 0.46849327715981004

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12330] Loss: 0.4685170393679589

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12355] Loss: 0.4686961443726872

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12380] Loss: 0.46865964399481563

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12405] Loss: 0.46838183347188733

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12430] Loss: 0.46832808973451645

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12455] Loss: 0.46829699302505934

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12480] Loss: 0.46827632944168845

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12505] Loss: 0.4680498731676545

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12530] Loss: 0.46837382942799616

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12555] Loss: 0.46822736477158133

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12580] Loss: 0.4682841053221421

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12605] Loss: 0.46820535711011435

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12630] Loss: 0.46854012068282436

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12655] Loss: 0.4686581227677457

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12680] Loss: 0.46855074616146225

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12705] Loss: 0.46853654032454084

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12730] Loss: 0.46869157428254926

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12755] Loss: 0.4686517457405986

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12780] Loss: 0.46861095481049186

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12805] Loss: 0.4686696264706921

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12830] Loss: 0.46843114117699985

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12855] Loss: 0.46860927102454064

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12880] Loss: 0.4686959956340986

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12905] Loss: 0.4686036785169301

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12930] Loss: 0.46834162009819863

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12955] Loss: 0.4685161467452746

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 12980] Loss: 0.46860829854498837

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13005] Loss: 0.4692486533542472

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13030] Loss: 0.46920164715159396

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13055] Loss: 0.4690710823550723

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13080] Loss: 0.46911597503749936

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13105] Loss: 0.46940764148940284

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13130] Loss: 0.4694178840617693

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13155] Loss: 0.4694070275323558

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13180] Loss: 0.4698032047752286

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13205] Loss: 0.4697407959578509

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8263
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13230] Loss: 0.4699872716279481

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13255] Loss: 0.4698423869110952

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13280] Loss: 0.46989968991490283

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13305] Loss: 0.4697218928407247

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13330] Loss: 0.46986041911436555

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13355] Loss: 0.47000795593678163

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13380] Loss: 0.46998825410258294

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13405] Loss: 0.4699128823727835

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13430] Loss: 0.46993518593352246

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13455] Loss: 0.47020943721675384

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13480] Loss: 0.47039771220590965

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13505] Loss: 0.47047146381631477

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13530] Loss: 0.47041928114965836

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13555] Loss: 0.47059567388875373

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13580] Loss: 0.4705071981400959

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13605] Loss: 0.4706081640059938

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13630] Loss: 0.4707314014603049

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13655] Loss: 0.4706345898984208

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13680] Loss: 0.4706576118072376

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13705] Loss: 0.4705989142024235

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13730] Loss: 0.47056247957655845

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13755] Loss: 0.47052122570903887

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13780] Loss: 0.470746423596672

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13805] Loss: 0.47092952084416984

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13830] Loss: 0.4708520395675815

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13855] Loss: 0.47093807144387734

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13880] Loss: 0.4707332095386522

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13905] Loss: 0.4710330514243811

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13930] Loss: 0.47125444845675296

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13955] Loss: 0.47109522840905144

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 13980] Loss: 0.47123376748387946

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14005] Loss: 0.4711413071987619

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14030] Loss: 0.4711681984827419

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14055] Loss: 0.4712694420519081

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14080] Loss: 0.4711551348358498

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14105] Loss: 0.4709793484667481

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14130] Loss: 0.47089205759432357

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14155] Loss: 0.4710351129819704

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14180] Loss: 0.4709241931907131

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14205] Loss: 0.47089811687707483

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8348000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[71 29]
 [15 85]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14230] Loss: 0.47069121824300825

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14255] Loss: 0.4708557279741712

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14280] Loss: 0.4707270678309844

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14305] Loss: 0.47082680879603606

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14330] Loss: 0.4710553022015194

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14355] Loss: 0.47110337064310304

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14380] Loss: 0.4714202498689749

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14405] Loss: 0.4714877345968603

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14430] Loss: 0.4713533569539279

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14455] Loss: 0.4713627092622974

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14480] Loss: 0.4715439844812801

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14505] Loss: 0.47153296912631537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14530] Loss: 0.4714516773230574

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14555] Loss: 0.47159740199967487

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14580] Loss: 0.4717013516262265

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14605] Loss: 0.471442390651138

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14630] Loss: 0.47168216687436315

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14655] Loss: 0.47185722326780694

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14680] Loss: 0.4719567244440083

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14705] Loss: 0.4718672064764077

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14730] Loss: 0.4721233969771113

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14755] Loss: 0.4721669982470238

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14780] Loss: 0.4722102681529156

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14805] Loss: 0.47224877308085933

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14830] Loss: 0.4722414717108304

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14855] Loss: 0.472072423949959

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14880] Loss: 0.47225230919921923

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14905] Loss: 0.4721947000525864

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14930] Loss: 0.4721542560322286

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14955] Loss: 0.4721187092521599

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 14980] Loss: 0.4720594634403432

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15005] Loss: 0.47195739652555524

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15030] Loss: 0.471945186611628

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15055] Loss: 0.4720999367358865

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15080] Loss: 0.4720604020694827

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15105] Loss: 0.4719844464356747

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15130] Loss: 0.4720458467641556

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15155] Loss: 0.4718109264429916

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15180] Loss: 0.47189270871770067

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15205] Loss: 0.4717455936589923

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8376
Using max F1-Score threshold, the confusion matrix is:
 [[79 21]
 [18 82]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15230] Loss: 0.4720391361883664

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15255] Loss: 0.4721127292421764

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15280] Loss: 0.47219693105062144

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15305] Loss: 0.4720713781540803

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15330] Loss: 0.4720112446702094

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15355] Loss: 0.47192206253356334

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15380] Loss: 0.47208109866156517

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15405] Loss: 0.47200356712444186

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15430] Loss: 0.4723211892106064

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15455] Loss: 0.47228108191684604

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15480] Loss: 0.4722171747414707

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15505] Loss: 0.47226760580922333

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15530] Loss: 0.47222269267309525

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15555] Loss: 0.47246837617766524

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15580] Loss: 0.4724957713603575

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15605] Loss: 0.47248600868127516

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15630] Loss: 0.4722825997816636

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15655] Loss: 0.47237968871677516

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15680] Loss: 0.472307609296748

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15705] Loss: 0.47223337603660237

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15730] Loss: 0.47222436992563094

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15755] Loss: 0.47217287626080356

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15780] Loss: 0.4722617986856515

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15805] Loss: 0.4721266712048982

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15830] Loss: 0.4719436565123178

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15855] Loss: 0.4718974044142737

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15880] Loss: 0.4719446093906627

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15905] Loss: 0.47177372158944614

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15930] Loss: 0.47181726660108286

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15955] Loss: 0.47192921155674783

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 15980] Loss: 0.47188518389004297

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16005] Loss: 0.4719334294633914

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16030] Loss: 0.4721492498717813

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16055] Loss: 0.4720698762113532

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16080] Loss: 0.4719928158925023

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16105] Loss: 0.4719681900106362

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16130] Loss: 0.4720387433868361

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16155] Loss: 0.471967803083083

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16180] Loss: 0.471945843658675

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16205] Loss: 0.4719991211000287

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8291000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [10 90]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16230] Loss: 0.471828949505974

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16255] Loss: 0.4718861883381172

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16280] Loss: 0.4719452032924988

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16305] Loss: 0.47186899904282426

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16330] Loss: 0.4721002029059881

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16355] Loss: 0.47202635861766856

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16380] Loss: 0.47208095146550716

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16405] Loss: 0.47232365466388826

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16430] Loss: 0.4722369657331861

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16455] Loss: 0.4720174270276793

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16480] Loss: 0.47224374758938165

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16505] Loss: 0.47221982041860316

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16530] Loss: 0.47229650733844497

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16555] Loss: 0.4721616061501562

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16580] Loss: 0.47196478688567006

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16605] Loss: 0.47212487522999774

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16630] Loss: 0.47216137218871784

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16655] Loss: 0.47211941486529624

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16680] Loss: 0.4719958131660407

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16705] Loss: 0.4719640213137359

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16730] Loss: 0.47195310937657464

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16755] Loss: 0.47230108687311717

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16780] Loss: 0.4722877321718823

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16805] Loss: 0.4722436303157393

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16830] Loss: 0.47223448359330944

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16855] Loss: 0.47218514289296304

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16880] Loss: 0.47215616313383213

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16905] Loss: 0.4722896032436996

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16930] Loss: 0.4724826057414085

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16955] Loss: 0.47252405594821467

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 16980] Loss: 0.4726121632764736

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17005] Loss: 0.4726429538226574

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17030] Loss: 0.4723880548610817

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17055] Loss: 0.47232181163839976

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17080] Loss: 0.4722452839238218

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17105] Loss: 0.4722916347586365

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17130] Loss: 0.4722188910822325

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17155] Loss: 0.47209701554827443

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17180] Loss: 0.4721623130089705

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17205] Loss: 0.4724085868132811

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8437
Using max F1-Score threshold, the confusion matrix is:
 [[69 31]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17230] Loss: 0.47235194440463996

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17255] Loss: 0.47230173423269994

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17280] Loss: 0.4723616004595323

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17305] Loss: 0.4723810307013273

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17330] Loss: 0.4722844715815461

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17355] Loss: 0.47224913222815945

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17380] Loss: 0.4721444882659912

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17405] Loss: 0.471996893418851

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17430] Loss: 0.47220390553099423

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17455] Loss: 0.4721368178797301

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17480] Loss: 0.47212420015394174

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17505] Loss: 0.4721123752907979

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17530] Loss: 0.47218722758823684

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17555] Loss: 0.47198109815114253

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17580] Loss: 0.4718964434103821

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17605] Loss: 0.471784902842128

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17630] Loss: 0.47171799002055154

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17655] Loss: 0.4718488004774918

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17680] Loss: 0.4718489792905883

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17705] Loss: 0.47177860144717787

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17730] Loss: 0.47184080943972945

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17755] Loss: 0.47194826730210354

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17780] Loss: 0.47197059281617615

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17805] Loss: 0.4719017102205719

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17830] Loss: 0.47181660597246344

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17855] Loss: 0.4716797709224862

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17880] Loss: 0.47168014054850854

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17905] Loss: 0.47169662272272544

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17930] Loss: 0.4718630200938436

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17955] Loss: 0.47203247884289495

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 17980] Loss: 0.47191205847775564

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18005] Loss: 0.47181541118215614

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18030] Loss: 0.4717854720149714

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18055] Loss: 0.47183015924512317

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18080] Loss: 0.47192387505565625

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18105] Loss: 0.47196905042536397

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18130] Loss: 0.4719555626998645

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18155] Loss: 0.47185181418430167

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18180] Loss: 0.4717143876717086

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18205] Loss: 0.47172404058290646

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8228
Using max F1-Score threshold, the confusion matrix is:
 [[53 47]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18230] Loss: 0.47166198049146024

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18255] Loss: 0.4716807817425791

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18280] Loss: 0.4716949043900904

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18305] Loss: 0.4716948054558059

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18330] Loss: 0.4717797723701694

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18355] Loss: 0.47172791374123385

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18380] Loss: 0.47182171440001164

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18405] Loss: 0.47177885285705196

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18430] Loss: 0.4719889647272607

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18455] Loss: 0.4719869309836753

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18480] Loss: 0.47196389046781684

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18505] Loss: 0.4719904509375466

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18530] Loss: 0.47175596021839117

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18555] Loss: 0.4716121015661173

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18580] Loss: 0.471659803654863

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18605] Loss: 0.47170122008416143

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18630] Loss: 0.47167227341357243

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18655] Loss: 0.4717254850768406

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18680] Loss: 0.4716086755493128

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18705] Loss: 0.47149638289449236

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18730] Loss: 0.4713303227278297

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18755] Loss: 0.4712773354624002

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18780] Loss: 0.4712150356264625

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18805] Loss: 0.4712125638253126

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18830] Loss: 0.4713722380255935

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18855] Loss: 0.4714136021468471

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18880] Loss: 0.47139976755587454

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18905] Loss: 0.47167974812725383

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18930] Loss: 0.471720789473882

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18955] Loss: 0.4714915498829393

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 18980] Loss: 0.4713934801444971

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19005] Loss: 0.4713748159414414

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19030] Loss: 0.4716187663181277

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19055] Loss: 0.4716981527799059

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19080] Loss: 0.4716530808653355

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19105] Loss: 0.471785976137252

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19130] Loss: 0.4717965891924137

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19155] Loss: 0.4716832456929746

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19180] Loss: 0.47155027460773424

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19205] Loss: 0.47160016936348365

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8357
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 7 93]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19230] Loss: 0.47158409107382826

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19255] Loss: 0.4715058642621046

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19280] Loss: 0.4714525140743178

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19305] Loss: 0.4715236547245593

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19330] Loss: 0.4714655793130243

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19355] Loss: 0.47130150442486735

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19380] Loss: 0.4711312489271985

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19405] Loss: 0.4710432833996114

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19430] Loss: 0.47107709802825143

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19455] Loss: 0.4709556377154619

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19480] Loss: 0.4710978357899571

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19505] Loss: 0.4710715232820394

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19530] Loss: 0.4709411907377128

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19555] Loss: 0.4709462509495112

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19580] Loss: 0.4708040152845988

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19605] Loss: 0.4709897160029774

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19630] Loss: 0.4709959183708962

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19655] Loss: 0.47086611656963817

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19680] Loss: 0.4709017300113062

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19705] Loss: 0.4709794012042393

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19730] Loss: 0.4707863848714019

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19755] Loss: 0.4707925655399861

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19780] Loss: 0.4708069153147011

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19805] Loss: 0.4707198142719641

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19830] Loss: 0.47068065121595754

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19855] Loss: 0.4705835409997681

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19880] Loss: 0.47053278969720086

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19905] Loss: 0.4703138723405857

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19930] Loss: 0.4702361408994316

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19955] Loss: 0.4702648761357501

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 19980] Loss: 0.4701848457440395

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20005] Loss: 0.47020323831343386

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20030] Loss: 0.4701168914310384

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20055] Loss: 0.47002622487101625

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20080] Loss: 0.47013289484714943

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20105] Loss: 0.4701798908014143

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20130] Loss: 0.4700508045658559

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20155] Loss: 0.47027809181491415

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20180] Loss: 0.4705562883631368

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20205] Loss: 0.4705956738072158

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.834
Using max F1-Score threshold, the confusion matrix is:
 [[55 45]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20230] Loss: 0.4704866615022472

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20255] Loss: 0.4705068645821868

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20280] Loss: 0.47059457796436394

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20305] Loss: 0.4706518234132784

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20330] Loss: 0.4706162322806052

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20355] Loss: 0.4705605051376537

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20380] Loss: 0.4703841123853533

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20405] Loss: 0.4705647128935488

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20430] Loss: 0.47046788655473687

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20455] Loss: 0.47047415274213694

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20480] Loss: 0.47051169736103743

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20505] Loss: 0.4704587701201222

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20530] Loss: 0.47054516528843354

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20555] Loss: 0.4705603202665562

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20580] Loss: 0.4706429197632577

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20605] Loss: 0.47061990509724255

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20630] Loss: 0.4706274785043187

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20655] Loss: 0.4706217216770052

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20680] Loss: 0.4705025218418108

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20705] Loss: 0.4707263885210386

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20730] Loss: 0.4708042225774213

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20755] Loss: 0.4707010874192266

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20780] Loss: 0.47068884986786463

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20805] Loss: 0.47059619146945

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20830] Loss: 0.4705859834241692

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20855] Loss: 0.4705839800222902

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20880] Loss: 0.4706563243742583

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20905] Loss: 0.4706379944371652

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20930] Loss: 0.47062377417250206

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20955] Loss: 0.4705139451552586

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 20980] Loss: 0.4704548563878836

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21005] Loss: 0.47033996040046194

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21030] Loss: 0.47033826034414383

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21055] Loss: 0.47032871115526864

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21080] Loss: 0.4703747836050356

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21105] Loss: 0.4704893721513654

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21130] Loss: 0.47062444838668754

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21155] Loss: 0.4706463057646685

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21180] Loss: 0.47051089146966824

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21205] Loss: 0.4704964005137709

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8385000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21230] Loss: 0.470426403458515

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21255] Loss: 0.4703312020461992

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21280] Loss: 0.47035983688000593

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21305] Loss: 0.47025659131490305

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21330] Loss: 0.4703093190840784

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21355] Loss: 0.47025816207743365

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21380] Loss: 0.4704806741653807

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21405] Loss: 0.47049324945489207

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21430] Loss: 0.4704118785273501

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21455] Loss: 0.47041551095243556

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21480] Loss: 0.4703281174770812

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21505] Loss: 0.47036945035287486

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21530] Loss: 0.47042810640771154

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21555] Loss: 0.470266889918213

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21580] Loss: 0.4702587798929948

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21605] Loss: 0.47045546846172315

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21630] Loss: 0.47034794166929617

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21655] Loss: 0.4702624531159131

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21680] Loss: 0.47028807905064784

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21705] Loss: 0.4704119106449489

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21730] Loss: 0.47058161266619714

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21755] Loss: 0.4704785116870875

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21780] Loss: 0.47043081016280136

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21805] Loss: 0.4704333765951187

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21830] Loss: 0.4705707085180584

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21855] Loss: 0.47046708426852063

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21880] Loss: 0.47037807518540964

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21905] Loss: 0.47030875771068437

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21930] Loss: 0.4703443511031794

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21955] Loss: 0.4703272759641287

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 21980] Loss: 0.47033138315850403

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22005] Loss: 0.4702819301983132

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22030] Loss: 0.4701677732179775

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22055] Loss: 0.47012249288301605

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22080] Loss: 0.47019127089024926

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22105] Loss: 0.4701665092371399

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22130] Loss: 0.4701360995184567

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22155] Loss: 0.47020947013264486

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22180] Loss: 0.4702269356160898

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22205] Loss: 0.47021456805346656

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.844
Using max F1-Score threshold, the confusion matrix is:
 [[69 31]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22230] Loss: 0.4702516079445097

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22255] Loss: 0.4701665536675203

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22280] Loss: 0.47019547131905287

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22305] Loss: 0.4701489959328012

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22330] Loss: 0.4700335319845585

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22355] Loss: 0.4698328382330196

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22380] Loss: 0.469749855040351

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22405] Loss: 0.46987611597976386

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22430] Loss: 0.4697582500243668

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22455] Loss: 0.4696670508113443

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22480] Loss: 0.4696123259849214

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22505] Loss: 0.4695701684615965

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22530] Loss: 0.4697002180023858

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22555] Loss: 0.4697772312192167

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22580] Loss: 0.4697682446549516

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22605] Loss: 0.4698519052829982

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22630] Loss: 0.4698694579823594

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22655] Loss: 0.47002050531929257

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22680] Loss: 0.4699879904146812

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22705] Loss: 0.469841690139556

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22730] Loss: 0.46975939639397624

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22755] Loss: 0.4698645376879165

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22780] Loss: 0.4698505999502678

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22805] Loss: 0.4698279027980202

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22830] Loss: 0.4698750174248642

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22855] Loss: 0.46989523380663595

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22880] Loss: 0.4698572304681041

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22905] Loss: 0.46975108100296875

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22930] Loss: 0.4696166406057665

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22955] Loss: 0.46974028790816014

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 22980] Loss: 0.46973958627123946

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23005] Loss: 0.46977842153429633

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23030] Loss: 0.46978461084420337

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23055] Loss: 0.4696600921847783

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23080] Loss: 0.4696130241901946

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23105] Loss: 0.46951970395069176

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23130] Loss: 0.46933726331171544

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23155] Loss: 0.4692537586678704

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23180] Loss: 0.46922990781513296

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23205] Loss: 0.46903605587008135

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.84
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23230] Loss: 0.4689600474620074

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23255] Loss: 0.46890793843495243

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23280] Loss: 0.4690569398380656

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23305] Loss: 0.469057109935872

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23330] Loss: 0.4691540604272282

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23355] Loss: 0.46928536416707795

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23380] Loss: 0.46940793666016123

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23405] Loss: 0.46950602141157066

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23430] Loss: 0.46947867672637345

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23455] Loss: 0.46956084437766843

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23480] Loss: 0.46951616605424046

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23505] Loss: 0.46949606233121954

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23530] Loss: 0.46944757309682617

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23555] Loss: 0.46940778749268885

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23580] Loss: 0.46931275940767886

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23605] Loss: 0.4693613278221613

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23630] Loss: 0.46942779909540133

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23655] Loss: 0.46959117753976076

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23680] Loss: 0.46970770978308973

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23705] Loss: 0.4697628038147068

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23730] Loss: 0.46967866902434224

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23755] Loss: 0.4695537614237985

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23780] Loss: 0.4694297148854377

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23805] Loss: 0.4693170707360856

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23830] Loss: 0.46924887733344667

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23855] Loss: 0.4691214417837157

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23880] Loss: 0.46924730701630507

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23905] Loss: 0.4693298781060019

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23930] Loss: 0.46927144244550895

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23955] Loss: 0.46930130184545216

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 23980] Loss: 0.4692896917780716

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24005] Loss: 0.46937952252332743

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24030] Loss: 0.46948633617957464

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24055] Loss: 0.4693992050661856

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24080] Loss: 0.4693398085895542

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24105] Loss: 0.4694399120685239

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24130] Loss: 0.46945028357820445

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24155] Loss: 0.46972594089914016

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24180] Loss: 0.46978252248499175

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24205] Loss: 0.4697486096421198

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8351
Using max F1-Score threshold, the confusion matrix is:
 [[71 29]
 [15 85]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24230] Loss: 0.4697707866031085

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24255] Loss: 0.46967702748882484

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24280] Loss: 0.46958821686659724

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24305] Loss: 0.4695165444964094

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24330] Loss: 0.46963454251284775

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24355] Loss: 0.46971053562329834

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24380] Loss: 0.46975654951244

CUDA Memory Allocated: 9090220032
[Epoch 4, Batch 24405] Loss: 0.469764230766141

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22] Loss: 0.469892899459869

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 47] Loss: 0.47002269190112345

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 72] Loss: 0.4701090877227489

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 97] Loss: 0.4701211844793064

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 122] Loss: 0.47024467823459454

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 147] Loss: 0.47020254318094573

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 172] Loss: 0.4701313795703325

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 197] Loss: 0.47015444308780124

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 222] Loss: 0.4701830687005168

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 247] Loss: 0.470046133508165

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 272] Loss: 0.4699759675336703

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 297] Loss: 0.4700153960368431

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 322] Loss: 0.46996878892991006

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 347] Loss: 0.4698953344573174

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 372] Loss: 0.4698263859836032

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 397] Loss: 0.4700351339989843

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 422] Loss: 0.46996725643458515

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 447] Loss: 0.46989509326146667

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 472] Loss: 0.46981759794998745

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 497] Loss: 0.4696787963669934

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 522] Loss: 0.46958071747988994

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 547] Loss: 0.4697090886210034

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 572] Loss: 0.469682022469255

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 597] Loss: 0.4695833488332575

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 622] Loss: 0.46959961474068773

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 647] Loss: 0.4696070051450719

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 672] Loss: 0.46962023542527565

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 697] Loss: 0.46964448730146413

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 722] Loss: 0.46953742304672386

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 747] Loss: 0.4693930716098847

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 772] Loss: 0.46933765786748266

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 797] Loss: 0.46928756014821266

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8285
Using max F1-Score threshold, the confusion matrix is:
 [[59 41]
 [ 7 93]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 822] Loss: 0.4693523308492451

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 847] Loss: 0.4692696690836388

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 872] Loss: 0.46922155437223556

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 897] Loss: 0.46919219384534233

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 922] Loss: 0.4691693260381389

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 947] Loss: 0.4691931622294423

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 972] Loss: 0.4691338345609685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 997] Loss: 0.4692305390106918

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1022] Loss: 0.4692127581473742

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1047] Loss: 0.4691870076447491

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1072] Loss: 0.46911353305299724

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1097] Loss: 0.4691575160653357

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1122] Loss: 0.46913740590734093

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1147] Loss: 0.46903537419099317

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1172] Loss: 0.4689042889520247

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1197] Loss: 0.4689094707014643

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1222] Loss: 0.4687596047805996

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1247] Loss: 0.46874716216714574

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1272] Loss: 0.468752758870954

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1297] Loss: 0.468624660461202

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1322] Loss: 0.46859943417489114

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1347] Loss: 0.4689172461639512

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1372] Loss: 0.4688475089382177

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1397] Loss: 0.46880962201557314

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1422] Loss: 0.46876119170330033

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1447] Loss: 0.468703811297628

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1472] Loss: 0.4687991646864433

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1497] Loss: 0.46874980083143536

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1522] Loss: 0.4687197003254503

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1547] Loss: 0.46870572870530347

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1572] Loss: 0.4685585787761104

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1597] Loss: 0.4684877990825654

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1622] Loss: 0.46841664459386856

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1647] Loss: 0.4683937751440697

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1672] Loss: 0.4684038943413556

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1697] Loss: 0.4683356350800196

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1722] Loss: 0.4683025030747447

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1747] Loss: 0.4682908973816293

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1772] Loss: 0.46826226366141577

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1797] Loss: 0.4682923264035211

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8291
Using max F1-Score threshold, the confusion matrix is:
 [[55 45]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1822] Loss: 0.46823371334207176

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1847] Loss: 0.4683493752713111

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1872] Loss: 0.4683867316473505

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1897] Loss: 0.46836521784016366

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1922] Loss: 0.4684311743910754

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1947] Loss: 0.4683455429670585

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1972] Loss: 0.4681918497979647

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 1997] Loss: 0.4681629045040935

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2022] Loss: 0.46810635574822307

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2047] Loss: 0.4680345071311701

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2072] Loss: 0.4680603487742581

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2097] Loss: 0.4680745457715832

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2122] Loss: 0.4680734500095241

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2147] Loss: 0.4680303367823399

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2172] Loss: 0.4680608196912561

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2197] Loss: 0.468039652425792

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2222] Loss: 0.46805366726588676

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2247] Loss: 0.46804241345883996

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2272] Loss: 0.4680245921319686

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2297] Loss: 0.46798000081759045

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2322] Loss: 0.4678389577418025

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2347] Loss: 0.46779716304565555

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2372] Loss: 0.4678405086046193

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2397] Loss: 0.46800025435343484

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2422] Loss: 0.4680518736136406

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2447] Loss: 0.4679257100155819

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2472] Loss: 0.46796685905627694

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2497] Loss: 0.46800692943757866

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2522] Loss: 0.46798220005662

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2547] Loss: 0.46807246501576905

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2572] Loss: 0.4681024059416768

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2597] Loss: 0.46815573713783093

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2622] Loss: 0.4681234013880134

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2647] Loss: 0.4680238402419026

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2672] Loss: 0.46812304259808163

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2697] Loss: 0.4680874334048863

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2722] Loss: 0.46802394266675135

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2747] Loss: 0.46799192036581605

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2772] Loss: 0.4678867923798043

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2797] Loss: 0.46784738911327195

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8303
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2822] Loss: 0.46795101684236745

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2847] Loss: 0.46800229627500606

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2872] Loss: 0.4681077810134492

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2897] Loss: 0.4681445493487399

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2922] Loss: 0.4681020229469211

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2947] Loss: 0.4681310437039512

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2972] Loss: 0.46817646707138233

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 2997] Loss: 0.4681542520648384

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3022] Loss: 0.46815183420622664

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3047] Loss: 0.4682060804794603

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3072] Loss: 0.46825877607818195

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3097] Loss: 0.4682517618472877

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3122] Loss: 0.4682997992038074

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3147] Loss: 0.4682173944868932

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3172] Loss: 0.4682606991449744

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3197] Loss: 0.46827641718770374

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3222] Loss: 0.46817994139662783

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3247] Loss: 0.4680853995526856

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3272] Loss: 0.46807137286041356

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3297] Loss: 0.46815450439962

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3322] Loss: 0.46805641079129007

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3347] Loss: 0.4681094986846627

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3372] Loss: 0.4680745397427276

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3397] Loss: 0.46808782980907665

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3422] Loss: 0.4680574583530038

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3447] Loss: 0.4679810983345565

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3472] Loss: 0.46798991814414154

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3497] Loss: 0.4680043576231395

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3522] Loss: 0.46802732862468716

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3547] Loss: 0.46814390077261414

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3572] Loss: 0.46815244786400567

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3597] Loss: 0.4681556492082725

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3622] Loss: 0.4681174892289273

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3647] Loss: 0.46814823877744394

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3672] Loss: 0.4680909440872281

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3697] Loss: 0.46805045876755125

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3722] Loss: 0.46799706352744885

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3747] Loss: 0.4680747242050057

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3772] Loss: 0.4679694715908103

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3797] Loss: 0.46794755012319905

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8352
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3822] Loss: 0.4679272235317138

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3847] Loss: 0.4680496148954848

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3872] Loss: 0.468016003019874

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3897] Loss: 0.46794864136776615

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3922] Loss: 0.4679428208019768

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3947] Loss: 0.4679417751793165

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3972] Loss: 0.4680281982221043

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 3997] Loss: 0.46803506907947356

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4022] Loss: 0.46797694280409224

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4047] Loss: 0.46796465600866255

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4072] Loss: 0.4680228640152685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4097] Loss: 0.4680237758411503

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4122] Loss: 0.4680160101272337

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4147] Loss: 0.4679759002935428

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4172] Loss: 0.4678995169867689

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4197] Loss: 0.4679687078414283

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4222] Loss: 0.46789128693270504

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4247] Loss: 0.467937760229281

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4272] Loss: 0.46798788757131127

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4297] Loss: 0.46798231999794426

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4322] Loss: 0.46793776539695114

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4347] Loss: 0.46786714766635745

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4372] Loss: 0.46786737398134826

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4397] Loss: 0.4678870028966745

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4422] Loss: 0.4679568085637178

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4447] Loss: 0.467898446245964

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4472] Loss: 0.4680316569331784

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4497] Loss: 0.46801059643631693

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4522] Loss: 0.46806413979003125

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4547] Loss: 0.4680851499816828

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4572] Loss: 0.4681040716208245

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4597] Loss: 0.46813486687366995

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4622] Loss: 0.4681997846315971

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4647] Loss: 0.4681535387988661

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4672] Loss: 0.4681893356848846

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4697] Loss: 0.46825115966079983

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4722] Loss: 0.4682586230639229

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4747] Loss: 0.46815469011143007

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4772] Loss: 0.4681294842360515

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4797] Loss: 0.4681544687878606

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8317
Using max F1-Score threshold, the confusion matrix is:
 [[55 45]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4822] Loss: 0.4682232737455737

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4847] Loss: 0.4682973237239778

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4872] Loss: 0.4683081455560931

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4897] Loss: 0.46829853681204486

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4922] Loss: 0.4683323085536322

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4947] Loss: 0.4682566174267043

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4972] Loss: 0.4683379630522826

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 4997] Loss: 0.46835024315410667

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5022] Loss: 0.4683586264782112

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5047] Loss: 0.46834710320560824

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5072] Loss: 0.4683285389844127

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5097] Loss: 0.46835259707754223

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5122] Loss: 0.46828248341499173

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5147] Loss: 0.4681552766692988

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5172] Loss: 0.4681165715573249

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5197] Loss: 0.4681090898660228

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5222] Loss: 0.4681092125932031

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5247] Loss: 0.4681112054770163

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5272] Loss: 0.4680999381837707

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5297] Loss: 0.4681441918507065

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5322] Loss: 0.4682411291417754

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5347] Loss: 0.46822094060964664

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5372] Loss: 0.46813025164946404

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5397] Loss: 0.4680412076232098

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5422] Loss: 0.4680290542803055

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5447] Loss: 0.4679408749927691

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5472] Loss: 0.4679128414981416

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5497] Loss: 0.467888395912513

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5522] Loss: 0.4679652529448934

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5547] Loss: 0.46801021790548003

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5572] Loss: 0.46800449586247816

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5597] Loss: 0.467987351994997

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5622] Loss: 0.4679787351702913

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5647] Loss: 0.467939914190236

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5672] Loss: 0.46792939694024743

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5697] Loss: 0.46787960664425077

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5722] Loss: 0.4679266917615652

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5747] Loss: 0.4679916002216714

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5772] Loss: 0.4679251678991335

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5797] Loss: 0.4679940884743225

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8426
Using max F1-Score threshold, the confusion matrix is:
 [[70 30]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5822] Loss: 0.46799593153210606

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5847] Loss: 0.4679626165845876

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5872] Loss: 0.46793218338870024

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5897] Loss: 0.4679387244565764

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5922] Loss: 0.46785740280975685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5947] Loss: 0.46790086146363224

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5972] Loss: 0.46787794050555637

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 5997] Loss: 0.4677706964034333

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6022] Loss: 0.4677231675915329

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6047] Loss: 0.46782168778782557

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6072] Loss: 0.4677641765538075

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6097] Loss: 0.46775468783322466

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6122] Loss: 0.4678048204347462

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6147] Loss: 0.467869894565256

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6172] Loss: 0.46784837650257777

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6197] Loss: 0.46774942158934174

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6222] Loss: 0.46768487541553205

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6247] Loss: 0.4676918433815155

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6272] Loss: 0.46761098895034875

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6297] Loss: 0.46763977306999815

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6322] Loss: 0.4675966325397323

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6347] Loss: 0.46757971680199617

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6372] Loss: 0.4676112362315559

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6397] Loss: 0.4676372062872454

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6422] Loss: 0.46758285943746164

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6447] Loss: 0.46760389438342825

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6472] Loss: 0.4675959025227492

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6497] Loss: 0.46754489559891144

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6522] Loss: 0.46757187621253904

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6547] Loss: 0.4675325172092666

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6572] Loss: 0.4674681093683453

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6597] Loss: 0.46747903927648715

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6622] Loss: 0.4675193317775359

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6647] Loss: 0.46743460171144685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6672] Loss: 0.46738655234237175

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6697] Loss: 0.46744418093085666

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6722] Loss: 0.4674003716922814

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6747] Loss: 0.46746587651828675

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6772] Loss: 0.4673917129783532

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6797] Loss: 0.4673538585725736

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8342999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 9 91]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6822] Loss: 0.467307950832306

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6847] Loss: 0.46718300933199197

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6872] Loss: 0.4670965124955197

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6897] Loss: 0.4671876805221197

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6922] Loss: 0.4672983853809737

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6947] Loss: 0.4673588858544648

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6972] Loss: 0.467323138579215

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 6997] Loss: 0.4673447708388549

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7022] Loss: 0.46729237146703373

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7047] Loss: 0.4672415677432831

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7072] Loss: 0.46726956129159863

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7097] Loss: 0.4672773709900016

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7122] Loss: 0.4673383216764431

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7147] Loss: 0.4674205205399683

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7172] Loss: 0.46736925396985074

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7197] Loss: 0.46733628164497

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7222] Loss: 0.46744422807839847

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7247] Loss: 0.467530876077811

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7272] Loss: 0.4674901050087158

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7297] Loss: 0.4674794795908066

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7322] Loss: 0.46744950551546977

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7347] Loss: 0.46738668707100467

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7372] Loss: 0.46735264971227053

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7397] Loss: 0.46739092218748424

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7422] Loss: 0.4673156359952909

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7447] Loss: 0.46727761188772315

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7472] Loss: 0.46732933823612277

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7497] Loss: 0.46734111701488223

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7522] Loss: 0.4673428915513472

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7547] Loss: 0.4673371816519851

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7572] Loss: 0.4673481169735992

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7597] Loss: 0.4673554046751859

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7622] Loss: 0.4673337724378567

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7647] Loss: 0.46721147896913456

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7672] Loss: 0.46719446594539216

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7697] Loss: 0.46711662930359904

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7722] Loss: 0.4671084215394116

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7747] Loss: 0.46707325640903274

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7772] Loss: 0.4670415688033929

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7797] Loss: 0.46714376552816267

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8279000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[52 48]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7822] Loss: 0.4672678073811456

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7847] Loss: 0.46718005442989435

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7872] Loss: 0.46723220203865046

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7897] Loss: 0.4671527754002673

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7922] Loss: 0.46711093395112985

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7947] Loss: 0.46716082332768405

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7972] Loss: 0.4671800524898294

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 7997] Loss: 0.4672256681562005

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8022] Loss: 0.4672848852778362

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8047] Loss: 0.4673653750995241

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8072] Loss: 0.4673346165474861

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8097] Loss: 0.4672646490653965

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8122] Loss: 0.4672878598556643

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8147] Loss: 0.46725004653115804

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8172] Loss: 0.46722640547901884

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8197] Loss: 0.46725650664928325

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8222] Loss: 0.4672727078082581

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8247] Loss: 0.4672488693458267

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8272] Loss: 0.4672861288035537

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8297] Loss: 0.467296056556405

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8322] Loss: 0.46725634859305787

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8347] Loss: 0.4672265297798087

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8372] Loss: 0.46725284533008876

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8397] Loss: 0.46728132676211087

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8422] Loss: 0.4672443623728318

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8447] Loss: 0.4671727904766066

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8472] Loss: 0.46724136673535316

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8497] Loss: 0.46724444071910815

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8522] Loss: 0.4671786499795848

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8547] Loss: 0.46709940359185376

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8572] Loss: 0.46709930459737065

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8597] Loss: 0.46714581157105656

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8622] Loss: 0.46720167007114793

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8647] Loss: 0.467132817954308

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8672] Loss: 0.46711760814890335

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8697] Loss: 0.46710593492894076

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8722] Loss: 0.46719797135766855

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8747] Loss: 0.4670944213243718

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8772] Loss: 0.4670675355065056

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8797] Loss: 0.46699970476032515

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8341999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8822] Loss: 0.46691563016926707

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8847] Loss: 0.4669661919041172

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8872] Loss: 0.46692800856774275

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8897] Loss: 0.4670316189222551

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8922] Loss: 0.46704017767165756

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8947] Loss: 0.4669839023349316

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8972] Loss: 0.4669873395837673

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 8997] Loss: 0.46698408486372134

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9022] Loss: 0.4669745823350893

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9047] Loss: 0.46698921831634455

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9072] Loss: 0.466975795709703

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9097] Loss: 0.46693984548952866

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9122] Loss: 0.4669339746151892

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9147] Loss: 0.4668682088371941

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9172] Loss: 0.46689735062779886

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9197] Loss: 0.4667992443182038

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9222] Loss: 0.46688165377548346

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9247] Loss: 0.4668733777898174

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9272] Loss: 0.4669204086860272

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9297] Loss: 0.4668668245277668

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9322] Loss: 0.46699642798824537

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9347] Loss: 0.4670091555064347

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9372] Loss: 0.46696247800710144

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9397] Loss: 0.46695463099142026

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9422] Loss: 0.46689253451537877

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9447] Loss: 0.46685339531738457

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9472] Loss: 0.46679021961946326

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9497] Loss: 0.46674909901546896

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9522] Loss: 0.46688899156568037

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9547] Loss: 0.4670333878673743

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9572] Loss: 0.46698699211827194

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9597] Loss: 0.4669271632463765

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9622] Loss: 0.46691429812738783

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9647] Loss: 0.4668607535563223

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9672] Loss: 0.4668922129207875

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9697] Loss: 0.46689050397677

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9722] Loss: 0.46692405411185856

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9747] Loss: 0.46686008560295267

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9772] Loss: 0.4668241862531179

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9797] Loss: 0.46682706362577187

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8391
Using max F1-Score threshold, the confusion matrix is:
 [[76 24]
 [20 80]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9822] Loss: 0.4668604452852182

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9847] Loss: 0.46680850377715183

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9872] Loss: 0.4667424964573346

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9897] Loss: 0.4667590370614748

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9922] Loss: 0.4666769503860064

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9947] Loss: 0.46670527636145337

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9972] Loss: 0.46672211426433197

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 9997] Loss: 0.4667047644307921

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10022] Loss: 0.4666850881679712

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10047] Loss: 0.4666298144828749

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10072] Loss: 0.4666468397066

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10097] Loss: 0.46664354009888537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10122] Loss: 0.4666631038047796

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10147] Loss: 0.46665110764286605

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10172] Loss: 0.4666337697432577

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10197] Loss: 0.466594115872205

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10222] Loss: 0.4665634196539075

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10247] Loss: 0.46659369251111166

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10272] Loss: 0.4665449440799546

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10297] Loss: 0.46661456869536594

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10322] Loss: 0.46662538011486715

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10347] Loss: 0.4666141019234842

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10372] Loss: 0.4666456554806837

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10397] Loss: 0.4666418566246738

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10422] Loss: 0.4666620770851017

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10447] Loss: 0.4666207028965169

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10472] Loss: 0.4666478095740565

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10497] Loss: 0.46663321616154685

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10522] Loss: 0.46654183550594996

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10547] Loss: 0.46656165551914613

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10572] Loss: 0.46652277652981217

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10597] Loss: 0.46655077874796325

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10622] Loss: 0.4665515297259038

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10647] Loss: 0.466511857953323

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10672] Loss: 0.466499376516961

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10697] Loss: 0.4665575013054254

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10722] Loss: 0.46652850279850294

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10747] Loss: 0.46646157162835655

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10772] Loss: 0.46644349286580356

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10797] Loss: 0.4664875091927015

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8405
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10822] Loss: 0.4665087625185354

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10847] Loss: 0.4665033664889229

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10872] Loss: 0.4665634464355399

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10897] Loss: 0.4665283122687158

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10922] Loss: 0.46651862677146694

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10947] Loss: 0.4666211874403509

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10972] Loss: 0.466543914334694

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 10997] Loss: 0.4664876432398478

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11022] Loss: 0.4665321357427035

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11047] Loss: 0.466446464189146

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11072] Loss: 0.46642952041030117

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11097] Loss: 0.46645625439214056

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11122] Loss: 0.466452375459518

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11147] Loss: 0.4664521013499615

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11172] Loss: 0.4665184693573617

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11197] Loss: 0.46649765568908863

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11222] Loss: 0.4664969181688522

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11247] Loss: 0.4664012225245829

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11272] Loss: 0.466255851563628

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11297] Loss: 0.4661999008273605

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11322] Loss: 0.46616287664930606

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11347] Loss: 0.46620693481935177

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11372] Loss: 0.466253560613255

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11397] Loss: 0.46626035574909985

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11422] Loss: 0.4663008352949766

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11447] Loss: 0.46632928754996517

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11472] Loss: 0.4663051184385613

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11497] Loss: 0.4663175864766447

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11522] Loss: 0.4662545841922444

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11547] Loss: 0.46617307769770017

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11572] Loss: 0.466164811774281

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11597] Loss: 0.46611244057910967

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11622] Loss: 0.4661643739198541

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11647] Loss: 0.46614206547697207

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11672] Loss: 0.46609283468549356

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11697] Loss: 0.4660848924471874

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11722] Loss: 0.4660497250940539

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11747] Loss: 0.46600752768791803

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11772] Loss: 0.46596437911010713

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11797] Loss: 0.46593143891255323

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8403999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [ 7 93]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11822] Loss: 0.46589437861321575

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11847] Loss: 0.4659521775122426

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11872] Loss: 0.4660411855319152

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11897] Loss: 0.4660101163470782

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11922] Loss: 0.46600766649373343

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11947] Loss: 0.4660357678717762

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11972] Loss: 0.4660260482466246

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 11997] Loss: 0.46605140533151096

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12022] Loss: 0.4659781761995132

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12047] Loss: 0.4659639719196826

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12072] Loss: 0.4660125342910147

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12097] Loss: 0.4660444185396231

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12122] Loss: 0.46601674896577283

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12147] Loss: 0.4660227372747856

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12172] Loss: 0.46606209328992404

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12197] Loss: 0.4660492178396702

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12222] Loss: 0.46600842007140386

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12247] Loss: 0.46597281588402956

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12272] Loss: 0.4660574776520394

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12297] Loss: 0.46596128849653273

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12322] Loss: 0.4659023157675416

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12347] Loss: 0.4659912015978907

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12372] Loss: 0.46596195061940204

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12397] Loss: 0.4658782220873566

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12422] Loss: 0.4659177198870414

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12447] Loss: 0.46588250916324464

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12472] Loss: 0.46586049690257986

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12497] Loss: 0.4658052394838249

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12522] Loss: 0.4657524554990071

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12547] Loss: 0.46570713614785475

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12572] Loss: 0.4657978307690269

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12597] Loss: 0.46576836545822436

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12622] Loss: 0.465754921368896

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12647] Loss: 0.46574172514220963

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12672] Loss: 0.4656485846697791

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12697] Loss: 0.465702549345333

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12722] Loss: 0.46570349377001075

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12747] Loss: 0.46570508949942924

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12772] Loss: 0.46572703616728767

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12797] Loss: 0.4656253698944521

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8385
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12822] Loss: 0.46568471040381637

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12847] Loss: 0.46565518053875854

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12872] Loss: 0.46567685941882303

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12897] Loss: 0.46566074220971204

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12922] Loss: 0.4656080101742727

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12947] Loss: 0.465587967085926

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12972] Loss: 0.46557135858314824

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 12997] Loss: 0.4655673719381887

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13022] Loss: 0.4655131875381719

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13047] Loss: 0.46546729614502214

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13072] Loss: 0.46548855821032314

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13097] Loss: 0.4654969347653588

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13122] Loss: 0.465459015402102

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13147] Loss: 0.4654404474580142

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13172] Loss: 0.46543141538376254

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13197] Loss: 0.4654672513337222

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13222] Loss: 0.4655174999335626

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13247] Loss: 0.46548134438152977

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13272] Loss: 0.4654663577247909

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13297] Loss: 0.4655102566386703

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13322] Loss: 0.4656039836571587

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13347] Loss: 0.46558773240074464

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13372] Loss: 0.46562532270728263

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13397] Loss: 0.4656100494577346

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13422] Loss: 0.4655865631484268

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13447] Loss: 0.46560679736590616

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13472] Loss: 0.46550617027042673

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13497] Loss: 0.4655676249962295

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13522] Loss: 0.46558182749251575

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13547] Loss: 0.4655751575114626

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13572] Loss: 0.46551459108700904

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13597] Loss: 0.46555451034195966

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13622] Loss: 0.46553770453236926

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13647] Loss: 0.4655090683774467

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13672] Loss: 0.46552173554737813

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13697] Loss: 0.46553045507447904

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13722] Loss: 0.46561015538519973

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13747] Loss: 0.4655417867347029

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13772] Loss: 0.4655595583171655

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13797] Loss: 0.46560617140639804

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8405999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [10 90]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13822] Loss: 0.46568056987926854

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13847] Loss: 0.46571210227539456

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13872] Loss: 0.46567340158820336

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13897] Loss: 0.46564458974316864

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13922] Loss: 0.46556482530380844

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13947] Loss: 0.465594865264552

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13972] Loss: 0.4655929038061998

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 13997] Loss: 0.46559141783984764

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14022] Loss: 0.4656011830589201

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14047] Loss: 0.4656378214613184

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14072] Loss: 0.4656316583812046

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14097] Loss: 0.46563015635581007

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14122] Loss: 0.4656157133946865

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14147] Loss: 0.4655573739660763

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14172] Loss: 0.4655584371436739

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14197] Loss: 0.46553354009984693

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14222] Loss: 0.4655706374589222

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14247] Loss: 0.46557924274561313

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14272] Loss: 0.4655101669768235

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14297] Loss: 0.46548947821053877

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14322] Loss: 0.4654580462048388

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14347] Loss: 0.4655178760487129

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14372] Loss: 0.4655004091462453

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14397] Loss: 0.46542480504814304

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14422] Loss: 0.46541605371464556

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14447] Loss: 0.4653839756387078

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14472] Loss: 0.4653940426956869

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14497] Loss: 0.4654303086557022

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14522] Loss: 0.4653734530142258

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14547] Loss: 0.46529733577573335

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14572] Loss: 0.4653282978296728

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14597] Loss: 0.46528718262055063

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14622] Loss: 0.46533925553377825

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14647] Loss: 0.465373069058694

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14672] Loss: 0.46537709773799696

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14697] Loss: 0.4653980729787046

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14722] Loss: 0.4653026428021083

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14747] Loss: 0.46525885350992136

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14772] Loss: 0.465227122266099

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14797] Loss: 0.465239131952859

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.842
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14822] Loss: 0.46526208961268717

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14847] Loss: 0.4653422792662663

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14872] Loss: 0.46528285703669936

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14897] Loss: 0.46525578437868714

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14922] Loss: 0.4652181644454134

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14947] Loss: 0.46513829354598585

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14972] Loss: 0.4651131531067232

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 14997] Loss: 0.46509986831088224

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15022] Loss: 0.4650347981185553

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15047] Loss: 0.4649786610292905

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15072] Loss: 0.46490678933129986

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15097] Loss: 0.4649155442284219

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15122] Loss: 0.4648840783032363

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15147] Loss: 0.46487776879023224

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15172] Loss: 0.4649774067082234

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15197] Loss: 0.464962609242495

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15222] Loss: 0.46499017681544264

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15247] Loss: 0.46489149727379275

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15272] Loss: 0.4648891795136445

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15297] Loss: 0.46482843575749655

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15322] Loss: 0.46485139238643897

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15347] Loss: 0.46486585455383406

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15372] Loss: 0.4649142697469857

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15397] Loss: 0.4648963922271564

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15422] Loss: 0.464865887200673

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15447] Loss: 0.4648054667462888

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15472] Loss: 0.46479513970770164

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15497] Loss: 0.46477885667636526

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15522] Loss: 0.4648018853876852

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15547] Loss: 0.4647562127939409

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15572] Loss: 0.4647414135187115

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15597] Loss: 0.4646720006468293

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15622] Loss: 0.46465040692921783

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15647] Loss: 0.46468269567520243

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15672] Loss: 0.46472116528530955

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15697] Loss: 0.4647537830663481

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15722] Loss: 0.46471290943185156

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15747] Loss: 0.46469002590736785

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15772] Loss: 0.46468328574745127

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15797] Loss: 0.46465975989165753

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8418
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15822] Loss: 0.46458729776545826

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15847] Loss: 0.4645554788657084

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15872] Loss: 0.4646281916915737

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15897] Loss: 0.46460971486897246

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15922] Loss: 0.46454546605265407

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15947] Loss: 0.4644980730662657

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15972] Loss: 0.4645686287400024

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 15997] Loss: 0.4645164189431876

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16022] Loss: 0.4644613643786187

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16047] Loss: 0.46444703212133465

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16072] Loss: 0.46459876395946303

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16097] Loss: 0.4645908659678624

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16122] Loss: 0.46463641543662554

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16147] Loss: 0.4646681471169519

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16172] Loss: 0.46472160273461827

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16197] Loss: 0.4646597491489813

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16222] Loss: 0.46464596321409896

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16247] Loss: 0.464579851561583

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16272] Loss: 0.4646335616242576

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16297] Loss: 0.464623130020163

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16322] Loss: 0.46459697884193846

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16347] Loss: 0.4646357720361841

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16372] Loss: 0.4646451363143693

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16397] Loss: 0.4646116012201122

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16422] Loss: 0.46459384395448744

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16447] Loss: 0.46459991252082333

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16472] Loss: 0.4645543947728918

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16497] Loss: 0.46454658580957464

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16522] Loss: 0.464527671451526

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16547] Loss: 0.4645467658419357

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16572] Loss: 0.46455619836496836

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16597] Loss: 0.4645764047023079

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16622] Loss: 0.4646611942785453

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16647] Loss: 0.46464042908110936

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16672] Loss: 0.46461369114637024

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16697] Loss: 0.46457452454706266

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16722] Loss: 0.46458487724818354

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16747] Loss: 0.4645987492762583

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16772] Loss: 0.4646079561004099

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16797] Loss: 0.46458165874387936

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8412
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [10 90]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16822] Loss: 0.46460332274135785

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16847] Loss: 0.46464771017120177

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16872] Loss: 0.4646520156163588

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16897] Loss: 0.46455622043950123

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16922] Loss: 0.4645159340271059

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16947] Loss: 0.4645678478048985

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16972] Loss: 0.4645415956143007

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 16997] Loss: 0.46453623820379636

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17022] Loss: 0.4645149932444836

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17047] Loss: 0.46450771967371024

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17072] Loss: 0.4645011013890707

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17097] Loss: 0.4645687482602219

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17122] Loss: 0.4644825588010194

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17147] Loss: 0.4644700402219464

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17172] Loss: 0.464449394443798

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17197] Loss: 0.46452382064983544

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17222] Loss: 0.4645253125804606

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17247] Loss: 0.4644715777582009

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17272] Loss: 0.46442542012210636

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17297] Loss: 0.46443548905405846

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17322] Loss: 0.4644085983012496

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17347] Loss: 0.46440665462160485

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17372] Loss: 0.4643568676068849

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17397] Loss: 0.4643532124060058

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17422] Loss: 0.46435786564294085

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17447] Loss: 0.4643901664751616

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17472] Loss: 0.46433119525250255

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17497] Loss: 0.46436789456836747

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17522] Loss: 0.4643374680119845

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17547] Loss: 0.4643952783082785

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17572] Loss: 0.4644037545760968

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17597] Loss: 0.4643994006215382

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17622] Loss: 0.46429976242188603

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17647] Loss: 0.4643203241054449

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17672] Loss: 0.4643153305577133

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17697] Loss: 0.4642890574402995

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17722] Loss: 0.4642750894376174

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17747] Loss: 0.46425863278868457

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17772] Loss: 0.46429153076106616

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17797] Loss: 0.4643033171946254

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8355
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17822] Loss: 0.4642845445952614

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17847] Loss: 0.4642926413170427

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17872] Loss: 0.46429527381819224

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17897] Loss: 0.4643090778958712

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17922] Loss: 0.46431695650938526

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17947] Loss: 0.46434470887035717

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17972] Loss: 0.4642725967125359

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 17997] Loss: 0.4642828753579825

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18022] Loss: 0.46429507914580614

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18047] Loss: 0.46422613819014374

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18072] Loss: 0.46429596993652184

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18097] Loss: 0.46432356909312594

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18122] Loss: 0.4643819359452083

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18147] Loss: 0.46440972824121224

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18172] Loss: 0.46442879329588044

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18197] Loss: 0.46437964993230846

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18222] Loss: 0.464335151344009

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18247] Loss: 0.46435933952358593

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18272] Loss: 0.46436650236974747

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18297] Loss: 0.4644091929405442

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18322] Loss: 0.4644024275180177

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18347] Loss: 0.46437941793971915

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18372] Loss: 0.46435487552742716

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18397] Loss: 0.46435173832101495

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18422] Loss: 0.4643012958923363

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18447] Loss: 0.46432429277107723

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18472] Loss: 0.46434999351344464

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18497] Loss: 0.46428516223006233

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18522] Loss: 0.46427668088791685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18547] Loss: 0.4642193195795185

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18572] Loss: 0.4642325347398481

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18597] Loss: 0.4642167483189118

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18622] Loss: 0.4641445350840263

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18647] Loss: 0.464210623958268

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18672] Loss: 0.46420360618565853

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18697] Loss: 0.46418879212330366

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18722] Loss: 0.4642860083906781

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18747] Loss: 0.4643398839820485

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18772] Loss: 0.46434641533818266

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18797] Loss: 0.46437574239266766

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8455
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18822] Loss: 0.4643673746368901

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18847] Loss: 0.46437862658715434

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18872] Loss: 0.46435227988601874

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18897] Loss: 0.46432739296849057

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18922] Loss: 0.4643497183593626

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18947] Loss: 0.46441707733156923

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18972] Loss: 0.4644560177830801

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 18997] Loss: 0.4644340127947264

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19022] Loss: 0.4644039325328301

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19047] Loss: 0.46438186032454315

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19072] Loss: 0.4644342363070464

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19097] Loss: 0.46441477825901

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19122] Loss: 0.4644167374814154

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19147] Loss: 0.4644129328686319

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19172] Loss: 0.46441205082015474

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19197] Loss: 0.46437936716169237

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19222] Loss: 0.46441124144227824

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19247] Loss: 0.4643862262863263

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19272] Loss: 0.46439007884758654

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19297] Loss: 0.46440939922077823

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19322] Loss: 0.46433508346388885

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19347] Loss: 0.464297057128322

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19372] Loss: 0.46430244608507604

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19397] Loss: 0.4642525322460442

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19422] Loss: 0.4642489880331867

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19447] Loss: 0.46420895662836686

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19472] Loss: 0.46424541632610505

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19497] Loss: 0.4643045410180709

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19522] Loss: 0.464224749188347

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19547] Loss: 0.46422922440776276

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19572] Loss: 0.4642223373571725

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19597] Loss: 0.46424821840826835

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19622] Loss: 0.4642812732641818

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19647] Loss: 0.4642218007859409

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19672] Loss: 0.46425539311674086

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19697] Loss: 0.46424421612012395

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19722] Loss: 0.46429956990565563

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19747] Loss: 0.46430995586305096

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19772] Loss: 0.464307564477465

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19797] Loss: 0.4643916135462449

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8451
Using max F1-Score threshold, the confusion matrix is:
 [[70 30]
 [12 88]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19822] Loss: 0.4644211614857475

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19847] Loss: 0.46442915593370254

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19872] Loss: 0.46437515824107

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19897] Loss: 0.46429108600743707

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19922] Loss: 0.46438324962833843

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19947] Loss: 0.46436134994777073

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19972] Loss: 0.4643694812974305

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 19997] Loss: 0.4644309718618688

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20022] Loss: 0.46443405442809443

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20047] Loss: 0.46444061872168924

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20072] Loss: 0.46438961649850297

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20097] Loss: 0.46437779098125387

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20122] Loss: 0.46443023803142947

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20147] Loss: 0.46440220066828897

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20172] Loss: 0.46438014202800715

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20197] Loss: 0.4644412992987156

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20222] Loss: 0.46445892966055924

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20247] Loss: 0.46445910328655293

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20272] Loss: 0.46454271381395607

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20297] Loss: 0.4645693901159457

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20322] Loss: 0.4644817277428947

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20347] Loss: 0.4644957741086685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20372] Loss: 0.4643984028744009

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20397] Loss: 0.4644255828129547

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20422] Loss: 0.4644324307107358

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20447] Loss: 0.46441584468505487

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20472] Loss: 0.46439310568328956

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20497] Loss: 0.4643408326224998

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20522] Loss: 0.4643079309145067

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20547] Loss: 0.4642563949748145

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20572] Loss: 0.4642466167619188

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20597] Loss: 0.46421314211947545

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20622] Loss: 0.4643342635306035

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20647] Loss: 0.464375033387026

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20672] Loss: 0.46434806162310804

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20697] Loss: 0.4643498085370736

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20722] Loss: 0.4643735925549222

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20747] Loss: 0.4643965019933569

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20772] Loss: 0.4644838247766289

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20797] Loss: 0.4645020468293058

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8391
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20822] Loss: 0.4644779171007403

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20847] Loss: 0.4644961659197194

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20872] Loss: 0.46453831816106056

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20897] Loss: 0.46458546959143515

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20922] Loss: 0.4645104456522719

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20947] Loss: 0.46449247765346846

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20972] Loss: 0.464469935206065

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 20997] Loss: 0.46446529825378563

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21022] Loss: 0.464480674358784

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21047] Loss: 0.4644674687275295

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21072] Loss: 0.4644652677583325

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21097] Loss: 0.46444220412685155

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21122] Loss: 0.46454095443993915

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21147] Loss: 0.4645354732921885

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21172] Loss: 0.46447230551751434

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21197] Loss: 0.46439391470119334

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21222] Loss: 0.46440957345794454

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21247] Loss: 0.4643706544577293

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21272] Loss: 0.4643605967790767

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21297] Loss: 0.46435826780299216

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21322] Loss: 0.4643653505904583

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21347] Loss: 0.4644372132523725

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21372] Loss: 0.46446913785526583

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21397] Loss: 0.4645006528901038

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21422] Loss: 0.4644535813285368

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21447] Loss: 0.46444707855696854

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21472] Loss: 0.46447810198023265

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21497] Loss: 0.4644796025723041

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21522] Loss: 0.4645177741428172

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21547] Loss: 0.4644755637496705

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21572] Loss: 0.46440827882317576

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21597] Loss: 0.46438298261210303

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21622] Loss: 0.46430568274657374

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21647] Loss: 0.4643043818105446

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21672] Loss: 0.46425428110255834

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21697] Loss: 0.46422653796145724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21722] Loss: 0.4642186563871686

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21747] Loss: 0.4642065623507706

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21772] Loss: 0.46429592352199955

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21797] Loss: 0.4642749921429754

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8362
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21822] Loss: 0.4642263446946875

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21847] Loss: 0.4642425827792675

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21872] Loss: 0.4641955980770697

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21897] Loss: 0.4641690042127898

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21922] Loss: 0.46413546706174685

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21947] Loss: 0.4641640750146309

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21972] Loss: 0.46411543471277167

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 21997] Loss: 0.46406026748259654

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22022] Loss: 0.4640247800164814

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22047] Loss: 0.4640301736781389

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22072] Loss: 0.4640577805581448

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22097] Loss: 0.4640590330577092

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22122] Loss: 0.46408088800954506

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22147] Loss: 0.4641489342203589

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22172] Loss: 0.46411157377251516

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22197] Loss: 0.464079486044182

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22222] Loss: 0.46411680256996846

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22247] Loss: 0.46411786561866236

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22272] Loss: 0.46411211375667333

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22297] Loss: 0.4640540896604389

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22322] Loss: 0.4640532006912535

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22347] Loss: 0.4640317461437177

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22372] Loss: 0.46401658216324615

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22397] Loss: 0.46406663991152963

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22422] Loss: 0.46406236514813504

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22447] Loss: 0.4640742370507793

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22472] Loss: 0.46397612925069964

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22497] Loss: 0.46404653759071746

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22522] Loss: 0.46407055495338834

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22547] Loss: 0.4640990836441436

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22572] Loss: 0.46410810137883496

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22597] Loss: 0.46417298319556977

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22622] Loss: 0.4641563302475969

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22647] Loss: 0.4641341355370266

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22672] Loss: 0.4641730478296367

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22697] Loss: 0.4641589469356577

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22722] Loss: 0.4641092072572442

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22747] Loss: 0.4640931564114219

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22772] Loss: 0.4641297408529327

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22797] Loss: 0.46410005861652276

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8372999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22822] Loss: 0.46406771953252063

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22847] Loss: 0.4641220749941446

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22872] Loss: 0.46409898788776643

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22897] Loss: 0.4640950611903497

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22922] Loss: 0.4640804445043915

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22947] Loss: 0.46404032440545995

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22972] Loss: 0.4639734069426765

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 22997] Loss: 0.463899329575123

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23022] Loss: 0.4639136094546792

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23047] Loss: 0.46394802338696084

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23072] Loss: 0.46397995394652924

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23097] Loss: 0.4639986481683708

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23122] Loss: 0.46405301677547695

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23147] Loss: 0.46402394868182856

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23172] Loss: 0.4639727231617339

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23197] Loss: 0.4639212763480469

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23222] Loss: 0.4639358909972906

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23247] Loss: 0.46393691731313963

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23272] Loss: 0.46390968515083525

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23297] Loss: 0.46386330244875507

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23322] Loss: 0.46381954544946014

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23347] Loss: 0.4637659308021238

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23372] Loss: 0.4637232790823494

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23397] Loss: 0.463698808785754

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23422] Loss: 0.4636949922899718

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23447] Loss: 0.463682607815019

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23472] Loss: 0.4636366737282677

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23497] Loss: 0.46370497951631506

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23522] Loss: 0.4636760599692181

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23547] Loss: 0.46367617608362427

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23572] Loss: 0.46363074914505475

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23597] Loss: 0.4636111754080559

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23622] Loss: 0.46367110604687267

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23647] Loss: 0.4636620059013258

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23672] Loss: 0.4636313775080274

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23697] Loss: 0.46360023675525364

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23722] Loss: 0.4635883941173082

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23747] Loss: 0.4635883876262605

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23772] Loss: 0.4635579849424036

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23797] Loss: 0.46357871491336633

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8351999999999998
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [10 90]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23822] Loss: 0.46355042536193614

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23847] Loss: 0.46350084275275577

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23872] Loss: 0.46352823800221393

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23897] Loss: 0.46353693018152436

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23922] Loss: 0.46358177547540097

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23947] Loss: 0.46351735306180997

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23972] Loss: 0.46358384281828563

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 23997] Loss: 0.4635445615631476

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24022] Loss: 0.46355585611894323

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24047] Loss: 0.46356608436055347

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24072] Loss: 0.46356321067865014

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24097] Loss: 0.46358552087308036

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24122] Loss: 0.4636297481464757

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24147] Loss: 0.4635831777361669

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24172] Loss: 0.4635944047420264

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24197] Loss: 0.46357092596573257

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24222] Loss: 0.4635628546056603

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24247] Loss: 0.46348065126521115

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24272] Loss: 0.46348040459231676

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24297] Loss: 0.4634848778575269

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24322] Loss: 0.46343065011534634

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24347] Loss: 0.46336538711310793

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24372] Loss: 0.4633326624992703

CUDA Memory Allocated: 9090220032
[Epoch 5, Batch 24397] Loss: 0.46334899992351625

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14] Loss: 0.4633566167243164

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 39] Loss: 0.4633384627763188

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 64] Loss: 0.4633313802605295

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 89] Loss: 0.46334343894980534

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 114] Loss: 0.4634237560916835

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 139] Loss: 0.46345603618383097

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 164] Loss: 0.4634922798778134

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 189] Loss: 0.4634675722268464

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 214] Loss: 0.4634397183731095

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 239] Loss: 0.46341995994839574

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 264] Loss: 0.46343516779336585

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 289] Loss: 0.4633837213705757

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 314] Loss: 0.46334842065063747

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 339] Loss: 0.4633254041391514

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 364] Loss: 0.46328142602108874

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 389] Loss: 0.46322580382171386

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8423999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[71 29]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 414] Loss: 0.463216709967529

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 439] Loss: 0.46321219537845476

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 464] Loss: 0.46315668580649794

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 489] Loss: 0.4631175065833647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 514] Loss: 0.4631964214645849

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 539] Loss: 0.46316197867530357

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 564] Loss: 0.46313166827470303

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 589] Loss: 0.46307897431832085

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 614] Loss: 0.4631438665079962

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 639] Loss: 0.4631135372418339

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 664] Loss: 0.4631393875955928

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 689] Loss: 0.4632212043489821

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 714] Loss: 0.46322716645794815

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 739] Loss: 0.46328037916799

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 764] Loss: 0.463253975319842

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 789] Loss: 0.46327768883228504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 814] Loss: 0.4633375685280477

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 839] Loss: 0.4633407755832709

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 864] Loss: 0.4633612125800353

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 889] Loss: 0.4633266040623981

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 914] Loss: 0.4632732386408279

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 939] Loss: 0.4632752861695643

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 964] Loss: 0.46327759354501447

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 989] Loss: 0.46328200846433476

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1014] Loss: 0.4632460448078574

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1039] Loss: 0.4631966982372098

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1064] Loss: 0.4631663859747508

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1089] Loss: 0.46311310633727015

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1114] Loss: 0.4631239428519864

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1139] Loss: 0.46316666204475454

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1164] Loss: 0.4631583886954593

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1189] Loss: 0.463142552533882

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1214] Loss: 0.4631769650327004

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1239] Loss: 0.463206244074034

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1264] Loss: 0.46316459502676455

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1289] Loss: 0.4631585924392537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1314] Loss: 0.4631175929349142

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1339] Loss: 0.46309207570524374

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1364] Loss: 0.4630969091100082

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1389] Loss: 0.463081075891191

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8408
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1414] Loss: 0.4630195643386575

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1439] Loss: 0.46300750314228095

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1464] Loss: 0.46299262072253505

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1489] Loss: 0.4630026505249041

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1514] Loss: 0.4629840142785153

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1539] Loss: 0.4630273717329709

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1564] Loss: 0.463092123798715

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1589] Loss: 0.46309633234532055

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1614] Loss: 0.46308044131675835

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1639] Loss: 0.46318554498450354

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1664] Loss: 0.46322171433156034

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1689] Loss: 0.4632425539366026

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1714] Loss: 0.46323813509299877

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1739] Loss: 0.46324708057780783

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1764] Loss: 0.4631877086234549

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1789] Loss: 0.46318801500328294

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1814] Loss: 0.4632244459309923

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1839] Loss: 0.46319262913718556

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1864] Loss: 0.46313010618098394

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1889] Loss: 0.4631178894316734

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1914] Loss: 0.46312651745528605

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1939] Loss: 0.4631138429482766

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1964] Loss: 0.46308611980550823

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 1989] Loss: 0.46306212321330437

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2014] Loss: 0.46304131283009986

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2039] Loss: 0.4629916254493913

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2064] Loss: 0.4629976355931404

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2089] Loss: 0.4629922624324519

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2114] Loss: 0.46302874579469316

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2139] Loss: 0.4630535326974933

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2164] Loss: 0.46307667885820003

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2189] Loss: 0.4630586592765962

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2214] Loss: 0.46304948078610353

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2239] Loss: 0.4630946877123346

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2264] Loss: 0.4631278806859584

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2289] Loss: 0.4631151811778096

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2314] Loss: 0.46307506457859204

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2339] Loss: 0.4630470099771593

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2364] Loss: 0.46304341868855464

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2389] Loss: 0.46297260487045

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8434
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2414] Loss: 0.46296744668434237

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2439] Loss: 0.462929244126658

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2464] Loss: 0.46287152332674136

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2489] Loss: 0.4628428725617691

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2514] Loss: 0.46280584444115924

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2539] Loss: 0.4627587993594924

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2564] Loss: 0.46278025562962016

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2589] Loss: 0.46275252419402013

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2614] Loss: 0.46269936460377825

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2639] Loss: 0.46266330439591014

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2664] Loss: 0.4626562930122482

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2689] Loss: 0.4626834696463736

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2714] Loss: 0.4626536551075505

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2739] Loss: 0.46263223353378413

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2764] Loss: 0.4626046679616546

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2789] Loss: 0.46264800656324007

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2814] Loss: 0.46265687737181665

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2839] Loss: 0.46265802476814255

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2864] Loss: 0.46267430038464397

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2889] Loss: 0.4626692370643761

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2914] Loss: 0.4627189101775309

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2939] Loss: 0.46271992084340346

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2964] Loss: 0.4626683009531142

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 2989] Loss: 0.4626533918582201

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3014] Loss: 0.46267874955066

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3039] Loss: 0.46271029386444457

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3064] Loss: 0.4626616079517767

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3089] Loss: 0.4626806252391759

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3114] Loss: 0.46270589024881903

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3139] Loss: 0.46263466506245243

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3164] Loss: 0.4626039695461884

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3189] Loss: 0.4626547855853848

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3214] Loss: 0.46267176522234355

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3239] Loss: 0.4626366894034983

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3264] Loss: 0.4626260929865065

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3289] Loss: 0.4626074403942123

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3314] Loss: 0.46264929683253436

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3339] Loss: 0.4626225292196505

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3364] Loss: 0.46259185926460894

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3389] Loss: 0.46257383778063

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8444
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3414] Loss: 0.4625709907838569

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3439] Loss: 0.4626760539473702

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3464] Loss: 0.4626622996437516

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3489] Loss: 0.4627760584646081

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3514] Loss: 0.46277502543988447

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3539] Loss: 0.4627510579261309

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3564] Loss: 0.4627280325668872

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3589] Loss: 0.4627164298910346

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3614] Loss: 0.4627379623103172

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3639] Loss: 0.4627162492240314

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3664] Loss: 0.4627145198811609

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3689] Loss: 0.4626753185057814

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3714] Loss: 0.4627065577029293

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3739] Loss: 0.46268475298468076

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3764] Loss: 0.4626448558765958

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3789] Loss: 0.46260779810537306

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3814] Loss: 0.4625549307304126

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3839] Loss: 0.4626029755132338

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3864] Loss: 0.46262187045346154

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3889] Loss: 0.46256634797024565

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3914] Loss: 0.46257505362878626

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3939] Loss: 0.46258396142005803

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3964] Loss: 0.4626119248143825

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 3989] Loss: 0.4625982608880011

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4014] Loss: 0.4626066073729044

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4039] Loss: 0.462601778998784

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4064] Loss: 0.4626153780077266

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4089] Loss: 0.46259380757647556

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4114] Loss: 0.46263329298455613

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4139] Loss: 0.4626538317885777

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4164] Loss: 0.4626680346245559

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4189] Loss: 0.4626026035928078

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4214] Loss: 0.4625708198058332

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4239] Loss: 0.4626193062991365

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4264] Loss: 0.462594643463351

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4289] Loss: 0.46260132027115863

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4314] Loss: 0.4626328234709065

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4339] Loss: 0.46257712449055177

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4364] Loss: 0.46258350123336867

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4389] Loss: 0.4625947771173417

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8459
Using max F1-Score threshold, the confusion matrix is:
 [[72 28]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4414] Loss: 0.4626414629909123

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4439] Loss: 0.4626312110648324

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4464] Loss: 0.4626018060960057

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4489] Loss: 0.46262372556144493

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4514] Loss: 0.4625774385506554

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4539] Loss: 0.46253576721279865

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4564] Loss: 0.46249052810964064

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4589] Loss: 0.46246756533953615

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4614] Loss: 0.4624806542626522

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4639] Loss: 0.4625118706769943

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4664] Loss: 0.46256747791085967

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4689] Loss: 0.4625941889773516

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4714] Loss: 0.46256294549894533

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4739] Loss: 0.46252287692765787

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4764] Loss: 0.4625330358943325

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4789] Loss: 0.46252874463298493

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4814] Loss: 0.4625823249643913

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4839] Loss: 0.46253659150552445

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4864] Loss: 0.4625292487599499

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4889] Loss: 0.462500452663991

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4914] Loss: 0.46250686112822603

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4939] Loss: 0.4624952073161022

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4964] Loss: 0.4625021118713281

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 4989] Loss: 0.46257641332190114

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5014] Loss: 0.46257749525361114

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5039] Loss: 0.46261373960506674

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5064] Loss: 0.4626524996390234

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5089] Loss: 0.46261474495996724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5114] Loss: 0.46261722554037127

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5139] Loss: 0.4626438099564604

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5164] Loss: 0.4626577602133619

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5189] Loss: 0.46271246104675745

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5214] Loss: 0.46270520558645595

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5239] Loss: 0.46266792685787317

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5264] Loss: 0.4626291858224118

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5289] Loss: 0.4625490459385736

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5314] Loss: 0.46252416241860583

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5339] Loss: 0.46250626745496226

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5364] Loss: 0.46249553598389354

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5389] Loss: 0.4625077758007002

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8419
Using max F1-Score threshold, the confusion matrix is:
 [[63 37]
 [10 90]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5414] Loss: 0.46250989190940606

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5439] Loss: 0.4624980100409632

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5464] Loss: 0.4624484442231842

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5489] Loss: 0.4624680726224632

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5514] Loss: 0.46242608149361825

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5539] Loss: 0.46240710426728127

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5564] Loss: 0.462461530350764

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5589] Loss: 0.46239976264173205

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5614] Loss: 0.46236714126447487

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5639] Loss: 0.4624046782615641

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5664] Loss: 0.46248189631855013

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5689] Loss: 0.4624790100393101

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5714] Loss: 0.46250462365038664

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5739] Loss: 0.46256859616471335

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5764] Loss: 0.4625381797087692

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5789] Loss: 0.4625072515816512

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5814] Loss: 0.4625185669652196

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5839] Loss: 0.462542569013042

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5864] Loss: 0.4624858631759921

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5889] Loss: 0.46244022930806755

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5914] Loss: 0.4624344013184424

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5939] Loss: 0.4624137899530322

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5964] Loss: 0.46244892308731733

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 5989] Loss: 0.4624800010660269

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6014] Loss: 0.462411776326771

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6039] Loss: 0.462401952769795

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6064] Loss: 0.4623407934894284

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6089] Loss: 0.46231571969021057

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6114] Loss: 0.46226923821883426

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6139] Loss: 0.46225991514841647

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6164] Loss: 0.46223149716751954

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6189] Loss: 0.46216771242333077

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6214] Loss: 0.4621528229993598

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6239] Loss: 0.4621433483318498

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6264] Loss: 0.4621029923287538

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6289] Loss: 0.46210680830177564

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6314] Loss: 0.4620995361909795

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6339] Loss: 0.46204815468599825

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6364] Loss: 0.46204895592414247

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6389] Loss: 0.4620568620096399

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8432
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6414] Loss: 0.46206163864546457

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6439] Loss: 0.4620681496328138

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6464] Loss: 0.4620318728754704

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6489] Loss: 0.4619585823513626

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6514] Loss: 0.4619236718219706

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6539] Loss: 0.46192385764583244

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6564] Loss: 0.4619829247866101

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6589] Loss: 0.46197564864376023

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6614] Loss: 0.46197948680017714

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6639] Loss: 0.4619576134081557

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6664] Loss: 0.4619254736955138

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6689] Loss: 0.46190968598824905

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6714] Loss: 0.46189414969798187

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6739] Loss: 0.46183931135867384

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6764] Loss: 0.4618734334439269

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6789] Loss: 0.46189218178065744

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6814] Loss: 0.4618962319707151

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6839] Loss: 0.46190120682564073

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6864] Loss: 0.4619124726906197

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6889] Loss: 0.46192540074899946

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6914] Loss: 0.4619008666892169

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6939] Loss: 0.46187013364109597

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6964] Loss: 0.4618472051906006

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 6989] Loss: 0.46182574790669734

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7014] Loss: 0.4617964647440892

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7039] Loss: 0.4617720983577352

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7064] Loss: 0.4617612505553136

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7089] Loss: 0.4617889604433468

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7114] Loss: 0.4617737957712683

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7139] Loss: 0.46178747603623294

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7164] Loss: 0.4617834914084384

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7189] Loss: 0.4617986042002549

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7214] Loss: 0.4617305136443798

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7239] Loss: 0.46176145669246227

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7264] Loss: 0.46170793694694445

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7289] Loss: 0.46167046677124085

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7314] Loss: 0.4616857450012442

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7339] Loss: 0.46166833536049484

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7364] Loss: 0.4616750593868683

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7389] Loss: 0.4616996609585998

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8406
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7414] Loss: 0.4617069408342393

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7439] Loss: 0.46175001204656246

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7464] Loss: 0.4617902093652343

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7489] Loss: 0.461749045893368

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7514] Loss: 0.4617055014290267

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7539] Loss: 0.4617080113118165

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7564] Loss: 0.4617077940647435

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7589] Loss: 0.4616987341572281

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7614] Loss: 0.46163561198235176

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7639] Loss: 0.4615944903263403

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7664] Loss: 0.46162125329576664

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7689] Loss: 0.46166015634437846

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7714] Loss: 0.4617141211002428

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7739] Loss: 0.4616802122705708

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7764] Loss: 0.46170620185591826

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7789] Loss: 0.4617144645415259

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7814] Loss: 0.4617209317901962

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7839] Loss: 0.46170272356770586

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7864] Loss: 0.4617327292861547

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7889] Loss: 0.46170967530486645

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7914] Loss: 0.4617033012587808

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7939] Loss: 0.4617037984040839

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7964] Loss: 0.4616610769713531

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 7989] Loss: 0.4616872867677059

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8014] Loss: 0.46163636079493553

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8039] Loss: 0.461656807583728

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8064] Loss: 0.4616045040308311

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8089] Loss: 0.4616450322909411

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8114] Loss: 0.46160334028899996

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8139] Loss: 0.46156261594327935

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8164] Loss: 0.46153199332129324

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8189] Loss: 0.4615256743794098

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8214] Loss: 0.4615319996960412

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8239] Loss: 0.4615516886529535

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8264] Loss: 0.4615445572760731

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8289] Loss: 0.461539911739364

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8314] Loss: 0.4615290668013795

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8339] Loss: 0.4615645915291308

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8364] Loss: 0.46159517636596986

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8389] Loss: 0.46162836574955335

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8403
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8414] Loss: 0.46163582257535224

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8439] Loss: 0.46164928443811554

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8464] Loss: 0.4616264817427167

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8489] Loss: 0.46159822329525146

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8514] Loss: 0.461551003972286

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8539] Loss: 0.4615568080656607

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8564] Loss: 0.461541161876852

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8589] Loss: 0.46154431967222215

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8614] Loss: 0.46162549390325053

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8639] Loss: 0.46159346970988085

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8664] Loss: 0.46156789116577657

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8689] Loss: 0.4615616537569425

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8714] Loss: 0.4615550191954447

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8739] Loss: 0.4615861508288848

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8764] Loss: 0.46164774844934275

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8789] Loss: 0.46162713683074297

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8814] Loss: 0.4616332402374289

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8839] Loss: 0.46167972555094117

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8864] Loss: 0.4616483310256497

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8889] Loss: 0.46162291643340153

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8914] Loss: 0.4616245081428944

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8939] Loss: 0.46164006419205633

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8964] Loss: 0.4616301743757178

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 8989] Loss: 0.46162586840357145

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9014] Loss: 0.4616488850166482

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9039] Loss: 0.46160957563854715

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9064] Loss: 0.46158854981200337

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9089] Loss: 0.46155480893787887

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9114] Loss: 0.4615938959532307

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9139] Loss: 0.46159420667731665

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9164] Loss: 0.4615657649626489

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9189] Loss: 0.4615303875666623

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9214] Loss: 0.46150757170858553

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9239] Loss: 0.4615022897966562

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9264] Loss: 0.46153223211970384

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9289] Loss: 0.46146593717997975

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9314] Loss: 0.4614373299739714

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9339] Loss: 0.46143753682581207

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9364] Loss: 0.46145776355540535

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9389] Loss: 0.4614724625245163

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8434
Using max F1-Score threshold, the confusion matrix is:
 [[74 26]
 [18 82]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9414] Loss: 0.4614735255202891

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9439] Loss: 0.46143100805997267

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9464] Loss: 0.4613887439498024

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9489] Loss: 0.4613946344436262

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9514] Loss: 0.46136596584381967

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9539] Loss: 0.4613183447072767

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9564] Loss: 0.461258390849125

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9589] Loss: 0.46126771557248775

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9614] Loss: 0.4612143370026058

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9639] Loss: 0.46121544130096503

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9664] Loss: 0.46128968891401856

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9689] Loss: 0.4612737021157324

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9714] Loss: 0.4612512754869025

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9739] Loss: 0.46122530571167647

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9764] Loss: 0.46123498598864254

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9789] Loss: 0.46124511573726423

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9814] Loss: 0.4612293528347918

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9839] Loss: 0.4612394336092372

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9864] Loss: 0.46123685618129073

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9889] Loss: 0.4612114322482631

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9914] Loss: 0.4611750698310767

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9939] Loss: 0.46115361922989145

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9964] Loss: 0.46117480657321475

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 9989] Loss: 0.46112689687359787

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10014] Loss: 0.461179988795832

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10039] Loss: 0.4612038519875565

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10064] Loss: 0.46121344237773837

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10089] Loss: 0.46116657921280724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10114] Loss: 0.46114585412372255

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10139] Loss: 0.4611113658547723

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10164] Loss: 0.46113008055298255

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10189] Loss: 0.4611742730415735

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10214] Loss: 0.4611495161972081

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10239] Loss: 0.46115120919400837

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10264] Loss: 0.4611405402088597

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10289] Loss: 0.46110996350442607

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10314] Loss: 0.4610651536529638

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10339] Loss: 0.461085576407166

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10364] Loss: 0.4610936978498072

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10389] Loss: 0.46106195800867833

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8442
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10414] Loss: 0.46108878877639287

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10439] Loss: 0.461063545891443

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10464] Loss: 0.46102858592084606

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10489] Loss: 0.46100606706870373

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10514] Loss: 0.4609868275071259

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10539] Loss: 0.4609789789589832

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10564] Loss: 0.46101667897495147

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10589] Loss: 0.4609961240847046

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10614] Loss: 0.4609916076341329

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10639] Loss: 0.4610225324450184

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10664] Loss: 0.4610013900881226

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10689] Loss: 0.4609823149175035

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10714] Loss: 0.46096504155662554

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10739] Loss: 0.46096646203199504

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10764] Loss: 0.4609523548427155

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10789] Loss: 0.4609726964770779

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10814] Loss: 0.4609396604992054

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10839] Loss: 0.4609099041932494

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10864] Loss: 0.4608566009970717

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10889] Loss: 0.46082971441063697

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10914] Loss: 0.4608724401641659

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10939] Loss: 0.4608303488217744

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10964] Loss: 0.4607507363655538

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 10989] Loss: 0.46077693304914363

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11014] Loss: 0.4607810899899892

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11039] Loss: 0.46075757292573805

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11064] Loss: 0.4607805468287715

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11089] Loss: 0.4607946405295907

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11114] Loss: 0.46078043841871974

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11139] Loss: 0.4607962030623484

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11164] Loss: 0.4607916955194205

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11189] Loss: 0.46076532375830953

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11214] Loss: 0.460714060444032

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11239] Loss: 0.46075983640923496

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11264] Loss: 0.4607948210665419

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11289] Loss: 0.46078208809681914

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11314] Loss: 0.46077272474368786

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11339] Loss: 0.4607570403821072

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11364] Loss: 0.46076778467096313

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11389] Loss: 0.46075273585582843

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8431
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11414] Loss: 0.4607406500244633

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11439] Loss: 0.46073287759894915

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11464] Loss: 0.4607942193431839

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11489] Loss: 0.46076826894494666

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11514] Loss: 0.460754823423401

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11539] Loss: 0.4607591201810695

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11564] Loss: 0.46073099254512745

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11589] Loss: 0.4607172644324783

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11614] Loss: 0.4607073962634863

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11639] Loss: 0.460686966211141

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11664] Loss: 0.46066387429284233

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11689] Loss: 0.46064938007161293

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11714] Loss: 0.46065229479045866

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11739] Loss: 0.4606489705945433

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11764] Loss: 0.4606632446602087

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11789] Loss: 0.4606476721792261

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11814] Loss: 0.4606760088564282

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11839] Loss: 0.4607228157006547

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11864] Loss: 0.4607726465886624

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11889] Loss: 0.46076364018528565

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11914] Loss: 0.46072535981689167

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11939] Loss: 0.4606784082985523

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11964] Loss: 0.46071915799472746

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 11989] Loss: 0.4606879755766212

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12014] Loss: 0.4607537874114744

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12039] Loss: 0.460735608931575

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12064] Loss: 0.46073785930125266

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12089] Loss: 0.460728638081124

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12114] Loss: 0.4607477607614825

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12139] Loss: 0.46074692854354266

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12164] Loss: 0.46073144362343893

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12189] Loss: 0.46075651658072436

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12214] Loss: 0.4607304785880745

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12239] Loss: 0.46074336130735133

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12264] Loss: 0.4607250461310655

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12289] Loss: 0.46076089573594603

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12314] Loss: 0.4607326185487186

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12339] Loss: 0.4607475593700986

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12364] Loss: 0.4607326351918958

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12389] Loss: 0.460723570137339

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8461
Using max F1-Score threshold, the confusion matrix is:
 [[69 31]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12414] Loss: 0.4607161269432006

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12439] Loss: 0.46067012271635144

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12464] Loss: 0.46062740827020204

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12489] Loss: 0.4605989874208241

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12514] Loss: 0.4605543184740509

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12539] Loss: 0.4606020854751652

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12564] Loss: 0.4605831189874875

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12589] Loss: 0.4605362088871637

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12614] Loss: 0.4605189985081754

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12639] Loss: 0.4605034628695454

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12664] Loss: 0.4605074914143414

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12689] Loss: 0.4605204897058929

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12714] Loss: 0.4605365317240045

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12739] Loss: 0.46052508838830325

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12764] Loss: 0.46052210478886507

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12789] Loss: 0.4605266576810903

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12814] Loss: 0.4605180056684902

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12839] Loss: 0.46053384159054694

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12864] Loss: 0.4605530928958952

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12889] Loss: 0.46053931383178365

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12914] Loss: 0.460482982497455

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12939] Loss: 0.4605053997063122

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12964] Loss: 0.46050013087331143

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 12989] Loss: 0.46046764183972877

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13014] Loss: 0.4604255235785817

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13039] Loss: 0.4603956068328139

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13064] Loss: 0.4604312305330285

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13089] Loss: 0.46041957987028603

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13114] Loss: 0.4604144934107167

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13139] Loss: 0.4604255038488092

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13164] Loss: 0.46039826780696547

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13189] Loss: 0.4603815369310144

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13214] Loss: 0.46035867997027996

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13239] Loss: 0.4603845369388922

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13264] Loss: 0.4604448430207086

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13289] Loss: 0.46043563255765113

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13314] Loss: 0.460477538422157

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13339] Loss: 0.4604668508955158

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13364] Loss: 0.46048303196006124

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13389] Loss: 0.4604953853320953

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.845
Using max F1-Score threshold, the confusion matrix is:
 [[69 31]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13414] Loss: 0.46050165244416164

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13439] Loss: 0.46047225801649155

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13464] Loss: 0.4604687871400994

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13489] Loss: 0.4604939083078444

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13514] Loss: 0.46049414350512824

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13539] Loss: 0.4604759506261883

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13564] Loss: 0.4604820240178253

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13589] Loss: 0.4604569386114404

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13614] Loss: 0.46041809772289266

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13639] Loss: 0.46040616353049674

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13664] Loss: 0.46035822200158977

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13689] Loss: 0.46037142919121504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13714] Loss: 0.4603803173405579

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13739] Loss: 0.4603910999923454

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13764] Loss: 0.4603657271049943

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13789] Loss: 0.4603224196491704

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13814] Loss: 0.4603519962288277

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13839] Loss: 0.4603419277907877

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13864] Loss: 0.4604075854057352

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13889] Loss: 0.4603435674206477

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13914] Loss: 0.4603382013409332

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13939] Loss: 0.4603288187251089

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13964] Loss: 0.46029706719425595

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 13989] Loss: 0.46029334146847495

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14014] Loss: 0.4602331071011663

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14039] Loss: 0.4602694779923496

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14064] Loss: 0.46027955563232237

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14089] Loss: 0.46029385525661554

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14114] Loss: 0.4602725064401189

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14139] Loss: 0.46029473200660975

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14164] Loss: 0.460252979212162

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14189] Loss: 0.46022966606499427

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14214] Loss: 0.4601621136477159

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14239] Loss: 0.4601357763079582

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14264] Loss: 0.46010864391027123

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14289] Loss: 0.4600933530578778

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14314] Loss: 0.4600811425354007

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14339] Loss: 0.46005492319434105

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14364] Loss: 0.4600605596638088

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14389] Loss: 0.46004439012123716

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8448000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14414] Loss: 0.4599776865993791

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14439] Loss: 0.4599934121154128

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14464] Loss: 0.45993561733269056

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14489] Loss: 0.45990657932095536

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14514] Loss: 0.459911945345698

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14539] Loss: 0.4599334110391091

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14564] Loss: 0.46000300542888606

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14589] Loss: 0.4600009970405516

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14614] Loss: 0.45999045403390343

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14639] Loss: 0.46000155136357457

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14664] Loss: 0.4599694839109327

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14689] Loss: 0.459938142801968

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14714] Loss: 0.45991870898529436

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14739] Loss: 0.45989166885225236

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14764] Loss: 0.45983688204925993

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14789] Loss: 0.45982077420616646

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14814] Loss: 0.4597965913542851

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14839] Loss: 0.4598085510877249

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14864] Loss: 0.4597911401700126

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14889] Loss: 0.4597466662591095

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14914] Loss: 0.4597576469315962

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14939] Loss: 0.4597470699544171

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14964] Loss: 0.45968651417821

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 14989] Loss: 0.45967114614797655

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15014] Loss: 0.4596987440640656

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15039] Loss: 0.45968025537068957

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15064] Loss: 0.4596375089093717

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15089] Loss: 0.4596331315237055

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15114] Loss: 0.45960340574606734

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15139] Loss: 0.4595976487856236

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15164] Loss: 0.45960762314892506

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15189] Loss: 0.4596281630328978

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15214] Loss: 0.4596488617244271

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15239] Loss: 0.45965530904010027

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15264] Loss: 0.4596953871037558

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15289] Loss: 0.4596909700079258

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15314] Loss: 0.45966519819945784

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15339] Loss: 0.45970293302274184

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15364] Loss: 0.45972032170834776

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15389] Loss: 0.45967835683936903

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8430999999999998
Using max F1-Score threshold, the confusion matrix is:
 [[67 33]
 [14 86]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15414] Loss: 0.4597573262014178

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15439] Loss: 0.4597471127707045

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15464] Loss: 0.459736255199356

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15489] Loss: 0.4597222431908535

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15514] Loss: 0.4597276451796162

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15539] Loss: 0.4597157205088731

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15564] Loss: 0.45976565783727225

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15589] Loss: 0.45977561063193384

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15614] Loss: 0.4597883466292476

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15639] Loss: 0.45979732607199475

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15664] Loss: 0.45980674474061883

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15689] Loss: 0.45983661060874736

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15714] Loss: 0.45978983808560775

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15739] Loss: 0.45977166484579773

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15764] Loss: 0.45973187444601815

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15789] Loss: 0.4597732714173157

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15814] Loss: 0.4598165455255068

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15839] Loss: 0.4597791296633448

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15864] Loss: 0.4597478497823824

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15889] Loss: 0.45976152782645086

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15914] Loss: 0.45976485875114487

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15939] Loss: 0.4597413714462371

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15964] Loss: 0.45975649007713654

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 15989] Loss: 0.4597968493186482

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16014] Loss: 0.4597958823701459

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16039] Loss: 0.4597501612317637

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16064] Loss: 0.4597136224185706

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16089] Loss: 0.45966529919678567

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16114] Loss: 0.4596709189295256

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16139] Loss: 0.4596448533495194

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16164] Loss: 0.45966125493655846

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16189] Loss: 0.45965117382157356

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16214] Loss: 0.4596353069211686

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16239] Loss: 0.45962308957251774

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16264] Loss: 0.45960631598803187

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16289] Loss: 0.4596148513818983

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16314] Loss: 0.4595770582591683

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16339] Loss: 0.4595262228815935

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16364] Loss: 0.459510989498721

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16389] Loss: 0.45951025402549917

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8444
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16414] Loss: 0.4595091716750242

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16439] Loss: 0.4595342371489745

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16464] Loss: 0.45952709183361534

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16489] Loss: 0.45950164751269074

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16514] Loss: 0.4594761281943709

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16539] Loss: 0.45944239012435417

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16564] Loss: 0.4594523951826993

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16589] Loss: 0.4594741312355647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16614] Loss: 0.45948157036669696

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16639] Loss: 0.4594562408162986

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16664] Loss: 0.4594701428555358

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16689] Loss: 0.4594495235289874

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16714] Loss: 0.45944760761259057

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16739] Loss: 0.4594035490650221

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16764] Loss: 0.4593855317569492

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16789] Loss: 0.4593588377650314

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16814] Loss: 0.4593629611149221

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16839] Loss: 0.4593395466983091

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16864] Loss: 0.45932006489602467

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16889] Loss: 0.4592883468806755

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16914] Loss: 0.45929282281663136

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16939] Loss: 0.45927657038604436

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16964] Loss: 0.4592727257922317

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 16989] Loss: 0.45924422605923865

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17014] Loss: 0.4592542452279683

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17039] Loss: 0.45925455514826313

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17064] Loss: 0.4592909605414869

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17089] Loss: 0.4592672833934009

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17114] Loss: 0.4592075391530031

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17139] Loss: 0.45924740379055323

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17164] Loss: 0.4592756854451692

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17189] Loss: 0.45927737217685055

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17214] Loss: 0.45929562738461177

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17239] Loss: 0.45926019164012505

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17264] Loss: 0.4592526061851853

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17289] Loss: 0.45927156771558214

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17314] Loss: 0.45927866983475946

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17339] Loss: 0.45932174004128007

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17364] Loss: 0.4593197436056822

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17389] Loss: 0.4593690030668769

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8425
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17414] Loss: 0.4594389353470926

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17439] Loss: 0.4594419761646427

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17464] Loss: 0.45940621652183083

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17489] Loss: 0.45942733203297037

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17514] Loss: 0.4594434752688805

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17539] Loss: 0.45943342123574465

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17564] Loss: 0.4594073526084715

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17589] Loss: 0.45940348721319224

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17614] Loss: 0.45937429450733813

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17639] Loss: 0.4593419041036842

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17664] Loss: 0.4593766736880723

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17689] Loss: 0.45937955594169255

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17714] Loss: 0.4593588901805797

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17739] Loss: 0.45936069649785116

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17764] Loss: 0.45935727566989815

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17789] Loss: 0.4593722969847607

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17814] Loss: 0.4593862898728477

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17839] Loss: 0.45934847855669925

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17864] Loss: 0.4593289339623226

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17889] Loss: 0.45933570935352785

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17914] Loss: 0.45932839261354064

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17939] Loss: 0.4593469467029166

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17964] Loss: 0.45934507849085876

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 17989] Loss: 0.4593729527046504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18014] Loss: 0.4593229562645398

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18039] Loss: 0.45933922715694553

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18064] Loss: 0.4593232131440988

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18089] Loss: 0.459357040537703

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18114] Loss: 0.45932652016448283

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18139] Loss: 0.4593297740783638

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18164] Loss: 0.4593099264109671

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18189] Loss: 0.4592710791783582

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18214] Loss: 0.459276134025191

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18239] Loss: 0.4592481268444542

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18264] Loss: 0.4592201307379528

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18289] Loss: 0.4591964759940154

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18314] Loss: 0.4591804807418289

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18339] Loss: 0.4591937184966747

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18364] Loss: 0.45918404800572615

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18389] Loss: 0.45915112693809074

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8393
Using max F1-Score threshold, the confusion matrix is:
 [[72 28]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18414] Loss: 0.4591772490939195

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18439] Loss: 0.4591511169444085

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18464] Loss: 0.45913173530278095

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18489] Loss: 0.4590907499970922

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18514] Loss: 0.45911486101797905

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18539] Loss: 0.4591001189470057

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18564] Loss: 0.45908793891532645

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18589] Loss: 0.4590584844354043

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18614] Loss: 0.45905962014540336

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18639] Loss: 0.45904892164058514

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18664] Loss: 0.45905368412808656

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18689] Loss: 0.4590547125792048

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18714] Loss: 0.45908477270931913

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18739] Loss: 0.45905484990156437

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18764] Loss: 0.4590626363665734

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18789] Loss: 0.459140235734403

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18814] Loss: 0.45915288113673863

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18839] Loss: 0.4591611509109807

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18864] Loss: 0.4591472104097874

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18889] Loss: 0.45912375610500455

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18914] Loss: 0.4591531081473388

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18939] Loss: 0.4591424135923504

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18964] Loss: 0.459150535248805

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 18989] Loss: 0.45918785166767095

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19014] Loss: 0.4591699932695698

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19039] Loss: 0.45916440261341807

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19064] Loss: 0.4591345486780475

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19089] Loss: 0.459148288352202

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19114] Loss: 0.4591400020968261

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19139] Loss: 0.45914014513082513

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19164] Loss: 0.45911237699097424

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19189] Loss: 0.45914697590926074

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19214] Loss: 0.4591471090578439

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19239] Loss: 0.45918956118656357

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19264] Loss: 0.4591201687670573

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19289] Loss: 0.4591375870141851

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19314] Loss: 0.4591467946815019

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19339] Loss: 0.4591280795964432

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19364] Loss: 0.4591733155573985

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19389] Loss: 0.4591360622632859

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8434999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19414] Loss: 0.4591228840994657

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19439] Loss: 0.45914177554549496

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19464] Loss: 0.4591578318339215

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19489] Loss: 0.4591526137834832

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19514] Loss: 0.45914540090738304

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19539] Loss: 0.4591804538653253

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19564] Loss: 0.4591959472532726

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19589] Loss: 0.4592072939501563

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19614] Loss: 0.4591988523413269

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19639] Loss: 0.4591964868062746

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19664] Loss: 0.45914193857103447

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19689] Loss: 0.45915431363939035

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19714] Loss: 0.4591374902213871

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19739] Loss: 0.4591393947358743

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19764] Loss: 0.4591155518771972

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19789] Loss: 0.45906602167161903

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19814] Loss: 0.4590734205657878

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19839] Loss: 0.4590818530542948

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19864] Loss: 0.45907102365281716

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19889] Loss: 0.4590924221694895

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19914] Loss: 0.45908748273446065

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19939] Loss: 0.4590401759410233

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19964] Loss: 0.4589863411697753

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 19989] Loss: 0.4590218843633184

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20014] Loss: 0.45902365639681275

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20039] Loss: 0.45899156275299924

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20064] Loss: 0.45897762590326857

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20089] Loss: 0.4589632584837485

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20114] Loss: 0.4590332479395316

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20139] Loss: 0.4590140020436172

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20164] Loss: 0.45901944451814264

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20189] Loss: 0.45900942390629784

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20214] Loss: 0.4590206714542813

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20239] Loss: 0.4589919961063301

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20264] Loss: 0.45900797525993037

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20289] Loss: 0.4590129393145974

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20314] Loss: 0.4589963742559445

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20339] Loss: 0.4589487371565175

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20364] Loss: 0.45896874328623183

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20389] Loss: 0.45896693981775105

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8416
Using max F1-Score threshold, the confusion matrix is:
 [[72 28]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20414] Loss: 0.4589773885015716

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20439] Loss: 0.45898348330649197

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20464] Loss: 0.4590350445629445

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20489] Loss: 0.4590113709973078

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20514] Loss: 0.45898970638998704

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20539] Loss: 0.45897849338022845

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20564] Loss: 0.45898299040955215

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20589] Loss: 0.4589887332165021

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20614] Loss: 0.45896733755174207

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20639] Loss: 0.45895052688257426

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20664] Loss: 0.45893257427443723

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20689] Loss: 0.45893922005858573

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20714] Loss: 0.45894793847321147

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20739] Loss: 0.4589805190857748

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20764] Loss: 0.4589376452218612

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20789] Loss: 0.4589289833860822

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20814] Loss: 0.45892812503484426

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20839] Loss: 0.45892236037306444

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20864] Loss: 0.45894143925868486

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20889] Loss: 0.4589367152020517

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20914] Loss: 0.4589163120384054

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20939] Loss: 0.45891610298828994

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20964] Loss: 0.45891121744673113

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 20989] Loss: 0.4588843736466185

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21014] Loss: 0.4589168664118085

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21039] Loss: 0.45891541512032014

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21064] Loss: 0.4588883249377976

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21089] Loss: 0.45887996079002485

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21114] Loss: 0.45890111746796736

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21139] Loss: 0.45889832157449423

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21164] Loss: 0.4588674223433442

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21189] Loss: 0.4588425867806612

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21214] Loss: 0.45889024056720906

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21239] Loss: 0.45892145067364826

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21264] Loss: 0.4589057351874089

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21289] Loss: 0.45891250590528865

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21314] Loss: 0.4589183801445549

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21339] Loss: 0.458902605945178

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21364] Loss: 0.4588962329858995

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21389] Loss: 0.4589044629577534

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.844
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [11 89]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21414] Loss: 0.45889985000724953

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21439] Loss: 0.45886991575051933

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21464] Loss: 0.45886478629758626

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21489] Loss: 0.45886472407467505

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21514] Loss: 0.4588614468566334

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21539] Loss: 0.45882834251133175

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21564] Loss: 0.4588272393607424

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21589] Loss: 0.4588272058929096

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21614] Loss: 0.458793759977087

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21639] Loss: 0.45880181169631135

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21664] Loss: 0.4587804873792613

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21689] Loss: 0.45874300678314006

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21714] Loss: 0.45875644916799385

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21739] Loss: 0.45879758744397175

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21764] Loss: 0.4587840814143501

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21789] Loss: 0.4587917074243358

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21814] Loss: 0.45878762151907737

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21839] Loss: 0.4587236991479738

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21864] Loss: 0.4587125844747494

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21889] Loss: 0.45868538433158085

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21914] Loss: 0.4587070232470921

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21939] Loss: 0.4586554557124355

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21964] Loss: 0.4587271804630562

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 21989] Loss: 0.45870324333746604

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22014] Loss: 0.45864860894715653

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22039] Loss: 0.45859725158359893

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22064] Loss: 0.4586073595702864

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22089] Loss: 0.4586281900297609

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22114] Loss: 0.45862046313290694

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22139] Loss: 0.4586390332758813

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22164] Loss: 0.45863380791150943

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22189] Loss: 0.4586808742243363

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22214] Loss: 0.4586451276882274

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22239] Loss: 0.4586513451552712

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22264] Loss: 0.4586656667143568

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22289] Loss: 0.4586621896083307

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22314] Loss: 0.4586604560845755

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22339] Loss: 0.4586523542184115

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22364] Loss: 0.4586736794602707

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22389] Loss: 0.45868455484099746

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.845
Using max F1-Score threshold, the confusion matrix is:
 [[65 35]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22414] Loss: 0.4586837462969787

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22439] Loss: 0.45865807959209737

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22464] Loss: 0.458656282308029

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22489] Loss: 0.4586519966276058

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22514] Loss: 0.4586458159179094

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22539] Loss: 0.45868252058458525

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22564] Loss: 0.458647151380768

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22589] Loss: 0.45859104706342757

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22614] Loss: 0.45861263635320215

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22639] Loss: 0.4586139796812766

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22664] Loss: 0.4585855951399172

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22689] Loss: 0.4586151152432406

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22714] Loss: 0.4586095486248663

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22739] Loss: 0.45861869005931166

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22764] Loss: 0.45864719805746984

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22789] Loss: 0.4586659983539546

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22814] Loss: 0.4586381049005311

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22839] Loss: 0.45867794110689664

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22864] Loss: 0.45870774753715443

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22889] Loss: 0.45870545757967013

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22914] Loss: 0.4586760508268477

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22939] Loss: 0.4586337220059755

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22964] Loss: 0.45869570783538566

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 22989] Loss: 0.45870304272749934

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23014] Loss: 0.4586901164194351

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23039] Loss: 0.458700014512544

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23064] Loss: 0.45868832291798634

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23089] Loss: 0.45860999182940765

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23114] Loss: 0.4586671535236781

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23139] Loss: 0.45864088475651904

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23164] Loss: 0.4586511579402329

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23189] Loss: 0.4586765796827503

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23214] Loss: 0.4586636946720448

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23239] Loss: 0.4586493727706531

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23264] Loss: 0.4586445111101753

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23289] Loss: 0.458679089255043

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23314] Loss: 0.4586653325370583

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23339] Loss: 0.458669150039767

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23364] Loss: 0.4586747286295624

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23389] Loss: 0.45870225163965156

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8449
Using max F1-Score threshold, the confusion matrix is:
 [[54 46]
 [ 6 94]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23414] Loss: 0.45868426376853283

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23439] Loss: 0.4586740069421061

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23464] Loss: 0.45873126530365876

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23489] Loss: 0.45872775209905203

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23514] Loss: 0.45872627164635116

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23539] Loss: 0.45871163469057097

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23564] Loss: 0.458718079374851

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23589] Loss: 0.45870342786216495

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23614] Loss: 0.458731283532549

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23639] Loss: 0.4586880900928041

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23664] Loss: 0.4586558315161055

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23689] Loss: 0.45870754262519225

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23714] Loss: 0.4587361351754004

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23739] Loss: 0.4587132664165637

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23764] Loss: 0.4587751215936015

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23789] Loss: 0.458755726021812

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23814] Loss: 0.4587252754403992

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23839] Loss: 0.4587516482046099

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23864] Loss: 0.458752025164285

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23889] Loss: 0.4587683010532056

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23914] Loss: 0.45880277065554514

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23939] Loss: 0.4587912770586224

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23964] Loss: 0.4587601485645773

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 23989] Loss: 0.4587605438551322

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24014] Loss: 0.45877023192661753

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24039] Loss: 0.45878770743344716

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24064] Loss: 0.4587476526693304

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24089] Loss: 0.45868721023677794

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24114] Loss: 0.45866974126852283

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24139] Loss: 0.45862946110344993

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24164] Loss: 0.45860319145627443

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24189] Loss: 0.45864144051472633

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24214] Loss: 0.4586632413944215

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24239] Loss: 0.45867675892604165

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24264] Loss: 0.4586807200217353

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24289] Loss: 0.4586370979273899

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24314] Loss: 0.4586290125757295

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24339] Loss: 0.4586242699839933

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24364] Loss: 0.4586376945188561

CUDA Memory Allocated: 9090220032
[Epoch 6, Batch 24389] Loss: 0.45862259480790724

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8422000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[66 34]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 6] Loss: 0.4586013411084537

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 31] Loss: 0.45857716261230264

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 56] Loss: 0.4585427821342507

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 81] Loss: 0.45853406134231284

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 106] Loss: 0.458519426606249

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 131] Loss: 0.4584811785241088

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 156] Loss: 0.45848535838562776

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 181] Loss: 0.4584663797707415

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 206] Loss: 0.45847687244031804

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 231] Loss: 0.45846308700874605

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 256] Loss: 0.4583957597090782

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 281] Loss: 0.45834954022594004

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 306] Loss: 0.4583267736960632

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 331] Loss: 0.45834657297267634

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 356] Loss: 0.45830415113915923

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 381] Loss: 0.4583196318874079

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 406] Loss: 0.45829506143980775

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 431] Loss: 0.4582761435464845

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 456] Loss: 0.4582373809125788

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 481] Loss: 0.4582328959030618

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 506] Loss: 0.4582147449064366

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 531] Loss: 0.4582423176545622

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 556] Loss: 0.45820020588673943

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 581] Loss: 0.4582066575185675

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 606] Loss: 0.45817708663006945

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 631] Loss: 0.458146765222502

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 656] Loss: 0.4581686681543394

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 681] Loss: 0.45815596969514294

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 706] Loss: 0.4581636627322693

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 731] Loss: 0.4581983953024514

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 756] Loss: 0.4581868509775535

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 781] Loss: 0.45823282959992573

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 806] Loss: 0.45825617437819127

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 831] Loss: 0.4582462551367278

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 856] Loss: 0.4582967225843041

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 881] Loss: 0.4582674813833075

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 906] Loss: 0.45822495887895515

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 931] Loss: 0.4582361448894537

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 956] Loss: 0.4581847485926363

CUDA Memory Allocated: 9090220032
[Epoch 7, Batch 981] Loss: 0.4581867858100174

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

