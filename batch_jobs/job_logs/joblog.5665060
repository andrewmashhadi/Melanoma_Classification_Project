Job 5665060 started on:    g6
Job 5665060 started on:    Wed Jan 4 09:32:53 PST 2023
 
Device: cuda:0
Number of devices: 2
Loading the pre-trained CNN weights.
CUDA Memory Allocated: 20931072
CUDA Memory Allocated: 8802686464
[Epoch 0, Batch 2205] Loss: 0.7006869912147522

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7201000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[57 43]
 [24 76]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2230] Loss: 0.5702309814783243

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2255] Loss: 0.6004356204294691

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2280] Loss: 0.6198294684290886

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2305] Loss: 0.6148014059751341

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2330] Loss: 0.6173180980341775

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2355] Loss: 0.6231032582308282

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2380] Loss: 0.6300367387858304

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2405] Loss: 0.6302975482905089

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2430] Loss: 0.6309729811892045

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2455] Loss: 0.6357207425324566

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2480] Loss: 0.635514784226383

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2505] Loss: 0.636974638581672

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2530] Loss: 0.6365150439044449

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2555] Loss: 0.6398649412682254

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2580] Loss: 0.6353895052316341

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2605] Loss: 0.6357260051362235

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2630] Loss: 0.6335720951568353

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2655] Loss: 0.6338717932183039

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2680] Loss: 0.6298118373300848

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2705] Loss: 0.628953854540389

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2730] Loss: 0.6272152665676726

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2755] Loss: 0.6285483692713528

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2780] Loss: 0.6268258825358417

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2805] Loss: 0.6249145880316735

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2830] Loss: 0.6220401447421064

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2855] Loss: 0.6221129766990146

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2880] Loss: 0.6246318542040311

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2905] Loss: 0.6242837405919008

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2930] Loss: 0.6220028972658572

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2955] Loss: 0.6226203107881483

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 2980] Loss: 0.6228036987643266

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3005] Loss: 0.6214711978268832

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3030] Loss: 0.6210746582931237

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3055] Loss: 0.6211088403761738

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3080] Loss: 0.6250189320613805

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3105] Loss: 0.6281114084011442

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3130] Loss: 0.6301815532003057

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3155] Loss: 0.6319256260380007

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3180] Loss: 0.6334535887190065

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3205] Loss: 0.6347603763078714

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.50205
Using max F1-Score threshold, the confusion matrix is:
 [[ 91   9]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3230] Loss: 0.6363203748334454

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3255] Loss: 0.6372975903562316

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3280] Loss: 0.6380952761463516

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3305] Loss: 0.6393365361655874

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3330] Loss: 0.6398665186937494

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3355] Loss: 0.6394227759461109

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3380] Loss: 0.6403941797206596

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3405] Loss: 0.6400637979263271

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3430] Loss: 0.6390811312354214

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3455] Loss: 0.6396990821277686

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3480] Loss: 0.6394907177241992

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3505] Loss: 0.6391637426307805

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3530] Loss: 0.6387914436704972

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3555] Loss: 0.6368740532991182

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3580] Loss: 0.6367850421473037

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3605] Loss: 0.636675362753749

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3630] Loss: 0.6364385647200267

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3655] Loss: 0.6362094861281321

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3680] Loss: 0.6358201061766645

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3705] Loss: 0.6346752169249774

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3730] Loss: 0.6350738922156013

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3755] Loss: 0.6337367346177633

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3780] Loss: 0.6321812545701029

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3805] Loss: 0.631577352316658

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3830] Loss: 0.6321125728104534

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3855] Loss: 0.6312105073703556

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3880] Loss: 0.6310518051815488

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3905] Loss: 0.6290846104519567

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3930] Loss: 0.6288055412013727

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3955] Loss: 0.6279889789055171

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 3980] Loss: 0.6282989522526125

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4005] Loss: 0.6273645170028841

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4030] Loss: 0.6253441195824844

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4055] Loss: 0.625750072980687

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4080] Loss: 0.6246909563030515

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4105] Loss: 0.6235262349302803

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4130] Loss: 0.6232617817440013

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4155] Loss: 0.6227900148018515

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4180] Loss: 0.6232667994734488

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4205] Loss: 0.6234453538100402

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.6955
Using max F1-Score threshold, the confusion matrix is:
 [[ 99   1]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4230] Loss: 0.6231950803017217

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4255] Loss: 0.623723592774453

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4280] Loss: 0.6241860172939209

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4305] Loss: 0.6236904139804704

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4330] Loss: 0.6229530924883858

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4355] Loss: 0.6231715039063032

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4380] Loss: 0.6228303616209065

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4405] Loss: 0.6225400509643642

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4430] Loss: 0.6215083140541815

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4455] Loss: 0.6219552830424323

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4480] Loss: 0.621008425715309

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4505] Loss: 0.6207837328243546

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4530] Loss: 0.6193041046144423

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4555] Loss: 0.6186136022774223

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4580] Loss: 0.6175054892935236

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4605] Loss: 0.6166243977295464

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4630] Loss: 0.6174664731027661

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4655] Loss: 0.6171886127902653

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4680] Loss: 0.6171664141226855

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4705] Loss: 0.6172425594629168

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4730] Loss: 0.6164310825833799

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4755] Loss: 0.6161351580331953

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4780] Loss: 0.6153595845868683

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4805] Loss: 0.6150678850764818

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4830] Loss: 0.6152580934381631

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4855] Loss: 0.615923600168059

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4880] Loss: 0.6161002631679244

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4905] Loss: 0.6153127494696025

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4930] Loss: 0.6149674700142614

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4955] Loss: 0.6146291851867376

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 4980] Loss: 0.6144885020786816

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5005] Loss: 0.6141769074193497

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5030] Loss: 0.6134735780694935

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5055] Loss: 0.6140097967838664

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5080] Loss: 0.6138643696023377

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5105] Loss: 0.613696227455624

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5130] Loss: 0.6129865087237736

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5155] Loss: 0.6122862690840686

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5180] Loss: 0.6128582866431804

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5205] Loss: 0.6126867841230318

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.7210000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[24 76]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5230] Loss: 0.6124351629488766

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5255] Loss: 0.6117422313758171

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5280] Loss: 0.6119760434846884

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5305] Loss: 0.6114962139040453

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5330] Loss: 0.610848677288014

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5355] Loss: 0.6111963915280106

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5380] Loss: 0.6112778078886664

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5405] Loss: 0.6107800352372292

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5430] Loss: 0.6107821378531252

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5455] Loss: 0.6110185448828568

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5480] Loss: 0.6114089577134713

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5505] Loss: 0.6123176512755036

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5530] Loss: 0.6130255579464563

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5555] Loss: 0.6132618829905898

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5580] Loss: 0.6136210341695079

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5605] Loss: 0.6144902708161687

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5630] Loss: 0.6150048676545482

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5655] Loss: 0.6152642890271226

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5680] Loss: 0.6158249192239912

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5705] Loss: 0.6161287668108157

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5730] Loss: 0.6164376434874819

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5755] Loss: 0.616999435226738

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5780] Loss: 0.6174215716653623

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5805] Loss: 0.6177346307563967

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5830] Loss: 0.6181653554079221

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5855] Loss: 0.6184149316584238

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5880] Loss: 0.618514649229483

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5905] Loss: 0.6187907717608658

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5930] Loss: 0.619203489607723

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5955] Loss: 0.6191724604112375

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 5980] Loss: 0.6192790116735939

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6005] Loss: 0.6193402453853217

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6030] Loss: 0.6195568075930331

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6055] Loss: 0.6192920472646063

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6080] Loss: 0.6199649921603986

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6105] Loss: 0.6200584082290534

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6130] Loss: 0.6200084380740969

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6155] Loss: 0.6203297578256602

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6180] Loss: 0.6206646398594322

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6205] Loss: 0.6206434403127863

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7561
Using max F1-Score threshold, the confusion matrix is:
 [[38 62]
 [ 8 92]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6230] Loss: 0.6206922780072813

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6255] Loss: 0.620392564136992

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6280] Loss: 0.6201287538281133

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6305] Loss: 0.6203271734426732

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6330] Loss: 0.6200635692360212

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6355] Loss: 0.6199902018002216

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6380] Loss: 0.6200810693832421

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6405] Loss: 0.6198019272541608

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6430] Loss: 0.6195881911119295

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6455] Loss: 0.6192634472445133

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6480] Loss: 0.6188379540879164

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6505] Loss: 0.6186132377433211

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6530] Loss: 0.6179332826329611

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6555] Loss: 0.6181596353208298

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6580] Loss: 0.617845756575547

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6605] Loss: 0.6172999810953081

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6630] Loss: 0.6167335715287959

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6655] Loss: 0.6166265666170138

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6680] Loss: 0.616572006784506

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6705] Loss: 0.616628721048503

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6730] Loss: 0.6163002759270894

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6755] Loss: 0.6162760620967448

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6780] Loss: 0.6155036603869102

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6805] Loss: 0.6150542685899287

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6830] Loss: 0.6152697714714843

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6855] Loss: 0.6144072675968955

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6880] Loss: 0.6138170277452857

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6905] Loss: 0.6140543956739856

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6930] Loss: 0.6138436005175291

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6955] Loss: 0.613516882670425

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 6980] Loss: 0.6132111353659301

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7005] Loss: 0.6130184924830946

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7030] Loss: 0.6128233999131233

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7055] Loss: 0.6121684159677291

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7080] Loss: 0.6116648061633403

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7105] Loss: 0.6109730007818246

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7130] Loss: 0.6107326293991099

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7155] Loss: 0.6110747327794452

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7180] Loss: 0.6106645648825878

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7205] Loss: 0.6106545580128292

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.767
Using max F1-Score threshold, the confusion matrix is:
 [[70 30]
 [25 75]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7230] Loss: 0.6115486748068872

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7255] Loss: 0.6115822923600001

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7280] Loss: 0.6114801707155738

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7305] Loss: 0.6109068073453541

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7330] Loss: 0.6107319535697013

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7355] Loss: 0.6102432748532439

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7380] Loss: 0.6100564842793221

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7405] Loss: 0.6098382137006715

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7430] Loss: 0.6096477890055708

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7455] Loss: 0.6096438479165853

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7480] Loss: 0.6096896382050139

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7505] Loss: 0.6092512653787459

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7530] Loss: 0.6087312813969962

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7555] Loss: 0.6086997866290815

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7580] Loss: 0.6084115166810252

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7605] Loss: 0.6082896390870156

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7630] Loss: 0.6082865910702775

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7655] Loss: 0.6079863393182078

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7680] Loss: 0.6074329483805128

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7705] Loss: 0.607031596539086

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7730] Loss: 0.60659937239129

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7755] Loss: 0.606215627048278

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7780] Loss: 0.6057338248965046

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7805] Loss: 0.6055874217223789

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7830] Loss: 0.6054414097011789

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7855] Loss: 0.6053512291035131

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7880] Loss: 0.6047179007862049

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7905] Loss: 0.6047126603749128

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7930] Loss: 0.6047132156784099

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7955] Loss: 0.6046523397250437

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 7980] Loss: 0.60447417161817

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8005] Loss: 0.6044045025468324

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8030] Loss: 0.6041071170469738

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8055] Loss: 0.6039847360232756

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8080] Loss: 0.6036621201098716

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8105] Loss: 0.6033193482898227

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8130] Loss: 0.6033829362434971

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8155] Loss: 0.603488737492226

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8180] Loss: 0.6043842096776867

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8205] Loss: 0.604567480364644

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.6470499999999999
Using max F1-Score threshold, the confusion matrix is:
 [[100   0]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8230] Loss: 0.604918553719252

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8255] Loss: 0.6053194512802892

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8280] Loss: 0.6056907850135562

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8305] Loss: 0.6059312512409666

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8330] Loss: 0.6060709226651496

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8355] Loss: 0.6063727358662875

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8380] Loss: 0.6066747961983259

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8405] Loss: 0.6068267073927436

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8430] Loss: 0.6069119497978089

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8455] Loss: 0.6070320272177262

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8480] Loss: 0.6072114483863496

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8505] Loss: 0.607071989658588

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8530] Loss: 0.6072851546895474

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8555] Loss: 0.6074092407075744

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8580] Loss: 0.6074755949726611

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8605] Loss: 0.6075649821728938

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8630] Loss: 0.6073295775658332

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8655] Loss: 0.6073912977721871

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8680] Loss: 0.6072251224778754

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8705] Loss: 0.6070726081394284

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8730] Loss: 0.6067078240909918

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8755] Loss: 0.6066559647668993

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8780] Loss: 0.6065792304490877

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8805] Loss: 0.6062483441261266

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8830] Loss: 0.6061517853889172

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8855] Loss: 0.6061565474038679

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8880] Loss: 0.6058205175060062

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8905] Loss: 0.605227409476861

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8930] Loss: 0.605073225129769

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8955] Loss: 0.6049807101251937

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 8980] Loss: 0.6045887558286682

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9005] Loss: 0.6043118933058805

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9030] Loss: 0.6042871315194878

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9055] Loss: 0.6041646890212821

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9080] Loss: 0.6037164702957335

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9105] Loss: 0.6036990329022943

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9130] Loss: 0.6037810814381076

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9155] Loss: 0.6035096957302063

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9180] Loss: 0.6030499817506589

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9205] Loss: 0.6033649174449972

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.8034
Using max F1-Score threshold, the confusion matrix is:
 [[100   0]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9230] Loss: 0.6031904366506815

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9255] Loss: 0.6031710147559685

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9280] Loss: 0.6033732764698763

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9305] Loss: 0.6032226440984504

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9330] Loss: 0.6031585607584644

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9355] Loss: 0.603351164921241

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9380] Loss: 0.6031513399742502

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9405] Loss: 0.6029727213936222

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9430] Loss: 0.6031522743502895

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9455] Loss: 0.6029412395725036

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9480] Loss: 0.6026616681125496

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9505] Loss: 0.602671047916781

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9530] Loss: 0.6026897649899828

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9555] Loss: 0.6027211155111474

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9580] Loss: 0.6026526839157199

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9605] Loss: 0.6026104161949467

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9630] Loss: 0.6023751265032494

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9655] Loss: 0.6021388228850194

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9680] Loss: 0.601572586552361

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9705] Loss: 0.6015311065282032

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9730] Loss: 0.6013191894039318

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9755] Loss: 0.601476914292652

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9780] Loss: 0.6013801146166865

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9805] Loss: 0.6015773403440285

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9830] Loss: 0.6015189397115814

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9855] Loss: 0.6013521103385835

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9880] Loss: 0.6007503832526866

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9905] Loss: 0.6006144845838625

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9930] Loss: 0.600842229869586

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9955] Loss: 0.6004031515612847

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 9980] Loss: 0.6003418611650022

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10005] Loss: 0.6003627118419003

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10030] Loss: 0.6005636986022315

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10055] Loss: 0.6004102271846898

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10080] Loss: 0.6001436277966683

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10105] Loss: 0.5999057500924571

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10130] Loss: 0.5998870919456453

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10155] Loss: 0.599570145743131

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10180] Loss: 0.5991872375571321

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10205] Loss: 0.5987225340677192

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.7953999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[41 59]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10230] Loss: 0.5987224778944407

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10255] Loss: 0.5983080908558025

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10280] Loss: 0.5983973786736727

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10305] Loss: 0.5982435690099965

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10330] Loss: 0.597940860678784

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10355] Loss: 0.5978984920285828

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10380] Loss: 0.5977188940980124

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10405] Loss: 0.5974108447595466

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10430] Loss: 0.5971687027771064

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10455] Loss: 0.596948193471304

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10480] Loss: 0.5964934137816833

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10505] Loss: 0.5963484116240576

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10530] Loss: 0.5960105350901023

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10555] Loss: 0.5958012680668857

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10580] Loss: 0.59546507606523

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10605] Loss: 0.5954583765207877

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10630] Loss: 0.5952135847521994

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10655] Loss: 0.5951535902972928

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10680] Loss: 0.5948753113884333

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10705] Loss: 0.5949568077737816

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10730] Loss: 0.5949624108315326

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10755] Loss: 0.5947116618437309

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10780] Loss: 0.5949061637246502

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10805] Loss: 0.594633008771051

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10830] Loss: 0.5943273637934382

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10855] Loss: 0.5943243449402915

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10880] Loss: 0.594198727252459

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10905] Loss: 0.5940595463919285

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10930] Loss: 0.5936765377888972

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10955] Loss: 0.5935427675824202

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 10980] Loss: 0.5933879156276047

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11005] Loss: 0.5932279316508022

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11030] Loss: 0.5932574892661826

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11055] Loss: 0.5927504947519097

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11080] Loss: 0.5929933244936628

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11105] Loss: 0.5927866545550081

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11130] Loss: 0.5925234647360472

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11155] Loss: 0.5926850070853718

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11180] Loss: 0.5926006418231994

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11205] Loss: 0.5923953372416046

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8122
Using max F1-Score threshold, the confusion matrix is:
 [[100   0]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11230] Loss: 0.5921750010762825

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11255] Loss: 0.5918697379323682

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11280] Loss: 0.5916092291457103

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11305] Loss: 0.5911359154072722

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11330] Loss: 0.5910632081828651

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11355] Loss: 0.5910936117159215

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11380] Loss: 0.5907679518255216

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11405] Loss: 0.5908832909326173

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11430] Loss: 0.5908843606614333

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11455] Loss: 0.5909312868938003

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11480] Loss: 0.5908216461607542

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11505] Loss: 0.590612847367601

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11530] Loss: 0.5904127559359975

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11555] Loss: 0.5904592258461101

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11580] Loss: 0.590033336371301

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11605] Loss: 0.5900788109600164

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11630] Loss: 0.5897774629799957

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11655] Loss: 0.5895120993444982

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11680] Loss: 0.5892858683890767

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11705] Loss: 0.5889157174503492

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11730] Loss: 0.5886642814066583

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11755] Loss: 0.58861532508071

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11780] Loss: 0.5885286454648968

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11805] Loss: 0.5885506301412898

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11830] Loss: 0.5882582269162373

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11855] Loss: 0.5880426524307163

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11880] Loss: 0.5876958391172161

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11905] Loss: 0.5875656663278596

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11930] Loss: 0.5874691819651472

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11955] Loss: 0.5874611522137825

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 11980] Loss: 0.587245019613468

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12005] Loss: 0.5867996477274801

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12030] Loss: 0.5868858772474244

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12055] Loss: 0.5869330612479515

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12080] Loss: 0.5871916552017296

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12105] Loss: 0.5870053748882469

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12130] Loss: 0.5866014186747758

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12155] Loss: 0.5868502555184988

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12180] Loss: 0.5865670798892348

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12205] Loss: 0.586643835381992

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.7972000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[43 57]
 [ 7 93]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12230] Loss: 0.5864935583378708

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12255] Loss: 0.5861940777488739

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12280] Loss: 0.5859421840582358

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12305] Loss: 0.585773018899368

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12330] Loss: 0.5857234372905085

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12355] Loss: 0.585941459900648

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12380] Loss: 0.5859032091153815

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12405] Loss: 0.5857340396148103

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12430] Loss: 0.5858859133161859

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12455] Loss: 0.5857143762988697

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12480] Loss: 0.5856749078435783

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12505] Loss: 0.5854711639953897

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12530] Loss: 0.5853359466521443

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12555] Loss: 0.585104214309503

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12580] Loss: 0.5848296779838341

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12605] Loss: 0.584713537783955

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12630] Loss: 0.5849754024045455

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12655] Loss: 0.5851502118545044

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12680] Loss: 0.5850273056891713

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12705] Loss: 0.5849420649718159

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12730] Loss: 0.5847165241371044

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12755] Loss: 0.5845478130976727

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12780] Loss: 0.5843364766002147

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12805] Loss: 0.5842637510515335

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12830] Loss: 0.5841699305864999

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12855] Loss: 0.5840136541892901

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12880] Loss: 0.5839417892703267

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12905] Loss: 0.583916207718207

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12930] Loss: 0.5842423155766975

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12955] Loss: 0.584457770216929

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 12980] Loss: 0.5842638252840225

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13005] Loss: 0.5840883872045537

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13030] Loss: 0.5839034797489208

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13055] Loss: 0.5835469356121699

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13080] Loss: 0.5832608407397548

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13105] Loss: 0.5832206791352404

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13130] Loss: 0.5828584167968571

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13155] Loss: 0.5832117184293797

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13180] Loss: 0.5831497684192407

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13205] Loss: 0.5830735753327351

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7835000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[59 41]
 [18 82]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13230] Loss: 0.5830099729808585

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13255] Loss: 0.583076709701245

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13280] Loss: 0.5829579652047929

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13305] Loss: 0.5831464915469647

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13330] Loss: 0.5833411742900448

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13355] Loss: 0.5831113310822932

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13380] Loss: 0.5832100039539337

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13405] Loss: 0.5830147525196006

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13430] Loss: 0.5831050053680222

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13455] Loss: 0.5830608233965092

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13480] Loss: 0.5831045299948832

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13505] Loss: 0.5832314261685836

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13530] Loss: 0.5831366040785495

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13555] Loss: 0.5830070687891623

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13580] Loss: 0.5828979614491374

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13605] Loss: 0.5826639037939705

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13630] Loss: 0.5823653504273952

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13655] Loss: 0.5824263628805483

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13680] Loss: 0.5823700386591311

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13705] Loss: 0.582276297966241

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13730] Loss: 0.582223421795274

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13755] Loss: 0.5820187004851491

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13780] Loss: 0.5820033455723878

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13805] Loss: 0.5820182410046573

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13830] Loss: 0.5820771464797622

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13855] Loss: 0.5821811074632252

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13880] Loss: 0.5822651059813121

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13905] Loss: 0.5823998354240372

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13930] Loss: 0.5825270675748597

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13955] Loss: 0.5824728964077175

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 13980] Loss: 0.5823395541908963

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14005] Loss: 0.5824240247350675

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14030] Loss: 0.5824622158458843

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14055] Loss: 0.582486491140477

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14080] Loss: 0.5824160424380135

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14105] Loss: 0.5823219906087659

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14130] Loss: 0.5821985563492262

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14155] Loss: 0.5819823837805324

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14180] Loss: 0.5818384226045149

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14205] Loss: 0.581875548668441

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7945
Using max F1-Score threshold, the confusion matrix is:
 [[37 63]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14230] Loss: 0.5818839620076444

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14255] Loss: 0.58197685955141

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14280] Loss: 0.5817598740790199

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14305] Loss: 0.5816551395494522

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14330] Loss: 0.5816856198766734

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14355] Loss: 0.5814947317833493

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14380] Loss: 0.5817718262972038

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14405] Loss: 0.5818000618283201

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14430] Loss: 0.5817813403991583

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14455] Loss: 0.581863276470392

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14480] Loss: 0.581960455542409

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14505] Loss: 0.5819822364554819

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14530] Loss: 0.581802370367019

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14555] Loss: 0.581750579163554

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14580] Loss: 0.5816806774798952

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14605] Loss: 0.581751117260033

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14630] Loss: 0.5817372995206441

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14655] Loss: 0.5817305985603306

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14680] Loss: 0.5816948953678556

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14705] Loss: 0.5815312647398625

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14730] Loss: 0.5814284594233174

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14755] Loss: 0.5813440331396268

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14780] Loss: 0.5811644747907192

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14805] Loss: 0.5810425463910448

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14830] Loss: 0.5809115751844289

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14855] Loss: 0.5810439209613878

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14880] Loss: 0.5811126229663885

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14905] Loss: 0.5811021501788984

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14930] Loss: 0.5810892173278923

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14955] Loss: 0.5810783134240042

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 14980] Loss: 0.5811175869334007

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15005] Loss: 0.5810992298951145

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15030] Loss: 0.5810623298662442

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15055] Loss: 0.5812241534077999

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15080] Loss: 0.5812216575216107

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15105] Loss: 0.5812865016262514

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15130] Loss: 0.5813356071215456

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15155] Loss: 0.5814007300555328

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15180] Loss: 0.5813218334218333

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15205] Loss: 0.581366992068228

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7978
Using max F1-Score threshold, the confusion matrix is:
 [[39 61]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15230] Loss: 0.5812909981319084

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15255] Loss: 0.581108237485629

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15280] Loss: 0.5811674216580992

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15305] Loss: 0.5813982285787797

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15330] Loss: 0.5813339050892135

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15355] Loss: 0.5813347962883573

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15380] Loss: 0.5813534877508422

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15405] Loss: 0.5813374321197468

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15430] Loss: 0.5811239437457992

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15455] Loss: 0.5811958906839082

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15480] Loss: 0.5812349868584766

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15505] Loss: 0.5811557506254724

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15530] Loss: 0.5811538950973568

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15555] Loss: 0.5811688185553476

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15580] Loss: 0.5810058682716371

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15605] Loss: 0.5808845765668526

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15630] Loss: 0.5808824213244144

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15655] Loss: 0.5807690196122571

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15680] Loss: 0.580682304040931

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15705] Loss: 0.5806250930062582

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15730] Loss: 0.5805823223721266

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15755] Loss: 0.5805178428628609

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15780] Loss: 0.5804507448963611

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15805] Loss: 0.5803896011959283

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15830] Loss: 0.5800720115954872

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15855] Loss: 0.5800549640488004

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15880] Loss: 0.5800190751987522

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15905] Loss: 0.5801434908368106

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15930] Loss: 0.5801350394165887

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15955] Loss: 0.5801168633965581

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 15980] Loss: 0.5801243672321003

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16005] Loss: 0.5801467590058842

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16030] Loss: 0.5800004868702008

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16055] Loss: 0.5799300609799695

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16080] Loss: 0.5797502276855184

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16105] Loss: 0.5797758026857996

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16130] Loss: 0.5799698819927032

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16155] Loss: 0.5798148817135953

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16180] Loss: 0.5799207615838815

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16205] Loss: 0.5799623842617012

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7816
Using max F1-Score threshold, the confusion matrix is:
 [[36 64]
 [ 4 96]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16230] Loss: 0.5798772560278771

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16255] Loss: 0.5797660789628736

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16280] Loss: 0.5798041206983303

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16305] Loss: 0.5795432810633518

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16330] Loss: 0.579313963650866

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16355] Loss: 0.5792858582707368

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16380] Loss: 0.5792420170278841

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16405] Loss: 0.5790933859841155

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16430] Loss: 0.5791597609555761

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16455] Loss: 0.5790068673890215

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16480] Loss: 0.57883316877672

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16505] Loss: 0.5786696621286841

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16530] Loss: 0.578615626959934

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16555] Loss: 0.5785929726631552

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16580] Loss: 0.5784979751362099

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16605] Loss: 0.5785446507835167

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16630] Loss: 0.5784952663653178

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16655] Loss: 0.578413266799434

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16680] Loss: 0.5782784385376067

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16705] Loss: 0.5780729473011735

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16730] Loss: 0.5780777309677698

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16755] Loss: 0.5779696025715199

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16780] Loss: 0.5778618881907764

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16805] Loss: 0.5776917978931895

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16830] Loss: 0.5774966280695479

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16855] Loss: 0.5774997229880542

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16880] Loss: 0.5773596371120183

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16905] Loss: 0.5773021271744355

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16930] Loss: 0.5773591875481522

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16955] Loss: 0.5773220984135778

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 16980] Loss: 0.5773334268976706

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17005] Loss: 0.5772421396491044

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17030] Loss: 0.5773539256033636

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17055] Loss: 0.5772044160413659

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17080] Loss: 0.5771833649914362

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17105] Loss: 0.5769284683274756

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17130] Loss: 0.5772588189007944

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17155] Loss: 0.577441218216103

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17180] Loss: 0.5775837752645692

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17205] Loss: 0.5776629782555048

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.6262
Using max F1-Score threshold, the confusion matrix is:
 [[100   0]
 [100   0]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17230] Loss: 0.5778103076604811

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17255] Loss: 0.5777389968770594

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17280] Loss: 0.5778777874308386

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17305] Loss: 0.5782774680261225

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17330] Loss: 0.5783367573694783

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17355] Loss: 0.5784142166149907

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17380] Loss: 0.5784400679430304

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17405] Loss: 0.5784477886263693

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17430] Loss: 0.5783954064945158

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17455] Loss: 0.578366663891967

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17480] Loss: 0.5782419822838926

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17505] Loss: 0.5783896248104229

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17530] Loss: 0.5783650956568606

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17555] Loss: 0.5784139402288854

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17580] Loss: 0.5784716350118495

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17605] Loss: 0.5784346116230817

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17630] Loss: 0.5784035086492674

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17655] Loss: 0.5785320894258029

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17680] Loss: 0.5783902772500799

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17705] Loss: 0.5784749685477906

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17730] Loss: 0.5787150037984681

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17755] Loss: 0.5786619972221783

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17780] Loss: 0.5786354202723574

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17805] Loss: 0.5786563208953867

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17830] Loss: 0.5785969457237803

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17855] Loss: 0.5784705175870783

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17880] Loss: 0.5783658475358667

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17905] Loss: 0.5783972595033885

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17930] Loss: 0.5784234721187521

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17955] Loss: 0.5782394043921016

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 17980] Loss: 0.5781742300853345

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18005] Loss: 0.578192186149251

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18030] Loss: 0.5782143665402544

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18055] Loss: 0.5782388206786383

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18080] Loss: 0.5781279756622114

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18105] Loss: 0.5784524425852037

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18130] Loss: 0.5784856275455685

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18155] Loss: 0.5784601656437802

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18180] Loss: 0.5784262602008099

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18205] Loss: 0.5784874994811338

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

cnn2_train_only.py:339: RuntimeWarning: invalid value encountered in true_divide
  f1scores = 2 * (precision * recall) / (precision + recall)
Area Under the ROC Curve: 0.7219
Using max F1-Score threshold, the confusion matrix is:
 [[32 68]
 [ 8 92]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18230] Loss: 0.5784122942037146

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18255] Loss: 0.5785330358464936

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18280] Loss: 0.5784941357538441

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18305] Loss: 0.578510829760424

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18330] Loss: 0.578434937017813

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18355] Loss: 0.5783608451690454

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18380] Loss: 0.5783106757048794

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18405] Loss: 0.5780538979559745

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18430] Loss: 0.578356869123866

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18455] Loss: 0.5782992328702762

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18480] Loss: 0.5782700290266698

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18505] Loss: 0.5782830867810993

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18530] Loss: 0.5783206107548737

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18555] Loss: 0.578365822029503

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18580] Loss: 0.5783000898278584

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18605] Loss: 0.5782527572128818

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18630] Loss: 0.5785454350175411

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18655] Loss: 0.5786261603958114

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18680] Loss: 0.578680641573844

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18705] Loss: 0.5786879423645206

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18730] Loss: 0.5787477984133592

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18755] Loss: 0.578738267802845

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18780] Loss: 0.5787236822551497

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18805] Loss: 0.5787066425146392

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18830] Loss: 0.5788307045814393

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18855] Loss: 0.5789569675301326

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18880] Loss: 0.5788075412538919

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18905] Loss: 0.5788632884151415

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18930] Loss: 0.5787082586785359

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18955] Loss: 0.5786731121120335

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 18980] Loss: 0.578617046583172

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19005] Loss: 0.5784253101277285

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19030] Loss: 0.5785640566508509

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19055] Loss: 0.5786350750254987

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19080] Loss: 0.5785631575432044

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19105] Loss: 0.5785235877460534

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19130] Loss: 0.5786676118151454

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19155] Loss: 0.5786444360318771

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19180] Loss: 0.5785726399330333

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19205] Loss: 0.5784919299612563

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8161999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[60 40]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19230] Loss: 0.5785087059964924

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19255] Loss: 0.5785307747701712

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19280] Loss: 0.5784450163107046

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19305] Loss: 0.5781951974481597

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19330] Loss: 0.5780429565635404

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19355] Loss: 0.5780283928770663

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19380] Loss: 0.5780079233758134

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19405] Loss: 0.5780687562640091

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19430] Loss: 0.5780276122828345

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19455] Loss: 0.5780362011938743

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19480] Loss: 0.5781712489675719

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19505] Loss: 0.578147682729129

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19530] Loss: 0.5782017624856046

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19555] Loss: 0.5781659455148158

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19580] Loss: 0.5782024809974031

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19605] Loss: 0.5780835931146702

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19630] Loss: 0.5781875331214317

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19655] Loss: 0.578115751999175

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19680] Loss: 0.5779699652604324

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19705] Loss: 0.5780032419222136

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19730] Loss: 0.5779098377514277

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19755] Loss: 0.5779904168748453

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19780] Loss: 0.5780101097504701

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19805] Loss: 0.5779759776826935

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19830] Loss: 0.5779974513769515

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19855] Loss: 0.5779344817248561

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19880] Loss: 0.5779444047311605

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19905] Loss: 0.5779517130108313

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19930] Loss: 0.5778248593670162

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19955] Loss: 0.5777788162852642

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 19980] Loss: 0.5777712999738277

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20005] Loss: 0.5777333651015708

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20030] Loss: 0.5776850930885823

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20055] Loss: 0.5775816281102871

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20080] Loss: 0.5775777135185212

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20105] Loss: 0.5776305574998464

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20130] Loss: 0.5776810263744172

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20155] Loss: 0.5776875193718648

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20180] Loss: 0.5776904164206255

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20205] Loss: 0.5777824555840481

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8083999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[62 38]
 [16 84]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20230] Loss: 0.5777347640581921

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20255] Loss: 0.5776957961003751

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20280] Loss: 0.5777216669024487

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20305] Loss: 0.5777195621915538

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20330] Loss: 0.5775666362081394

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20355] Loss: 0.5774680006819962

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20380] Loss: 0.5776043619950708

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20405] Loss: 0.577708738672066

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20430] Loss: 0.5780193907834493

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20455] Loss: 0.5781716160714205

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20480] Loss: 0.578290594340147

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20505] Loss: 0.5783935950312886

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20530] Loss: 0.5785461872284308

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20555] Loss: 0.5786639763101505

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20580] Loss: 0.5787768579077204

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20605] Loss: 0.5789224345302408

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20630] Loss: 0.578959192389627

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20655] Loss: 0.5789305357077046

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20680] Loss: 0.5788955124311631

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20705] Loss: 0.5789204666728387

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20730] Loss: 0.5789440703360821

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20755] Loss: 0.5790288908670459

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20780] Loss: 0.5788858686385293

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20805] Loss: 0.5788196959480676

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20830] Loss: 0.5788002003487898

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20855] Loss: 0.578685989865355

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20880] Loss: 0.5785962748082949

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20905] Loss: 0.5784957951832076

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20930] Loss: 0.5786044234156283

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20955] Loss: 0.5785386719754884

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 20980] Loss: 0.5785108272102909

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21005] Loss: 0.5784099352437603

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21030] Loss: 0.5784373581168041

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21055] Loss: 0.5783715678388722

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21080] Loss: 0.578322637899226

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21105] Loss: 0.5784039171297779

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21130] Loss: 0.5785777487607149

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21155] Loss: 0.5787115223966427

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21180] Loss: 0.5788410796982536

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21205] Loss: 0.5788460985276236

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7925000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[37 63]
 [ 5 95]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21230] Loss: 0.5788308052083935

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21255] Loss: 0.5789377641160215

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21280] Loss: 0.5788548951240131

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21305] Loss: 0.5787638827579527

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21330] Loss: 0.5786928063916678

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21355] Loss: 0.5785994133222203

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21380] Loss: 0.5785401057483823

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21405] Loss: 0.5786116575321383

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21430] Loss: 0.5786110860704725

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21455] Loss: 0.5785322100288663

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21480] Loss: 0.5784580372718421

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21505] Loss: 0.5783885385086268

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21530] Loss: 0.5784383458186075

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21555] Loss: 0.5785233267943383

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21580] Loss: 0.5785739411989075

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21605] Loss: 0.5785018206291712

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21630] Loss: 0.5784095971890444

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21655] Loss: 0.5784218762569621

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21680] Loss: 0.5784424344273955

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21705] Loss: 0.5783696820469741

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21730] Loss: 0.578299254884528

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21755] Loss: 0.5782877348203725

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21780] Loss: 0.5783312717364346

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21805] Loss: 0.5782787371178798

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21830] Loss: 0.5782638844176649

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21855] Loss: 0.5781932689344681

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21880] Loss: 0.5781537613392779

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21905] Loss: 0.5781705186435078

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21930] Loss: 0.5782135405722096

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21955] Loss: 0.5782232504766366

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 21980] Loss: 0.5782072634769989

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22005] Loss: 0.5781583187574961

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22030] Loss: 0.5782254314825914

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22055] Loss: 0.5780746762440773

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22080] Loss: 0.5781870521886154

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22105] Loss: 0.578226661125123

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22130] Loss: 0.5781972057448834

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22155] Loss: 0.5781516973423119

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22180] Loss: 0.5780754415348208

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22205] Loss: 0.5779797116262002

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8157
Using max F1-Score threshold, the confusion matrix is:
 [[68 32]
 [19 81]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22230] Loss: 0.5780359701770896

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22255] Loss: 0.5780052304146005

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22280] Loss: 0.5779913911088621

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22305] Loss: 0.5779231819553308

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22330] Loss: 0.5778766375701031

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22355] Loss: 0.5779502552096397

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22380] Loss: 0.5779037805906335

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22405] Loss: 0.5780596006203391

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22430] Loss: 0.5779784951610628

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22455] Loss: 0.5779982433572921

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22480] Loss: 0.5779982300570411

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22505] Loss: 0.5780863786300388

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22530] Loss: 0.578093791401235

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22555] Loss: 0.5780399306114168

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22580] Loss: 0.5779967845900589

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22605] Loss: 0.5779404565286569

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22630] Loss: 0.5779257534746791

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22655] Loss: 0.5778382036305425

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22680] Loss: 0.5777914810508729

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22705] Loss: 0.5776660509346101

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22730] Loss: 0.5776478613673346

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22755] Loss: 0.5776803451299981

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22780] Loss: 0.5779416212872899

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22805] Loss: 0.5779138151855528

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22830] Loss: 0.577896547925226

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22855] Loss: 0.5778729601829348

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22880] Loss: 0.5778799283572809

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22905] Loss: 0.5778636996329772

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22930] Loss: 0.577938001761958

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22955] Loss: 0.5779266643982529

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 22980] Loss: 0.5778924032074282

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23005] Loss: 0.5778620101867513

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23030] Loss: 0.577774419910325

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23055] Loss: 0.5776029838308314

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23080] Loss: 0.5774801734131465

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23105] Loss: 0.5772954964133636

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23130] Loss: 0.577375955426266

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23155] Loss: 0.5773403622692956

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23180] Loss: 0.5772493001427729

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23205] Loss: 0.5773643763468658

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8026
Using max F1-Score threshold, the confusion matrix is:
 [[42 58]
 [ 7 93]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23230] Loss: 0.5772909892900672

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23255] Loss: 0.577366954421507

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23280] Loss: 0.5774060842022724

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23305] Loss: 0.5774510461420582

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23330] Loss: 0.5774537751754963

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23355] Loss: 0.5775828238349974

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23380] Loss: 0.5776081177262462

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23405] Loss: 0.5776473464107175

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23430] Loss: 0.5777875960470271

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23455] Loss: 0.5778769455032527

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23480] Loss: 0.5779008018731872

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23505] Loss: 0.5778436320876928

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23530] Loss: 0.5778061367770841

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23555] Loss: 0.5777456792616968

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23580] Loss: 0.5776076631275114

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23605] Loss: 0.5776227809479025

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23630] Loss: 0.5776662664578543

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23655] Loss: 0.5777071660594584

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23680] Loss: 0.5776230703918258

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23705] Loss: 0.5776228998633456

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23730] Loss: 0.5775763691622499

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23755] Loss: 0.5775016297451302

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23780] Loss: 0.5776189593541269

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23805] Loss: 0.5776411419847578

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23830] Loss: 0.5776165865241453

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23855] Loss: 0.5775620412886897

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23880] Loss: 0.5774428021679366

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23905] Loss: 0.5773015820155327

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23930] Loss: 0.5771972773899969

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23955] Loss: 0.5773065303607355

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 23980] Loss: 0.5772368359801336

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24005] Loss: 0.5775209466033622

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24030] Loss: 0.5776631284295533

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24055] Loss: 0.5777830456356973

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24080] Loss: 0.577888182921597

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24105] Loss: 0.577882660395945

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24130] Loss: 0.577823249851189

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24155] Loss: 0.5777653362344886

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24180] Loss: 0.5776906390348941

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24205] Loss: 0.5776401508521123

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7707
Using max F1-Score threshold, the confusion matrix is:
 [[64 36]
 [25 75]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24230] Loss: 0.5776295135438532

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24255] Loss: 0.5776280316154525

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24280] Loss: 0.5776440067905922

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24305] Loss: 0.5776699563572391

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24330] Loss: 0.5776644134448683

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24355] Loss: 0.5776339569843172

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24380] Loss: 0.5776870567679155

CUDA Memory Allocated: 9090220032
[Epoch 0, Batch 24405] Loss: 0.5778033096746162

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 22] Loss: 0.577831364450558

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 47] Loss: 0.577867763414547

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 72] Loss: 0.5778552011813661

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 97] Loss: 0.5778090150782206

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 122] Loss: 0.5778053601894871

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 147] Loss: 0.5777870015939603

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 172] Loss: 0.5777952130456063

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 197] Loss: 0.5777930116926906

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 222] Loss: 0.5778248480880034

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 247] Loss: 0.5777519092816316

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 272] Loss: 0.577699977186384

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 297] Loss: 0.5776656723676162

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 322] Loss: 0.5776918918993461

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 347] Loss: 0.5777753137384429

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 372] Loss: 0.5776730283973033

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 397] Loss: 0.5777735766533542

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 422] Loss: 0.5777426028244996

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 447] Loss: 0.5778175303601062

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 472] Loss: 0.5778267789754638

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 497] Loss: 0.5777317410181755

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 522] Loss: 0.577782626675979

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 547] Loss: 0.5777550393961195

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 572] Loss: 0.5777796816333022

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 597] Loss: 0.5777483962229218

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 622] Loss: 0.577713750318296

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 647] Loss: 0.5777333151917701

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 672] Loss: 0.5776273293070877

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 697] Loss: 0.5776122634736964

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 722] Loss: 0.5775493384374419

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 747] Loss: 0.5774673001791123

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 772] Loss: 0.5774066329395079

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 797] Loss: 0.5773745009697567

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.7624000000000001
Using max F1-Score threshold, the confusion matrix is:
 [[70 30]
 [27 73]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 822] Loss: 0.5772402067055161

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 847] Loss: 0.577181419710373

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 872] Loss: 0.5770491220482878

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 897] Loss: 0.5769552717489366

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 922] Loss: 0.5768479378848062

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 947] Loss: 0.5767947952814787

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 972] Loss: 0.5767204705084081

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 997] Loss: 0.5767607129721695

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1022] Loss: 0.576676337886305

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1047] Loss: 0.5766147556974872

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1072] Loss: 0.5765483422895622

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1097] Loss: 0.5766918405484058

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1122] Loss: 0.5767362339775535

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1147] Loss: 0.5766744458718714

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1172] Loss: 0.5766139260417043

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1197] Loss: 0.5765756436859518

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1222] Loss: 0.5764900726836066

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1247] Loss: 0.5764513404404569

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1272] Loss: 0.5763850421223439

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1297] Loss: 0.5763171764642214

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1322] Loss: 0.5761899032013182

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1347] Loss: 0.5761050067599676

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1372] Loss: 0.5760582457343953

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1397] Loss: 0.5760207838945864

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1422] Loss: 0.5760291261537132

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1447] Loss: 0.576037105468048

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1472] Loss: 0.5760322663576496

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1497] Loss: 0.5759733662279272

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1522] Loss: 0.575835136258316

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1547] Loss: 0.5758137672847522

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1572] Loss: 0.5757562345030753

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1597] Loss: 0.5757950190400722

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1622] Loss: 0.5758236960392149

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1647] Loss: 0.575805107703959

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1672] Loss: 0.5758332789304977

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1697] Loss: 0.575869828418959

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1722] Loss: 0.575693444188578

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1747] Loss: 0.5757002690452747

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1772] Loss: 0.5755962550635134

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1797] Loss: 0.5754721895152691

*********** Saving network weights and optimizer state *********** 


******************************************************************
*********************** Performance Update ***********************
******************************************************************

Area Under the ROC Curve: 0.8223999999999999
Using max F1-Score threshold, the confusion matrix is:
 [[57 43]
 [13 87]]

******************************************************************
****************** Performance Update Complete! ******************
******************************************************************


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1822] Loss: 0.5754846482650332

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1847] Loss: 0.5754349799824031

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1872] Loss: 0.5753642186116471

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1897] Loss: 0.5753740758986093

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1922] Loss: 0.5754080795379783

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1947] Loss: 0.5754758223812899

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1972] Loss: 0.5754383995211889

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 1997] Loss: 0.5754058657789826

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2022] Loss: 0.5752602581567998

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2047] Loss: 0.5754309009565067

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2072] Loss: 0.5753966629435182

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2097] Loss: 0.5753598982707928

*********** Saving network weights and optimizer state *********** 


CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2122] Loss: 0.5752790492126927

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2147] Loss: 0.5752111218769024

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2172] Loss: 0.5751053950378582

CUDA Memory Allocated: 9090220032
[Epoch 1, Batch 2197] Loss: 0.5749864889173927

*********** Saving network weights and optimizer state *********** 


*********** Finished Training this Epoch in 25829.27452135086 seconds ***********
Job 5665060 ended on:    g6
Job 5665060 ended on:    Wed Jan 4 16:43:51 PST 2023
 
