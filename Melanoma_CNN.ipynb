{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030ccd3",
   "metadata": {},
   "source": [
    "# Melanoma Detection with Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce87f3",
   "metadata": {},
   "source": [
    "This code was used in the Hoffman2 Linux Compute Cluster, making use of UCLA's high performance cloud computing resources like the Tesla P4 - GPU (6.1 Compute Capability, 2560 CUDA Cores, 8GB) with additional 32GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460317",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1e190",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a1310",
   "metadata": {},
   "source": [
    "General histograms and bar charts for frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262eb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_df = pd.read_csv(os.path.join('train_data', 'train.csv'))\n",
    "gt = mel_df['target']\n",
    "isic_id = mel_df['image_name']\n",
    "\n",
    "# proportion of postives\n",
    "print(\"Proportion of positives:\", np.mean(gt))\n",
    "\n",
    "plt.hist(mel_df['age_approx'])\n",
    "plt.title('Histogram of Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = mel_df['benign_malignant'],\n",
    "            y = mel_df['age_approx'])\n",
    "plt.title('Ages Grouped By Benign / Malignant Status')\n",
    "plt.xlabel('Benign / Malignant Status')\n",
    "plt.ylabel('Approximate Age')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(mel_df.sex.value_counts().index,  mel_df.sex.value_counts().values)\n",
    "plt.title('Sex / Gender in Dataset')\n",
    "plt.show()\n",
    "\n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, mel_df.anatom_site_general_challenge.value_counts().values)\n",
    "plt.title('Lesion Locations in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb11e5",
   "metadata": {},
   "source": [
    "Tests to find potential correlation between target variables and other categorical variables such as sex/gender or lesion location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['benign_malignant'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df1 = mel_df.groupby(['sex']).mean()\n",
    "plt.bar(mel_df.sex.value_counts().index,  g_df1['target'].values)\n",
    "plt.title(\"Proportion of positives by Sex / Gender\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\\n******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['anatom_site_general_challenge'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df2 = mel_df.groupby(['anatom_site_general_challenge']).mean() \n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, g_df2['target'].values)\n",
    "plt.title(\"Proportion of positives by Lesion Location\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713af71",
   "metadata": {},
   "source": [
    "## CNN Mark \\#1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efcaad",
   "metadata": {},
   "source": [
    "Set device as CPU, or GPU if available. Code will have to change if using multiple GPUs (cuda:0, cuda:1, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# If on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cea86",
   "metadata": {},
   "source": [
    "We create a custom dataset loader class to use the ID and target information from the CSV to properly load our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset to load in with the benign \n",
    "# and malignant images in the same directory\n",
    "class ISICDatasetImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, patientfile, num_samples=100, start_ind=0, up_sample=False, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        mel_df = pd.read_csv(patientfile) \n",
    "        \n",
    "        if up_sample:\n",
    "            \n",
    "            # Separate majority and minority classes\n",
    "            df_benign = mel_df[mel_df['target']==0]\n",
    "            df_malignant = mel_df[mel_df['target']==1]\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            # sample minority class\n",
    "            df_benign_sampled = resample(df_benign, \n",
    "                                         replace=False,     # sample without replacement\n",
    "                                         n_samples=num_samples//2,    # to have 50/50\n",
    "                                         random_state=123) # reproducible results\n",
    "            \n",
    "\n",
    "            # Upsample minority class\n",
    "            df_malignant_upsampled = resample(df_malignant, \n",
    "                                              replace=True,     # sample with replacement\n",
    "                                              n_samples=num_samples//2,    # to have 50/50\n",
    "                                              random_state=123) # reproducible results\n",
    "            \n",
    "            # Combine majority class with upsampled minority class\n",
    "            mel_df = pd.concat([df_benign_sampled, df_malignant_upsampled])\n",
    "            \n",
    "            # randomly mix them up (not necessary due to shuffling in dataloader)\n",
    "            mel_df = shuffle(mel_df, random_state=123) \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.start_ind = start_ind\n",
    "            self.end_ind = start_ind+num_samples\n",
    "\n",
    "            if self.end_ind > len(mel_df):\n",
    "                self.end_ind = len(mel_df)\n",
    "        \n",
    "            mel_df = mel_df[self.start_ind:self.end_ind]\n",
    "            \n",
    "        self.gt = mel_df['target'].reset_index(drop=True)\n",
    "        self.isic_id = mel_df['image_name'].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{self.isic_id[idx]}.jpg\")\n",
    "        img = read_image(img_path).float()\n",
    "        class_id = torch.tensor([self.gt[idx]])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        \n",
    "        return img, class_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c73fa",
   "metadata": {},
   "source": [
    "We create a custom collate function to pad lower resolution images with zeros to maintain a constant high resolution of 3x4000x6000 for the CNN to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for padding images one at a time\n",
    "def pad2d_4k6k(_image):\n",
    "\n",
    "    rows = _image.shape[1]\n",
    "    cols = _image.shape[2]\n",
    "\n",
    "    top = np.ceil((4000 - rows)/2).astype('int')\n",
    "    bottom = np.floor((4000 - rows)/2).astype('int')\n",
    "    right = np.ceil((6000 - cols)/2).astype('int')\n",
    "    left = np.floor((6000 - cols)/2).astype('int')\n",
    "\n",
    "    pad_func = nn.ConstantPad2d((left, right, top, bottom), 0)\n",
    "    \n",
    "    return pad_func(_image)\n",
    "\n",
    "\n",
    "# recall that a CNN needs the inputs to be the same dimension so we \n",
    "# custom collate function to pad small res images with 0s if they are not 3x4000x6000\n",
    "def pad_collate2d(batch):\n",
    "    \n",
    "    # init lists\n",
    "    image_list, label_list = [], []\n",
    "   \n",
    "    for _image, _label in batch:\n",
    "    \n",
    "        pad_image = pad2d_4k6k(_image)\n",
    "        \n",
    "        image_list.append(torch.unsqueeze(pad_image, dim=0))\n",
    "        label_list.append(_label)\n",
    "        \n",
    "\n",
    "    image_out = torch.cat(image_list, dim=0) \n",
    "    label_out = torch.tensor(label_list, dtype=torch.int64)\n",
    "   \n",
    "    return image_out, label_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "# set our batch size\n",
    "batch_size = 2\n",
    "\n",
    "transf = transforms.Compose(\n",
    "    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"train.csv\"), \n",
    "                            num_samples=24408, up_sample=True, start_ind=0, transform=transf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate2d)\n",
    "\n",
    "\n",
    "val_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"val.csv\"), \n",
    "                            num_samples=100, up_sample=True, start_ind=0, transform=transf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=pad_collate2d)\n",
    "\n",
    "\n",
    "\n",
    "# test DataLoader with custom settings\n",
    "if testing:\n",
    "    for imgs, labels in train_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e4f1",
   "metadata": {},
   "source": [
    "Sample and image from the data loader object to confirm it worked. Continue to run the cell for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ead6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show the image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg.astype('int'), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "label_id = [\"Benign\", \"Malignant\"]\n",
    "\n",
    "if testing:\n",
    "    # get some random training images\n",
    "    trainiter = iter(train_loader)\n",
    "    images, labels = next(trainiter)\n",
    "    print(\"Size:\", images.shape)\n",
    "\n",
    "\n",
    "    # show images\n",
    "    imshow(images[0,])\n",
    "\n",
    "    # print labels\n",
    "    print(\"Label:\", label_id[labels[0,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could add batch normalization, change the subsampling method, change the optimizer to adam\n",
    "# and add more linear layers....\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "        stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 15, 5)\n",
    "        self.conv3 = nn.Conv2d(15, 25, 5)\n",
    "        self.conv4 = nn.Conv2d(25, 40, 5)\n",
    "        self.conv5 = nn.Conv2d(40, 50, 5)\n",
    "        self.conv6 = nn.Conv2d(50, 60, 5)\n",
    "        self.conv7 = nn.Conv2d(60, 75, 5)\n",
    "        self.conv8 = nn.Conv2d(75, 85, 5)\n",
    "        self.conv9 = nn.Conv2d(85, 100, 5)\n",
    "        self.fc1 = nn.Linear(100*7*3, 100) \n",
    "        self.fc2 = nn.Linear(100, 85)\n",
    "        self.fc3 = nn.Linear(85, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = self.pool(F.relu(self.conv7(x)))\n",
    "        x = self.pool(F.relu(self.conv8(x)))\n",
    "        x = self.pool(F.relu(self.conv9(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d401950",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights = True\n",
    "PATH = './melanoma_cnn.pth'\n",
    "\n",
    "if load_weights:\n",
    "    print('Loading the pre-trained CNN weights.')\n",
    "    \n",
    "    # network weights load\n",
    "    net = Net()\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.to(device)\n",
    "    \n",
    "    # optimizer state load\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "    \n",
    "else:\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_weights = True\n",
    "\n",
    "print(\"Pre-Training CUDA Memory Allocation:\", torch.cuda.max_memory_allocated())\n",
    "\n",
    "if learn_weights:\n",
    "\n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #torch.cuda.empty_cache()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "            # print every 25 mini-batch\n",
    "            if i % 25 == 0:\n",
    "                print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "                print(f'[Epoch {epoch}, Batch {i}] Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "            # save every 1000 mini-batch\n",
    "            if i % 1000 == 0:\n",
    "                \n",
    "                print(\"******************************************************************\")\n",
    "                print(\"*********************** Performance Update ***********************\")\n",
    "                print(\"******************************************************************\\n\")\n",
    "                \n",
    "                ground_truths = []\n",
    "                probs = []\n",
    "                \n",
    "                # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "                with torch.no_grad():\n",
    "                    for j, valdata in enumerate(val_loader, 0):\n",
    "                        image, label = valdata\n",
    "\n",
    "                        # save for analysis\n",
    "                        ground_truths.append(label)\n",
    "\n",
    "                        # calculate outputs by running images through the network \n",
    "                        outputs = net(image)\n",
    "\n",
    "                        # # save for analysis\n",
    "                        probs.append(F.softmax(outputs, dim=1)[:, 1])\n",
    "                        print(\"preds\", j)\n",
    "                \n",
    "                print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "\n",
    "                precision, recall, thresholds = metrics.precision_recall_curve(ground_truths, probs)\n",
    "                f1scores = 2 * (precision * recall) / (precision + recall)\n",
    "                opt_thresh = thresholds[np.argmax(f1scores)]\n",
    "                opt_preds = probs > opt_thresh\n",
    "\n",
    "\n",
    "                print(\"Using max F1-Score threshold, the confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, opt_preds))\n",
    "                \n",
    "                print(\"******************************************************************\")\n",
    "                print(\"****************** Performance Update Complete! ******************\")\n",
    "                print(\"******************************************************************\\n\\n\")\n",
    "\n",
    "                print(\"*********** Saving network weights and optimizer state *********** \\n\\n\")\n",
    "                # save the weights and optimizer\n",
    "                #torch.save({'model_state_dict': net.state_dict(), \n",
    "                            #'optimizer_state_dict': optimizer.state_dict()}, PATH)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "    print('*********** Finished Training this Epoch in', time.time() - start_time, 'seconds ***********')\n",
    "    \n",
    "    # save the weights and optimizer\n",
    "    torch.save({'model_state_dict': net.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict()}, PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f63c0",
   "metadata": {},
   "source": [
    "Okay, now let us see what the convolutional neural network thinks of a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b172eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "val_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"val.csv\"), \n",
    "                            num_samples=200, up_sample=True, start_ind=0, transform=transf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate2d)\n",
    "\n",
    "\n",
    "\n",
    "valiter = iter(val_loader)\n",
    "images, labels = next(valiter)\n",
    "\n",
    "# print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072622c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9271d8",
   "metadata": {},
   "source": [
    "Now to formally test accuracy on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = []\n",
    "probs = []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        images, labels = data\n",
    "        \n",
    "        # save for analysis\n",
    "        ground_truths.append(labels)\n",
    "        \n",
    "        # calculate outputs by running images through the network \n",
    "        outputs = net(images)\n",
    "        \n",
    "        # # save for analysis\n",
    "        probs.append(F.softmax(outputs, dim=1)[:, 1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(ground_truths, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "\n",
    "accuracy_scores = []\n",
    "for thresh in thresholds:\n",
    "    accuracy_scores.append(metrics.accuracy_score(ground_truths, [m > thresh for m in probs]))\n",
    "\n",
    "\n",
    "plt.plot(thresholds, accuracy_scores)\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlim([0.47625, 0.4765])\n",
    "plt.show()\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(ground_truths, probs)\n",
    "f1scores = 2 * (precision * recall) / (precision + recall)\n",
    "opt_thresh = thresholds[np.argmax(f1scores)]\n",
    "opt_preds = probs > opt_thresh\n",
    "\n",
    "\n",
    "print(\"Using max F1-Score threshold, the confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, opt_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAS Pytorch CUDA",
   "language": "python",
   "name": "mas_pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
