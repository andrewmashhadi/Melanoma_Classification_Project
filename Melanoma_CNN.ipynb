{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030ccd3",
   "metadata": {},
   "source": [
    "# Melanoma Detection with Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce87f3",
   "metadata": {},
   "source": [
    "This code was used in the Hoffman2 Linux Compute Cluster, making use of UCLA's high performance cloud computing resources like the Tesla P4 - GPU (6.1 Compute Capability, 2560 CUDA Cores, 8GB) with additional 32GB RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf460317",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad9aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewmashhadi/opt/anaconda3/envs/pt/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1e190",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a1310",
   "metadata": {},
   "source": [
    "General histograms and bar charts for frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262eb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_df = pd.read_csv(os.path.join('train_data', 'train.csv'))\n",
    "gt = mel_df['target']\n",
    "isic_id = mel_df['image_name']\n",
    "\n",
    "# proportion of postives\n",
    "print(\"Proportion of positives:\", np.mean(gt))\n",
    "\n",
    "plt.hist(mel_df['age_approx'])\n",
    "plt.title('Histogram of Ages')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = mel_df['benign_malignant'],\n",
    "            y = mel_df['age_approx'])\n",
    "plt.title('Ages Grouped By Benign / Malignant Status')\n",
    "plt.xlabel('Benign / Malignant Status')\n",
    "plt.ylabel('Approximate Age')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(mel_df.sex.value_counts().index,  mel_df.sex.value_counts().values)\n",
    "plt.title('Sex / Gender in Dataset')\n",
    "plt.show()\n",
    "\n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, mel_df.anatom_site_general_challenge.value_counts().values)\n",
    "plt.title('Lesion Locations in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb11e5",
   "metadata": {},
   "source": [
    "Tests to find potential correlation between target variables and other categorical variables such as sex/gender or lesion location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"******************* TARGET W/ SEX INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['benign_malignant'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df1 = mel_df.groupby(['sex']).mean()\n",
    "plt.bar(mel_df.sex.value_counts().index,  g_df1['target'].values)\n",
    "plt.title(\"Proportion of positives by Sex / Gender\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\\n******************* TARGET W/ LESION LOCATION INDEPENDENCE TESTS *******************\")\n",
    "\n",
    "data_crosstab = pd.crosstab(mel_df['sex'],\n",
    "                            mel_df['anatom_site_general_challenge'], \n",
    "                            margins = False)\n",
    "print(data_crosstab)\n",
    "\n",
    "chi2, p, dof, ex = ss.chi2_contingency(data_crosstab)\n",
    "\n",
    "print(\"Chi-Squared test of independence (P-value):\", p, \"\\n\")\n",
    "\n",
    "g_df2 = mel_df.groupby(['anatom_site_general_challenge']).mean() \n",
    "plt.barh(mel_df.anatom_site_general_challenge.value_counts().index, g_df2['target'].values)\n",
    "plt.title(\"Proportion of positives by Lesion Location\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713af71",
   "metadata": {},
   "source": [
    "## CNN Mark \\#1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efcaad",
   "metadata": {},
   "source": [
    "Set device as CPU, or GPU if available. Code will have to change if using multiple GPUs (cuda:0, cuda:1, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    n_workers = os.cpu_count()\n",
    "else:\n",
    "    n_workers = torch.cuda.device_count()\n",
    "\n",
    "# If on a CUDA machine, this should print a CUDA device:\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of devices:\", n_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cea86",
   "metadata": {},
   "source": [
    "We create a custom dataset loader class to use the ID and target information from the CSV to properly load our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset to load in with the benign \n",
    "# and malignant images in the same directory\n",
    "class ISICDatasetImages(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, patientfile, num_samples=100, start_ind=0, up_sample=False, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        mel_df = pd.read_csv(patientfile) \n",
    "        \n",
    "        if up_sample:\n",
    "            \n",
    "            # Separate majority and minority classes\n",
    "            df_benign = mel_df[mel_df['target']==0]\n",
    "            df_malignant = mel_df[mel_df['target']==1]\n",
    "            \n",
    "\n",
    "            # sample minority class\n",
    "            df_benign_sampled = resample(df_benign, \n",
    "                                         replace=True,     # sample with replacement\n",
    "                                         n_samples=num_samples//2)\n",
    "            \n",
    "\n",
    "            # Upsample minority class\n",
    "            df_malignant_upsampled = resample(df_malignant, \n",
    "                                              replace=True,     # sample with replacement\n",
    "                                              n_samples=num_samples//2)\n",
    "            \n",
    "            # Combine majority class with upsampled minority class\n",
    "            mel_df = pd.concat([df_benign_sampled, df_malignant_upsampled])\n",
    "            \n",
    "            # randomly mix them up (not necessary due to shuffling in dataloader)\n",
    "            mel_df = shuffle(mel_df)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.start_ind = start_ind\n",
    "            self.end_ind = start_ind+num_samples\n",
    "\n",
    "            if self.end_ind > len(mel_df):\n",
    "                self.end_ind = len(mel_df)\n",
    "        \n",
    "            mel_df = mel_df[self.start_ind:self.end_ind]\n",
    "            \n",
    "        self.gt = mel_df['target'].reset_index(drop=True)\n",
    "        self.isic_id = mel_df['image_name'].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{self.isic_id[idx]}.jpg\")\n",
    "        img = read_image(img_path).float()\n",
    "        class_id = torch.tensor([self.gt[idx]])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        \n",
    "        return img, class_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c73fa",
   "metadata": {},
   "source": [
    "We create a custom collate function to pad lower resolution images with zeros to maintain a constant high resolution of 3x4000x6000 for the CNN to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for padding images one at a time\n",
    "def pad2d_4k6k(_image):\n",
    "\n",
    "    rows = _image.shape[1]\n",
    "    cols = _image.shape[2]\n",
    "\n",
    "    top = np.ceil((4000 - rows)/2).astype('int')\n",
    "    bottom = np.floor((4000 - rows)/2).astype('int')\n",
    "    right = np.ceil((6000 - cols)/2).astype('int')\n",
    "    left = np.floor((6000 - cols)/2).astype('int')\n",
    "\n",
    "    pad_func = nn.ConstantPad2d((left, right, top, bottom), 0)\n",
    "    \n",
    "    return pad_func(_image)\n",
    "\n",
    "\n",
    "# recall that a CNN needs the inputs to be the same dimension so we \n",
    "# custom collate function to pad small res images with 0s if they are not 3x4000x6000\n",
    "def pad_collate2d(batch):\n",
    "    \n",
    "    # init lists\n",
    "    image_list, label_list = [], []\n",
    "   \n",
    "    for _image, _label in batch:\n",
    "    \n",
    "        pad_image = pad2d_4k6k(_image)\n",
    "        \n",
    "        image_list.append(torch.unsqueeze(pad_image, dim=0))\n",
    "        label_list.append(_label)\n",
    "        \n",
    "\n",
    "    image_out = torch.cat(image_list, dim=0) \n",
    "    label_out = torch.tensor(label_list, dtype=torch.int64)\n",
    "   \n",
    "    return image_out, label_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False\n",
    "\n",
    "# set our batch size\n",
    "batch_size = 2\n",
    "\n",
    "transf = transforms.Compose(\n",
    "    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"train.csv\"), \n",
    "                            num_samples=2*24408, up_sample=True, start_ind=0, transform=transf)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate2d, \n",
    "                          num_workers=n_workers)\n",
    "\n",
    "\n",
    "val_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"val.csv\"), \n",
    "                            num_samples=100, up_sample=True, start_ind=0, transform=transf)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, collate_fn=pad_collate2d, \n",
    "                        num_workers=n_workers)\n",
    "\n",
    "\n",
    "\n",
    "# test DataLoader with custom settings\n",
    "if testing:\n",
    "    for imgs, labels in train_loader:\n",
    "        print(\"Batch of images has shape: \",imgs.shape)\n",
    "        print(\"Batch of labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e4f1",
   "metadata": {},
   "source": [
    "Sample and image from the data loader object to confirm it worked. Continue to run the cell for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ead6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show the image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg.astype('int'), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "label_id = [\"Benign\", \"Malignant\"]\n",
    "\n",
    "if testing:\n",
    "    # get some random training images\n",
    "    trainiter = iter(train_loader)\n",
    "    images, labels = next(trainiter)\n",
    "    print(\"Size:\", images.shape)\n",
    "\n",
    "\n",
    "    # show images\n",
    "    imshow(images[0,])\n",
    "\n",
    "    # print labels\n",
    "    print(\"Label:\", label_id[labels[0,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "        stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 15, 5)\n",
    "        self.conv3 = nn.Conv2d(15, 25, 5)\n",
    "        self.conv4 = nn.Conv2d(25, 40, 5)\n",
    "        self.conv5 = nn.Conv2d(40, 50, 5)\n",
    "        self.conv6 = nn.Conv2d(50, 60, 5)\n",
    "        self.conv7 = nn.Conv2d(60, 75, 5)\n",
    "        self.conv8 = nn.Conv2d(75, 85, 5)\n",
    "        self.conv9 = nn.Conv2d(85, 100, 5)\n",
    "        self.fc1 = nn.Linear(100*7*3, 100) \n",
    "        self.fc2 = nn.Linear(100, 85)\n",
    "        self.fc3 = nn.Linear(85, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = self.pool(F.relu(self.conv7(x)))\n",
    "        x = self.pool(F.relu(self.conv8(x)))\n",
    "        x = self.pool(F.relu(self.conv9(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d401950",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights = True\n",
    "PATH = './melanoma_cnn.pth'\n",
    "\n",
    "if load_weights:\n",
    "    print('Loading the pre-trained CNN weights.')\n",
    "    \n",
    "    # network weights load\n",
    "    net = Net()\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net.to(device)\n",
    "    \n",
    "    # optimizer state load\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=24408, gamma=0.1)\n",
    "    lr_sched.load_state_dict(checkpoint['lr_sched'])\n",
    "    \n",
    "    # total mini_batch state load\n",
    "    mini_batch = checkpoint['mini_batch']\n",
    "    \n",
    "    print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "    \n",
    "else:\n",
    "    mini_batch = 0\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    lr_sched = optim.lr_scheduler.StepLR(optimizer, step_size=24408, gamma=0.1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_weights = True\n",
    "\n",
    "print(\"Pre-Training CUDA Memory Allocation:\", torch.cuda.max_memory_allocated())\n",
    "\n",
    "if learn_weights:\n",
    "\n",
    "    # set start time for cnn training\n",
    "    start_time = time.time()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net.forward(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.unsqueeze(-1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sched.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # update mini-batch count\n",
    "        mini_batch += 1\n",
    "        epoch = mini_batch // 24408\n",
    "\n",
    "        # print every 25 mini-batch\n",
    "        if i % 25 == 0:\n",
    "            print(\"CUDA Memory Allocated:\", torch.cuda.max_memory_allocated())\n",
    "            print(f'[Epoch {epoch}, Batch {mini_batch % 24408}] Loss: {running_loss / (i+1)}\\n')\n",
    "\n",
    "        # save every 100 mini-batch\n",
    "        if i % 100 == 0:\n",
    "            print(\"*********** Saving network weights and optimizer state *********** \\n\\n\")\n",
    "            # save the weights and optimizer\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "\n",
    "        # validate every 1000 mini-batch\n",
    "        if i % 1000 == 0:\n",
    "\n",
    "            print(\"******************************************************************\")\n",
    "            print(\"*********************** Performance Update ***********************\")\n",
    "            print(\"******************************************************************\\n\")\n",
    "            \n",
    "            ground_truths = []\n",
    "            probs = []\n",
    "\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            with torch.no_grad():\n",
    "                for j, valdata in enumerate(val_loader, 0):\n",
    "                    image, label = valdata\n",
    "                    image = image.to(device)\n",
    "\n",
    "                    # save for analysis\n",
    "                    ground_truths.append(label)\n",
    "\n",
    "                    # calculate outputs by running images through the network \n",
    "                    outputs = net(image)\n",
    "                    outputs = outputs.to(\"cpu\")\n",
    "\n",
    "                    # # save for analysis\n",
    "                    probs.append(outputs)\n",
    "\n",
    "            print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "\n",
    "            precision, recall, thresholds = metrics.precision_recall_curve(ground_truths, probs)\n",
    "            f1scores = 2 * (precision * recall) / (precision + recall)\n",
    "            opt_thresh = thresholds[np.argmax(f1scores)]\n",
    "            opt_preds = probs > opt_thresh\n",
    "\n",
    "\n",
    "            print(\"Using max F1-Score threshold, the confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, opt_preds))\n",
    "            \n",
    "            \n",
    "            print(\"\\n******************************************************************\")\n",
    "            print(\"****************** Performance Update Complete! ******************\")\n",
    "            print(\"******************************************************************\\n\\n\")\n",
    "\n",
    "        # save unique set of weights and optimizer for validation later\n",
    "        if mini_batch % 3000 == 0:\n",
    "            uPATH = f'./melanoma_cnn_{epoch}e_{mini_batch % 24408}b.pth'\n",
    "            torch.save({'mini_batch': mini_batch,\n",
    "                        'model_state_dict': net.state_dict(), \n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'lr_sched': lr_sched.state_dict()}, uPATH)\n",
    "\n",
    "    print('*********** Finished Training this Epoch in', time.time() - start_time, 'seconds ***********')\n",
    "    \n",
    "    # save the weights and optimizer\n",
    "    torch.save({'mini_batch': mini_batch,\n",
    "                'model_state_dict': net.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict(), \n",
    "                'lr_sched': lr_sched.state_dict()}, PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f63c0",
   "metadata": {},
   "source": [
    "Okay, now let us see what the convolutional neural network thinks of a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b172eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "test_dataset = ISICDatasetImages(img_dir=os.path.join(\"train_data\", \"jpgs\"), \n",
    "                            patientfile=os.path.join(\"train_data\", \"val.csv\"), \n",
    "                            num_samples=8281, up_sample=False, start_ind=0, transform=transf)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate2d)\n",
    "\n",
    "\n",
    "\n",
    "testiter = iter(test_loader)\n",
    "images, labels = next(testiter)\n",
    "\n",
    "# print images\n",
    "print('GroundTruth: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072622c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % label_id[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9988905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['melanoma_cnn_1e_18456b.pth',\n",
       " 'melanoma_cnn_0e_24103b.pth',\n",
       " 'melanoma_cnn_2e_1224b.pth']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./saved_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9271d8",
   "metadata": {},
   "source": [
    "Now to formally test accuracy on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_fnames = os.listdir('./saved_weights/')\n",
    "batch_sizes = []\n",
    "losses = []\n",
    "\n",
    "for fname in weight_fnames:\n",
    "    \n",
    "    print(f'Loading: {fname}')\n",
    "    \n",
    "    checkpoint = torch.load(f'./saved_weights/{fname}', map_location='cpu')\n",
    "    \n",
    "    # network weights load\n",
    "    net = Net()\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    ground_truths = []\n",
    "    probs = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, testdata in enumerate(test_loader, 0):\n",
    "            image, label = testdata\n",
    "\n",
    "            # save for analysis\n",
    "            ground_truths.append(label)\n",
    "\n",
    "            # calculate outputs by running images through the network \n",
    "            outputs = net(image)\n",
    "            \n",
    "            loss = criterion(outputs, labels.unsqueeze(-1).float())\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "\n",
    "            # # save for analysis\n",
    "            probs.append(outputs)\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print(\"Processing...\")\n",
    "                \n",
    "    print(f'Testing Loss: {running_loss / (i+1)}')\n",
    "    \n",
    "    batch_sizes.append(checkpoint['mini_batch'])\n",
    "    losses.append(running_loss / (i+1))         \n",
    "                \n",
    "    # Save ground-truths and probability results¶\n",
    "    res = {}\n",
    "    res[\"ground_truths\"] = ground_truths\n",
    "    res[\"probs\"] = probs\n",
    "    res[\"num_batches\"] = checkpoint['mini_batch']\n",
    "    res[\"testing_loss\"] = running_loss / (i+1)\n",
    "\n",
    "    with open(f'./saved_results/results_cnn_{checkpoint['mini_batch']}b.pkl', 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "\n",
    "        \n",
    "plt.plot(batch_sizes, losses)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title(\"Testing Loss Over Time\")\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Overall Testing Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f86c7e",
   "metadata": {},
   "source": [
    "## Choose the results from the best performing model (training size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size = 7777\n",
    "\n",
    "with open(f'./saved_results/results_cnn_{best_batch_size}.pkl', 'wb') as f:\n",
    "    res = pickle.load(f)\n",
    "    \n",
    "    \n",
    "ground_truths = res[\"ground_truths\"]\n",
    "probs = res[\"probs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc478afa",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(ground_truths, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Area Under the ROC Curve:\", metrics.roc_auc_score(ground_truths, probs))\n",
    "\n",
    "accuracy_scores = []\n",
    "for thresh in thresholds:\n",
    "    accuracy_scores.append(metrics.accuracy_score(ground_truths, [m > thresh for m in probs]))\n",
    "\n",
    "\n",
    "plt.plot(thresholds, accuracy_scores)\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(ground_truths, probs)\n",
    "f1scores = 2 * (precision * recall) / (precision + recall)\n",
    "gmeans = np.sqrt(precision * recall)\n",
    "f1_opt_thresh = thresholds[np.argmax(f1scores)]\n",
    "f1_opt_preds = probs > f1_opt_thresh\n",
    "gm_opt_thresh = thresholds[np.argmax(gmeans)]\n",
    "gm_opt_preds = probs > gm_opt_thresh\n",
    "\n",
    "\n",
    "print(\"Using max F1-Score threshold, the confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, f1_opt_preds))\n",
    "print(\"Using max G-Mean threshold, the confusion matrix is:\\n\", metrics.confusion_matrix(ground_truths, gm_opt_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
